{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| distributed init (rank 0): env://\n",
      "temp/2022-1129-193642\n",
      "Namespace(data_path='../../../input/pascal', device='cuda', num_classes=20, batch_size=10, batch_size_val=8, aux=False, start_epoch=0, epochs=100, sync_bn=False, workers=4, lr=0.0001, momentum=0.9, weight_decay=0.0001, print_freq=5, checkpoint_dir='./results/temp/2022-1129-193642', resume='', test_only=False, world_size=1, dist_url='env://', amp=True, seed=304, name_date='temp/2022-1129-193642', wandb=False, wandb_model='run', model_name='dcnet_resnet50', project_dim=128, loss_name='double', contrast=1, pre_trained='fcn_resnet50_coco', L3_loss=0.1, L2_loss=0.1, L1_loss=0.1, rank=0, gpu=0, distributed=True, dist_backend='nccl')\n",
      "Creating data loaders\n",
      "Creating model\n",
      "missing_keys:  ['classifier.L3u.0.weight', 'classifier.L3u.1.weight', 'classifier.L3u.1.bias', 'classifier.L3u.1.running_mean', 'classifier.L3u.1.running_var', 'classifier.L2u.0.weight', 'classifier.L2u.1.weight', 'classifier.L2u.1.bias', 'classifier.L2u.1.running_mean', 'classifier.L2u.1.running_var', 'classifier.L1u.1.weight', 'classifier.L1u.2.weight', 'classifier.L1u.2.bias', 'classifier.L1u.2.running_mean', 'classifier.L1u.2.running_var', 'classifier.cls.1.weight', 'classifier.cls.1.bias', 'ProjectorHead_1d.0.weight', 'ProjectorHead_1d.1.weight', 'ProjectorHead_1d.1.bias', 'ProjectorHead_1d.1.running_mean', 'ProjectorHead_1d.1.running_var', 'ProjectorHead_1d.3.weight', 'ProjectorHead_1d.4.weight', 'ProjectorHead_1d.4.bias', 'ProjectorHead_1d.4.running_mean', 'ProjectorHead_1d.4.running_var', 'ProjectorHead_1u.0.weight', 'ProjectorHead_1u.1.weight', 'ProjectorHead_1u.1.bias', 'ProjectorHead_1u.1.running_mean', 'ProjectorHead_1u.1.running_var', 'ProjectorHead_1u.3.weight', 'ProjectorHead_1u.4.weight', 'ProjectorHead_1u.4.bias', 'ProjectorHead_1u.4.running_mean', 'ProjectorHead_1u.4.running_var', 'ProjectorHead_2d.0.weight', 'ProjectorHead_2d.1.weight', 'ProjectorHead_2d.1.bias', 'ProjectorHead_2d.1.running_mean', 'ProjectorHead_2d.1.running_var', 'ProjectorHead_2d.3.weight', 'ProjectorHead_2d.4.weight', 'ProjectorHead_2d.4.bias', 'ProjectorHead_2d.4.running_mean', 'ProjectorHead_2d.4.running_var', 'ProjectorHead_2u.0.weight', 'ProjectorHead_2u.1.weight', 'ProjectorHead_2u.1.bias', 'ProjectorHead_2u.1.running_mean', 'ProjectorHead_2u.1.running_var', 'ProjectorHead_2u.3.weight', 'ProjectorHead_2u.4.weight', 'ProjectorHead_2u.4.bias', 'ProjectorHead_2u.4.running_mean', 'ProjectorHead_2u.4.running_var', 'ProjectorHead_3d.0.weight', 'ProjectorHead_3d.1.weight', 'ProjectorHead_3d.1.bias', 'ProjectorHead_3d.1.running_mean', 'ProjectorHead_3d.1.running_var', 'ProjectorHead_3d.3.weight', 'ProjectorHead_3d.4.weight', 'ProjectorHead_3d.4.bias', 'ProjectorHead_3d.4.running_mean', 'ProjectorHead_3d.4.running_var', 'ProjectorHead_3u.0.weight', 'ProjectorHead_3u.1.weight', 'ProjectorHead_3u.1.bias', 'ProjectorHead_3u.1.running_mean', 'ProjectorHead_3u.1.running_var', 'ProjectorHead_3u.3.weight', 'ProjectorHead_3u.4.weight', 'ProjectorHead_3u.4.bias', 'ProjectorHead_3u.4.running_mean', 'ProjectorHead_3u.4.running_var']\n",
      "unexpected_keys:  ['aux_classifier.0.weight', 'aux_classifier.1.weight', 'aux_classifier.1.bias', 'aux_classifier.1.running_mean', 'aux_classifier.1.running_var', 'aux_classifier.1.num_batches_tracked', 'aux_classifier.4.weight', 'aux_classifier.4.bias', 'classifier.0.weight', 'classifier.1.weight', 'classifier.1.bias', 'classifier.1.running_mean', 'classifier.1.running_var', 'classifier.1.num_batches_tracked', 'classifier.4.weight', 'classifier.4.bias']\n",
      "DistributedDataParallel(\n",
      "  (module): FCN(\n",
      "    (backbone): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): FCNHead(\n",
      "      (L3u): Sequential(\n",
      "        (0): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (L2u): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (L1u): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "      )\n",
      "      (cls): Sequential(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (ProjectorHead_1d): ProjectorHead(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (ProjectorHead_1u): ProjectorHead(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (ProjectorHead_2d): ProjectorHead(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (ProjectorHead_2u): ProjectorHead(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (ProjectorHead_3d): ProjectorHead(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (ProjectorHead_3u): ProjectorHead(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Start training\n",
      "Epoch: [0]  [  0/146]  eta: 0:14:00  lr: 0.000001  loss: 3.2755 (3.2755)  time: 5.7559  data: 0.5736  max mem: 7076\n",
      "Epoch: [0]  [  5/146]  eta: 0:07:01  lr: 0.000004  loss: 3.1793 (3.2244)  time: 2.9867  data: 0.1043  max mem: 7539\n",
      "Epoch: [0]  [ 10/146]  eta: 0:06:11  lr: 0.000008  loss: 3.1506 (3.2088)  time: 2.7281  data: 0.0611  max mem: 7540\n",
      "Epoch: [0]  [ 15/146]  eta: 0:05:45  lr: 0.000011  loss: 3.2260 (3.2164)  time: 2.6345  data: 0.0453  max mem: 7542\n",
      "Epoch: [0]  [ 20/146]  eta: 0:05:26  lr: 0.000014  loss: 3.1169 (3.2014)  time: 2.4306  data: 0.0101  max mem: 7542\n",
      "Epoch: [0]  [ 25/146]  eta: 0:05:10  lr: 0.000018  loss: 3.0799 (3.1836)  time: 2.4380  data: 0.0099  max mem: 7542\n",
      "Epoch: [0]  [ 30/146]  eta: 0:04:55  lr: 0.000021  loss: 3.0386 (3.1606)  time: 2.4471  data: 0.0099  max mem: 7542\n",
      "Epoch: [0]  [ 35/146]  eta: 0:04:41  lr: 0.000025  loss: 3.0520 (3.1351)  time: 2.4522  data: 0.0097  max mem: 7542\n",
      "Epoch: [0]  [ 40/146]  eta: 0:04:27  lr: 0.000028  loss: 2.8634 (3.1003)  time: 2.4539  data: 0.0093  max mem: 7542\n",
      "Epoch: [0]  [ 45/146]  eta: 0:04:14  lr: 0.000032  loss: 2.7597 (3.0678)  time: 2.4529  data: 0.0091  max mem: 7542\n",
      "Epoch: [0]  [ 50/146]  eta: 0:04:01  lr: 0.000035  loss: 2.7930 (3.0321)  time: 2.4545  data: 0.0091  max mem: 7542\n",
      "Epoch: [0]  [ 55/146]  eta: 0:03:48  lr: 0.000038  loss: 2.5965 (2.9972)  time: 2.4593  data: 0.0089  max mem: 7542\n",
      "Epoch: [0]  [ 60/146]  eta: 0:03:35  lr: 0.000042  loss: 2.5579 (2.9622)  time: 2.4630  data: 0.0090  max mem: 7542\n",
      "Epoch: [0]  [ 65/146]  eta: 0:03:22  lr: 0.000045  loss: 2.4954 (2.9225)  time: 2.4631  data: 0.0093  max mem: 7542\n",
      "Epoch: [0]  [ 70/146]  eta: 0:03:09  lr: 0.000049  loss: 2.3927 (2.8799)  time: 2.4661  data: 0.0093  max mem: 7542\n",
      "Epoch: [0]  [ 75/146]  eta: 0:02:57  lr: 0.000052  loss: 2.2423 (2.8381)  time: 2.4651  data: 0.0093  max mem: 7542\n",
      "Epoch: [0]  [ 80/146]  eta: 0:02:44  lr: 0.000056  loss: 2.0580 (2.7956)  time: 2.4707  data: 0.0099  max mem: 7542\n",
      "Epoch: [0]  [ 85/146]  eta: 0:02:32  lr: 0.000059  loss: 1.9921 (2.7556)  time: 2.4735  data: 0.0096  max mem: 7542\n",
      "Epoch: [0]  [ 90/146]  eta: 0:02:19  lr: 0.000062  loss: 1.9165 (2.7165)  time: 2.4712  data: 0.0096  max mem: 7542\n",
      "Epoch: [0]  [ 95/146]  eta: 0:02:06  lr: 0.000066  loss: 1.7582 (2.6774)  time: 2.4686  data: 0.0097  max mem: 7542\n",
      "Epoch: [0]  [100/146]  eta: 0:01:54  lr: 0.000069  loss: 1.8059 (2.6370)  time: 2.4678  data: 0.0092  max mem: 7542\n",
      "Epoch: [0]  [105/146]  eta: 0:01:42  lr: 0.000073  loss: 1.7082 (2.5954)  time: 2.4678  data: 0.0092  max mem: 7542\n",
      "Epoch: [0]  [110/146]  eta: 0:01:29  lr: 0.000076  loss: 1.6911 (2.5593)  time: 2.4694  data: 0.0089  max mem: 7542\n",
      "Epoch: [0]  [115/146]  eta: 0:01:17  lr: 0.000079  loss: 1.5842 (2.5197)  time: 2.4722  data: 0.0088  max mem: 7542\n",
      "Epoch: [0]  [120/146]  eta: 0:01:04  lr: 0.000083  loss: 1.5656 (2.4793)  time: 2.4713  data: 0.0086  max mem: 7542\n",
      "Epoch: [0]  [125/146]  eta: 0:00:52  lr: 0.000086  loss: 1.4606 (2.4444)  time: 2.4690  data: 0.0085  max mem: 7542\n",
      "Epoch: [0]  [130/146]  eta: 0:00:39  lr: 0.000090  loss: 1.4628 (2.4083)  time: 2.4698  data: 0.0085  max mem: 7542\n",
      "Epoch: [0]  [135/146]  eta: 0:00:27  lr: 0.000093  loss: 1.4629 (2.3728)  time: 2.4703  data: 0.0088  max mem: 7542\n",
      "Epoch: [0]  [140/146]  eta: 0:00:14  lr: 0.000097  loss: 1.4563 (2.3396)  time: 2.4695  data: 0.0088  max mem: 7542\n",
      "Epoch: [0]  [145/146]  eta: 0:00:02  lr: 0.000100  loss: 1.5951 (2.3029)  time: 2.4752  data: 0.0088  max mem: 7542\n",
      "Epoch: [0] Total time: 0:06:02\n",
      "Test:  [  0/182]  eta: 0:07:03    time: 2.3296  data: 0.6330  max mem: 7542\n",
      "Test:  [ 10/182]  eta: 0:03:34    time: 1.2475  data: 0.0718  max mem: 7542\n",
      "Test:  [ 20/182]  eta: 0:03:23    time: 1.2035  data: 0.0152  max mem: 7542\n",
      "Test:  [ 30/182]  eta: 0:03:12    time: 1.2771  data: 0.0148  max mem: 7542\n",
      "Test:  [ 40/182]  eta: 0:03:01    time: 1.2962  data: 0.0157  max mem: 7542\n",
      "Test:  [ 50/182]  eta: 0:02:50    time: 1.3323  data: 0.0169  max mem: 7542\n",
      "Test:  [ 60/182]  eta: 0:02:35    time: 1.2834  data: 0.0167  max mem: 7542\n",
      "Test:  [ 70/182]  eta: 0:02:21    time: 1.2045  data: 0.0188  max mem: 7542\n",
      "Test:  [ 80/182]  eta: 0:02:10    time: 1.2688  data: 0.0210  max mem: 7542\n",
      "Test:  [ 90/182]  eta: 0:01:57    time: 1.3252  data: 0.0242  max mem: 7542\n",
      "Test:  [100/182]  eta: 0:01:44    time: 1.2797  data: 0.0270  max mem: 7542\n",
      "Test:  [110/182]  eta: 0:01:31    time: 1.2243  data: 0.0250  max mem: 7542\n",
      "Test:  [120/182]  eta: 0:01:18    time: 1.2463  data: 0.0246  max mem: 7542\n",
      "Test:  [130/182]  eta: 0:01:06    time: 1.3647  data: 0.0260  max mem: 7542\n",
      "Test:  [140/182]  eta: 0:00:54    time: 1.4632  data: 0.0271  max mem: 7542\n",
      "Test:  [150/182]  eta: 0:00:41    time: 1.3884  data: 0.0273  max mem: 7542\n",
      "Test:  [160/182]  eta: 0:00:28    time: 1.3008  data: 0.0267  max mem: 7542\n",
      "Test:  [170/182]  eta: 0:00:15    time: 1.2473  data: 0.0254  max mem: 7542\n",
      "Test:  [180/182]  eta: 0:00:02    time: 1.2396  data: 0.0256  max mem: 7542\n",
      "Test: Total time: 0:03:54\n",
      "global correct: 88.7\n",
      "average row correct: ['95.2', '65.1', '3.8', '69.8', '14.6', '7.4', '85.2', '72.0', '93.1', '25.7', '67.5', '24.4', '87.5', '82.7', '85.3', '96.2', '5.2', '76.8', '27.5', '81.2', '78.4']\n",
      "IoU: ['91.0', '59.2', '3.3', '63.3', '14.3', '7.3', '83.3', '65.9', '66.7', '18.9', '61.7', '21.0', '37.2', '54.2', '68.2', '75.9', '5.0', '56.2', '23.5', '76.0', '46.8']\n",
      "mean IoU: 47.6\n",
      "Epoch: [1]  [  0/146]  eta: 0:08:53  lr: 0.000100  loss: 4.5388 (4.5388)  time: 3.6530  data: 0.9151  max mem: 7542\n",
      "Epoch: [1]  [  5/146]  eta: 0:06:30  lr: 0.000100  loss: 4.7313 (4.4291)  time: 2.7703  data: 0.1657  max mem: 7542\n",
      "Epoch: [1]  [ 10/146]  eta: 0:06:05  lr: 0.000100  loss: 4.6427 (4.3907)  time: 2.6875  data: 0.0961  max mem: 7542\n",
      "Epoch: [1]  [ 15/146]  eta: 0:05:47  lr: 0.000100  loss: 4.2682 (4.3383)  time: 2.6547  data: 0.0713  max mem: 7542\n",
      "Epoch: [1]  [ 20/146]  eta: 0:05:32  lr: 0.000100  loss: 4.1020 (4.3286)  time: 2.5876  data: 0.0147  max mem: 7542\n",
      "Epoch: [1]  [ 25/146]  eta: 0:05:18  lr: 0.000100  loss: 4.0633 (4.3298)  time: 2.5886  data: 0.0143  max mem: 7542\n",
      "Epoch: [1]  [ 30/146]  eta: 0:05:04  lr: 0.000100  loss: 4.3340 (4.3171)  time: 2.5891  data: 0.0151  max mem: 7542\n",
      "Epoch: [1]  [ 35/146]  eta: 0:04:50  lr: 0.000100  loss: 3.9344 (4.2994)  time: 2.5949  data: 0.0147  max mem: 7542\n",
      "Epoch: [1]  [ 40/146]  eta: 0:04:37  lr: 0.000100  loss: 4.1380 (4.2754)  time: 2.5950  data: 0.0153  max mem: 7542\n",
      "Epoch: [1]  [ 45/146]  eta: 0:04:24  lr: 0.000100  loss: 4.4408 (4.2762)  time: 2.5984  data: 0.0159  max mem: 7542\n",
      "Epoch: [1]  [ 50/146]  eta: 0:04:11  lr: 0.000100  loss: 3.9112 (4.2483)  time: 2.6024  data: 0.0161  max mem: 7542\n",
      "Epoch: [1]  [ 55/146]  eta: 0:03:57  lr: 0.000100  loss: 3.9226 (4.2277)  time: 2.5959  data: 0.0160  max mem: 7542\n",
      "Epoch: [1]  [ 60/146]  eta: 0:03:44  lr: 0.000100  loss: 4.0348 (4.2097)  time: 2.5941  data: 0.0157  max mem: 7542\n",
      "Epoch: [1]  [ 65/146]  eta: 0:03:31  lr: 0.000100  loss: 4.1053 (4.2035)  time: 2.5889  data: 0.0149  max mem: 7542\n",
      "Epoch: [1]  [ 70/146]  eta: 0:03:18  lr: 0.000100  loss: 3.9736 (4.1818)  time: 2.5870  data: 0.0141  max mem: 7542\n",
      "Epoch: [1]  [ 75/146]  eta: 0:03:05  lr: 0.000100  loss: 3.7387 (4.1638)  time: 2.5916  data: 0.0143  max mem: 7542\n",
      "Epoch: [1]  [ 80/146]  eta: 0:02:52  lr: 0.000099  loss: 4.0137 (4.1545)  time: 2.5994  data: 0.0145  max mem: 7542\n",
      "Epoch: [1]  [ 85/146]  eta: 0:02:38  lr: 0.000099  loss: 3.6689 (4.1407)  time: 2.5997  data: 0.0147  max mem: 7542\n",
      "Epoch: [1]  [ 90/146]  eta: 0:02:25  lr: 0.000099  loss: 4.0784 (4.1242)  time: 2.5953  data: 0.0148  max mem: 7542\n",
      "Epoch: [1]  [ 95/146]  eta: 0:02:12  lr: 0.000099  loss: 4.0355 (4.1147)  time: 2.5985  data: 0.0143  max mem: 7542\n",
      "Epoch: [1]  [100/146]  eta: 0:01:59  lr: 0.000099  loss: 3.6048 (4.0948)  time: 2.5938  data: 0.0140  max mem: 7542\n",
      "Epoch: [1]  [105/146]  eta: 0:01:46  lr: 0.000099  loss: 3.6686 (4.0846)  time: 2.5963  data: 0.0139  max mem: 7542\n",
      "Epoch: [1]  [110/146]  eta: 0:01:33  lr: 0.000099  loss: 4.0657 (4.0723)  time: 2.5975  data: 0.0137  max mem: 7542\n",
      "Epoch: [1]  [115/146]  eta: 0:01:20  lr: 0.000099  loss: 4.1920 (4.0702)  time: 2.5905  data: 0.0149  max mem: 7542\n",
      "Epoch: [1]  [120/146]  eta: 0:01:07  lr: 0.000099  loss: 3.6949 (4.0534)  time: 2.5888  data: 0.0152  max mem: 7542\n",
      "Epoch: [1]  [125/146]  eta: 0:00:54  lr: 0.000099  loss: 3.7192 (4.0429)  time: 2.5853  data: 0.0148  max mem: 7542\n",
      "Epoch: [1]  [130/146]  eta: 0:00:41  lr: 0.000099  loss: 3.6999 (4.0252)  time: 2.5856  data: 0.0158  max mem: 7542\n",
      "Epoch: [1]  [135/146]  eta: 0:00:28  lr: 0.000099  loss: 3.6362 (4.0115)  time: 2.5819  data: 0.0141  max mem: 7542\n",
      "Epoch: [1]  [140/146]  eta: 0:00:15  lr: 0.000099  loss: 3.5934 (3.9993)  time: 2.5832  data: 0.0140  max mem: 7542\n",
      "Epoch: [1]  [145/146]  eta: 0:00:02  lr: 0.000099  loss: 4.0162 (3.9913)  time: 2.5841  data: 0.0141  max mem: 7542\n",
      "Epoch: [1] Total time: 0:06:19\n",
      "Test:  [  0/182]  eta: 0:07:03    time: 2.3255  data: 1.0071  max mem: 7542\n",
      "Test:  [ 10/182]  eta: 0:03:37    time: 1.2629  data: 0.1129  max mem: 7542\n",
      "Test:  [ 20/182]  eta: 0:03:26    time: 1.2243  data: 0.0245  max mem: 7542\n",
      "Test:  [ 30/182]  eta: 0:03:15    time: 1.3036  data: 0.0268  max mem: 7542\n",
      "Test:  [ 40/182]  eta: 0:03:04    time: 1.3264  data: 0.0286  max mem: 7542\n",
      "Test:  [ 50/182]  eta: 0:02:53    time: 1.3589  data: 0.0277  max mem: 7542\n",
      "Test:  [ 60/182]  eta: 0:02:38    time: 1.3073  data: 0.0258  max mem: 7542\n",
      "Test:  [ 70/182]  eta: 0:02:24    time: 1.2251  data: 0.0257  max mem: 7542\n",
      "Test:  [ 80/182]  eta: 0:02:12    time: 1.2836  data: 0.0279  max mem: 7542\n",
      "Test:  [ 90/182]  eta: 0:01:59    time: 1.3323  data: 0.0291  max mem: 7542\n",
      "Test:  [100/182]  eta: 0:01:46    time: 1.2827  data: 0.0280  max mem: 7542\n",
      "Test:  [110/182]  eta: 0:01:32    time: 1.2335  data: 0.0264  max mem: 7542\n",
      "Test:  [120/182]  eta: 0:01:19    time: 1.2558  data: 0.0265  max mem: 7542\n",
      "Test:  [130/182]  eta: 0:01:07    time: 1.3643  data: 0.0290  max mem: 7542\n",
      "Test:  [140/182]  eta: 0:00:55    time: 1.4619  data: 0.0324  max mem: 7542\n",
      "Test:  [150/182]  eta: 0:00:41    time: 1.3916  data: 0.0299  max mem: 7542\n",
      "Test:  [160/182]  eta: 0:00:28    time: 1.3024  data: 0.0267  max mem: 7542\n",
      "Test:  [170/182]  eta: 0:00:15    time: 1.2466  data: 0.0249  max mem: 7542\n",
      "Test:  [180/182]  eta: 0:00:02    time: 1.2388  data: 0.0235  max mem: 7542\n",
      "Test: Total time: 0:03:56\n",
      "global correct: 92.0\n",
      "average row correct: ['97.1', '90.8', '12.5', '85.8', '62.3', '36.1', '91.0', '85.4', '96.9', '28.5', '74.0', '22.3', '81.7', '78.8', '88.2', '95.5', '16.6', '80.9', '61.7', '88.5', '82.2']\n",
      "IoU: ['92.4', '82.8', '10.0', '77.8', '58.6', '35.4', '87.5', '74.5', '70.2', '25.8', '68.7', '21.3', '63.9', '69.3', '71.8', '82.5', '16.5', '69.3', '47.9', '81.7', '65.1']\n",
      "mean IoU: 60.6\n",
      "Epoch: [2]  [  0/146]  eta: 0:09:03  lr: 0.000099  loss: 3.3179 (3.3179)  time: 3.7202  data: 1.0665  max mem: 7542\n",
      "Epoch: [2]  [  5/146]  eta: 0:06:31  lr: 0.000099  loss: 3.7116 (3.6083)  time: 2.7801  data: 0.1912  max mem: 7542\n",
      "Epoch: [2]  [ 10/146]  eta: 0:06:06  lr: 0.000099  loss: 3.6610 (3.5629)  time: 2.6949  data: 0.1093  max mem: 7542\n",
      "Epoch: [2]  [ 15/146]  eta: 0:05:48  lr: 0.000099  loss: 3.6182 (3.5826)  time: 2.6641  data: 0.0797  max mem: 7542\n",
      "Epoch: [2]  [ 20/146]  eta: 0:05:33  lr: 0.000099  loss: 4.1122 (3.5828)  time: 2.5915  data: 0.0140  max mem: 7542\n",
      "Epoch: [2]  [ 25/146]  eta: 0:05:18  lr: 0.000099  loss: 3.4747 (3.5887)  time: 2.5923  data: 0.0133  max mem: 7542\n",
      "Epoch: [2]  [ 30/146]  eta: 0:05:05  lr: 0.000099  loss: 3.4656 (3.5977)  time: 2.5960  data: 0.0140  max mem: 7542\n",
      "Epoch: [2]  [ 35/146]  eta: 0:04:51  lr: 0.000099  loss: 3.5813 (3.6146)  time: 2.5940  data: 0.0141  max mem: 7542\n",
      "Epoch: [2]  [ 40/146]  eta: 0:04:37  lr: 0.000099  loss: 3.1559 (3.6019)  time: 2.5954  data: 0.0142  max mem: 7542\n",
      "Epoch: [2]  [ 45/146]  eta: 0:04:24  lr: 0.000099  loss: 3.6541 (3.5996)  time: 2.5921  data: 0.0150  max mem: 7542\n",
      "Epoch: [2]  [ 50/146]  eta: 0:04:10  lr: 0.000099  loss: 3.3488 (3.6000)  time: 2.5885  data: 0.0157  max mem: 7542\n",
      "Epoch: [2]  [ 55/146]  eta: 0:03:57  lr: 0.000099  loss: 3.6752 (3.5968)  time: 2.5896  data: 0.0158  max mem: 7542\n",
      "Epoch: [2]  [ 60/146]  eta: 0:03:44  lr: 0.000099  loss: 3.6084 (3.5992)  time: 2.5865  data: 0.0156  max mem: 7542\n",
      "Epoch: [2]  [ 65/146]  eta: 0:03:31  lr: 0.000099  loss: 3.6623 (3.6074)  time: 2.5933  data: 0.0152  max mem: 7542\n",
      "Epoch: [2]  [ 70/146]  eta: 0:03:18  lr: 0.000099  loss: 3.7410 (3.6046)  time: 2.5972  data: 0.0145  max mem: 7542\n",
      "Epoch: [2]  [ 75/146]  eta: 0:03:05  lr: 0.000099  loss: 3.5583 (3.6105)  time: 2.5983  data: 0.0139  max mem: 7542\n",
      "Epoch: [2]  [ 80/146]  eta: 0:02:52  lr: 0.000099  loss: 3.7129 (3.6091)  time: 2.5982  data: 0.0136  max mem: 7542\n",
      "Epoch: [2]  [ 85/146]  eta: 0:02:38  lr: 0.000099  loss: 3.2992 (3.5949)  time: 2.5920  data: 0.0139  max mem: 7542\n",
      "Epoch: [2]  [ 90/146]  eta: 0:02:25  lr: 0.000099  loss: 3.7663 (3.5886)  time: 2.5834  data: 0.0138  max mem: 7542\n",
      "Epoch: [2]  [ 95/146]  eta: 0:02:12  lr: 0.000098  loss: 4.0368 (3.5945)  time: 2.5806  data: 0.0142  max mem: 7542\n",
      "Epoch: [2]  [100/146]  eta: 0:01:59  lr: 0.000098  loss: 3.2281 (3.5823)  time: 2.5810  data: 0.0142  max mem: 7542\n",
      "Epoch: [2]  [105/146]  eta: 0:01:46  lr: 0.000098  loss: 3.4931 (3.5753)  time: 2.5806  data: 0.0143  max mem: 7542\n",
      "Epoch: [2]  [110/146]  eta: 0:01:33  lr: 0.000098  loss: 3.3200 (3.5684)  time: 2.5830  data: 0.0149  max mem: 7542\n",
      "Epoch: [2]  [115/146]  eta: 0:01:20  lr: 0.000098  loss: 3.4327 (3.5571)  time: 2.5869  data: 0.0148  max mem: 7542\n",
      "Epoch: [2]  [120/146]  eta: 0:01:07  lr: 0.000098  loss: 3.3557 (3.5468)  time: 2.5911  data: 0.0151  max mem: 7542\n",
      "Epoch: [2]  [125/146]  eta: 0:00:54  lr: 0.000098  loss: 3.6654 (3.5485)  time: 2.5937  data: 0.0149  max mem: 7542\n",
      "Epoch: [2]  [130/146]  eta: 0:00:41  lr: 0.000098  loss: 3.2788 (3.5426)  time: 2.5927  data: 0.0136  max mem: 7542\n",
      "Epoch: [2]  [135/146]  eta: 0:00:28  lr: 0.000098  loss: 3.2748 (3.5377)  time: 2.5892  data: 0.0138  max mem: 7542\n",
      "Epoch: [2]  [140/146]  eta: 0:00:15  lr: 0.000098  loss: 3.2184 (3.5335)  time: 2.5820  data: 0.0136  max mem: 7542\n",
      "Epoch: [2]  [145/146]  eta: 0:00:02  lr: 0.000098  loss: 3.7285 (3.5319)  time: 2.5796  data: 0.0137  max mem: 7542\n",
      "Epoch: [2] Total time: 0:06:19\n",
      "Test:  [  0/182]  eta: 0:07:08    time: 2.3539  data: 0.9829  max mem: 7542\n",
      "Test:  [ 10/182]  eta: 0:03:38    time: 1.2728  data: 0.1133  max mem: 7542\n",
      "Test:  [ 20/182]  eta: 0:03:27    time: 1.2273  data: 0.0258  max mem: 7542\n",
      "Test:  [ 30/182]  eta: 0:03:15    time: 1.2980  data: 0.0258  max mem: 7542\n",
      "Test:  [ 40/182]  eta: 0:03:04    time: 1.3206  data: 0.0276  max mem: 7542\n",
      "Test:  [ 50/182]  eta: 0:02:53    time: 1.3603  data: 0.0300  max mem: 7542\n",
      "Test:  [ 60/182]  eta: 0:02:38    time: 1.3094  data: 0.0297  max mem: 7542\n",
      "Test:  [ 70/182]  eta: 0:02:24    time: 1.2187  data: 0.0260  max mem: 7542\n",
      "Test:  [ 80/182]  eta: 0:02:12    time: 1.2738  data: 0.0257  max mem: 7542\n",
      "Test:  [ 90/182]  eta: 0:01:59    time: 1.3294  data: 0.0284  max mem: 7542\n",
      "Test:  [100/182]  eta: 0:01:46    time: 1.2842  data: 0.0277  max mem: 7542\n",
      "Test:  [110/182]  eta: 0:01:32    time: 1.2332  data: 0.0266  max mem: 7542\n",
      "Test:  [120/182]  eta: 0:01:19    time: 1.2547  data: 0.0271  max mem: 7542\n",
      "Test:  [130/182]  eta: 0:01:07    time: 1.3584  data: 0.0289  max mem: 7542\n",
      "Test:  [140/182]  eta: 0:00:55    time: 1.4526  data: 0.0307  max mem: 7542\n",
      "Test:  [150/182]  eta: 0:00:41    time: 1.3887  data: 0.0290  max mem: 7542\n",
      "Test:  [160/182]  eta: 0:00:28    time: 1.3029  data: 0.0281  max mem: 7542\n",
      "Test:  [170/182]  eta: 0:00:15    time: 1.2508  data: 0.0274  max mem: 7542\n",
      "Test:  [180/182]  eta: 0:00:02    time: 1.2397  data: 0.0248  max mem: 7542\n",
      "Test: Total time: 0:03:55\n",
      "global correct: 93.2\n",
      "average row correct: ['97.7', '91.5', '6.5', '83.5', '71.2', '51.7', '93.0', '88.5', '94.1', '39.0', '76.6', '46.5', '81.9', '86.9', '87.2', '94.3', '34.0', '84.6', '65.4', '86.3', '83.3']\n",
      "IoU: ['93.2', '84.7', '5.9', '78.9', '65.3', '50.1', '88.0', '76.9', '78.4', '33.9', '71.0', '41.6', '70.3', '73.5', '75.7', '86.0', '33.5', '73.0', '50.2', '82.2', '73.3']\n",
      "mean IoU: 66.0\n",
      "Epoch: [3]  [  0/146]  eta: 0:08:23  lr: 0.000098  loss: 3.0564 (3.0564)  time: 3.4508  data: 0.8646  max mem: 7542\n",
      "Epoch: [3]  [  5/146]  eta: 0:06:25  lr: 0.000098  loss: 3.6742 (3.3237)  time: 2.7327  data: 0.1573  max mem: 7542\n",
      "Epoch: [3]  [ 10/146]  eta: 0:06:02  lr: 0.000098  loss: 3.2722 (3.2988)  time: 2.6653  data: 0.0914  max mem: 7542\n",
      "Epoch: [3]  [ 15/146]  eta: 0:05:45  lr: 0.000098  loss: 3.1621 (3.3195)  time: 2.6374  data: 0.0670  max mem: 7542\n",
      "Epoch: [3]  [ 20/146]  eta: 0:05:30  lr: 0.000098  loss: 3.4796 (3.3452)  time: 2.5837  data: 0.0147  max mem: 7542\n",
      "Epoch: [3]  [ 25/146]  eta: 0:05:17  lr: 0.000098  loss: 3.2244 (3.3242)  time: 2.5866  data: 0.0143  max mem: 7542\n",
      "Epoch: [3]  [ 30/146]  eta: 0:05:03  lr: 0.000098  loss: 3.5952 (3.3437)  time: 2.5842  data: 0.0141  max mem: 7542\n",
      "Epoch: [3]  [ 35/146]  eta: 0:04:49  lr: 0.000098  loss: 3.2205 (3.3683)  time: 2.5893  data: 0.0139  max mem: 7542\n",
      "Epoch: [3]  [ 40/146]  eta: 0:04:36  lr: 0.000098  loss: 3.5357 (3.3763)  time: 2.5932  data: 0.0127  max mem: 7542\n",
      "Epoch: [3]  [ 45/146]  eta: 0:04:23  lr: 0.000098  loss: 3.3583 (3.3992)  time: 2.5923  data: 0.0128  max mem: 7542\n",
      "Epoch: [3]  [ 50/146]  eta: 0:04:10  lr: 0.000098  loss: 3.1861 (3.3932)  time: 2.5946  data: 0.0126  max mem: 7542\n",
      "Epoch: [3]  [ 55/146]  eta: 0:03:57  lr: 0.000098  loss: 3.1272 (3.3874)  time: 2.5941  data: 0.0140  max mem: 7542\n",
      "Epoch: [3]  [ 60/146]  eta: 0:03:43  lr: 0.000098  loss: 3.4328 (3.3899)  time: 2.5941  data: 0.0138  max mem: 7542\n",
      "Epoch: [3]  [ 65/146]  eta: 0:03:30  lr: 0.000098  loss: 3.1271 (3.3910)  time: 2.5973  data: 0.0141  max mem: 7542\n",
      "Epoch: [3]  [ 70/146]  eta: 0:03:17  lr: 0.000098  loss: 3.5404 (3.3805)  time: 2.5970  data: 0.0147  max mem: 7542\n",
      "Epoch: [3]  [ 75/146]  eta: 0:03:04  lr: 0.000098  loss: 3.1915 (3.3768)  time: 2.5973  data: 0.0137  max mem: 7542\n",
      "Epoch: [3]  [ 80/146]  eta: 0:02:51  lr: 0.000098  loss: 3.1501 (3.3814)  time: 2.5954  data: 0.0140  max mem: 7542\n",
      "Epoch: [3]  [ 85/146]  eta: 0:02:38  lr: 0.000098  loss: 3.3079 (3.3733)  time: 2.5883  data: 0.0135  max mem: 7542\n",
      "Epoch: [3]  [ 90/146]  eta: 0:02:25  lr: 0.000098  loss: 3.3951 (3.3761)  time: 2.5917  data: 0.0139  max mem: 7542\n",
      "Epoch: [3]  [ 95/146]  eta: 0:02:12  lr: 0.000098  loss: 3.5906 (3.3826)  time: 2.5905  data: 0.0143  max mem: 7542\n",
      "Epoch: [3]  [100/146]  eta: 0:01:59  lr: 0.000098  loss: 3.0567 (3.3713)  time: 2.5831  data: 0.0143  max mem: 7542\n",
      "Epoch: [3]  [105/146]  eta: 0:01:46  lr: 0.000098  loss: 3.2441 (3.3686)  time: 2.5836  data: 0.0147  max mem: 7542\n",
      "Epoch: [3]  [110/146]  eta: 0:01:33  lr: 0.000097  loss: 3.3405 (3.3657)  time: 2.5815  data: 0.0140  max mem: 7542\n",
      "Epoch: [3]  [115/146]  eta: 0:01:20  lr: 0.000097  loss: 3.1162 (3.3546)  time: 2.5861  data: 0.0137  max mem: 7542\n",
      "Epoch: [3]  [120/146]  eta: 0:01:07  lr: 0.000097  loss: 3.4441 (3.3500)  time: 2.5909  data: 0.0134  max mem: 7542\n",
      "Epoch: [3]  [125/146]  eta: 0:00:54  lr: 0.000097  loss: 3.3244 (3.3457)  time: 2.5937  data: 0.0130  max mem: 7542\n",
      "Epoch: [3]  [130/146]  eta: 0:00:41  lr: 0.000097  loss: 2.9626 (3.3462)  time: 2.5960  data: 0.0135  max mem: 7542\n",
      "Epoch: [3]  [135/146]  eta: 0:00:28  lr: 0.000097  loss: 3.3867 (3.3492)  time: 2.5971  data: 0.0145  max mem: 7542\n",
      "Epoch: [3]  [140/146]  eta: 0:00:15  lr: 0.000097  loss: 3.2907 (3.3458)  time: 2.5974  data: 0.0146  max mem: 7542\n",
      "Epoch: [3]  [145/146]  eta: 0:00:02  lr: 0.000097  loss: 3.1652 (3.3453)  time: 2.5952  data: 0.0147  max mem: 7542\n",
      "Epoch: [3] Total time: 0:06:19\n",
      "Test:  [  0/182]  eta: 0:06:47    time: 2.2374  data: 0.9131  max mem: 7542\n",
      "Test:  [ 10/182]  eta: 0:03:36    time: 1.2559  data: 0.1053  max mem: 7542\n",
      "Test:  [ 20/182]  eta: 0:03:26    time: 1.2281  data: 0.0254  max mem: 7542\n",
      "Test:  [ 30/182]  eta: 0:03:15    time: 1.3045  data: 0.0258  max mem: 7542\n",
      "Test:  [ 40/182]  eta: 0:03:04    time: 1.3226  data: 0.0271  max mem: 7542\n",
      "Test:  [ 50/182]  eta: 0:02:53    time: 1.3632  data: 0.0298  max mem: 7542\n",
      "Test:  [ 60/182]  eta: 0:02:39    time: 1.3130  data: 0.0301  max mem: 7542\n",
      "Test:  [ 70/182]  eta: 0:02:24    time: 1.2204  data: 0.0265  max mem: 7542\n",
      "Test:  [ 80/182]  eta: 0:02:12    time: 1.2751  data: 0.0267  max mem: 7542\n",
      "Test:  [ 90/182]  eta: 0:01:59    time: 1.3343  data: 0.0301  max mem: 7542\n",
      "Test:  [100/182]  eta: 0:01:46    time: 1.2900  data: 0.0286  max mem: 7542\n",
      "Test:  [110/182]  eta: 0:01:32    time: 1.2342  data: 0.0269  max mem: 7542\n",
      "Test:  [120/182]  eta: 0:01:19    time: 1.2544  data: 0.0268  max mem: 7542\n",
      "Test:  [130/182]  eta: 0:01:07    time: 1.3585  data: 0.0279  max mem: 7542\n",
      "Test:  [140/182]  eta: 0:00:55    time: 1.4494  data: 0.0289  max mem: 7542\n",
      "Test:  [150/182]  eta: 0:00:41    time: 1.3831  data: 0.0279  max mem: 7542\n",
      "Test:  [160/182]  eta: 0:00:28    time: 1.3033  data: 0.0278  max mem: 7542\n",
      "Test:  [170/182]  eta: 0:00:15    time: 1.2510  data: 0.0275  max mem: 7542\n",
      "Test:  [180/182]  eta: 0:00:02    time: 1.2379  data: 0.0248  max mem: 7542\n",
      "Test: Total time: 0:03:55\n",
      "global correct: 93.5\n",
      "average row correct: ['97.4', '89.3', '8.0', '86.9', '73.6', '63.6', '93.0', '90.0', '94.4', '50.8', '82.2', '60.2', '81.3', '83.9', '85.9', '94.7', '47.4', '84.0', '68.4', '85.4', '85.0']\n",
      "IoU: ['93.5', '85.5', '7.6', '79.5', '67.7', '59.5', '87.8', '76.7', '77.6', '39.8', '73.8', '50.9', '71.6', '74.8', '76.7', '86.7', '45.4', '74.4', '50.5', '81.3', '74.2']\n",
      "mean IoU: 68.4\n",
      "Epoch: [4]  [  0/146]  eta: 0:08:33  lr: 0.000097  loss: 3.1116 (3.1116)  time: 3.5159  data: 0.9891  max mem: 7542\n",
      "Epoch: [4]  [  5/146]  eta: 0:06:30  lr: 0.000097  loss: 3.5459 (3.1487)  time: 2.7692  data: 0.1764  max mem: 7542\n",
      "Epoch: [4]  [ 10/146]  eta: 0:06:05  lr: 0.000097  loss: 3.1411 (3.2186)  time: 2.6885  data: 0.1038  max mem: 7542\n",
      "Epoch: [4]  [ 15/146]  eta: 0:05:48  lr: 0.000097  loss: 3.2229 (3.2016)  time: 2.6572  data: 0.0756  max mem: 7542\n",
      "Epoch: [4]  [ 20/146]  eta: 0:05:32  lr: 0.000097  loss: 2.9114 (3.1792)  time: 2.5979  data: 0.0151  max mem: 7542\n",
      "Epoch: [4]  [ 25/146]  eta: 0:05:18  lr: 0.000097  loss: 3.3568 (3.1929)  time: 2.5907  data: 0.0154  max mem: 7542\n",
      "Epoch: [4]  [ 30/146]  eta: 0:05:04  lr: 0.000097  loss: 3.2891 (3.1736)  time: 2.5923  data: 0.0158  max mem: 7542\n",
      "Epoch: [4]  [ 35/146]  eta: 0:04:50  lr: 0.000097  loss: 2.9014 (3.1584)  time: 2.5919  data: 0.0156  max mem: 7542\n",
      "Epoch: [4]  [ 40/146]  eta: 0:04:37  lr: 0.000097  loss: 3.2930 (3.1592)  time: 2.5909  data: 0.0147  max mem: 7542\n",
      "Epoch: [4]  [ 45/146]  eta: 0:04:23  lr: 0.000097  loss: 3.0549 (3.1688)  time: 2.5888  data: 0.0147  max mem: 7542\n",
      "Epoch: [4]  [ 50/146]  eta: 0:04:10  lr: 0.000097  loss: 3.1528 (3.1833)  time: 2.5914  data: 0.0140  max mem: 7542\n",
      "Epoch: [4]  [ 55/146]  eta: 0:03:57  lr: 0.000097  loss: 3.1661 (3.1872)  time: 2.5910  data: 0.0144  max mem: 7542\n",
      "Epoch: [4]  [ 60/146]  eta: 0:03:44  lr: 0.000097  loss: 2.8435 (3.1807)  time: 2.5961  data: 0.0150  max mem: 7542\n",
      "Epoch: [4]  [ 65/146]  eta: 0:03:31  lr: 0.000097  loss: 3.3332 (3.1719)  time: 2.5965  data: 0.0150  max mem: 7542\n",
      "Epoch: [4]  [ 70/146]  eta: 0:03:18  lr: 0.000097  loss: 3.6491 (3.1784)  time: 2.5939  data: 0.0143  max mem: 7542\n",
      "Epoch: [4]  [ 75/146]  eta: 0:03:04  lr: 0.000097  loss: 3.2312 (3.1763)  time: 2.5905  data: 0.0141  max mem: 7542\n",
      "Epoch: [4]  [ 80/146]  eta: 0:02:51  lr: 0.000097  loss: 3.4965 (3.1815)  time: 2.5856  data: 0.0145  max mem: 7542\n",
      "Epoch: [4]  [ 85/146]  eta: 0:02:38  lr: 0.000097  loss: 3.7242 (3.2026)  time: 2.5877  data: 0.0142  max mem: 7542\n",
      "Epoch: [4]  [ 90/146]  eta: 0:02:25  lr: 0.000097  loss: 3.2476 (3.2072)  time: 2.5842  data: 0.0141  max mem: 7542\n",
      "Epoch: [4]  [ 95/146]  eta: 0:02:12  lr: 0.000097  loss: 3.4173 (3.2083)  time: 2.5897  data: 0.0138  max mem: 7542\n",
      "Epoch: [4]  [100/146]  eta: 0:01:59  lr: 0.000097  loss: 3.1920 (3.2145)  time: 2.5904  data: 0.0129  max mem: 7542\n",
      "Epoch: [4]  [105/146]  eta: 0:01:46  lr: 0.000097  loss: 3.0110 (3.2129)  time: 2.5893  data: 0.0129  max mem: 7542\n",
      "Epoch: [4]  [110/146]  eta: 0:01:33  lr: 0.000097  loss: 3.1710 (3.2090)  time: 2.5939  data: 0.0139  max mem: 7542\n",
      "Epoch: [4]  [115/146]  eta: 0:01:20  lr: 0.000097  loss: 3.4094 (3.2082)  time: 2.6009  data: 0.0148  max mem: 7542\n",
      "Epoch: [4]  [120/146]  eta: 0:01:07  lr: 0.000097  loss: 2.9865 (3.2035)  time: 2.5980  data: 0.0153  max mem: 7542\n",
      "Epoch: [4]  [125/146]  eta: 0:00:54  lr: 0.000096  loss: 2.8241 (3.1987)  time: 2.5932  data: 0.0151  max mem: 7542\n",
      "Epoch: [4]  [130/146]  eta: 0:00:41  lr: 0.000096  loss: 3.4001 (3.1965)  time: 2.5879  data: 0.0146  max mem: 7542\n",
      "Epoch: [4]  [135/146]  eta: 0:00:28  lr: 0.000096  loss: 3.3197 (3.1889)  time: 2.5801  data: 0.0140  max mem: 7542\n",
      "Epoch: [4]  [140/146]  eta: 0:00:15  lr: 0.000096  loss: 3.1634 (3.1889)  time: 2.5838  data: 0.0140  max mem: 7542\n",
      "Epoch: [4]  [145/146]  eta: 0:00:02  lr: 0.000096  loss: 3.3664 (3.1865)  time: 2.5894  data: 0.0143  max mem: 7542\n",
      "Epoch: [4] Total time: 0:06:19\n",
      "Test:  [  0/182]  eta: 0:06:42    time: 2.2124  data: 0.8766  max mem: 7542\n",
      "Test:  [ 10/182]  eta: 0:03:36    time: 1.2581  data: 0.1036  max mem: 7542\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!experiment_name=\"temp\";cd ../ ;\\\n",
    "    name_date=\"${experiment_name}/$(date +%Y-%m%d-%H%M%S)\";\\\n",
    "    dir=\"./results/${name_date}\";mkdir -p ${dir};dir_log=\"${dir}/output.log\";\\\n",
    "CUDA_VISIBLE_DEVICES=1 torchrun --nproc_per_node=1 --master_port 12345 train_multi_GPU.py \\\n",
    "    --wandb False --wandb_model run --sync_bn False --amp True --aux False \\\n",
    "    --batch_size 10 --batch_size_val 8 \\\n",
    "    --epochs 100 --start_epoch 0 \\\n",
    "    --contrast 1\\\n",
    "    --model_name dcnet_resnet50 --pre_trained fcn_resnet50_coco \\\n",
    "    --loss_name double --L3_loss 0.1\\\n",
    "    --name_date $name_date \\\n",
    "    2>&1 | tee $dir_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42a4ea106d429adb85b92cbf5fe6fad5ad2431a3e82cdef4435b2cc92f522609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
