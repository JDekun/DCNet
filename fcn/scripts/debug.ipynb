{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/zk/GIT/working/DCNet/fcn/train_multi_GPU.py\", line 7, in <module>\n",
            "    from train_utils import train_one_epoch, evaluate, create_lr_scheduler, init_distributed_mode, save_on_master, mkdir\n",
            "  File \"/home/zk/GIT/working/DCNet/fcn/train_utils/__init__.py\", line 1, in <module>\n",
            "    from .train_and_eval import train_one_epoch, evaluate, create_lr_scheduler\n",
            "  File \"/home/zk/GIT/working/DCNet/fcn/train_utils/train_and_eval.py\", line 7, in <module>\n",
            "    from train_utils.loss_manage import criterion\n",
            "  File \"/home/zk/GIT/working/DCNet/fcn/train_utils/loss_manage/__init__.py\", line 6, in <module>\n",
            "    from .aspp_loss import  ASPP_CONTRAST_Loss\n",
            "  File \"/home/zk/GIT/working/DCNet/fcn/train_utils/loss_manage/aspp_loss.py\", line 3, in <module>\n",
            "    from .samples import Sampling\n",
            "  File \"/home/zk/GIT/working/DCNet/fcn/train_utils/loss_manage/samples/__init__.py\", line 2, in <module>\n",
            "    from .sample_manage import Sampling\n",
            "  File \"/home/zk/GIT/working/DCNet/fcn/train_utils/loss_manage/samples/sample_manage.py\", line 3, in <module>\n",
            "    import samples\n",
            "ModuleNotFoundError: No module named 'samples'\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 11100) of binary: /home/zk/anaconda3/bin/python\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/zk/anaconda3/bin/torchrun\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/run.py\", line 762, in main\n",
            "    run(args)\n",
            "  File \"/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/run.py\", line 753, in run\n",
            "    elastic_launch(\n",
            "  File \"/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/home/zk/anaconda3/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 246, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "train_multi_GPU.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2023-03-23_13:25:45\n",
            "  host      : GPU1\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 11100)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# simsiam\n",
        "!experiment_name=\"debug\";cd ../ ;\\\n",
        "    name_date=\"${experiment_name}/$(date +%Y-%m%d-%H%M%S)\";\\\n",
        "    dir=\"./results/${name_date}\";mkdir -p ${dir};dir_log=\"${dir}/output.log\";\\\n",
        "CUDA_VISIBLE_DEVICES=8 torchrun --nproc_per_node=1 --master_port=12345 train_multi_GPU.py \\\n",
        "    --wandb False --wandb_model run --sync_bn False --amp True --aux False \\\n",
        "    --model_name aspp_contrast_resnet50 --pre_trained deeplabv3_resnet50_coco.pth \\\n",
        "    --weight_only_backbone False \\\n",
        "    --data_path pascal-voc-2012 --num_classes 21 \\\n",
        "    --epochs 40 --batch_size 8 --batch_size_val 8 --memory_size 0 \\\n",
        "    --contrast 1 --sample self_pace3 \\\n",
        "    --loss_name aspp_loss --L1_loss 0 --L2_loss 0 --L3_loss 0\\\n",
        "    --name_date $name_date \\\n",
        "    2>&1 | tee $dir_log"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
