{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| distributed init (rank 0): env://\n",
      "temp/2023-0405-224733\n",
      "Namespace(data_path='pascal-voc-2012', data_train_type='train.txt', device='cuda', num_classes=21, batch_size=8, batch_size_val=6, aux=False, start_epoch=0, epochs=40, sync_bn=False, workers=1, lr=0.001, momentum=0.9, weight_decay=0.0001, print_freq=10, checkpoint_dir='./results/temp/2023-0405-224733', resume='', test_only=False, world_size=1, dist_url='env://', amp=True, seed=304, name_date='temp/2023-0405-224733', wandb=False, wandb_model='dryrun', run_name='', model_name='aspp_contrast_resnet101', project_dim=128, loss_name='aspp_loss', contrast=0, pre_trained='deeplabv3_resnet101_coco.pth', L3_loss=0.1, L2_loss=0.1, L1_loss=0.1, GAcc=1, memory_size=16384, proj_dim=128, network_stride=8, pixel_update_freq=10, ddp=False, weight_only_backbone=False, sample='self_pace_ploy', rank=0, gpu=0, distributed=True, dist_backend='nccl')\n",
      "Creating data loaders\n",
      "Creating model\n",
      "missing_keys:  ['encode3_queue', 'encode3_queue_ptr', 'code3_queue_label', 'encode2_queue', 'encode2_queue_ptr', 'code2_queue_label', 'encode1_queue', 'encode1_queue_ptr', 'code1_queue_label', 'contrast.convs.0.0.weight', 'contrast.convs.0.1.weight', 'contrast.convs.0.1.bias', 'contrast.convs.0.1.running_mean', 'contrast.convs.0.1.running_var', 'contrast.convs.0.3.weight', 'contrast.convs.0.4.weight', 'contrast.convs.0.4.bias', 'contrast.convs.0.4.running_mean', 'contrast.convs.0.4.running_var', 'contrast.convs.1.0.weight', 'contrast.convs.1.1.weight', 'contrast.convs.1.1.bias', 'contrast.convs.1.1.running_mean', 'contrast.convs.1.1.running_var', 'contrast.convs.1.3.weight', 'contrast.convs.1.4.weight', 'contrast.convs.1.4.bias', 'contrast.convs.1.4.running_mean', 'contrast.convs.1.4.running_var', 'contrast.convs.2.0.weight', 'contrast.convs.2.1.weight', 'contrast.convs.2.1.bias', 'contrast.convs.2.1.running_mean', 'contrast.convs.2.1.running_var', 'contrast.convs.2.3.weight', 'contrast.convs.2.4.weight', 'contrast.convs.2.4.bias', 'contrast.convs.2.4.running_mean', 'contrast.convs.2.4.running_var']\n",
      "unexpected_keys:  ['aux_classifier.0.weight', 'aux_classifier.1.weight', 'aux_classifier.1.bias', 'aux_classifier.1.running_mean', 'aux_classifier.1.running_var', 'aux_classifier.1.num_batches_tracked', 'aux_classifier.4.weight', 'aux_classifier.4.bias']\n",
      "DistributedDataParallel(\n",
      "  (module): DeepLabV3(\n",
      "    (backbone): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (6): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (7): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (8): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (9): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (10): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (11): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (12): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (13): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (14): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (15): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (16): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (17): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (18): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (19): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (20): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (21): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (22): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): DeepLabHead(\n",
      "      (0): ASPP(\n",
      "        (convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): ASPPPooling(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (contrast): contrast_head(\n",
      "      (convs): ModuleList(\n",
      "        (0): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Start training\n",
      "Epoch: [0] Train  [  0/183]  eta: 0:46:24  lr: 0.000006  loss: 3.2045 (3.2045)  time: 15.2158  data: 0.4949  max mem: 9039\n",
      "Epoch: [0] Train  [ 10/183]  eta: 0:37:33  lr: 0.000061  loss: 2.8127 (2.7349)  time: 13.0267  data: 0.0455  max mem: 9511\n",
      "Epoch: [0] Train  [ 20/183]  eta: 0:34:49  lr: 0.000116  loss: 2.7883 (2.8270)  time: 12.6999  data: 0.0004  max mem: 9511\n",
      "Epoch: [0] Train  [ 30/183]  eta: 0:32:38  lr: 0.000170  loss: 2.7476 (2.8424)  time: 12.6743  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Train  [ 40/183]  eta: 0:30:23  lr: 0.000225  loss: 4.0132 (2.9550)  time: 12.6830  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Train  [ 50/183]  eta: 0:28:13  lr: 0.000279  loss: 3.3288 (2.9929)  time: 12.6365  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Train  [ 60/183]  eta: 0:26:01  lr: 0.000334  loss: 3.1430 (3.0408)  time: 12.5801  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Train  [ 70/183]  eta: 0:23:51  lr: 0.000389  loss: 3.4399 (3.0715)  time: 12.4960  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Train  [ 80/183]  eta: 0:21:41  lr: 0.000443  loss: 3.0306 (3.0799)  time: 12.4618  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Train  [ 90/183]  eta: 0:19:33  lr: 0.000498  loss: 3.0944 (3.0979)  time: 12.4637  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Train  [100/183]  eta: 0:17:27  lr: 0.000552  loss: 3.0184 (3.1173)  time: 12.5311  data: 0.0004  max mem: 9511\n",
      "Epoch: [0] Train  [110/183]  eta: 0:15:21  lr: 0.000607  loss: 3.3105 (3.1567)  time: 12.6297  data: 0.0004  max mem: 9511\n",
      "Epoch: [0] Train  [120/183]  eta: 0:13:14  lr: 0.000662  loss: 3.1900 (3.1675)  time: 12.6244  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Train  [130/183]  eta: 0:11:07  lr: 0.000716  loss: 3.2489 (3.1771)  time: 12.4855  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Train  [140/183]  eta: 0:09:01  lr: 0.000771  loss: 2.9642 (3.1836)  time: 12.5188  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Train  [150/183]  eta: 0:06:55  lr: 0.000825  loss: 2.8715 (3.1890)  time: 12.5824  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Train  [160/183]  eta: 0:04:49  lr: 0.000880  loss: 3.2466 (3.2133)  time: 12.5059  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Train  [170/183]  eta: 0:02:43  lr: 0.000934  loss: 3.0791 (3.2148)  time: 12.4834  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Train  [180/183]  eta: 0:00:37  lr: 0.000989  loss: 2.9279 (3.2208)  time: 12.4628  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Train Total time: 0:38:21\n",
      "Epoch: [0] Test  [  0/242]  eta: 0:07:46    time: 1.9294  data: 0.4434  max mem: 9511\n",
      "Epoch: [0] Test  [ 10/242]  eta: 0:04:00    time: 1.0372  data: 0.0406  max mem: 9511\n",
      "Epoch: [0] Test  [ 20/242]  eta: 0:03:38    time: 0.9367  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [ 30/242]  eta: 0:03:33    time: 0.9888  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [ 40/242]  eta: 0:03:25    time: 1.0489  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [ 50/242]  eta: 0:03:15    time: 1.0411  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [ 60/242]  eta: 0:03:08    time: 1.0743  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [ 70/242]  eta: 0:02:58    time: 1.0868  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [ 80/242]  eta: 0:02:47    time: 1.0301  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [ 90/242]  eta: 0:02:35    time: 0.9763  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [100/242]  eta: 0:02:26    time: 1.0097  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [110/242]  eta: 0:02:15    time: 1.0275  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Test  [120/242]  eta: 0:02:05    time: 1.0400  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [130/242]  eta: 0:01:54    time: 1.0298  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [140/242]  eta: 0:01:44    time: 0.9818  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [150/242]  eta: 0:01:33    time: 0.9901  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Test  [160/242]  eta: 0:01:23    time: 0.9998  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Test  [170/242]  eta: 0:01:13    time: 1.0638  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [180/242]  eta: 0:01:04    time: 1.1250  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [190/242]  eta: 0:00:53    time: 1.1104  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [200/242]  eta: 0:00:43    time: 1.0553  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Test  [210/242]  eta: 0:00:33    time: 1.0301  data: 0.0002  max mem: 9511\n",
      "Epoch: [0] Test  [220/242]  eta: 0:00:22    time: 1.0410  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [230/242]  eta: 0:00:12    time: 1.0471  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test  [240/242]  eta: 0:00:02    time: 1.0075  data: 0.0003  max mem: 9511\n",
      "Epoch: [0] Test Total time: 0:04:09\n",
      "global correct: 95.4\n",
      "average row correct: ['96.9', '98.1', '84.6', '94.8', '83.3', '85.6', '98.6', '85.4', '97.6', '71.7', '94.9', '69.1', '90.6', '93.3', '96.7', '95.9', '81.0', '96.8', '73.8', '96.6', '91.3']\n",
      "IoU: ['94.8', '92.3', '41.2', '83.5', '73.7', '73.7', '96.1', '81.1', '87.9', '55.3', '90.1', '63.0', '85.4', '87.1', '83.4', '89.8', '69.6', '80.6', '64.8', '89.7', '71.3']\n",
      "mean IoU: 78.8\n",
      "Epoch: [1] Train  [  0/183]  eta: 0:39:13  lr: 0.001000  loss: 3.0589 (3.0589)  time: 12.8597  data: 0.3604  max mem: 9511\n",
      "Epoch: [1] Train  [ 10/183]  eta: 0:36:05  lr: 0.000999  loss: 3.0641 (3.1612)  time: 12.5172  data: 0.0330  max mem: 9511\n",
      "Epoch: [1] Train  [ 20/183]  eta: 0:34:05  lr: 0.000997  loss: 3.8725 (3.2300)  time: 12.5322  data: 0.0002  max mem: 9511\n",
      "Epoch: [1] Train  [ 30/183]  eta: 0:31:55  lr: 0.000996  loss: 3.6242 (3.2819)  time: 12.5214  data: 0.0002  max mem: 9511\n",
      "Epoch: [1] Train  [ 40/183]  eta: 0:29:48  lr: 0.000995  loss: 2.9786 (3.2736)  time: 12.4696  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Train  [ 50/183]  eta: 0:27:46  lr: 0.000994  loss: 3.6956 (3.2841)  time: 12.5390  data: 0.0004  max mem: 9511\n",
      "Epoch: [1] Train  [ 60/183]  eta: 0:25:42  lr: 0.000992  loss: 2.8518 (3.2797)  time: 12.5977  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Train  [ 70/183]  eta: 0:23:36  lr: 0.000991  loss: 3.1168 (3.2731)  time: 12.5657  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Train  [ 80/183]  eta: 0:21:32  lr: 0.000990  loss: 3.2494 (3.2822)  time: 12.5630  data: 0.0005  max mem: 9511\n",
      "Epoch: [1] Train  [ 90/183]  eta: 0:19:26  lr: 0.000989  loss: 3.0207 (3.2752)  time: 12.5399  data: 0.0004  max mem: 9511\n",
      "Epoch: [1] Train  [100/183]  eta: 0:17:21  lr: 0.000987  loss: 3.0556 (3.2814)  time: 12.5400  data: 0.0005  max mem: 9511\n",
      "Epoch: [1] Train  [110/183]  eta: 0:15:15  lr: 0.000986  loss: 3.5012 (3.2827)  time: 12.5261  data: 0.0005  max mem: 9511\n",
      "Epoch: [1] Train  [120/183]  eta: 0:13:10  lr: 0.000985  loss: 2.9352 (3.2851)  time: 12.5549  data: 0.0002  max mem: 9511\n",
      "Epoch: [1] Train  [130/183]  eta: 0:11:04  lr: 0.000983  loss: 3.2355 (3.2852)  time: 12.5504  data: 0.0002  max mem: 9511\n",
      "Epoch: [1] Train  [140/183]  eta: 0:08:58  lr: 0.000982  loss: 3.5572 (3.2859)  time: 12.4684  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Train  [150/183]  eta: 0:06:53  lr: 0.000981  loss: 3.3588 (3.2827)  time: 12.5325  data: 0.0006  max mem: 9511\n",
      "Epoch: [1] Train  [160/183]  eta: 0:04:48  lr: 0.000980  loss: 3.3326 (3.2834)  time: 12.5320  data: 0.0006  max mem: 9511\n",
      "Epoch: [1] Train  [170/183]  eta: 0:02:42  lr: 0.000978  loss: 3.2655 (3.2854)  time: 12.5089  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Train  [180/183]  eta: 0:00:37  lr: 0.000977  loss: 3.2977 (3.2847)  time: 12.4662  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Train Total time: 0:38:11\n",
      "Epoch: [1] Test  [  0/242]  eta: 0:06:04    time: 1.5067  data: 0.4501  max mem: 9511\n",
      "Epoch: [1] Test  [ 10/242]  eta: 0:03:51    time: 0.9976  data: 0.0412  max mem: 9511\n",
      "Epoch: [1] Test  [ 20/242]  eta: 0:03:33    time: 0.9356  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [ 30/242]  eta: 0:03:30    time: 0.9870  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [ 40/242]  eta: 0:03:22    time: 1.0490  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [ 50/242]  eta: 0:03:14    time: 1.0423  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [ 60/242]  eta: 0:03:06    time: 1.0734  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [ 70/242]  eta: 0:02:57    time: 1.0835  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [ 80/242]  eta: 0:02:46    time: 1.0287  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [ 90/242]  eta: 0:02:34    time: 0.9780  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [100/242]  eta: 0:02:25    time: 1.0132  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [110/242]  eta: 0:02:14    time: 1.0324  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [120/242]  eta: 0:02:05    time: 1.0425  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [130/242]  eta: 0:01:54    time: 1.0281  data: 0.0002  max mem: 9511\n",
      "Epoch: [1] Test  [140/242]  eta: 0:01:44    time: 0.9783  data: 0.0002  max mem: 9511\n",
      "Epoch: [1] Test  [150/242]  eta: 0:01:33    time: 0.9892  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [160/242]  eta: 0:01:23    time: 1.0022  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [170/242]  eta: 0:01:13    time: 1.0521  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [180/242]  eta: 0:01:03    time: 1.1106  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [190/242]  eta: 0:00:53    time: 1.1112  data: 0.0002  max mem: 9511\n",
      "Epoch: [1] Test  [200/242]  eta: 0:00:43    time: 1.0577  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [210/242]  eta: 0:00:33    time: 1.0309  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [220/242]  eta: 0:00:22    time: 1.0666  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [230/242]  eta: 0:00:12    time: 1.0729  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test  [240/242]  eta: 0:00:02    time: 1.0072  data: 0.0003  max mem: 9511\n",
      "Epoch: [1] Test Total time: 0:04:09\n",
      "global correct: 95.1\n",
      "average row correct: ['97.2', '95.8', '74.0', '91.7', '85.3', '80.5', '99.0', '83.8', '95.9', '58.7', '94.0', '74.2', '80.1', '91.2', '92.2', '96.5', '78.2', '96.8', '83.8', '93.1', '88.2']\n",
      "IoU: ['94.9', '93.8', '52.5', '87.1', '77.6', '71.8', '89.5', '80.1', '85.3', '46.5', '87.3', '66.4', '77.0', '81.4', '88.6', '89.8', '67.5', '69.2', '66.1', '86.3', '68.0']\n",
      "mean IoU: 77.5\n",
      "Epoch: [2] Train  [  0/183]  eta: 0:40:04  lr: 0.000977  loss: 3.3153 (3.3153)  time: 13.1394  data: 0.4481  max mem: 9511\n",
      "Epoch: [2] Train  [ 10/183]  eta: 0:36:23  lr: 0.000976  loss: 3.1306 (3.3760)  time: 12.6187  data: 0.0411  max mem: 9511\n",
      "Epoch: [2] Train  [ 20/183]  eta: 0:34:11  lr: 0.000974  loss: 3.0107 (3.2591)  time: 12.5609  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train  [ 30/183]  eta: 0:31:59  lr: 0.000973  loss: 3.3089 (3.2714)  time: 12.5070  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Train  [ 40/183]  eta: 0:29:53  lr: 0.000972  loss: 3.6124 (3.2671)  time: 12.4924  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Train  [ 50/183]  eta: 0:27:46  lr: 0.000970  loss: 2.9978 (3.2741)  time: 12.5107  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Train  [ 60/183]  eta: 0:25:42  lr: 0.000969  loss: 3.2771 (3.2624)  time: 12.5296  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Train  [ 70/183]  eta: 0:23:37  lr: 0.000968  loss: 3.5928 (3.2672)  time: 12.5643  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train  [ 80/183]  eta: 0:21:29  lr: 0.000967  loss: 3.5442 (3.2767)  time: 12.4824  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train  [ 90/183]  eta: 0:19:24  lr: 0.000965  loss: 3.1098 (3.2999)  time: 12.4553  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train  [100/183]  eta: 0:17:19  lr: 0.000964  loss: 3.5603 (3.3126)  time: 12.5067  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train  [110/183]  eta: 0:15:14  lr: 0.000963  loss: 3.4236 (3.3207)  time: 12.5174  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Train  [120/183]  eta: 0:13:09  lr: 0.000962  loss: 3.3264 (3.3380)  time: 12.5451  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Train  [130/183]  eta: 0:11:03  lr: 0.000960  loss: 3.4223 (3.3318)  time: 12.5454  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train  [140/183]  eta: 0:08:58  lr: 0.000959  loss: 3.0999 (3.3273)  time: 12.4818  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Train  [150/183]  eta: 0:06:53  lr: 0.000958  loss: 3.5383 (3.3240)  time: 12.4663  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Train  [160/183]  eta: 0:04:47  lr: 0.000957  loss: 3.0870 (3.3344)  time: 12.4827  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train  [170/183]  eta: 0:02:42  lr: 0.000955  loss: 3.1847 (3.3333)  time: 12.5069  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train  [180/183]  eta: 0:00:37  lr: 0.000954  loss: 2.9678 (3.3301)  time: 12.5537  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Train Total time: 0:38:11\n",
      "Epoch: [2] Test  [  0/242]  eta: 0:05:56    time: 1.4727  data: 0.4155  max mem: 9511\n",
      "Epoch: [2] Test  [ 10/242]  eta: 0:03:51    time: 0.9969  data: 0.0380  max mem: 9511\n",
      "Epoch: [2] Test  [ 20/242]  eta: 0:03:33    time: 0.9363  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [ 30/242]  eta: 0:03:29    time: 0.9858  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Test  [ 40/242]  eta: 0:03:22    time: 1.0479  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [ 50/242]  eta: 0:03:13    time: 1.0415  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [ 60/242]  eta: 0:03:06    time: 1.0734  data: 0.0004  max mem: 9511\n",
      "Epoch: [2] Test  [ 70/242]  eta: 0:02:57    time: 1.0852  data: 0.0004  max mem: 9511\n",
      "Epoch: [2] Test  [ 80/242]  eta: 0:02:46    time: 1.0279  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Test  [ 90/242]  eta: 0:02:34    time: 0.9760  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Test  [100/242]  eta: 0:02:25    time: 1.0125  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [110/242]  eta: 0:02:14    time: 1.0290  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [120/242]  eta: 0:02:05    time: 1.0401  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [130/242]  eta: 0:01:54    time: 1.0304  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [140/242]  eta: 0:01:44    time: 0.9812  data: 0.0002  max mem: 9511\n",
      "Epoch: [2] Test  [150/242]  eta: 0:01:33    time: 0.9899  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [160/242]  eta: 0:01:23    time: 1.0044  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [170/242]  eta: 0:01:13    time: 1.0536  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [180/242]  eta: 0:01:03    time: 1.1110  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [190/242]  eta: 0:00:53    time: 1.1125  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [200/242]  eta: 0:00:43    time: 1.0577  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [210/242]  eta: 0:00:33    time: 1.0320  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [220/242]  eta: 0:00:22    time: 1.0419  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [230/242]  eta: 0:00:12    time: 1.0473  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test  [240/242]  eta: 0:00:02    time: 1.0088  data: 0.0003  max mem: 9511\n",
      "Epoch: [2] Test Total time: 0:04:08\n",
      "global correct: 95.7\n",
      "average row correct: ['96.9', '98.3', '84.6', '94.9', '87.2', '91.9', '98.0', '94.6', '97.8', '66.1', '93.5', '77.7', '93.5', '95.1', '95.2', '94.4', '73.1', '95.3', '84.8', '97.0', '90.5']\n",
      "IoU: ['95.1', '93.7', '59.0', '88.6', '74.4', '68.6', '94.9', '86.5', '89.7', '50.6', '90.0', '68.6', '85.9', '90.7', '89.6', '90.4', '65.6', '84.9', '64.1', '87.5', '76.7']\n",
      "mean IoU: 80.7\n",
      "Epoch: [3] Train  [  0/183]  eta: 0:41:04  lr: 0.000954  loss: 3.2375 (3.2375)  time: 13.4655  data: 0.4416  max mem: 9511\n",
      "Epoch: [3] Train  [ 10/183]  eta: 0:36:26  lr: 0.000952  loss: 3.3441 (3.2975)  time: 12.6394  data: 0.0405  max mem: 9511\n",
      "Epoch: [3] Train  [ 20/183]  eta: 0:34:19  lr: 0.000951  loss: 3.4187 (3.2922)  time: 12.5952  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Train  [ 30/183]  eta: 0:32:16  lr: 0.000950  loss: 3.1704 (3.3020)  time: 12.6692  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Train  [ 40/183]  eta: 0:30:02  lr: 0.000949  loss: 3.4856 (3.3077)  time: 12.5700  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Train  [ 50/183]  eta: 0:27:52  lr: 0.000947  loss: 3.2497 (3.3176)  time: 12.4462  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Train  [ 60/183]  eta: 0:25:47  lr: 0.000946  loss: 3.7049 (3.3305)  time: 12.5335  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Train  [ 70/183]  eta: 0:23:39  lr: 0.000945  loss: 3.4750 (3.3452)  time: 12.5243  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Train  [ 80/183]  eta: 0:21:34  lr: 0.000943  loss: 3.1007 (3.3440)  time: 12.5382  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Train  [ 90/183]  eta: 0:19:28  lr: 0.000942  loss: 3.3326 (3.3488)  time: 12.5783  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Train  [100/183]  eta: 0:17:23  lr: 0.000941  loss: 3.3592 (3.3553)  time: 12.5599  data: 0.0005  max mem: 9511\n",
      "Epoch: [3] Train  [110/183]  eta: 0:15:18  lr: 0.000940  loss: 3.2229 (3.3537)  time: 12.6508  data: 0.0004  max mem: 9511\n",
      "Epoch: [3] Train  [120/183]  eta: 0:13:11  lr: 0.000938  loss: 3.1810 (3.3518)  time: 12.5820  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Train  [130/183]  eta: 0:11:05  lr: 0.000937  loss: 3.3889 (3.3493)  time: 12.4750  data: 0.0010  max mem: 9511\n",
      "Epoch: [3] Train  [140/183]  eta: 0:09:00  lr: 0.000936  loss: 3.1880 (3.3449)  time: 12.5041  data: 0.0010  max mem: 9511\n",
      "Epoch: [3] Train  [150/183]  eta: 0:06:54  lr: 0.000935  loss: 3.1614 (3.3379)  time: 12.4648  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Train  [160/183]  eta: 0:04:48  lr: 0.000933  loss: 3.3710 (3.3364)  time: 12.4720  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Train  [170/183]  eta: 0:02:43  lr: 0.000932  loss: 3.1894 (3.3409)  time: 12.5055  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Train  [180/183]  eta: 0:00:37  lr: 0.000931  loss: 3.1254 (3.3388)  time: 12.5086  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Train Total time: 0:38:15\n",
      "Epoch: [3] Test  [  0/242]  eta: 0:06:45    time: 1.6770  data: 0.6133  max mem: 9511\n",
      "Epoch: [3] Test  [ 10/242]  eta: 0:03:55    time: 1.0162  data: 0.0560  max mem: 9511\n",
      "Epoch: [3] Test  [ 20/242]  eta: 0:03:35    time: 0.9365  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [ 30/242]  eta: 0:03:31    time: 0.9861  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Test  [ 40/242]  eta: 0:03:23    time: 1.0479  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Test  [ 50/242]  eta: 0:03:15    time: 1.0455  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Test  [ 60/242]  eta: 0:03:07    time: 1.0807  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [ 70/242]  eta: 0:02:58    time: 1.0874  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [ 80/242]  eta: 0:02:47    time: 1.0286  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [ 90/242]  eta: 0:02:35    time: 0.9779  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [100/242]  eta: 0:02:25    time: 1.0110  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [110/242]  eta: 0:02:15    time: 1.0284  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [120/242]  eta: 0:02:05    time: 1.0414  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [130/242]  eta: 0:01:54    time: 1.0311  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [140/242]  eta: 0:01:44    time: 0.9808  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [150/242]  eta: 0:01:33    time: 0.9877  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [160/242]  eta: 0:01:23    time: 1.0023  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [170/242]  eta: 0:01:13    time: 1.0520  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [180/242]  eta: 0:01:03    time: 1.1120  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Test  [190/242]  eta: 0:00:53    time: 1.1146  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Test  [200/242]  eta: 0:00:43    time: 1.0588  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [210/242]  eta: 0:00:33    time: 1.0329  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [220/242]  eta: 0:00:22    time: 1.0428  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [230/242]  eta: 0:00:12    time: 1.0499  data: 0.0003  max mem: 9511\n",
      "Epoch: [3] Test  [240/242]  eta: 0:00:02    time: 1.0117  data: 0.0002  max mem: 9511\n",
      "Epoch: [3] Test Total time: 0:04:09\n",
      "global correct: 95.2\n",
      "average row correct: ['96.4', '98.0', '80.0', '94.5', '84.0', '88.7', '98.4', '94.0', '97.6', '78.0', '89.1', '82.8', '92.2', '95.6', '97.5', '94.4', '74.1', '95.7', '74.5', '96.9', '88.7']\n",
      "IoU: ['94.8', '93.2', '62.6', '89.1', '75.7', '72.5', '95.4', '87.3', '90.7', '43.4', '85.6', '72.3', '86.1', '84.1', '86.7', '89.5', '65.6', '85.7', '54.6', '83.3', '70.9']\n",
      "mean IoU: 79.5\n",
      "Epoch: [4] Train  [  0/183]  eta: 0:41:01  lr: 0.000930  loss: 3.0260 (3.0260)  time: 13.4505  data: 0.4266  max mem: 9511\n",
      "Epoch: [4] Train  [ 10/183]  eta: 0:36:04  lr: 0.000929  loss: 3.4681 (3.2762)  time: 12.5142  data: 0.0390  max mem: 9511\n",
      "Epoch: [4] Train  [ 20/183]  eta: 0:34:08  lr: 0.000928  loss: 2.8795 (3.2557)  time: 12.5214  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Train  [ 30/183]  eta: 0:32:05  lr: 0.000927  loss: 3.3845 (3.2841)  time: 12.6259  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Train  [ 40/183]  eta: 0:29:54  lr: 0.000925  loss: 3.5773 (3.2704)  time: 12.5263  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Train  [ 50/183]  eta: 0:27:46  lr: 0.000924  loss: 3.6178 (3.2806)  time: 12.4453  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Train  [ 60/183]  eta: 0:25:41  lr: 0.000923  loss: 3.3729 (3.2819)  time: 12.5138  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Train  [ 70/183]  eta: 0:23:36  lr: 0.000921  loss: 3.3257 (3.2845)  time: 12.5534  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Train  [ 80/183]  eta: 0:21:29  lr: 0.000920  loss: 3.0408 (3.2822)  time: 12.4748  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train  [ 90/183]  eta: 0:19:24  lr: 0.000919  loss: 3.2281 (3.2725)  time: 12.4762  data: 0.0004  max mem: 9511\n",
      "Epoch: [4] Train  [100/183]  eta: 0:17:19  lr: 0.000918  loss: 3.7611 (3.2791)  time: 12.5444  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train  [110/183]  eta: 0:15:14  lr: 0.000916  loss: 3.3690 (3.2934)  time: 12.5127  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train  [120/183]  eta: 0:13:08  lr: 0.000915  loss: 3.5439 (3.3013)  time: 12.5075  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Train  [130/183]  eta: 0:11:03  lr: 0.000914  loss: 2.9846 (3.3040)  time: 12.4586  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train  [140/183]  eta: 0:08:57  lr: 0.000913  loss: 3.9830 (3.3102)  time: 12.4215  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train  [150/183]  eta: 0:06:52  lr: 0.000911  loss: 3.4542 (3.3120)  time: 12.4343  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train  [160/183]  eta: 0:04:47  lr: 0.000910  loss: 3.2112 (3.3112)  time: 12.5189  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train  [170/183]  eta: 0:02:42  lr: 0.000909  loss: 4.0189 (3.3135)  time: 12.5327  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train  [180/183]  eta: 0:00:37  lr: 0.000907  loss: 3.4101 (3.3194)  time: 12.4920  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Train Total time: 0:38:09\n",
      "Epoch: [4] Test  [  0/242]  eta: 0:05:52    time: 1.4574  data: 0.3946  max mem: 9511\n",
      "Epoch: [4] Test  [ 10/242]  eta: 0:03:51    time: 0.9972  data: 0.0362  max mem: 9511\n",
      "Epoch: [4] Test  [ 20/242]  eta: 0:03:34    time: 0.9397  data: 0.0004  max mem: 9511\n",
      "Epoch: [4] Test  [ 30/242]  eta: 0:03:30    time: 0.9892  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [ 40/242]  eta: 0:03:23    time: 1.0491  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [ 50/242]  eta: 0:03:14    time: 1.0454  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [ 60/242]  eta: 0:03:07    time: 1.0800  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [ 70/242]  eta: 0:02:57    time: 1.0887  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [ 80/242]  eta: 0:02:46    time: 1.0323  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Test  [ 90/242]  eta: 0:02:35    time: 0.9815  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Test  [100/242]  eta: 0:02:25    time: 1.0143  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [110/242]  eta: 0:02:15    time: 1.0309  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [120/242]  eta: 0:02:05    time: 1.0443  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [130/242]  eta: 0:01:54    time: 1.0334  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Test  [140/242]  eta: 0:01:44    time: 0.9823  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Test  [150/242]  eta: 0:01:33    time: 0.9910  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [160/242]  eta: 0:01:23    time: 1.0035  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Test  [170/242]  eta: 0:01:13    time: 1.0541  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [180/242]  eta: 0:01:03    time: 1.1141  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Test  [190/242]  eta: 0:00:53    time: 1.1143  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [200/242]  eta: 0:00:43    time: 1.0588  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [210/242]  eta: 0:00:33    time: 1.0323  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [220/242]  eta: 0:00:22    time: 1.0408  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [230/242]  eta: 0:00:12    time: 1.0472  data: 0.0003  max mem: 9511\n",
      "Epoch: [4] Test  [240/242]  eta: 0:00:02    time: 1.0102  data: 0.0002  max mem: 9511\n",
      "Epoch: [4] Test Total time: 0:04:09\n",
      "global correct: 95.2\n",
      "average row correct: ['96.4', '97.5', '89.5', '95.8', '91.0', '85.1', '98.1', '95.0', '98.0', '73.7', '94.1', '77.7', '89.6', '95.9', '97.7', '94.0', '84.0', '97.4', '74.2', '97.6', '86.9']\n",
      "IoU: ['94.8', '92.5', '59.4', '88.1', '72.3', '72.4', '95.9', '84.2', '86.7', '41.6', '90.9', '70.1', '83.1', '86.9', '89.6', '89.9', '63.4', '84.8', '54.0', '85.8', '80.1']\n",
      "mean IoU: 79.4\n",
      "Epoch: [5] Train  [  0/183]  eta: 0:40:29  lr: 0.000907  loss: 3.0341 (3.0341)  time: 13.2777  data: 0.3681  max mem: 9511\n",
      "Epoch: [5] Train  [ 10/183]  eta: 0:36:29  lr: 0.000906  loss: 3.1478 (3.1756)  time: 12.6581  data: 0.0337  max mem: 9511\n",
      "Epoch: [5] Train  [ 20/183]  eta: 0:34:07  lr: 0.000905  loss: 3.4164 (3.2144)  time: 12.5245  data: 0.0004  max mem: 9511\n",
      "Epoch: [5] Train  [ 30/183]  eta: 0:31:58  lr: 0.000903  loss: 3.0911 (3.2736)  time: 12.4787  data: 0.0004  max mem: 9511\n",
      "Epoch: [5] Train  [ 40/183]  eta: 0:29:48  lr: 0.000902  loss: 3.5129 (3.2661)  time: 12.4505  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Train  [ 50/183]  eta: 0:27:47  lr: 0.000901  loss: 3.1916 (3.2850)  time: 12.5256  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Train  [ 60/183]  eta: 0:25:43  lr: 0.000899  loss: 3.0389 (3.2763)  time: 12.6292  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Train  [ 70/183]  eta: 0:23:36  lr: 0.000898  loss: 3.2843 (3.2772)  time: 12.5393  data: 0.0004  max mem: 9511\n",
      "Epoch: [5] Train  [ 80/183]  eta: 0:21:30  lr: 0.000897  loss: 3.2108 (3.2837)  time: 12.4685  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Train  [ 90/183]  eta: 0:19:24  lr: 0.000896  loss: 3.2473 (3.2853)  time: 12.4628  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Train  [100/183]  eta: 0:17:19  lr: 0.000894  loss: 3.4007 (3.2831)  time: 12.5163  data: 0.0004  max mem: 9511\n",
      "Epoch: [5] Train  [110/183]  eta: 0:15:16  lr: 0.000893  loss: 3.4730 (3.2755)  time: 12.6841  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Train  [120/183]  eta: 0:13:10  lr: 0.000892  loss: 3.3317 (3.2725)  time: 12.6675  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Train  [130/183]  eta: 0:11:04  lr: 0.000890  loss: 3.4026 (3.2641)  time: 12.5038  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Train  [140/183]  eta: 0:08:59  lr: 0.000889  loss: 3.1618 (3.2559)  time: 12.5181  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Train  [150/183]  eta: 0:06:53  lr: 0.000888  loss: 3.3057 (3.2550)  time: 12.4655  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Train  [160/183]  eta: 0:04:48  lr: 0.000887  loss: 2.9054 (3.2525)  time: 12.4734  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Train  [170/183]  eta: 0:02:42  lr: 0.000885  loss: 3.0823 (3.2428)  time: 12.5018  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Train  [180/183]  eta: 0:00:37  lr: 0.000884  loss: 3.0459 (3.2433)  time: 12.4070  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Train Total time: 0:38:11\n",
      "Epoch: [5] Test  [  0/242]  eta: 0:05:54    time: 1.4649  data: 0.3987  max mem: 9511\n",
      "Epoch: [5] Test  [ 10/242]  eta: 0:03:52    time: 1.0007  data: 0.0365  max mem: 9511\n",
      "Epoch: [5] Test  [ 20/242]  eta: 0:03:34    time: 0.9407  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [ 30/242]  eta: 0:03:30    time: 0.9902  data: 0.0004  max mem: 9511\n",
      "Epoch: [5] Test  [ 40/242]  eta: 0:03:23    time: 1.0516  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [ 50/242]  eta: 0:03:14    time: 1.0438  data: 0.0004  max mem: 9511\n",
      "Epoch: [5] Test  [ 60/242]  eta: 0:03:07    time: 1.0776  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [ 70/242]  eta: 0:02:57    time: 1.0877  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [ 80/242]  eta: 0:02:46    time: 1.0292  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [ 90/242]  eta: 0:02:35    time: 0.9790  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [100/242]  eta: 0:02:25    time: 1.0120  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [110/242]  eta: 0:02:15    time: 1.0303  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [120/242]  eta: 0:02:05    time: 1.0433  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [130/242]  eta: 0:01:54    time: 1.0312  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [140/242]  eta: 0:01:44    time: 0.9814  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [150/242]  eta: 0:01:33    time: 0.9892  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [160/242]  eta: 0:01:23    time: 1.0025  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [170/242]  eta: 0:01:13    time: 1.0517  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [180/242]  eta: 0:01:03    time: 1.1099  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [190/242]  eta: 0:00:53    time: 1.1123  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [200/242]  eta: 0:00:43    time: 1.0591  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Test  [210/242]  eta: 0:00:33    time: 1.0327  data: 0.0002  max mem: 9511\n",
      "Epoch: [5] Test  [220/242]  eta: 0:00:22    time: 1.0400  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [230/242]  eta: 0:00:12    time: 1.0460  data: 0.0003  max mem: 9511\n",
      "Epoch: [5] Test  [240/242]  eta: 0:00:02    time: 1.0114  data: 0.0004  max mem: 9511\n",
      "Epoch: [5] Test Total time: 0:04:09\n",
      "global correct: 95.7\n",
      "average row correct: ['97.3', '96.4', '89.3', '92.9', '88.0', '90.3', '98.9', '92.1', '97.3', '60.7', '93.7', '79.2', '89.9', '95.8', '96.9', '94.3', '75.9', '97.0', '75.2', '94.7', '90.1']\n",
      "IoU: ['95.3', '93.1', '61.2', '83.3', '77.6', '67.5', '96.2', '87.8', '89.1', '46.4', '91.1', '72.5', '82.3', '85.7', '90.7', '89.7', '66.5', '87.2', '60.0', '89.0', '77.8']\n",
      "mean IoU: 80.5\n",
      "Epoch: [6] Train  [  0/183]  eta: 0:40:23  lr: 0.000884  loss: 3.1872 (3.1872)  time: 13.2448  data: 0.4268  max mem: 9511\n",
      "Epoch: [6] Train  [ 10/183]  eta: 0:36:25  lr: 0.000882  loss: 3.1653 (3.3934)  time: 12.6350  data: 0.0404  max mem: 9511\n",
      "Epoch: [6] Train  [ 20/183]  eta: 0:34:07  lr: 0.000881  loss: 2.9124 (3.2934)  time: 12.5263  data: 0.0010  max mem: 9511\n",
      "Epoch: [6] Train  [ 30/183]  eta: 0:32:00  lr: 0.000880  loss: 3.1793 (3.2772)  time: 12.5084  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Train  [ 40/183]  eta: 0:29:50  lr: 0.000879  loss: 3.0025 (3.2375)  time: 12.4795  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Train  [ 50/183]  eta: 0:27:37  lr: 0.000877  loss: 3.1118 (3.2222)  time: 12.3198  data: 0.0004  max mem: 9511\n",
      "Epoch: [6] Train  [ 60/183]  eta: 0:25:33  lr: 0.000876  loss: 3.2024 (3.2091)  time: 12.3479  data: 0.0004  max mem: 9511\n",
      "Epoch: [6] Train  [ 70/183]  eta: 0:23:29  lr: 0.000875  loss: 2.8840 (3.2060)  time: 12.5182  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Train  [ 80/183]  eta: 0:21:22  lr: 0.000873  loss: 2.9403 (3.1799)  time: 12.4135  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Train  [ 90/183]  eta: 0:19:15  lr: 0.000872  loss: 3.2096 (3.1812)  time: 12.2596  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Train  [100/183]  eta: 0:17:11  lr: 0.000871  loss: 3.1485 (3.1745)  time: 12.3498  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Train  [110/183]  eta: 0:15:06  lr: 0.000870  loss: 3.3396 (3.1762)  time: 12.3997  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Train  [120/183]  eta: 0:13:02  lr: 0.000868  loss: 2.8616 (3.1681)  time: 12.3361  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Train  [130/183]  eta: 0:10:58  lr: 0.000867  loss: 2.9071 (3.1577)  time: 12.3717  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Train  [140/183]  eta: 0:08:53  lr: 0.000866  loss: 3.0698 (3.1541)  time: 12.3942  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Train  [150/183]  eta: 0:06:49  lr: 0.000865  loss: 2.7600 (3.1520)  time: 12.4295  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Train  [160/183]  eta: 0:04:45  lr: 0.000863  loss: 2.9488 (3.1450)  time: 12.5260  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Train  [170/183]  eta: 0:02:41  lr: 0.000862  loss: 3.3678 (3.1514)  time: 12.5778  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Train  [180/183]  eta: 0:00:37  lr: 0.000861  loss: 3.1120 (3.1502)  time: 12.5383  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Train Total time: 0:37:56\n",
      "Epoch: [6] Test  [  0/242]  eta: 0:05:53    time: 1.4611  data: 0.3980  max mem: 9511\n",
      "Epoch: [6] Test  [ 10/242]  eta: 0:03:50    time: 0.9945  data: 0.0364  max mem: 9511\n",
      "Epoch: [6] Test  [ 20/242]  eta: 0:03:33    time: 0.9377  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [ 30/242]  eta: 0:03:30    time: 0.9903  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [ 40/242]  eta: 0:03:23    time: 1.0509  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [ 50/242]  eta: 0:03:14    time: 1.0454  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Test  [ 60/242]  eta: 0:03:07    time: 1.0782  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [ 70/242]  eta: 0:02:57    time: 1.0862  data: 0.0004  max mem: 9511\n",
      "Epoch: [6] Test  [ 80/242]  eta: 0:02:46    time: 1.0296  data: 0.0004  max mem: 9511\n",
      "Epoch: [6] Test  [ 90/242]  eta: 0:02:35    time: 0.9808  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [100/242]  eta: 0:02:25    time: 1.0133  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Test  [110/242]  eta: 0:02:15    time: 1.0292  data: 0.0004  max mem: 9511\n",
      "Epoch: [6] Test  [120/242]  eta: 0:02:05    time: 1.0435  data: 0.0004  max mem: 9511\n",
      "Epoch: [6] Test  [130/242]  eta: 0:01:54    time: 1.0324  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [140/242]  eta: 0:01:44    time: 0.9802  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [150/242]  eta: 0:01:33    time: 0.9893  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Test  [160/242]  eta: 0:01:23    time: 1.0046  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [170/242]  eta: 0:01:13    time: 1.0529  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [180/242]  eta: 0:01:03    time: 1.1117  data: 0.0002  max mem: 9511\n",
      "Epoch: [6] Test  [190/242]  eta: 0:00:53    time: 1.1143  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [200/242]  eta: 0:00:43    time: 1.0603  data: 0.0004  max mem: 9511\n",
      "Epoch: [6] Test  [210/242]  eta: 0:00:33    time: 1.0335  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [220/242]  eta: 0:00:22    time: 1.0411  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [230/242]  eta: 0:00:12    time: 1.0471  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test  [240/242]  eta: 0:00:02    time: 1.0092  data: 0.0003  max mem: 9511\n",
      "Epoch: [6] Test Total time: 0:04:09\n",
      "global correct: 95.0\n",
      "average row correct: ['96.5', '96.7', '86.4', '93.2', '89.1', '90.0', '98.8', '92.6', '97.1', '69.9', '93.6', '79.7', '91.8', '92.3', '96.7', '94.2', '80.4', '97.2', '67.8', '93.0', '91.4']\n",
      "IoU: ['94.6', '84.2', '64.4', '84.2', '68.4', '73.6', '95.3', '85.3', '90.0', '42.8', '89.8', '71.5', '85.5', '87.0', '87.2', '89.9', '62.5', '73.4', '54.2', '87.0', '65.6']\n",
      "mean IoU: 77.9\n",
      "Epoch: [7] Train  [  0/183]  eta: 0:40:11  lr: 0.000860  loss: 3.3717 (3.3717)  time: 13.1763  data: 0.4300  max mem: 9511\n",
      "Epoch: [7] Train  [ 10/183]  eta: 0:36:36  lr: 0.000859  loss: 3.2278 (3.0770)  time: 12.6943  data: 0.0393  max mem: 9511\n",
      "Epoch: [7] Train  [ 20/183]  eta: 0:34:14  lr: 0.000858  loss: 3.0796 (3.0678)  time: 12.5748  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [ 30/183]  eta: 0:32:05  lr: 0.000856  loss: 3.1042 (3.0624)  time: 12.5260  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [ 40/183]  eta: 0:29:59  lr: 0.000855  loss: 2.8594 (3.0520)  time: 12.5590  data: 0.0004  max mem: 9511\n",
      "Epoch: [7] Train  [ 50/183]  eta: 0:27:49  lr: 0.000854  loss: 3.2132 (3.0565)  time: 12.4994  data: 0.0005  max mem: 9511\n",
      "Epoch: [7] Train  [ 60/183]  eta: 0:25:44  lr: 0.000853  loss: 2.8807 (3.0419)  time: 12.5030  data: 0.0005  max mem: 9511\n",
      "Epoch: [7] Train  [ 70/183]  eta: 0:23:40  lr: 0.000851  loss: 2.7637 (3.0380)  time: 12.6117  data: 0.0004  max mem: 9511\n",
      "Epoch: [7] Train  [ 80/183]  eta: 0:21:31  lr: 0.000850  loss: 2.9536 (3.0663)  time: 12.5045  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [ 90/183]  eta: 0:19:25  lr: 0.000849  loss: 3.0287 (3.0672)  time: 12.3934  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [100/183]  eta: 0:17:20  lr: 0.000847  loss: 2.7609 (3.0650)  time: 12.5218  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [110/183]  eta: 0:15:15  lr: 0.000846  loss: 2.9031 (3.0551)  time: 12.5586  data: 0.0002  max mem: 9511\n",
      "Epoch: [7] Train  [120/183]  eta: 0:13:09  lr: 0.000845  loss: 3.1473 (3.0553)  time: 12.4693  data: 0.0002  max mem: 9511\n",
      "Epoch: [7] Train  [130/183]  eta: 0:11:03  lr: 0.000844  loss: 3.5149 (3.0518)  time: 12.3804  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [140/183]  eta: 0:08:57  lr: 0.000842  loss: 2.7679 (3.0462)  time: 12.3807  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [150/183]  eta: 0:06:53  lr: 0.000841  loss: 3.4066 (3.0493)  time: 12.5518  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [160/183]  eta: 0:04:47  lr: 0.000840  loss: 3.0624 (3.0491)  time: 12.5426  data: 0.0004  max mem: 9511\n",
      "Epoch: [7] Train  [170/183]  eta: 0:02:42  lr: 0.000838  loss: 2.9561 (3.0521)  time: 12.4847  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train  [180/183]  eta: 0:00:37  lr: 0.000837  loss: 3.0602 (3.0536)  time: 12.4978  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Train Total time: 0:38:08\n",
      "Epoch: [7] Test  [  0/242]  eta: 0:06:01    time: 1.4934  data: 0.4153  max mem: 9511\n",
      "Epoch: [7] Test  [ 10/242]  eta: 0:03:51    time: 0.9991  data: 0.0380  max mem: 9511\n",
      "Epoch: [7] Test  [ 20/242]  eta: 0:03:34    time: 0.9394  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [ 30/242]  eta: 0:03:30    time: 0.9897  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [ 40/242]  eta: 0:03:23    time: 1.0492  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [ 50/242]  eta: 0:03:14    time: 1.0448  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [ 60/242]  eta: 0:03:07    time: 1.0778  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [ 70/242]  eta: 0:02:57    time: 1.0884  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [ 80/242]  eta: 0:02:46    time: 1.0332  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [ 90/242]  eta: 0:02:35    time: 0.9810  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [100/242]  eta: 0:02:25    time: 1.0129  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [110/242]  eta: 0:02:15    time: 1.0303  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [120/242]  eta: 0:02:05    time: 1.0425  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [130/242]  eta: 0:01:54    time: 1.0328  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [140/242]  eta: 0:01:44    time: 0.9845  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [150/242]  eta: 0:01:33    time: 0.9928  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [160/242]  eta: 0:01:23    time: 1.0064  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [170/242]  eta: 0:01:13    time: 1.0542  data: 0.0002  max mem: 9511\n",
      "Epoch: [7] Test  [180/242]  eta: 0:01:03    time: 1.1137  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [190/242]  eta: 0:00:53    time: 1.1162  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [200/242]  eta: 0:00:43    time: 1.0608  data: 0.0002  max mem: 9511\n",
      "Epoch: [7] Test  [210/242]  eta: 0:00:33    time: 1.0359  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [220/242]  eta: 0:00:22    time: 1.0445  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [230/242]  eta: 0:00:12    time: 1.0502  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test  [240/242]  eta: 0:00:02    time: 1.0116  data: 0.0003  max mem: 9511\n",
      "Epoch: [7] Test Total time: 0:04:09\n",
      "global correct: 95.1\n",
      "average row correct: ['96.6', '97.9', '86.2', '94.7', '91.0', '90.1', '98.6', '93.7', '97.0', '71.1', '95.3', '75.2', '93.1', '92.3', '92.4', '93.8', '79.2', '95.4', '72.3', '92.6', '89.8']\n",
      "IoU: ['94.6', '88.4', '62.1', '87.8', '73.0', '72.8', '94.0', '86.3', '90.3', '39.2', '88.0', '68.8', '85.8', '87.8', '88.2', '89.5', '65.8', '86.5', '54.9', '86.7', '72.7']\n",
      "mean IoU: 79.2\n",
      "Epoch: [8] Train  [  0/183]  eta: 0:40:03  lr: 0.000837  loss: 3.1100 (3.1100)  time: 13.1329  data: 0.3779  max mem: 9511\n",
      "Epoch: [8] Train  [ 10/183]  eta: 0:36:42  lr: 0.000835  loss: 3.0567 (3.0194)  time: 12.7294  data: 0.0346  max mem: 9511\n",
      "Epoch: [8] Train  [ 20/183]  eta: 0:34:12  lr: 0.000834  loss: 2.8215 (2.9420)  time: 12.5627  data: 0.0002  max mem: 9511\n",
      "Epoch: [8] Train  [ 30/183]  eta: 0:31:55  lr: 0.000833  loss: 3.1683 (2.9717)  time: 12.4021  data: 0.0002  max mem: 9511\n",
      "Epoch: [8] Train  [ 40/183]  eta: 0:29:48  lr: 0.000832  loss: 3.9479 (3.0222)  time: 12.4201  data: 0.0002  max mem: 9511\n",
      "Epoch: [8] Train  [ 50/183]  eta: 0:27:45  lr: 0.000830  loss: 2.8414 (2.9912)  time: 12.5257  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Train  [ 60/183]  eta: 0:25:39  lr: 0.000829  loss: 2.7124 (2.9961)  time: 12.5416  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Train  [ 70/183]  eta: 0:23:33  lr: 0.000828  loss: 3.3213 (2.9908)  time: 12.4824  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Train  [ 80/183]  eta: 0:21:28  lr: 0.000826  loss: 2.8312 (2.9875)  time: 12.4768  data: 0.0004  max mem: 9511\n",
      "Epoch: [8] Train  [ 90/183]  eta: 0:19:20  lr: 0.000825  loss: 3.0746 (2.9857)  time: 12.3859  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Train  [100/183]  eta: 0:17:15  lr: 0.000824  loss: 2.7670 (2.9799)  time: 12.3403  data: 0.0004  max mem: 9511\n",
      "Epoch: [8] Train  [110/183]  eta: 0:15:10  lr: 0.000823  loss: 3.0845 (2.9766)  time: 12.4068  data: 0.0009  max mem: 9511\n",
      "Epoch: [8] Train  [120/183]  eta: 0:13:06  lr: 0.000821  loss: 2.9592 (2.9878)  time: 12.5435  data: 0.0009  max mem: 9511\n",
      "Epoch: [8] Train  [130/183]  eta: 0:11:01  lr: 0.000820  loss: 2.7591 (2.9875)  time: 12.4925  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Train  [140/183]  eta: 0:08:55  lr: 0.000819  loss: 2.6313 (2.9977)  time: 12.3293  data: 0.0004  max mem: 9511\n",
      "Epoch: [8] Train  [150/183]  eta: 0:06:51  lr: 0.000817  loss: 2.8429 (2.9985)  time: 12.3937  data: 0.0004  max mem: 9511\n",
      "Epoch: [8] Train  [160/183]  eta: 0:04:46  lr: 0.000816  loss: 2.6294 (2.9954)  time: 12.5073  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Train  [170/183]  eta: 0:02:42  lr: 0.000815  loss: 3.0275 (2.9953)  time: 12.4948  data: 0.0002  max mem: 9511\n",
      "Epoch: [8] Train  [180/183]  eta: 0:00:37  lr: 0.000814  loss: 2.9332 (2.9925)  time: 12.3586  data: 0.0002  max mem: 9511\n",
      "Epoch: [8] Train Total time: 0:38:00\n",
      "Epoch: [8] Test  [  0/242]  eta: 0:05:56    time: 1.4720  data: 0.3859  max mem: 9511\n",
      "Epoch: [8] Test  [ 10/242]  eta: 0:03:51    time: 0.9988  data: 0.0355  max mem: 9511\n",
      "Epoch: [8] Test  [ 20/242]  eta: 0:03:34    time: 0.9403  data: 0.0004  max mem: 9511\n",
      "Epoch: [8] Test  [ 30/242]  eta: 0:03:30    time: 0.9919  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [ 40/242]  eta: 0:03:23    time: 1.0527  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [ 50/242]  eta: 0:03:14    time: 1.0469  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [ 60/242]  eta: 0:03:07    time: 1.0789  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [ 70/242]  eta: 0:02:58    time: 1.0873  data: 0.0004  max mem: 9511\n",
      "Epoch: [8] Test  [ 80/242]  eta: 0:02:47    time: 1.0306  data: 0.0004  max mem: 9511\n",
      "Epoch: [8] Test  [ 90/242]  eta: 0:02:35    time: 0.9796  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [100/242]  eta: 0:02:25    time: 1.0160  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [110/242]  eta: 0:02:15    time: 1.0333  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [120/242]  eta: 0:02:05    time: 1.0437  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [130/242]  eta: 0:01:54    time: 1.0312  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [140/242]  eta: 0:01:44    time: 0.9802  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [150/242]  eta: 0:01:33    time: 0.9878  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [160/242]  eta: 0:01:23    time: 1.0000  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [170/242]  eta: 0:01:13    time: 1.0495  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [180/242]  eta: 0:01:03    time: 1.1101  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [190/242]  eta: 0:00:53    time: 1.1152  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [200/242]  eta: 0:00:43    time: 1.0604  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [210/242]  eta: 0:00:33    time: 1.0329  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [220/242]  eta: 0:00:22    time: 1.0418  data: 0.0002  max mem: 9511\n",
      "Epoch: [8] Test  [230/242]  eta: 0:00:12    time: 1.0475  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test  [240/242]  eta: 0:00:02    time: 1.0093  data: 0.0003  max mem: 9511\n",
      "Epoch: [8] Test Total time: 0:04:09\n",
      "global correct: 95.1\n",
      "average row correct: ['97.4', '97.3', '88.7', '95.6', '88.4', '88.3', '99.0', '88.6', '97.4', '64.1', '92.6', '65.3', '84.1', '90.0', '93.0', '93.6', '73.3', '96.3', '62.3', '94.0', '89.0']\n",
      "IoU: ['94.9', '93.4', '61.6', '86.7', '72.7', '69.8', '91.7', '85.8', '81.4', '45.1', '86.1', '60.0', '79.6', '85.8', '87.6', '89.1', '65.2', '78.4', '52.3', '89.5', '75.3']\n",
      "mean IoU: 77.7\n",
      "Epoch: [9] Train  [  0/183]  eta: 0:36:51  lr: 0.000813  loss: 3.0597 (3.0597)  time: 12.0855  data: 0.3907  max mem: 9511\n",
      "Epoch: [9] Train  [ 10/183]  eta: 0:35:46  lr: 0.000812  loss: 2.7299 (2.8929)  time: 12.4072  data: 0.0357  max mem: 9511\n",
      "Epoch: [9] Train  [ 20/183]  eta: 0:33:48  lr: 0.000811  loss: 3.9261 (3.0237)  time: 12.4655  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Train  [ 30/183]  eta: 0:31:43  lr: 0.000809  loss: 2.8515 (2.9988)  time: 12.4636  data: 0.0004  max mem: 9511\n",
      "Epoch: [9] Train  [ 40/183]  eta: 0:29:37  lr: 0.000808  loss: 3.0059 (2.9966)  time: 12.4099  data: 0.0004  max mem: 9511\n",
      "Epoch: [9] Train  [ 50/183]  eta: 0:27:31  lr: 0.000807  loss: 2.8296 (2.9818)  time: 12.3780  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Train  [ 60/183]  eta: 0:25:28  lr: 0.000805  loss: 2.7918 (2.9811)  time: 12.4120  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Train  [ 70/183]  eta: 0:23:23  lr: 0.000804  loss: 2.8715 (2.9640)  time: 12.4349  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Train  [ 80/183]  eta: 0:21:19  lr: 0.000803  loss: 2.8188 (2.9650)  time: 12.4190  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Train  [ 90/183]  eta: 0:19:15  lr: 0.000802  loss: 2.9051 (2.9706)  time: 12.4208  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Train  [100/183]  eta: 0:17:11  lr: 0.000800  loss: 2.7280 (2.9635)  time: 12.4350  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Train  [110/183]  eta: 0:15:06  lr: 0.000799  loss: 2.8313 (2.9617)  time: 12.4327  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Train  [120/183]  eta: 0:13:02  lr: 0.000798  loss: 2.7836 (2.9665)  time: 12.4320  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Train  [130/183]  eta: 0:10:58  lr: 0.000796  loss: 3.0754 (2.9671)  time: 12.3951  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Train  [140/183]  eta: 0:08:54  lr: 0.000795  loss: 2.9077 (2.9576)  time: 12.4773  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Train  [150/183]  eta: 0:06:50  lr: 0.000794  loss: 3.0782 (2.9609)  time: 12.5213  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Train  [160/183]  eta: 0:04:46  lr: 0.000793  loss: 3.0523 (2.9587)  time: 12.4593  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Train  [170/183]  eta: 0:02:41  lr: 0.000791  loss: 2.9253 (2.9546)  time: 12.4010  data: 0.0004  max mem: 9511\n",
      "Epoch: [9] Train  [180/183]  eta: 0:00:37  lr: 0.000790  loss: 3.2035 (2.9532)  time: 12.3434  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Train Total time: 0:37:54\n",
      "Epoch: [9] Test  [  0/242]  eta: 0:05:47    time: 1.4339  data: 0.3656  max mem: 9511\n",
      "Epoch: [9] Test  [ 10/242]  eta: 0:03:50    time: 0.9923  data: 0.0335  max mem: 9511\n",
      "Epoch: [9] Test  [ 20/242]  eta: 0:03:33    time: 0.9371  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [ 30/242]  eta: 0:03:29    time: 0.9881  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [ 40/242]  eta: 0:03:22    time: 1.0495  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [ 50/242]  eta: 0:03:14    time: 1.0449  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [ 60/242]  eta: 0:03:07    time: 1.0789  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [ 70/242]  eta: 0:02:57    time: 1.0877  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [ 80/242]  eta: 0:02:46    time: 1.0301  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Test  [ 90/242]  eta: 0:02:35    time: 0.9796  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [100/242]  eta: 0:02:25    time: 1.0146  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [110/242]  eta: 0:02:15    time: 1.0327  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [120/242]  eta: 0:02:05    time: 1.0422  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [130/242]  eta: 0:01:54    time: 1.0302  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [140/242]  eta: 0:01:44    time: 0.9821  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [150/242]  eta: 0:01:33    time: 0.9916  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [160/242]  eta: 0:01:23    time: 1.0042  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [170/242]  eta: 0:01:13    time: 1.0522  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [180/242]  eta: 0:01:03    time: 1.1130  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [190/242]  eta: 0:00:53    time: 1.1160  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [200/242]  eta: 0:00:43    time: 1.0611  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [210/242]  eta: 0:00:33    time: 1.0345  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [220/242]  eta: 0:00:22    time: 1.0423  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [230/242]  eta: 0:00:12    time: 1.0485  data: 0.0003  max mem: 9511\n",
      "Epoch: [9] Test  [240/242]  eta: 0:00:02    time: 1.0108  data: 0.0002  max mem: 9511\n",
      "Epoch: [9] Test Total time: 0:04:09\n",
      "global correct: 95.4\n",
      "average row correct: ['97.0', '96.5', '83.6', '94.2', '91.0', '75.0', '98.9', '95.7', '96.0', '56.5', '96.0', '75.4', '92.1', '89.9', '96.8', '94.9', '76.0', '95.9', '82.3', '95.7', '89.7']\n",
      "IoU: ['94.9', '93.3', '59.5', '88.0', '72.5', '67.3', '93.6', '89.9', '89.7', '45.5', '89.4', '67.3', '86.9', '85.7', '89.6', '90.1', '65.7', '85.3', '52.0', '88.3', '79.5']\n",
      "mean IoU: 79.7\n",
      "Epoch: [10] Train  [  0/183]  eta: 0:38:42  lr: 0.000790  loss: 2.5947 (2.5947)  time: 12.6931  data: 0.4175  max mem: 9511\n",
      "Epoch: [10] Train  [ 10/183]  eta: 0:35:41  lr: 0.000788  loss: 2.9402 (2.8182)  time: 12.3800  data: 0.0383  max mem: 9511\n",
      "Epoch: [10] Train  [ 20/183]  eta: 0:33:39  lr: 0.000787  loss: 3.0016 (2.8587)  time: 12.3774  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Train  [ 30/183]  eta: 0:31:32  lr: 0.000786  loss: 3.2984 (2.8690)  time: 12.3674  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Train  [ 40/183]  eta: 0:29:31  lr: 0.000784  loss: 3.2827 (2.9112)  time: 12.3848  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Train  [ 50/183]  eta: 0:27:28  lr: 0.000783  loss: 2.8533 (2.9225)  time: 12.4363  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Train  [ 60/183]  eta: 0:25:28  lr: 0.000782  loss: 2.6706 (2.9247)  time: 12.4983  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Train  [ 70/183]  eta: 0:23:21  lr: 0.000780  loss: 2.5703 (2.9081)  time: 12.4291  data: 0.0005  max mem: 9511\n",
      "Epoch: [10] Train  [ 80/183]  eta: 0:21:17  lr: 0.000779  loss: 2.6399 (2.8936)  time: 12.3262  data: 0.0005  max mem: 9511\n",
      "Epoch: [10] Train  [ 90/183]  eta: 0:19:12  lr: 0.000778  loss: 3.0854 (2.8976)  time: 12.3603  data: 0.0005  max mem: 9511\n",
      "Epoch: [10] Train  [100/183]  eta: 0:17:09  lr: 0.000777  loss: 2.6619 (2.8967)  time: 12.4030  data: 0.0006  max mem: 9511\n",
      "Epoch: [10] Train  [110/183]  eta: 0:15:06  lr: 0.000775  loss: 2.5538 (2.8984)  time: 12.4812  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Train  [120/183]  eta: 0:13:01  lr: 0.000774  loss: 3.6642 (2.9092)  time: 12.4449  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Train  [130/183]  eta: 0:10:57  lr: 0.000773  loss: 2.6381 (2.9042)  time: 12.3432  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Train  [140/183]  eta: 0:08:53  lr: 0.000771  loss: 2.8658 (2.9060)  time: 12.3906  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Train  [150/183]  eta: 0:06:49  lr: 0.000770  loss: 2.9443 (2.9005)  time: 12.4994  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Train  [160/183]  eta: 0:04:45  lr: 0.000769  loss: 2.8071 (2.8941)  time: 12.4925  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Train  [170/183]  eta: 0:02:41  lr: 0.000768  loss: 3.1170 (2.8989)  time: 12.4230  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Train  [180/183]  eta: 0:00:37  lr: 0.000766  loss: 2.6490 (2.9019)  time: 12.4040  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Train Total time: 0:37:52\n",
      "Epoch: [10] Test  [  0/242]  eta: 0:05:53    time: 1.4597  data: 0.3970  max mem: 9511\n",
      "Epoch: [10] Test  [ 10/242]  eta: 0:03:51    time: 0.9977  data: 0.0363  max mem: 9511\n",
      "Epoch: [10] Test  [ 20/242]  eta: 0:03:34    time: 0.9399  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [ 30/242]  eta: 0:03:30    time: 0.9905  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [ 40/242]  eta: 0:03:23    time: 1.0511  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [ 50/242]  eta: 0:03:14    time: 1.0461  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [ 60/242]  eta: 0:03:07    time: 1.0788  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [ 70/242]  eta: 0:02:57    time: 1.0867  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [ 80/242]  eta: 0:02:46    time: 1.0277  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [ 90/242]  eta: 0:02:35    time: 0.9777  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [100/242]  eta: 0:02:25    time: 1.0136  data: 0.0005  max mem: 9511\n",
      "Epoch: [10] Test  [110/242]  eta: 0:02:15    time: 1.0312  data: 0.0005  max mem: 9511\n",
      "Epoch: [10] Test  [120/242]  eta: 0:02:05    time: 1.0442  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [130/242]  eta: 0:01:54    time: 1.0320  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [140/242]  eta: 0:01:44    time: 0.9809  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [150/242]  eta: 0:01:33    time: 0.9897  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [160/242]  eta: 0:01:23    time: 1.0024  data: 0.0004  max mem: 9511\n",
      "Epoch: [10] Test  [170/242]  eta: 0:01:13    time: 1.0505  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [180/242]  eta: 0:01:03    time: 1.1104  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [190/242]  eta: 0:00:53    time: 1.1124  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [200/242]  eta: 0:00:43    time: 1.0586  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [210/242]  eta: 0:00:33    time: 1.0319  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [220/242]  eta: 0:00:22    time: 1.0392  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test  [230/242]  eta: 0:00:12    time: 1.0457  data: 0.0002  max mem: 9511\n",
      "Epoch: [10] Test  [240/242]  eta: 0:00:02    time: 1.0070  data: 0.0003  max mem: 9511\n",
      "Epoch: [10] Test Total time: 0:04:09\n",
      "global correct: 95.2\n",
      "average row correct: ['96.6', '97.3', '88.7', '94.4', '94.3', '90.4', '98.7', '95.4', '98.0', '63.2', '96.3', '83.7', '86.3', '91.8', '97.2', '95.5', '74.1', '86.9', '67.9', '97.1', '89.0']\n",
      "IoU: ['94.9', '88.9', '58.5', '88.9', '74.6', '72.5', '95.7', '89.5', '83.3', '46.1', '84.6', '70.4', '80.4', '86.2', '87.2', '88.8', '66.0', '81.3', '53.2', '88.7', '72.2']\n",
      "mean IoU: 78.7\n",
      "Epoch: [11] Train  [  0/183]  eta: 0:39:47  lr: 0.000766  loss: 2.5290 (2.5290)  time: 13.0453  data: 0.4054  max mem: 9511\n",
      "Epoch: [11] Train  [ 10/183]  eta: 0:35:49  lr: 0.000765  loss: 2.6412 (2.8402)  time: 12.4248  data: 0.0372  max mem: 9511\n",
      "Epoch: [11] Train  [ 20/183]  eta: 0:33:56  lr: 0.000763  loss: 3.2394 (2.9026)  time: 12.4672  data: 0.0004  max mem: 9511\n",
      "Epoch: [11] Train  [ 30/183]  eta: 0:31:50  lr: 0.000762  loss: 2.9263 (2.8976)  time: 12.5173  data: 0.0004  max mem: 9511\n",
      "Epoch: [11] Train  [ 40/183]  eta: 0:29:46  lr: 0.000761  loss: 2.8412 (2.9016)  time: 12.4868  data: 0.0004  max mem: 9511\n",
      "Epoch: [11] Train  [ 50/183]  eta: 0:27:39  lr: 0.000759  loss: 2.6469 (2.8753)  time: 12.4644  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [ 60/183]  eta: 0:25:30  lr: 0.000758  loss: 2.9394 (2.8708)  time: 12.3426  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [ 70/183]  eta: 0:23:26  lr: 0.000757  loss: 2.9713 (2.8691)  time: 12.3687  data: 0.0002  max mem: 9511\n",
      "Epoch: [11] Train  [ 80/183]  eta: 0:21:20  lr: 0.000755  loss: 2.6414 (2.8632)  time: 12.4006  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [ 90/183]  eta: 0:19:15  lr: 0.000754  loss: 2.8723 (2.8659)  time: 12.3571  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [100/183]  eta: 0:17:12  lr: 0.000753  loss: 2.7777 (2.8735)  time: 12.4733  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [110/183]  eta: 0:15:09  lr: 0.000752  loss: 2.6970 (2.8749)  time: 12.5690  data: 0.0004  max mem: 9511\n",
      "Epoch: [11] Train  [120/183]  eta: 0:13:04  lr: 0.000750  loss: 2.9651 (2.8780)  time: 12.5140  data: 0.0004  max mem: 9511\n",
      "Epoch: [11] Train  [130/183]  eta: 0:10:59  lr: 0.000749  loss: 2.5097 (2.8677)  time: 12.4174  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [140/183]  eta: 0:08:54  lr: 0.000748  loss: 2.6343 (2.8749)  time: 12.3633  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [150/183]  eta: 0:06:50  lr: 0.000746  loss: 2.6456 (2.8731)  time: 12.4052  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [160/183]  eta: 0:04:46  lr: 0.000745  loss: 2.6175 (2.8693)  time: 12.4252  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [170/183]  eta: 0:02:41  lr: 0.000744  loss: 2.6832 (2.8639)  time: 12.3337  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train  [180/183]  eta: 0:00:37  lr: 0.000742  loss: 2.8328 (2.8640)  time: 12.3728  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Train Total time: 0:37:55\n",
      "Epoch: [11] Test  [  0/242]  eta: 0:06:01    time: 1.4933  data: 0.4209  max mem: 9511\n",
      "Epoch: [11] Test  [ 10/242]  eta: 0:03:52    time: 1.0023  data: 0.0385  max mem: 9511\n",
      "Epoch: [11] Test  [ 20/242]  eta: 0:03:34    time: 0.9392  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [ 30/242]  eta: 0:03:30    time: 0.9865  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [ 40/242]  eta: 0:03:23    time: 1.0483  data: 0.0002  max mem: 9511\n",
      "Epoch: [11] Test  [ 50/242]  eta: 0:03:14    time: 1.0441  data: 0.0002  max mem: 9511\n",
      "Epoch: [11] Test  [ 60/242]  eta: 0:03:07    time: 1.0780  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [ 70/242]  eta: 0:02:57    time: 1.0882  data: 0.0002  max mem: 9511\n",
      "Epoch: [11] Test  [ 80/242]  eta: 0:02:46    time: 1.0305  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [ 90/242]  eta: 0:02:35    time: 0.9800  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [100/242]  eta: 0:02:25    time: 1.0129  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [110/242]  eta: 0:02:15    time: 1.0291  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [120/242]  eta: 0:02:05    time: 1.0407  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [130/242]  eta: 0:01:54    time: 1.0290  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [140/242]  eta: 0:01:44    time: 0.9801  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [150/242]  eta: 0:01:33    time: 0.9893  data: 0.0002  max mem: 9511\n",
      "Epoch: [11] Test  [160/242]  eta: 0:01:23    time: 1.0025  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [170/242]  eta: 0:01:13    time: 1.0512  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [180/242]  eta: 0:01:03    time: 1.1121  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [190/242]  eta: 0:00:53    time: 1.1157  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [200/242]  eta: 0:00:43    time: 1.0605  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [210/242]  eta: 0:00:33    time: 1.0330  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [220/242]  eta: 0:00:22    time: 1.0403  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [230/242]  eta: 0:00:12    time: 1.0487  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test  [240/242]  eta: 0:00:02    time: 1.0119  data: 0.0003  max mem: 9511\n",
      "Epoch: [11] Test Total time: 0:04:09\n",
      "global correct: 95.4\n",
      "average row correct: ['97.5', '95.9', '89.0', '95.6', '90.3', '88.2', '97.8', '94.2', '97.9', '63.7', '91.7', '80.6', '83.5', '91.9', '95.0', '94.7', '75.3', '96.1', '61.3', '88.2', '87.1']\n",
      "IoU: ['95.3', '90.9', '63.4', '89.6', '77.5', '73.1', '95.3', '90.1', '81.2', '42.5', '85.9', '70.3', '75.6', '88.4', '90.2', '89.5', '65.3', '84.3', '53.1', '85.0', '79.4']\n",
      "mean IoU: 79.3\n",
      "Epoch: [12] Train  [  0/183]  eta: 0:40:16  lr: 0.000742  loss: 2.7750 (2.7750)  time: 13.2032  data: 0.4048  max mem: 9511\n",
      "Epoch: [12] Train  [ 10/183]  eta: 0:36:12  lr: 0.000741  loss: 2.7525 (2.8168)  time: 12.5551  data: 0.0370  max mem: 9511\n",
      "Epoch: [12] Train  [ 20/183]  eta: 0:33:44  lr: 0.000739  loss: 3.1463 (2.8405)  time: 12.3821  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Train  [ 30/183]  eta: 0:31:43  lr: 0.000738  loss: 2.7489 (2.8350)  time: 12.3830  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Train  [ 40/183]  eta: 0:29:43  lr: 0.000737  loss: 2.5613 (2.8306)  time: 12.5208  data: 0.0004  max mem: 9511\n",
      "Epoch: [12] Train  [ 50/183]  eta: 0:27:36  lr: 0.000735  loss: 2.7054 (2.8266)  time: 12.4756  data: 0.0004  max mem: 9511\n",
      "Epoch: [12] Train  [ 60/183]  eta: 0:25:29  lr: 0.000734  loss: 2.7902 (2.8338)  time: 12.3752  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Train  [ 70/183]  eta: 0:23:29  lr: 0.000733  loss: 2.8025 (2.8216)  time: 12.5014  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Train  [ 80/183]  eta: 0:21:24  lr: 0.000732  loss: 2.8027 (2.8203)  time: 12.5615  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Train  [ 90/183]  eta: 0:19:18  lr: 0.000730  loss: 2.5828 (2.8179)  time: 12.4343  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Train  [100/183]  eta: 0:17:14  lr: 0.000729  loss: 3.0179 (2.8315)  time: 12.4660  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Train  [110/183]  eta: 0:15:10  lr: 0.000728  loss: 2.9945 (2.8364)  time: 12.4922  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Train  [120/183]  eta: 0:13:04  lr: 0.000726  loss: 3.0398 (2.8441)  time: 12.3510  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Train  [130/183]  eta: 0:10:59  lr: 0.000725  loss: 2.4748 (2.8402)  time: 12.2592  data: 0.0004  max mem: 9511\n",
      "Epoch: [12] Train  [140/183]  eta: 0:08:53  lr: 0.000724  loss: 2.9347 (2.8369)  time: 12.2273  data: 0.0004  max mem: 9511\n",
      "Epoch: [12] Train  [150/183]  eta: 0:06:49  lr: 0.000722  loss: 2.8326 (2.8256)  time: 12.2615  data: 0.0004  max mem: 9511\n",
      "Epoch: [12] Train  [160/183]  eta: 0:04:45  lr: 0.000721  loss: 2.8247 (2.8241)  time: 12.4127  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Train  [170/183]  eta: 0:02:41  lr: 0.000720  loss: 2.7605 (2.8267)  time: 12.5045  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Train  [180/183]  eta: 0:00:37  lr: 0.000719  loss: 2.8355 (2.8296)  time: 12.5708  data: 0.0010  max mem: 9511\n",
      "Epoch: [12] Train Total time: 0:37:56\n",
      "Epoch: [12] Test  [  0/242]  eta: 0:06:01    time: 1.4935  data: 0.4275  max mem: 9511\n",
      "Epoch: [12] Test  [ 10/242]  eta: 0:03:52    time: 1.0010  data: 0.0391  max mem: 9511\n",
      "Epoch: [12] Test  [ 20/242]  eta: 0:03:34    time: 0.9397  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [ 30/242]  eta: 0:03:30    time: 0.9899  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Test  [ 40/242]  eta: 0:03:23    time: 1.0511  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [ 50/242]  eta: 0:03:14    time: 1.0446  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [ 60/242]  eta: 0:03:07    time: 1.0776  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [ 70/242]  eta: 0:02:57    time: 1.0880  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [ 80/242]  eta: 0:02:46    time: 1.0309  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [ 90/242]  eta: 0:02:35    time: 0.9809  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Test  [100/242]  eta: 0:02:25    time: 1.0144  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Test  [110/242]  eta: 0:02:15    time: 1.0297  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Test  [120/242]  eta: 0:02:05    time: 1.0443  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Test  [130/242]  eta: 0:01:54    time: 1.0337  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Test  [140/242]  eta: 0:01:44    time: 0.9813  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [150/242]  eta: 0:01:33    time: 0.9908  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [160/242]  eta: 0:01:23    time: 1.0043  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Test  [170/242]  eta: 0:01:13    time: 1.0535  data: 0.0002  max mem: 9511\n",
      "Epoch: [12] Test  [180/242]  eta: 0:01:03    time: 1.1125  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [190/242]  eta: 0:00:53    time: 1.1134  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [200/242]  eta: 0:00:43    time: 1.0588  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [210/242]  eta: 0:00:33    time: 1.0331  data: 0.0010  max mem: 9511\n",
      "Epoch: [12] Test  [220/242]  eta: 0:00:22    time: 1.0401  data: 0.0010  max mem: 9511\n",
      "Epoch: [12] Test  [230/242]  eta: 0:00:12    time: 1.0469  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test  [240/242]  eta: 0:00:02    time: 1.0123  data: 0.0003  max mem: 9511\n",
      "Epoch: [12] Test Total time: 0:04:09\n",
      "global correct: 95.1\n",
      "average row correct: ['97.2', '95.9', '89.0', '95.5', '93.1', '86.3', '99.1', '94.7', '96.6', '76.2', '92.8', '78.2', '81.5', '92.0', '96.1', '93.4', '74.1', '94.5', '54.6', '90.1', '91.4']\n",
      "IoU: ['95.0', '92.2', '59.4', '88.2', '69.1', '75.8', '93.3', '90.1', '81.1', '43.3', '86.5', '69.2', '75.3', '87.8', '88.7', '89.3', '65.0', '83.9', '50.9', '84.7', '69.2']\n",
      "mean IoU: 78.0\n",
      "Epoch: [13] Train  [  0/183]  eta: 0:38:00  lr: 0.000718  loss: 2.8126 (2.8126)  time: 12.4620  data: 0.4083  max mem: 9511\n",
      "Epoch: [13] Train  [ 10/183]  eta: 0:36:08  lr: 0.000717  loss: 2.7175 (2.7775)  time: 12.5342  data: 0.0373  max mem: 9511\n",
      "Epoch: [13] Train  [ 20/183]  eta: 0:33:57  lr: 0.000715  loss: 2.7499 (2.7658)  time: 12.5003  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Train  [ 30/183]  eta: 0:31:48  lr: 0.000714  loss: 2.5499 (2.8054)  time: 12.4389  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Train  [ 40/183]  eta: 0:29:35  lr: 0.000713  loss: 2.7909 (2.8314)  time: 12.3359  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Train  [ 50/183]  eta: 0:27:33  lr: 0.000712  loss: 2.5295 (2.8235)  time: 12.3773  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Train  [ 60/183]  eta: 0:25:30  lr: 0.000710  loss: 2.6168 (2.8142)  time: 12.4901  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Train  [ 70/183]  eta: 0:23:23  lr: 0.000709  loss: 2.7886 (2.7938)  time: 12.3785  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Train  [ 80/183]  eta: 0:21:18  lr: 0.000708  loss: 2.5116 (2.7899)  time: 12.3118  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Train  [ 90/183]  eta: 0:19:14  lr: 0.000706  loss: 2.6340 (2.7936)  time: 12.3798  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Train  [100/183]  eta: 0:17:09  lr: 0.000705  loss: 2.7033 (2.7894)  time: 12.3887  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Train  [110/183]  eta: 0:15:06  lr: 0.000704  loss: 2.7343 (2.7921)  time: 12.4343  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Train  [120/183]  eta: 0:13:01  lr: 0.000702  loss: 2.9041 (2.7888)  time: 12.3879  data: 0.0004  max mem: 9511\n",
      "Epoch: [13] Train  [130/183]  eta: 0:10:57  lr: 0.000701  loss: 3.0775 (2.7869)  time: 12.3671  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Train  [140/183]  eta: 0:08:53  lr: 0.000700  loss: 2.9101 (2.7905)  time: 12.4515  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Train  [150/183]  eta: 0:06:49  lr: 0.000698  loss: 2.8631 (2.7931)  time: 12.4772  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Train  [160/183]  eta: 0:04:45  lr: 0.000697  loss: 3.1258 (2.7983)  time: 12.4978  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Train  [170/183]  eta: 0:02:41  lr: 0.000696  loss: 2.5555 (2.7964)  time: 12.5427  data: 0.0004  max mem: 9511\n",
      "Epoch: [13] Train  [180/183]  eta: 0:00:37  lr: 0.000695  loss: 2.6870 (2.7930)  time: 12.4718  data: 0.0004  max mem: 9511\n",
      "Epoch: [13] Train Total time: 0:37:54\n",
      "Epoch: [13] Test  [  0/242]  eta: 0:05:46    time: 1.4330  data: 0.3642  max mem: 9511\n",
      "Epoch: [13] Test  [ 10/242]  eta: 0:03:50    time: 0.9929  data: 0.0333  max mem: 9511\n",
      "Epoch: [13] Test  [ 20/242]  eta: 0:03:33    time: 0.9383  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [ 30/242]  eta: 0:03:29    time: 0.9887  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [ 40/242]  eta: 0:03:22    time: 1.0501  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Test  [ 50/242]  eta: 0:03:14    time: 1.0446  data: 0.0010  max mem: 9511\n",
      "Epoch: [13] Test  [ 60/242]  eta: 0:03:07    time: 1.0781  data: 0.0016  max mem: 9511\n",
      "Epoch: [13] Test  [ 70/242]  eta: 0:02:57    time: 1.0898  data: 0.0009  max mem: 9511\n",
      "Epoch: [13] Test  [ 80/242]  eta: 0:02:46    time: 1.0304  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Test  [ 90/242]  eta: 0:02:35    time: 0.9781  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Test  [100/242]  eta: 0:02:25    time: 1.0138  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Test  [110/242]  eta: 0:02:15    time: 1.0323  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [120/242]  eta: 0:02:05    time: 1.0434  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [130/242]  eta: 0:01:54    time: 1.0300  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [140/242]  eta: 0:01:44    time: 0.9811  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [150/242]  eta: 0:01:33    time: 0.9894  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Test  [160/242]  eta: 0:01:23    time: 1.0035  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [170/242]  eta: 0:01:13    time: 1.0546  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [180/242]  eta: 0:01:03    time: 1.1120  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [190/242]  eta: 0:00:53    time: 1.1136  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [200/242]  eta: 0:00:43    time: 1.0599  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [210/242]  eta: 0:00:33    time: 1.0341  data: 0.0003  max mem: 9511\n",
      "Epoch: [13] Test  [220/242]  eta: 0:00:22    time: 1.0448  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [230/242]  eta: 0:00:12    time: 1.0513  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test  [240/242]  eta: 0:00:02    time: 1.0123  data: 0.0002  max mem: 9511\n",
      "Epoch: [13] Test Total time: 0:04:09\n",
      "global correct: 95.5\n",
      "average row correct: ['97.8', '95.9', '86.0', '94.4', '89.4', '88.7', '98.0', '94.3', '96.5', '55.0', '91.4', '72.8', '83.0', '91.7', '96.6', '94.5', '76.6', '95.0', '65.0', '94.7', '84.8']\n",
      "IoU: ['95.3', '92.9', '60.9', '90.2', '73.4', '75.9', '94.5', '90.5', '82.8', '43.0', '85.7', '68.1', '75.0', '87.6', '89.2', '89.4', '66.2', '80.5', '56.4', '88.2', '79.7']\n",
      "mean IoU: 79.3\n",
      "Epoch: [14] Train  [  0/183]  eta: 0:40:31  lr: 0.000694  loss: 2.8216 (2.8216)  time: 13.2848  data: 0.3979  max mem: 9511\n",
      "Epoch: [14] Train  [ 10/183]  eta: 0:36:21  lr: 0.000693  loss: 2.7724 (2.7103)  time: 12.6088  data: 0.0364  max mem: 9511\n",
      "Epoch: [14] Train  [ 20/183]  eta: 0:33:51  lr: 0.000691  loss: 3.1342 (2.7469)  time: 12.4239  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [ 30/183]  eta: 0:31:39  lr: 0.000690  loss: 2.8169 (2.7374)  time: 12.3124  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [ 40/183]  eta: 0:29:35  lr: 0.000689  loss: 2.7958 (2.7461)  time: 12.3630  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [ 50/183]  eta: 0:27:29  lr: 0.000688  loss: 2.6415 (2.7541)  time: 12.3852  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [ 60/183]  eta: 0:25:24  lr: 0.000686  loss: 2.8284 (2.7418)  time: 12.3458  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [ 70/183]  eta: 0:23:18  lr: 0.000685  loss: 2.4926 (2.7438)  time: 12.2952  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [ 80/183]  eta: 0:21:16  lr: 0.000684  loss: 2.9364 (2.7351)  time: 12.3844  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [ 90/183]  eta: 0:19:13  lr: 0.000682  loss: 2.6762 (2.7349)  time: 12.4831  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [100/183]  eta: 0:17:08  lr: 0.000681  loss: 2.5126 (2.7373)  time: 12.4154  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Train  [110/183]  eta: 0:15:04  lr: 0.000680  loss: 2.3237 (2.7316)  time: 12.3286  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [120/183]  eta: 0:13:00  lr: 0.000678  loss: 2.6329 (2.7341)  time: 12.3152  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Train  [130/183]  eta: 0:10:55  lr: 0.000677  loss: 2.5593 (2.7319)  time: 12.3202  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Train  [140/183]  eta: 0:08:52  lr: 0.000676  loss: 2.8142 (2.7308)  time: 12.4413  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Train  [150/183]  eta: 0:06:49  lr: 0.000674  loss: 2.5152 (2.7258)  time: 12.5201  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Train  [160/183]  eta: 0:04:45  lr: 0.000673  loss: 2.6343 (2.7303)  time: 12.4426  data: 0.0004  max mem: 9511\n",
      "Epoch: [14] Train  [170/183]  eta: 0:02:41  lr: 0.000672  loss: 2.5788 (2.7314)  time: 12.4242  data: 0.0004  max mem: 9511\n",
      "Epoch: [14] Train  [180/183]  eta: 0:00:37  lr: 0.000670  loss: 2.5560 (2.7329)  time: 12.4214  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Train Total time: 0:37:49\n",
      "Epoch: [14] Test  [  0/242]  eta: 0:05:57    time: 1.4757  data: 0.4075  max mem: 9511\n",
      "Epoch: [14] Test  [ 10/242]  eta: 0:03:51    time: 0.9991  data: 0.0373  max mem: 9511\n",
      "Epoch: [14] Test  [ 20/242]  eta: 0:03:34    time: 0.9394  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [ 30/242]  eta: 0:03:30    time: 0.9878  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [ 40/242]  eta: 0:03:23    time: 1.0489  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [ 50/242]  eta: 0:03:14    time: 1.0450  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [ 60/242]  eta: 0:03:07    time: 1.0769  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [ 70/242]  eta: 0:02:57    time: 1.0886  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [ 80/242]  eta: 0:02:46    time: 1.0310  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [ 90/242]  eta: 0:02:35    time: 0.9778  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [100/242]  eta: 0:02:25    time: 1.0135  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [110/242]  eta: 0:02:15    time: 1.0302  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [120/242]  eta: 0:02:05    time: 1.0411  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [130/242]  eta: 0:01:54    time: 1.0312  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [140/242]  eta: 0:01:44    time: 0.9822  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [150/242]  eta: 0:01:33    time: 0.9896  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [160/242]  eta: 0:01:23    time: 1.0038  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [170/242]  eta: 0:01:13    time: 1.0532  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [180/242]  eta: 0:01:03    time: 1.1129  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [190/242]  eta: 0:00:53    time: 1.1180  data: 0.0002  max mem: 9511\n",
      "Epoch: [14] Test  [200/242]  eta: 0:00:43    time: 1.0635  data: 0.0005  max mem: 9511\n",
      "Epoch: [14] Test  [210/242]  eta: 0:00:33    time: 1.0354  data: 0.0006  max mem: 9511\n",
      "Epoch: [14] Test  [220/242]  eta: 0:00:22    time: 1.0431  data: 0.0004  max mem: 9511\n",
      "Epoch: [14] Test  [230/242]  eta: 0:00:12    time: 1.0493  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test  [240/242]  eta: 0:00:02    time: 1.0109  data: 0.0003  max mem: 9511\n",
      "Epoch: [14] Test Total time: 0:04:09\n",
      "global correct: 95.0\n",
      "average row correct: ['96.9', '96.3', '86.3', '94.0', '90.4', '84.0', '97.8', '92.1', '96.0', '68.7', '89.9', '80.5', '80.3', '93.0', '92.3', '95.6', '75.1', '96.6', '68.0', '95.9', '90.2']\n",
      "IoU: ['95.1', '92.4', '67.1', '88.2', '75.2', '74.3', '92.0', '87.1', '82.8', '40.0', '85.8', '64.9', '75.2', '80.9', '87.4', '89.7', '66.6', '66.8', '58.3', '87.6', '73.6']\n",
      "mean IoU: 77.7\n",
      "Epoch: [15] Train  [  0/183]  eta: 0:39:02  lr: 0.000670  loss: 2.7127 (2.7127)  time: 12.8006  data: 0.4513  max mem: 9511\n",
      "Epoch: [15] Train  [ 10/183]  eta: 0:35:47  lr: 0.000669  loss: 2.3681 (2.7280)  time: 12.4144  data: 0.0414  max mem: 9511\n",
      "Epoch: [15] Train  [ 20/183]  eta: 0:33:37  lr: 0.000667  loss: 2.7553 (2.7132)  time: 12.3540  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Train  [ 30/183]  eta: 0:31:34  lr: 0.000666  loss: 2.7993 (2.7196)  time: 12.3598  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Train  [ 40/183]  eta: 0:29:33  lr: 0.000665  loss: 2.7957 (2.7388)  time: 12.4305  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Train  [ 50/183]  eta: 0:27:28  lr: 0.000663  loss: 2.6678 (2.7489)  time: 12.4163  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Train  [ 60/183]  eta: 0:25:24  lr: 0.000662  loss: 2.4696 (2.7439)  time: 12.3687  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Train  [ 70/183]  eta: 0:23:22  lr: 0.000661  loss: 2.4228 (2.7364)  time: 12.4503  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Train  [ 80/183]  eta: 0:21:16  lr: 0.000659  loss: 2.6095 (2.7343)  time: 12.4078  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Train  [ 90/183]  eta: 0:19:11  lr: 0.000658  loss: 2.6899 (2.7260)  time: 12.3039  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Train  [100/183]  eta: 0:17:08  lr: 0.000657  loss: 2.7058 (2.7354)  time: 12.3749  data: 0.0005  max mem: 9511\n",
      "Epoch: [15] Train  [110/183]  eta: 0:15:05  lr: 0.000656  loss: 2.7580 (2.7335)  time: 12.4700  data: 0.0005  max mem: 9511\n",
      "Epoch: [15] Train  [120/183]  eta: 0:13:01  lr: 0.000654  loss: 2.4706 (2.7232)  time: 12.4708  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Train  [130/183]  eta: 0:10:57  lr: 0.000653  loss: 2.6357 (2.7283)  time: 12.3897  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Train  [140/183]  eta: 0:08:53  lr: 0.000652  loss: 2.6742 (2.7298)  time: 12.3487  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Train  [150/183]  eta: 0:06:48  lr: 0.000650  loss: 2.6460 (2.7248)  time: 12.3233  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Train  [160/183]  eta: 0:04:45  lr: 0.000649  loss: 2.7458 (2.7314)  time: 12.4747  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Train  [170/183]  eta: 0:02:41  lr: 0.000648  loss: 2.6628 (2.7332)  time: 12.6062  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Train  [180/183]  eta: 0:00:37  lr: 0.000646  loss: 2.8918 (2.7341)  time: 12.4252  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Train Total time: 0:37:50\n",
      "Epoch: [15] Test  [  0/242]  eta: 0:06:01    time: 1.4938  data: 0.4196  max mem: 9511\n",
      "Epoch: [15] Test  [ 10/242]  eta: 0:03:52    time: 1.0005  data: 0.0384  max mem: 9511\n",
      "Epoch: [15] Test  [ 20/242]  eta: 0:03:34    time: 0.9399  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [ 30/242]  eta: 0:03:30    time: 0.9897  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [ 40/242]  eta: 0:03:23    time: 1.0520  data: 0.0002  max mem: 9511\n",
      "Epoch: [15] Test  [ 50/242]  eta: 0:03:14    time: 1.0467  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [ 60/242]  eta: 0:03:07    time: 1.0784  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [ 70/242]  eta: 0:02:58    time: 1.0921  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [ 80/242]  eta: 0:02:47    time: 1.0354  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [ 90/242]  eta: 0:02:35    time: 0.9820  data: 0.0002  max mem: 9511\n",
      "Epoch: [15] Test  [100/242]  eta: 0:02:26    time: 1.0146  data: 0.0002  max mem: 9511\n",
      "Epoch: [15] Test  [110/242]  eta: 0:02:15    time: 1.0337  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [120/242]  eta: 0:02:05    time: 1.0485  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [130/242]  eta: 0:01:55    time: 1.0346  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [140/242]  eta: 0:01:44    time: 0.9832  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [150/242]  eta: 0:01:34    time: 0.9929  data: 0.0002  max mem: 9511\n",
      "Epoch: [15] Test  [160/242]  eta: 0:01:23    time: 1.0058  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [170/242]  eta: 0:01:13    time: 1.0537  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [180/242]  eta: 0:01:04    time: 1.1133  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Test  [190/242]  eta: 0:00:53    time: 1.1163  data: 0.0004  max mem: 9511\n",
      "Epoch: [15] Test  [200/242]  eta: 0:00:43    time: 1.0614  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [210/242]  eta: 0:00:33    time: 1.0341  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [220/242]  eta: 0:00:22    time: 1.0432  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [230/242]  eta: 0:00:12    time: 1.0491  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test  [240/242]  eta: 0:00:02    time: 1.0117  data: 0.0003  max mem: 9511\n",
      "Epoch: [15] Test Total time: 0:04:09\n",
      "global correct: 95.5\n",
      "average row correct: ['97.7', '96.2', '85.5', '94.1', '91.9', '82.4', '98.3', '93.4', '95.1', '61.5', '92.3', '69.0', '85.5', '88.8', '95.9', '94.5', '67.2', '95.3', '73.7', '94.2', '89.7']\n",
      "IoU: ['95.4', '93.5', '60.4', '87.8', '71.8', '71.3', '95.1', '90.7', '85.2', '44.9', '85.8', '65.2', '79.1', '85.1', '85.5', '90.0', '61.6', '78.3', '59.0', '89.4', '77.6']\n",
      "mean IoU: 78.7\n",
      "Epoch: [16] Train  [  0/183]  eta: 0:39:37  lr: 0.000646  loss: 2.4285 (2.4285)  time: 12.9928  data: 0.3999  max mem: 9511\n",
      "Epoch: [16] Train  [ 10/183]  eta: 0:35:57  lr: 0.000645  loss: 2.7362 (2.5736)  time: 12.4695  data: 0.0366  max mem: 9511\n",
      "Epoch: [16] Train  [ 20/183]  eta: 0:33:58  lr: 0.000643  loss: 2.7177 (2.6562)  time: 12.4817  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Train  [ 30/183]  eta: 0:31:42  lr: 0.000642  loss: 2.5177 (2.6332)  time: 12.4110  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Train  [ 40/183]  eta: 0:29:33  lr: 0.000641  loss: 2.7729 (2.6418)  time: 12.2880  data: 0.0004  max mem: 9511\n",
      "Epoch: [16] Train  [ 50/183]  eta: 0:27:28  lr: 0.000639  loss: 2.3215 (2.6548)  time: 12.3350  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Train  [ 60/183]  eta: 0:25:24  lr: 0.000638  loss: 2.5289 (2.6723)  time: 12.3899  data: 0.0005  max mem: 9511\n",
      "Epoch: [16] Train  [ 70/183]  eta: 0:23:19  lr: 0.000637  loss: 2.4559 (2.6785)  time: 12.3556  data: 0.0005  max mem: 9511\n",
      "Epoch: [16] Train  [ 80/183]  eta: 0:21:16  lr: 0.000635  loss: 2.4595 (2.6693)  time: 12.3677  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Train  [ 90/183]  eta: 0:19:14  lr: 0.000634  loss: 2.5166 (2.6590)  time: 12.5159  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Train  [100/183]  eta: 0:17:10  lr: 0.000633  loss: 2.9221 (2.6651)  time: 12.5131  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Train  [110/183]  eta: 0:15:06  lr: 0.000631  loss: 2.4781 (2.6640)  time: 12.4243  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Train  [120/183]  eta: 0:13:02  lr: 0.000630  loss: 2.8067 (2.6749)  time: 12.4111  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Train  [130/183]  eta: 0:10:57  lr: 0.000629  loss: 2.8480 (2.6875)  time: 12.4037  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Train  [140/183]  eta: 0:08:54  lr: 0.000627  loss: 2.7697 (2.6877)  time: 12.4695  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Train  [150/183]  eta: 0:06:49  lr: 0.000626  loss: 2.8788 (2.6851)  time: 12.4243  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Train  [160/183]  eta: 0:04:45  lr: 0.000625  loss: 2.9321 (2.6887)  time: 12.4504  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Train  [170/183]  eta: 0:02:41  lr: 0.000623  loss: 2.7414 (2.6913)  time: 12.5130  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Train  [180/183]  eta: 0:00:37  lr: 0.000622  loss: 2.7228 (2.6992)  time: 12.4426  data: 0.0004  max mem: 9511\n",
      "Epoch: [16] Train Total time: 0:37:54\n",
      "Epoch: [16] Test  [  0/242]  eta: 0:05:51    time: 1.4518  data: 0.3818  max mem: 9511\n",
      "Epoch: [16] Test  [ 10/242]  eta: 0:03:51    time: 0.9958  data: 0.0349  max mem: 9511\n",
      "Epoch: [16] Test  [ 20/242]  eta: 0:03:33    time: 0.9386  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [ 30/242]  eta: 0:03:30    time: 0.9884  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [ 40/242]  eta: 0:03:22    time: 1.0487  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Test  [ 50/242]  eta: 0:03:14    time: 1.0445  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [ 60/242]  eta: 0:03:07    time: 1.0791  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [ 70/242]  eta: 0:02:57    time: 1.0885  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [ 80/242]  eta: 0:02:46    time: 1.0319  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [ 90/242]  eta: 0:02:35    time: 0.9816  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [100/242]  eta: 0:02:25    time: 1.0149  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [110/242]  eta: 0:02:15    time: 1.0330  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [120/242]  eta: 0:02:05    time: 1.0439  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [130/242]  eta: 0:01:54    time: 1.0308  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [140/242]  eta: 0:01:44    time: 0.9804  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [150/242]  eta: 0:01:33    time: 0.9884  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [160/242]  eta: 0:01:23    time: 1.0033  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [170/242]  eta: 0:01:13    time: 1.0517  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [180/242]  eta: 0:01:03    time: 1.1088  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [190/242]  eta: 0:00:53    time: 1.1137  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [200/242]  eta: 0:00:43    time: 1.0599  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [210/242]  eta: 0:00:33    time: 1.0325  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [220/242]  eta: 0:00:22    time: 1.0432  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test  [230/242]  eta: 0:00:12    time: 1.0523  data: 0.0002  max mem: 9511\n",
      "Epoch: [16] Test  [240/242]  eta: 0:00:02    time: 1.0146  data: 0.0003  max mem: 9511\n",
      "Epoch: [16] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['97.7', '92.3', '87.0', '93.5', '88.7', '83.2', '96.2', '94.1', '95.9', '67.2', '93.9', '66.3', '89.0', '93.1', '94.9', '94.7', '71.1', '95.9', '60.0', '86.8', '85.8']\n",
      "IoU: ['95.0', '90.8', '61.6', '88.8', '74.4', '69.7', '94.2', '88.2', '86.0', '42.4', '89.4', '62.9', '79.9', '89.6', '87.9', '90.4', '64.6', '86.6', '53.2', '82.6', '71.0']\n",
      "mean IoU: 78.5\n",
      "Epoch: [17] Train  [  0/183]  eta: 0:39:48  lr: 0.000622  loss: 2.6373 (2.6373)  time: 13.0530  data: 0.4373  max mem: 9511\n",
      "Epoch: [17] Train  [ 10/183]  eta: 0:36:02  lr: 0.000620  loss: 2.5928 (2.6688)  time: 12.4987  data: 0.0400  max mem: 9511\n",
      "Epoch: [17] Train  [ 20/183]  eta: 0:33:41  lr: 0.000619  loss: 2.6756 (2.6658)  time: 12.3667  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [ 30/183]  eta: 0:31:48  lr: 0.000618  loss: 2.6787 (2.6486)  time: 12.4552  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [ 40/183]  eta: 0:29:44  lr: 0.000616  loss: 2.3940 (2.6220)  time: 12.5690  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [ 50/183]  eta: 0:27:42  lr: 0.000615  loss: 2.7672 (2.6348)  time: 12.5399  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [ 60/183]  eta: 0:25:38  lr: 0.000614  loss: 2.6556 (2.6401)  time: 12.5684  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [ 70/183]  eta: 0:23:34  lr: 0.000612  loss: 2.5213 (2.6323)  time: 12.5673  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [ 80/183]  eta: 0:21:28  lr: 0.000611  loss: 2.7584 (2.6382)  time: 12.4946  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Train  [ 90/183]  eta: 0:19:23  lr: 0.000610  loss: 2.7090 (2.6388)  time: 12.4886  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [100/183]  eta: 0:17:18  lr: 0.000608  loss: 2.6057 (2.6452)  time: 12.5211  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Train  [110/183]  eta: 0:15:12  lr: 0.000607  loss: 2.7503 (2.6473)  time: 12.4577  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Train  [120/183]  eta: 0:13:08  lr: 0.000606  loss: 2.4745 (2.6489)  time: 12.5384  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [130/183]  eta: 0:11:03  lr: 0.000604  loss: 2.6051 (2.6480)  time: 12.6297  data: 0.0004  max mem: 9511\n",
      "Epoch: [17] Train  [140/183]  eta: 0:08:57  lr: 0.000603  loss: 2.7465 (2.6527)  time: 12.4781  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [150/183]  eta: 0:06:52  lr: 0.000602  loss: 2.8039 (2.6593)  time: 12.3883  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Train  [160/183]  eta: 0:04:47  lr: 0.000600  loss: 2.7544 (2.6513)  time: 12.4785  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Train  [170/183]  eta: 0:02:42  lr: 0.000599  loss: 2.3931 (2.6494)  time: 12.5643  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train  [180/183]  eta: 0:00:37  lr: 0.000598  loss: 2.3769 (2.6576)  time: 12.5155  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Train Total time: 0:38:08\n",
      "Epoch: [17] Test  [  0/242]  eta: 0:06:04    time: 1.5071  data: 0.4404  max mem: 9511\n",
      "Epoch: [17] Test  [ 10/242]  eta: 0:03:52    time: 1.0005  data: 0.0403  max mem: 9511\n",
      "Epoch: [17] Test  [ 20/242]  eta: 0:03:34    time: 0.9400  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [ 30/242]  eta: 0:03:30    time: 0.9909  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [ 40/242]  eta: 0:03:23    time: 1.0510  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [ 50/242]  eta: 0:03:14    time: 1.0451  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [ 60/242]  eta: 0:03:07    time: 1.0780  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [ 70/242]  eta: 0:02:57    time: 1.0874  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Test  [ 80/242]  eta: 0:02:46    time: 1.0299  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [ 90/242]  eta: 0:02:35    time: 0.9790  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [100/242]  eta: 0:02:25    time: 1.0114  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Test  [110/242]  eta: 0:02:15    time: 1.0303  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Test  [120/242]  eta: 0:02:05    time: 1.0430  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [130/242]  eta: 0:01:54    time: 1.0306  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [140/242]  eta: 0:01:44    time: 0.9799  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Test  [150/242]  eta: 0:01:33    time: 0.9884  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [160/242]  eta: 0:01:23    time: 1.0032  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [170/242]  eta: 0:01:13    time: 1.0522  data: 0.0002  max mem: 9511\n",
      "Epoch: [17] Test  [180/242]  eta: 0:01:03    time: 1.1127  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [190/242]  eta: 0:00:53    time: 1.1145  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [200/242]  eta: 0:00:43    time: 1.0600  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [210/242]  eta: 0:00:33    time: 1.0358  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [220/242]  eta: 0:00:22    time: 1.0434  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [230/242]  eta: 0:00:12    time: 1.0491  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test  [240/242]  eta: 0:00:02    time: 1.0116  data: 0.0003  max mem: 9511\n",
      "Epoch: [17] Test Total time: 0:04:09\n",
      "global correct: 95.8\n",
      "average row correct: ['97.8', '94.2', '89.6', '95.6', '88.5', '86.8', '98.7', '93.5', '95.9', '66.0', '95.6', '75.8', '86.5', '93.9', '93.3', '94.4', '79.5', '96.6', '63.9', '95.5', '88.4']\n",
      "IoU: ['95.7', '92.2', '67.7', '88.9', '73.4', '73.1', '94.2', '89.9', '86.7', '43.9', '91.3', '69.3', '82.1', '90.0', '86.6', '90.5', '68.3', '83.3', '53.7', '90.6', '76.5']\n",
      "mean IoU: 80.4\n",
      "Epoch: [18] Train  [  0/183]  eta: 0:38:51  lr: 0.000597  loss: 2.6233 (2.6233)  time: 12.7410  data: 0.4556  max mem: 9511\n",
      "Epoch: [18] Train  [ 10/183]  eta: 0:36:20  lr: 0.000596  loss: 2.6959 (2.6080)  time: 12.6029  data: 0.0416  max mem: 9511\n",
      "Epoch: [18] Train  [ 20/183]  eta: 0:34:11  lr: 0.000595  loss: 2.9491 (2.6427)  time: 12.5774  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [ 30/183]  eta: 0:31:50  lr: 0.000593  loss: 2.6754 (2.6341)  time: 12.4234  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [ 40/183]  eta: 0:29:46  lr: 0.000592  loss: 2.6769 (2.6395)  time: 12.3959  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [ 50/183]  eta: 0:27:42  lr: 0.000591  loss: 2.4715 (2.6159)  time: 12.5198  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [ 60/183]  eta: 0:25:36  lr: 0.000589  loss: 2.9109 (2.6239)  time: 12.4964  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [ 70/183]  eta: 0:23:31  lr: 0.000588  loss: 2.8276 (2.6412)  time: 12.4602  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [ 80/183]  eta: 0:21:25  lr: 0.000587  loss: 2.7419 (2.6411)  time: 12.4415  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [ 90/183]  eta: 0:19:21  lr: 0.000585  loss: 2.2809 (2.6242)  time: 12.4908  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [100/183]  eta: 0:17:16  lr: 0.000584  loss: 3.2385 (2.6174)  time: 12.4922  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [110/183]  eta: 0:15:10  lr: 0.000582  loss: 2.3541 (2.6151)  time: 12.4185  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [120/183]  eta: 0:13:05  lr: 0.000581  loss: 2.6316 (2.6246)  time: 12.4302  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Train  [130/183]  eta: 0:11:01  lr: 0.000580  loss: 2.5766 (2.6216)  time: 12.4740  data: 0.0004  max mem: 9511\n",
      "Epoch: [18] Train  [140/183]  eta: 0:08:55  lr: 0.000578  loss: 2.5539 (2.6375)  time: 12.3773  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [150/183]  eta: 0:06:51  lr: 0.000577  loss: 2.7240 (2.6318)  time: 12.3843  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [160/183]  eta: 0:04:46  lr: 0.000576  loss: 2.5466 (2.6303)  time: 12.4831  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [170/183]  eta: 0:02:41  lr: 0.000574  loss: 2.4784 (2.6313)  time: 12.3730  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train  [180/183]  eta: 0:00:37  lr: 0.000573  loss: 2.5382 (2.6236)  time: 12.3558  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Train Total time: 0:37:57\n",
      "Epoch: [18] Test  [  0/242]  eta: 0:05:58    time: 1.4814  data: 0.4129  max mem: 9511\n",
      "Epoch: [18] Test  [ 10/242]  eta: 0:03:52    time: 1.0020  data: 0.0378  max mem: 9511\n",
      "Epoch: [18] Test  [ 20/242]  eta: 0:03:34    time: 0.9423  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [ 30/242]  eta: 0:03:30    time: 0.9914  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [ 40/242]  eta: 0:03:23    time: 1.0519  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [ 50/242]  eta: 0:03:15    time: 1.0488  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [ 60/242]  eta: 0:03:07    time: 1.0812  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [ 70/242]  eta: 0:02:58    time: 1.0898  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [ 80/242]  eta: 0:02:47    time: 1.0329  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [ 90/242]  eta: 0:02:35    time: 0.9813  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [100/242]  eta: 0:02:26    time: 1.0139  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [110/242]  eta: 0:02:15    time: 1.0315  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Test  [120/242]  eta: 0:02:05    time: 1.0441  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [130/242]  eta: 0:01:54    time: 1.0314  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [140/242]  eta: 0:01:44    time: 0.9824  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Test  [150/242]  eta: 0:01:34    time: 0.9915  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [160/242]  eta: 0:01:23    time: 1.0068  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [170/242]  eta: 0:01:13    time: 1.0553  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [180/242]  eta: 0:01:04    time: 1.1132  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [190/242]  eta: 0:00:53    time: 1.1164  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [200/242]  eta: 0:00:43    time: 1.0604  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [210/242]  eta: 0:00:33    time: 1.0327  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Test  [220/242]  eta: 0:00:22    time: 1.0411  data: 0.0003  max mem: 9511\n",
      "Epoch: [18] Test  [230/242]  eta: 0:00:12    time: 1.0490  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Test  [240/242]  eta: 0:00:02    time: 1.0125  data: 0.0002  max mem: 9511\n",
      "Epoch: [18] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['97.4', '96.2', '91.4', '94.9', '94.2', '82.7', '98.9', '92.3', '96.0', '73.4', '95.9', '74.0', '85.9', '90.7', '88.0', '95.0', '75.5', '96.8', '54.4', '97.0', '87.9']\n",
      "IoU: ['95.2', '92.4', '60.5', '87.7', '70.8', '69.5', '94.9', '86.2', '86.1', '45.5', '86.8', '68.6', '79.6', '85.5', '82.1', '90.3', '66.0', '77.8', '50.7', '87.2', '80.0']\n",
      "mean IoU: 78.3\n",
      "Epoch: [19] Train  [  0/183]  eta: 0:40:19  lr: 0.000573  loss: 2.4640 (2.4640)  time: 13.2236  data: 0.3996  max mem: 9511\n",
      "Epoch: [19] Train  [ 10/183]  eta: 0:36:02  lr: 0.000571  loss: 2.4705 (2.6283)  time: 12.4973  data: 0.0367  max mem: 9511\n",
      "Epoch: [19] Train  [ 20/183]  eta: 0:33:59  lr: 0.000570  loss: 2.5920 (2.6387)  time: 12.4775  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Train  [ 30/183]  eta: 0:31:51  lr: 0.000569  loss: 2.5105 (2.6387)  time: 12.4866  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [ 40/183]  eta: 0:29:43  lr: 0.000567  loss: 2.7673 (2.6425)  time: 12.4255  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [ 50/183]  eta: 0:27:40  lr: 0.000566  loss: 2.4668 (2.6340)  time: 12.4842  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [ 60/183]  eta: 0:25:36  lr: 0.000565  loss: 2.4705 (2.6218)  time: 12.5401  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [ 70/183]  eta: 0:23:31  lr: 0.000563  loss: 2.3096 (2.6230)  time: 12.4891  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [ 80/183]  eta: 0:21:23  lr: 0.000562  loss: 2.6890 (2.6280)  time: 12.3782  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [ 90/183]  eta: 0:19:17  lr: 0.000561  loss: 2.9453 (2.6412)  time: 12.3080  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [100/183]  eta: 0:17:12  lr: 0.000559  loss: 2.5675 (2.6450)  time: 12.3103  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [110/183]  eta: 0:15:08  lr: 0.000558  loss: 2.2036 (2.6347)  time: 12.4403  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [120/183]  eta: 0:13:03  lr: 0.000557  loss: 2.7549 (2.6195)  time: 12.4893  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Train  [130/183]  eta: 0:10:58  lr: 0.000555  loss: 2.5715 (2.6156)  time: 12.3302  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [140/183]  eta: 0:08:55  lr: 0.000554  loss: 2.5109 (2.6117)  time: 12.4538  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [150/183]  eta: 0:06:50  lr: 0.000553  loss: 2.2807 (2.6053)  time: 12.5420  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Train  [160/183]  eta: 0:04:46  lr: 0.000551  loss: 2.7087 (2.6057)  time: 12.4302  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Train  [170/183]  eta: 0:02:41  lr: 0.000550  loss: 2.3899 (2.5984)  time: 12.3701  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train  [180/183]  eta: 0:00:37  lr: 0.000549  loss: 2.5500 (2.5990)  time: 12.3569  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Train Total time: 0:37:55\n",
      "Epoch: [19] Test  [  0/242]  eta: 0:05:51    time: 1.4508  data: 0.3892  max mem: 9511\n",
      "Epoch: [19] Test  [ 10/242]  eta: 0:03:50    time: 0.9957  data: 0.0356  max mem: 9511\n",
      "Epoch: [19] Test  [ 20/242]  eta: 0:03:33    time: 0.9394  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [ 30/242]  eta: 0:03:30    time: 0.9903  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [ 40/242]  eta: 0:03:23    time: 1.0494  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [ 50/242]  eta: 0:03:14    time: 1.0444  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [ 60/242]  eta: 0:03:07    time: 1.0784  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [ 70/242]  eta: 0:02:57    time: 1.0869  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Test  [ 80/242]  eta: 0:02:46    time: 1.0294  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [ 90/242]  eta: 0:02:35    time: 0.9796  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Test  [100/242]  eta: 0:02:25    time: 1.0154  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [110/242]  eta: 0:02:15    time: 1.0333  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [120/242]  eta: 0:02:05    time: 1.0449  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [130/242]  eta: 0:01:54    time: 1.0324  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [140/242]  eta: 0:01:44    time: 0.9806  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [150/242]  eta: 0:01:33    time: 0.9880  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [160/242]  eta: 0:01:23    time: 1.0032  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [170/242]  eta: 0:01:13    time: 1.0520  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [180/242]  eta: 0:01:03    time: 1.1111  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [190/242]  eta: 0:00:53    time: 1.1152  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Test  [200/242]  eta: 0:00:43    time: 1.0606  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [210/242]  eta: 0:00:33    time: 1.0343  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [220/242]  eta: 0:00:22    time: 1.0426  data: 0.0003  max mem: 9511\n",
      "Epoch: [19] Test  [230/242]  eta: 0:00:12    time: 1.0482  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Test  [240/242]  eta: 0:00:02    time: 1.0113  data: 0.0002  max mem: 9511\n",
      "Epoch: [19] Test Total time: 0:04:09\n",
      "global correct: 95.4\n",
      "average row correct: ['97.4', '96.2', '89.3', '94.8', '92.3', '88.4', '98.3', '93.8', '98.3', '66.9', '95.7', '83.2', '80.1', '91.5', '92.2', '94.4', '80.4', '96.0', '60.8', '96.3', '89.5']\n",
      "IoU: ['95.4', '93.7', '68.5', '89.3', '69.5', '73.5', '95.1', '88.0', '79.2', '45.7', '87.8', '73.5', '75.0', '87.1', '86.8', '89.6', '69.9', '86.4', '55.5', '89.6', '71.2']\n",
      "mean IoU: 79.5\n",
      "Epoch: [20] Train  [  0/183]  eta: 0:38:37  lr: 0.000548  loss: 2.8008 (2.8008)  time: 12.6644  data: 0.3776  max mem: 9511\n",
      "Epoch: [20] Train  [ 10/183]  eta: 0:35:54  lr: 0.000547  loss: 2.4063 (2.4724)  time: 12.4555  data: 0.0346  max mem: 9511\n",
      "Epoch: [20] Train  [ 20/183]  eta: 0:33:45  lr: 0.000545  loss: 2.4732 (2.5074)  time: 12.4159  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [ 30/183]  eta: 0:31:40  lr: 0.000544  loss: 3.2164 (2.5493)  time: 12.3986  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [ 40/183]  eta: 0:29:32  lr: 0.000543  loss: 2.4329 (2.5677)  time: 12.3576  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [ 50/183]  eta: 0:27:26  lr: 0.000541  loss: 2.4150 (2.5683)  time: 12.3242  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [ 60/183]  eta: 0:25:22  lr: 0.000540  loss: 2.4389 (2.5522)  time: 12.3433  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [ 70/183]  eta: 0:23:22  lr: 0.000539  loss: 2.2943 (2.5534)  time: 12.4827  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [ 80/183]  eta: 0:21:20  lr: 0.000537  loss: 2.8749 (2.5495)  time: 12.5895  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [ 90/183]  eta: 0:19:15  lr: 0.000536  loss: 2.3297 (2.5412)  time: 12.4683  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Train  [100/183]  eta: 0:17:12  lr: 0.000535  loss: 2.9471 (2.5471)  time: 12.5117  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Train  [110/183]  eta: 0:15:09  lr: 0.000533  loss: 2.6433 (2.5583)  time: 12.6336  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Train  [120/183]  eta: 0:13:04  lr: 0.000532  loss: 2.4210 (2.5564)  time: 12.5180  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [130/183]  eta: 0:10:59  lr: 0.000531  loss: 2.5850 (2.5512)  time: 12.3205  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [140/183]  eta: 0:08:55  lr: 0.000529  loss: 2.5733 (2.5504)  time: 12.3860  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [150/183]  eta: 0:06:50  lr: 0.000528  loss: 2.5658 (2.5520)  time: 12.4471  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [160/183]  eta: 0:04:46  lr: 0.000526  loss: 2.7252 (2.5551)  time: 12.3609  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [170/183]  eta: 0:02:41  lr: 0.000525  loss: 2.6724 (2.5552)  time: 12.3693  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Train  [180/183]  eta: 0:00:37  lr: 0.000524  loss: 2.4658 (2.5578)  time: 12.5002  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Train Total time: 0:37:57\n",
      "Epoch: [20] Test  [  0/242]  eta: 0:06:02    time: 1.4995  data: 0.4254  max mem: 9511\n",
      "Epoch: [20] Test  [ 10/242]  eta: 0:03:52    time: 1.0042  data: 0.0389  max mem: 9511\n",
      "Epoch: [20] Test  [ 20/242]  eta: 0:03:34    time: 0.9418  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [ 30/242]  eta: 0:03:31    time: 0.9905  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [ 40/242]  eta: 0:03:23    time: 1.0523  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [ 50/242]  eta: 0:03:15    time: 1.0479  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [ 60/242]  eta: 0:03:07    time: 1.0788  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [ 70/242]  eta: 0:02:58    time: 1.0888  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [ 80/242]  eta: 0:02:47    time: 1.0334  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [ 90/242]  eta: 0:02:35    time: 0.9814  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [100/242]  eta: 0:02:26    time: 1.0162  data: 0.0002  max mem: 9511\n",
      "Epoch: [20] Test  [110/242]  eta: 0:02:15    time: 1.0347  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [120/242]  eta: 0:02:05    time: 1.0465  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [130/242]  eta: 0:01:55    time: 1.0330  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [140/242]  eta: 0:01:44    time: 0.9812  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [150/242]  eta: 0:01:34    time: 0.9911  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [160/242]  eta: 0:01:23    time: 1.0044  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [170/242]  eta: 0:01:13    time: 1.0536  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [180/242]  eta: 0:01:04    time: 1.1135  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [190/242]  eta: 0:00:53    time: 1.1146  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [200/242]  eta: 0:00:43    time: 1.0605  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [210/242]  eta: 0:00:33    time: 1.0330  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [220/242]  eta: 0:00:22    time: 1.0392  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [230/242]  eta: 0:00:12    time: 1.0466  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test  [240/242]  eta: 0:00:02    time: 1.0109  data: 0.0003  max mem: 9511\n",
      "Epoch: [20] Test Total time: 0:04:09\n",
      "global correct: 95.6\n",
      "average row correct: ['97.3', '97.9', '83.0', '95.4', '88.7', '85.7', '98.4', '95.6', '97.9', '61.6', '95.2', '78.6', '85.5', '93.8', '95.5', '94.1', '84.6', '96.6', '70.8', '96.0', '84.8']\n",
      "IoU: ['95.4', '88.3', '64.7', '88.5', '77.6', '72.6', '94.1', '88.5', '83.3', '44.8', '89.5', '73.3', '77.8', '88.7', '86.9', '90.1', '73.2', '86.4', '53.9', '84.7', '80.9']\n",
      "mean IoU: 80.2\n",
      "Epoch: [21] Train  [  0/183]  eta: 0:38:36  lr: 0.000523  loss: 2.5519 (2.5519)  time: 12.6604  data: 0.4093  max mem: 9511\n",
      "Epoch: [21] Train  [ 10/183]  eta: 0:35:59  lr: 0.000522  loss: 2.4128 (2.5713)  time: 12.4841  data: 0.0375  max mem: 9511\n",
      "Epoch: [21] Train  [ 20/183]  eta: 0:33:49  lr: 0.000521  loss: 2.6100 (2.5605)  time: 12.4432  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Train  [ 30/183]  eta: 0:31:47  lr: 0.000519  loss: 2.6712 (2.5682)  time: 12.4552  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [ 40/183]  eta: 0:29:41  lr: 0.000518  loss: 2.7371 (2.5849)  time: 12.4612  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [ 50/183]  eta: 0:27:38  lr: 0.000517  loss: 2.4922 (2.5740)  time: 12.4779  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [ 60/183]  eta: 0:25:35  lr: 0.000515  loss: 2.5678 (2.5665)  time: 12.5272  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [ 70/183]  eta: 0:23:27  lr: 0.000514  loss: 2.5427 (2.5617)  time: 12.4278  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [ 80/183]  eta: 0:21:20  lr: 0.000513  loss: 2.3988 (2.5600)  time: 12.3017  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [ 90/183]  eta: 0:19:16  lr: 0.000511  loss: 2.4029 (2.5408)  time: 12.3692  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [100/183]  eta: 0:17:12  lr: 0.000510  loss: 2.8487 (2.5532)  time: 12.4652  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [110/183]  eta: 0:15:07  lr: 0.000508  loss: 2.5848 (2.5566)  time: 12.3768  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [120/183]  eta: 0:13:03  lr: 0.000507  loss: 2.5611 (2.5605)  time: 12.3783  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [130/183]  eta: 0:10:58  lr: 0.000506  loss: 2.0986 (2.5560)  time: 12.3946  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [140/183]  eta: 0:08:54  lr: 0.000504  loss: 2.2556 (2.5502)  time: 12.3439  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Train  [150/183]  eta: 0:06:49  lr: 0.000503  loss: 2.8301 (2.5546)  time: 12.3788  data: 0.0006  max mem: 9511\n",
      "Epoch: [21] Train  [160/183]  eta: 0:04:45  lr: 0.000502  loss: 2.3963 (2.5542)  time: 12.5309  data: 0.0006  max mem: 9511\n",
      "Epoch: [21] Train  [170/183]  eta: 0:02:41  lr: 0.000500  loss: 2.2725 (2.5573)  time: 12.5702  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Train  [180/183]  eta: 0:00:37  lr: 0.000499  loss: 2.6743 (2.5540)  time: 12.4903  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Train Total time: 0:37:56\n",
      "Epoch: [21] Test  [  0/242]  eta: 0:06:03    time: 1.5021  data: 0.4246  max mem: 9511\n",
      "Epoch: [21] Test  [ 10/242]  eta: 0:03:52    time: 1.0020  data: 0.0388  max mem: 9511\n",
      "Epoch: [21] Test  [ 20/242]  eta: 0:03:35    time: 0.9419  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [ 30/242]  eta: 0:03:31    time: 0.9927  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [ 40/242]  eta: 0:03:24    time: 1.0556  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [ 50/242]  eta: 0:03:15    time: 1.0511  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [ 60/242]  eta: 0:03:08    time: 1.0817  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Test  [ 70/242]  eta: 0:02:58    time: 1.0910  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Test  [ 80/242]  eta: 0:02:47    time: 1.0343  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Test  [ 90/242]  eta: 0:02:36    time: 0.9840  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [100/242]  eta: 0:02:26    time: 1.0173  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [110/242]  eta: 0:02:15    time: 1.0357  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [120/242]  eta: 0:02:06    time: 1.0491  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [130/242]  eta: 0:01:55    time: 1.0348  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [140/242]  eta: 0:01:44    time: 0.9822  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Test  [150/242]  eta: 0:01:34    time: 0.9925  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [160/242]  eta: 0:01:23    time: 1.0077  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [170/242]  eta: 0:01:14    time: 1.0569  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [180/242]  eta: 0:01:04    time: 1.1168  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [190/242]  eta: 0:00:53    time: 1.1182  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [200/242]  eta: 0:00:43    time: 1.0633  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Test  [210/242]  eta: 0:00:33    time: 1.0376  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Test  [220/242]  eta: 0:00:22    time: 1.0450  data: 0.0002  max mem: 9511\n",
      "Epoch: [21] Test  [230/242]  eta: 0:00:12    time: 1.0518  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test  [240/242]  eta: 0:00:02    time: 1.0158  data: 0.0003  max mem: 9511\n",
      "Epoch: [21] Test Total time: 0:04:10\n",
      "global correct: 95.3\n",
      "average row correct: ['97.2', '96.6', '89.6', '95.6', '90.7', '86.7', '98.4', '91.6', '96.7', '76.7', '94.0', '73.8', '80.1', '91.4', '95.7', '95.5', '69.3', '97.1', '66.9', '94.8', '87.1']\n",
      "IoU: ['95.2', '93.0', '67.5', '88.2', '78.0', '74.2', '93.8', '88.1', '82.9', '43.0', '87.4', '69.2', '76.2', '83.1', '90.0', '90.0', '62.1', '76.1', '53.6', '89.0', '82.2']\n",
      "mean IoU: 79.2\n",
      "Epoch: [22] Train  [  0/183]  eta: 0:39:56  lr: 0.000499  loss: 2.5382 (2.5382)  time: 13.0965  data: 0.4039  max mem: 9511\n",
      "Epoch: [22] Train  [ 10/183]  eta: 0:35:56  lr: 0.000497  loss: 2.5027 (2.5794)  time: 12.4680  data: 0.0370  max mem: 9511\n",
      "Epoch: [22] Train  [ 20/183]  eta: 0:33:45  lr: 0.000496  loss: 2.6155 (2.5623)  time: 12.3925  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Train  [ 30/183]  eta: 0:31:40  lr: 0.000494  loss: 2.9502 (2.5493)  time: 12.3917  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Train  [ 40/183]  eta: 0:29:36  lr: 0.000493  loss: 2.3755 (2.5606)  time: 12.4259  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [ 50/183]  eta: 0:27:32  lr: 0.000492  loss: 2.9318 (2.5691)  time: 12.4327  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [ 60/183]  eta: 0:25:30  lr: 0.000490  loss: 2.2168 (2.5827)  time: 12.4802  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [ 70/183]  eta: 0:23:26  lr: 0.000489  loss: 2.6067 (2.5789)  time: 12.4993  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [ 80/183]  eta: 0:21:19  lr: 0.000488  loss: 2.5797 (2.5784)  time: 12.3657  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [ 90/183]  eta: 0:19:15  lr: 0.000486  loss: 2.1834 (2.5705)  time: 12.3575  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [100/183]  eta: 0:17:10  lr: 0.000485  loss: 2.7776 (2.5639)  time: 12.3518  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Train  [110/183]  eta: 0:15:05  lr: 0.000483  loss: 3.0071 (2.5694)  time: 12.3287  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Train  [120/183]  eta: 0:13:02  lr: 0.000482  loss: 2.4392 (2.5664)  time: 12.4360  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [130/183]  eta: 0:10:57  lr: 0.000481  loss: 2.8721 (2.5662)  time: 12.3915  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [140/183]  eta: 0:08:53  lr: 0.000479  loss: 2.2649 (2.5507)  time: 12.4138  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [150/183]  eta: 0:06:49  lr: 0.000478  loss: 2.6644 (2.5448)  time: 12.3747  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Train  [160/183]  eta: 0:04:45  lr: 0.000477  loss: 2.8879 (2.5559)  time: 12.3042  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [170/183]  eta: 0:02:41  lr: 0.000475  loss: 2.3934 (2.5514)  time: 12.3432  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Train  [180/183]  eta: 0:00:37  lr: 0.000474  loss: 3.1172 (2.5530)  time: 12.4318  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Train Total time: 0:37:49\n",
      "Epoch: [22] Test  [  0/242]  eta: 0:06:10    time: 1.5316  data: 0.4478  max mem: 9511\n",
      "Epoch: [22] Test  [ 10/242]  eta: 0:03:53    time: 1.0059  data: 0.0410  max mem: 9511\n",
      "Epoch: [22] Test  [ 20/242]  eta: 0:03:35    time: 0.9423  data: 0.0005  max mem: 9511\n",
      "Epoch: [22] Test  [ 30/242]  eta: 0:03:31    time: 0.9930  data: 0.0005  max mem: 9511\n",
      "Epoch: [22] Test  [ 40/242]  eta: 0:03:24    time: 1.0540  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [ 50/242]  eta: 0:03:15    time: 1.0485  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [ 60/242]  eta: 0:03:08    time: 1.0808  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [ 70/242]  eta: 0:02:58    time: 1.0900  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [ 80/242]  eta: 0:02:47    time: 1.0319  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [ 90/242]  eta: 0:02:35    time: 0.9807  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [100/242]  eta: 0:02:26    time: 1.0166  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [110/242]  eta: 0:02:15    time: 1.0343  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [120/242]  eta: 0:02:05    time: 1.0451  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [130/242]  eta: 0:01:55    time: 1.0335  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Test  [140/242]  eta: 0:01:44    time: 0.9831  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [150/242]  eta: 0:01:34    time: 0.9925  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [160/242]  eta: 0:01:23    time: 1.0067  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [170/242]  eta: 0:01:13    time: 1.0543  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Test  [180/242]  eta: 0:01:04    time: 1.1144  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [190/242]  eta: 0:00:53    time: 1.1201  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [200/242]  eta: 0:00:43    time: 1.0660  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test  [210/242]  eta: 0:00:33    time: 1.0359  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Test  [220/242]  eta: 0:00:22    time: 1.0444  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Test  [230/242]  eta: 0:00:12    time: 1.0533  data: 0.0002  max mem: 9511\n",
      "Epoch: [22] Test  [240/242]  eta: 0:00:02    time: 1.0159  data: 0.0003  max mem: 9511\n",
      "Epoch: [22] Test Total time: 0:04:10\n",
      "global correct: 95.4\n",
      "average row correct: ['97.3', '96.7', '88.3', '92.2', '92.7', '81.9', '99.0', '95.0', '97.2', '71.4', '94.9', '76.5', '86.1', '86.5', '96.6', '94.3', '77.5', '96.1', '65.0', '93.8', '88.2']\n",
      "IoU: ['95.2', '93.9', '65.8', '87.8', '73.0', '74.4', '93.9', '88.0', '85.9', '43.3', '84.5', '68.4', '79.2', '84.0', '90.2', '89.6', '68.0', '83.9', '52.9', '89.4', '77.1']\n",
      "mean IoU: 79.4\n",
      "Epoch: [23] Train  [  0/183]  eta: 0:39:32  lr: 0.000474  loss: 2.3419 (2.3419)  time: 12.9622  data: 0.3793  max mem: 9511\n",
      "Epoch: [23] Train  [ 10/183]  eta: 0:35:26  lr: 0.000472  loss: 2.4564 (2.5405)  time: 12.2936  data: 0.0346  max mem: 9511\n",
      "Epoch: [23] Train  [ 20/183]  eta: 0:33:29  lr: 0.000471  loss: 2.3885 (2.5340)  time: 12.2989  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [ 30/183]  eta: 0:31:34  lr: 0.000469  loss: 2.4853 (2.5215)  time: 12.4327  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [ 40/183]  eta: 0:29:33  lr: 0.000468  loss: 2.4618 (2.5191)  time: 12.4825  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [ 50/183]  eta: 0:27:29  lr: 0.000467  loss: 2.6775 (2.5092)  time: 12.4374  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [ 60/183]  eta: 0:25:23  lr: 0.000465  loss: 2.8170 (2.5148)  time: 12.3437  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [ 70/183]  eta: 0:23:22  lr: 0.000464  loss: 2.4376 (2.5059)  time: 12.4137  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [ 80/183]  eta: 0:21:18  lr: 0.000463  loss: 2.4116 (2.5070)  time: 12.4855  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [ 90/183]  eta: 0:19:14  lr: 0.000461  loss: 2.1819 (2.4887)  time: 12.4525  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [100/183]  eta: 0:17:10  lr: 0.000460  loss: 2.4151 (2.4941)  time: 12.4422  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [110/183]  eta: 0:15:07  lr: 0.000458  loss: 2.3283 (2.4904)  time: 12.4663  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [120/183]  eta: 0:13:03  lr: 0.000457  loss: 2.4899 (2.4835)  time: 12.5826  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [130/183]  eta: 0:10:59  lr: 0.000456  loss: 2.3420 (2.4768)  time: 12.5195  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Train  [140/183]  eta: 0:08:55  lr: 0.000454  loss: 2.7387 (2.4778)  time: 12.5342  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Train  [150/183]  eta: 0:06:50  lr: 0.000453  loss: 2.4056 (2.4795)  time: 12.5068  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Train  [160/183]  eta: 0:04:46  lr: 0.000452  loss: 2.6494 (2.4762)  time: 12.3534  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Train  [170/183]  eta: 0:02:41  lr: 0.000450  loss: 2.5071 (2.4698)  time: 12.3485  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Train  [180/183]  eta: 0:00:37  lr: 0.000449  loss: 2.7863 (2.4755)  time: 12.3396  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Train Total time: 0:37:55\n",
      "Epoch: [23] Test  [  0/242]  eta: 0:05:52    time: 1.4564  data: 0.3821  max mem: 9511\n",
      "Epoch: [23] Test  [ 10/242]  eta: 0:03:52    time: 1.0004  data: 0.0350  max mem: 9511\n",
      "Epoch: [23] Test  [ 20/242]  eta: 0:03:34    time: 0.9435  data: 0.0004  max mem: 9511\n",
      "Epoch: [23] Test  [ 30/242]  eta: 0:03:31    time: 0.9928  data: 0.0004  max mem: 9511\n",
      "Epoch: [23] Test  [ 40/242]  eta: 0:03:24    time: 1.0545  data: 0.0004  max mem: 9511\n",
      "Epoch: [23] Test  [ 50/242]  eta: 0:03:15    time: 1.0513  data: 0.0005  max mem: 9511\n",
      "Epoch: [23] Test  [ 60/242]  eta: 0:03:08    time: 1.0831  data: 0.0004  max mem: 9511\n",
      "Epoch: [23] Test  [ 70/242]  eta: 0:02:58    time: 1.0914  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [ 80/242]  eta: 0:02:47    time: 1.0336  data: 0.0004  max mem: 9511\n",
      "Epoch: [23] Test  [ 90/242]  eta: 0:02:35    time: 0.9832  data: 0.0004  max mem: 9511\n",
      "Epoch: [23] Test  [100/242]  eta: 0:02:26    time: 1.0180  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [110/242]  eta: 0:02:15    time: 1.0359  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Test  [120/242]  eta: 0:02:06    time: 1.0474  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [130/242]  eta: 0:01:55    time: 1.0326  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [140/242]  eta: 0:01:44    time: 0.9825  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [150/242]  eta: 0:01:34    time: 0.9937  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [160/242]  eta: 0:01:23    time: 1.0082  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [170/242]  eta: 0:01:13    time: 1.0563  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [180/242]  eta: 0:01:04    time: 1.1164  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [190/242]  eta: 0:00:53    time: 1.1199  data: 0.0004  max mem: 9511\n",
      "Epoch: [23] Test  [200/242]  eta: 0:00:43    time: 1.0636  data: 0.0004  max mem: 9511\n",
      "Epoch: [23] Test  [210/242]  eta: 0:00:33    time: 1.0369  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Test  [220/242]  eta: 0:00:22    time: 1.0458  data: 0.0002  max mem: 9511\n",
      "Epoch: [23] Test  [230/242]  eta: 0:00:12    time: 1.0524  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test  [240/242]  eta: 0:00:02    time: 1.0154  data: 0.0003  max mem: 9511\n",
      "Epoch: [23] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['97.7', '94.9', '87.7', '94.6', '87.4', '90.1', '98.5', '95.0', '97.9', '68.1', '95.4', '76.8', '81.0', '91.7', '93.3', '94.3', '63.1', '94.8', '70.3', '94.8', '89.2']\n",
      "IoU: ['95.4', '93.1', '69.9', '88.8', '77.1', '76.8', '95.2', '87.9', '83.6', '46.7', '88.0', '70.8', '77.3', '88.6', '88.2', '90.1', '58.8', '87.1', '56.8', '89.1', '78.4']\n",
      "mean IoU: 80.4\n",
      "Epoch: [24] Train  [  0/183]  eta: 0:39:15  lr: 0.000448  loss: 2.8115 (2.8115)  time: 12.8717  data: 0.4251  max mem: 9511\n",
      "Epoch: [24] Train  [ 10/183]  eta: 0:36:00  lr: 0.000447  loss: 1.9334 (2.4501)  time: 12.4862  data: 0.0389  max mem: 9511\n",
      "Epoch: [24] Train  [ 20/183]  eta: 0:33:37  lr: 0.000446  loss: 2.5376 (2.4081)  time: 12.3549  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [ 30/183]  eta: 0:31:23  lr: 0.000444  loss: 2.6470 (2.4082)  time: 12.2134  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Train  [ 40/183]  eta: 0:29:18  lr: 0.000443  loss: 3.0727 (2.4155)  time: 12.2051  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Train  [ 50/183]  eta: 0:27:15  lr: 0.000441  loss: 2.9338 (2.4446)  time: 12.2849  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [ 60/183]  eta: 0:25:17  lr: 0.000440  loss: 2.3661 (2.4411)  time: 12.4247  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Train  [ 70/183]  eta: 0:23:13  lr: 0.000439  loss: 2.5992 (2.4500)  time: 12.4279  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Train  [ 80/183]  eta: 0:21:09  lr: 0.000437  loss: 2.6615 (2.4589)  time: 12.2712  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Train  [ 90/183]  eta: 0:19:06  lr: 0.000436  loss: 2.4997 (2.4589)  time: 12.3189  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [100/183]  eta: 0:17:04  lr: 0.000435  loss: 2.6638 (2.4760)  time: 12.4532  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [110/183]  eta: 0:15:01  lr: 0.000433  loss: 2.0657 (2.4730)  time: 12.4241  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [120/183]  eta: 0:12:58  lr: 0.000432  loss: 2.5487 (2.4698)  time: 12.4260  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [130/183]  eta: 0:10:55  lr: 0.000430  loss: 2.9416 (2.4767)  time: 12.4218  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [140/183]  eta: 0:08:51  lr: 0.000429  loss: 2.3190 (2.4793)  time: 12.4160  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Train  [150/183]  eta: 0:06:48  lr: 0.000428  loss: 2.3868 (2.4850)  time: 12.4204  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [160/183]  eta: 0:04:44  lr: 0.000426  loss: 2.2586 (2.4842)  time: 12.3974  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [170/183]  eta: 0:02:40  lr: 0.000425  loss: 2.4459 (2.4786)  time: 12.3244  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Train  [180/183]  eta: 0:00:37  lr: 0.000423  loss: 2.2641 (2.4773)  time: 12.3600  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Train Total time: 0:37:44\n",
      "Epoch: [24] Test  [  0/242]  eta: 0:05:48    time: 1.4402  data: 0.3662  max mem: 9511\n",
      "Epoch: [24] Test  [ 10/242]  eta: 0:03:51    time: 0.9985  data: 0.0336  max mem: 9511\n",
      "Epoch: [24] Test  [ 20/242]  eta: 0:03:34    time: 0.9433  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [ 30/242]  eta: 0:03:31    time: 0.9937  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [ 40/242]  eta: 0:03:23    time: 1.0544  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [ 50/242]  eta: 0:03:15    time: 1.0503  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [ 60/242]  eta: 0:03:08    time: 1.0836  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [ 70/242]  eta: 0:02:58    time: 1.0916  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [ 80/242]  eta: 0:02:47    time: 1.0328  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [ 90/242]  eta: 0:02:35    time: 0.9836  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Test  [100/242]  eta: 0:02:26    time: 1.0171  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [110/242]  eta: 0:02:15    time: 1.0350  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Test  [120/242]  eta: 0:02:06    time: 1.0489  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [130/242]  eta: 0:01:55    time: 1.0355  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [140/242]  eta: 0:01:44    time: 0.9853  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [150/242]  eta: 0:01:34    time: 0.9949  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [160/242]  eta: 0:01:24    time: 1.0115  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [170/242]  eta: 0:01:14    time: 1.0597  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [180/242]  eta: 0:01:04    time: 1.1166  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [190/242]  eta: 0:00:53    time: 1.1192  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Test  [200/242]  eta: 0:00:43    time: 1.0637  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Test  [210/242]  eta: 0:00:33    time: 1.0364  data: 0.0002  max mem: 9511\n",
      "Epoch: [24] Test  [220/242]  eta: 0:00:22    time: 1.0462  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [230/242]  eta: 0:00:12    time: 1.0533  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test  [240/242]  eta: 0:00:02    time: 1.0146  data: 0.0003  max mem: 9511\n",
      "Epoch: [24] Test Total time: 0:04:10\n",
      "global correct: 95.2\n",
      "average row correct: ['97.2', '96.2', '90.4', '95.4', '91.8', '85.7', '97.1', '95.9', '98.1', '77.2', '94.8', '79.0', '79.4', '94.8', '96.1', '93.6', '59.2', '96.8', '59.6', '95.2', '90.8']\n",
      "IoU: ['95.1', '93.8', '65.7', '89.1', '73.6', '76.0', '93.9', '85.2', '79.0', '44.9', '89.8', '71.5', '74.0', '89.1', '89.6', '90.0', '56.0', '85.4', '51.5', '88.4', '74.0']\n",
      "mean IoU: 78.8\n",
      "Epoch: [25] Train  [  0/183]  eta: 0:38:00  lr: 0.000423  loss: 2.4812 (2.4812)  time: 12.4631  data: 0.4471  max mem: 9511\n",
      "Epoch: [25] Train  [ 10/183]  eta: 0:36:00  lr: 0.000422  loss: 2.3358 (2.5682)  time: 12.4870  data: 0.0409  max mem: 9511\n",
      "Epoch: [25] Train  [ 20/183]  eta: 0:33:47  lr: 0.000420  loss: 2.4089 (2.5282)  time: 12.4371  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [ 30/183]  eta: 0:31:41  lr: 0.000419  loss: 2.3229 (2.5136)  time: 12.3947  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [ 40/183]  eta: 0:29:33  lr: 0.000417  loss: 2.7290 (2.5017)  time: 12.3696  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [ 50/183]  eta: 0:27:30  lr: 0.000416  loss: 2.4499 (2.5078)  time: 12.3798  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [ 60/183]  eta: 0:25:24  lr: 0.000415  loss: 2.6013 (2.4861)  time: 12.3747  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [ 70/183]  eta: 0:23:22  lr: 0.000413  loss: 2.6197 (2.4910)  time: 12.4313  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [ 80/183]  eta: 0:21:18  lr: 0.000412  loss: 2.8730 (2.5043)  time: 12.4545  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [ 90/183]  eta: 0:19:14  lr: 0.000411  loss: 2.4422 (2.5129)  time: 12.3897  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [100/183]  eta: 0:17:10  lr: 0.000409  loss: 2.4023 (2.5125)  time: 12.4410  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [110/183]  eta: 0:15:06  lr: 0.000408  loss: 2.7160 (2.5053)  time: 12.4687  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [120/183]  eta: 0:13:03  lr: 0.000406  loss: 2.2174 (2.4997)  time: 12.5310  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Train  [130/183]  eta: 0:10:59  lr: 0.000405  loss: 2.4358 (2.4967)  time: 12.5188  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Train  [140/183]  eta: 0:08:54  lr: 0.000404  loss: 2.7185 (2.4982)  time: 12.3722  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Train  [150/183]  eta: 0:06:49  lr: 0.000402  loss: 2.4147 (2.4945)  time: 12.3199  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Train  [160/183]  eta: 0:04:45  lr: 0.000401  loss: 2.4960 (2.4933)  time: 12.3182  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [170/183]  eta: 0:02:41  lr: 0.000399  loss: 2.5727 (2.4912)  time: 12.3446  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train  [180/183]  eta: 0:00:37  lr: 0.000398  loss: 2.3242 (2.4887)  time: 12.4411  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Train Total time: 0:37:52\n",
      "Epoch: [25] Test  [  0/242]  eta: 0:05:54    time: 1.4662  data: 0.3947  max mem: 9511\n",
      "Epoch: [25] Test  [ 10/242]  eta: 0:03:52    time: 1.0021  data: 0.0362  max mem: 9511\n",
      "Epoch: [25] Test  [ 20/242]  eta: 0:03:35    time: 0.9445  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [ 30/242]  eta: 0:03:31    time: 0.9937  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [ 40/242]  eta: 0:03:24    time: 1.0533  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [ 50/242]  eta: 0:03:15    time: 1.0486  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [ 60/242]  eta: 0:03:08    time: 1.0819  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Test  [ 70/242]  eta: 0:02:58    time: 1.0917  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Test  [ 80/242]  eta: 0:02:47    time: 1.0336  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [ 90/242]  eta: 0:02:35    time: 0.9823  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [100/242]  eta: 0:02:26    time: 1.0192  data: 0.0004  max mem: 9511\n",
      "Epoch: [25] Test  [110/242]  eta: 0:02:15    time: 1.0361  data: 0.0004  max mem: 9511\n",
      "Epoch: [25] Test  [120/242]  eta: 0:02:06    time: 1.0462  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Test  [130/242]  eta: 0:01:55    time: 1.0342  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [140/242]  eta: 0:01:44    time: 0.9864  data: 0.0005  max mem: 9511\n",
      "Epoch: [25] Test  [150/242]  eta: 0:01:34    time: 0.9954  data: 0.0005  max mem: 9511\n",
      "Epoch: [25] Test  [160/242]  eta: 0:01:23    time: 1.0079  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [170/242]  eta: 0:01:14    time: 1.0554  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [180/242]  eta: 0:01:04    time: 1.1133  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [190/242]  eta: 0:00:53    time: 1.1189  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test  [200/242]  eta: 0:00:43    time: 1.0647  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Test  [210/242]  eta: 0:00:33    time: 1.0371  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Test  [220/242]  eta: 0:00:22    time: 1.0461  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Test  [230/242]  eta: 0:00:12    time: 1.0522  data: 0.0002  max mem: 9511\n",
      "Epoch: [25] Test  [240/242]  eta: 0:00:02    time: 1.0147  data: 0.0003  max mem: 9511\n",
      "Epoch: [25] Test Total time: 0:04:10\n",
      "global correct: 95.7\n",
      "average row correct: ['97.5', '95.5', '86.0', '95.0', '90.9', '86.0', '96.9', '93.9', '96.2', '66.8', '95.7', '80.6', '88.5', '93.3', '94.6', '95.5', '59.3', '96.3', '73.1', '94.7', '89.1']\n",
      "IoU: ['95.4', '93.0', '71.0', '89.3', '76.2', '76.3', '94.2', '89.7', '86.5', '42.8', '90.0', '73.1', '82.8', '89.6', '88.4', '90.4', '56.0', '85.4', '55.0', '88.4', '80.4']\n",
      "mean IoU: 80.7\n",
      "Epoch: [26] Train  [  0/183]  eta: 0:40:03  lr: 0.000398  loss: 2.2874 (2.2874)  time: 13.1362  data: 0.3995  max mem: 9511\n",
      "Epoch: [26] Train  [ 10/183]  eta: 0:35:45  lr: 0.000396  loss: 2.4360 (2.3935)  time: 12.3992  data: 0.0366  max mem: 9511\n",
      "Epoch: [26] Train  [ 20/183]  eta: 0:33:33  lr: 0.000395  loss: 2.1852 (2.3830)  time: 12.3165  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [ 30/183]  eta: 0:31:32  lr: 0.000393  loss: 2.7068 (2.3900)  time: 12.3553  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [ 40/183]  eta: 0:29:33  lr: 0.000392  loss: 2.4087 (2.4099)  time: 12.4513  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [ 50/183]  eta: 0:27:27  lr: 0.000391  loss: 2.6603 (2.4159)  time: 12.4110  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [ 60/183]  eta: 0:25:23  lr: 0.000389  loss: 2.4518 (2.4270)  time: 12.3624  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [ 70/183]  eta: 0:23:22  lr: 0.000388  loss: 2.0564 (2.4088)  time: 12.4759  data: 0.0004  max mem: 9511\n",
      "Epoch: [26] Train  [ 80/183]  eta: 0:21:20  lr: 0.000386  loss: 2.4808 (2.4297)  time: 12.5689  data: 0.0004  max mem: 9511\n",
      "Epoch: [26] Train  [ 90/183]  eta: 0:19:17  lr: 0.000385  loss: 2.4141 (2.4299)  time: 12.5475  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [100/183]  eta: 0:17:10  lr: 0.000384  loss: 2.3891 (2.4366)  time: 12.3694  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [110/183]  eta: 0:15:07  lr: 0.000382  loss: 2.6214 (2.4448)  time: 12.3696  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [120/183]  eta: 0:13:02  lr: 0.000381  loss: 2.2831 (2.4443)  time: 12.3795  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Train  [130/183]  eta: 0:10:57  lr: 0.000379  loss: 2.3615 (2.4426)  time: 12.2726  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Train  [140/183]  eta: 0:08:52  lr: 0.000378  loss: 2.7834 (2.4449)  time: 12.2785  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [150/183]  eta: 0:06:49  lr: 0.000377  loss: 2.5316 (2.4457)  time: 12.3612  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Train  [160/183]  eta: 0:04:45  lr: 0.000375  loss: 2.4473 (2.4414)  time: 12.4282  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Train  [170/183]  eta: 0:02:41  lr: 0.000374  loss: 2.6794 (2.4404)  time: 12.3381  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Train  [180/183]  eta: 0:00:37  lr: 0.000372  loss: 2.7321 (2.4501)  time: 12.3385  data: 0.0004  max mem: 9511\n",
      "Epoch: [26] Train Total time: 0:37:48\n",
      "Epoch: [26] Test  [  0/242]  eta: 0:06:02    time: 1.4971  data: 0.4241  max mem: 9511\n",
      "Epoch: [26] Test  [ 10/242]  eta: 0:03:53    time: 1.0061  data: 0.0389  max mem: 9511\n",
      "Epoch: [26] Test  [ 20/242]  eta: 0:03:35    time: 0.9445  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [ 30/242]  eta: 0:03:31    time: 0.9935  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [ 40/242]  eta: 0:03:24    time: 1.0522  data: 0.0006  max mem: 9511\n",
      "Epoch: [26] Test  [ 50/242]  eta: 0:03:15    time: 1.0453  data: 0.0005  max mem: 9511\n",
      "Epoch: [26] Test  [ 60/242]  eta: 0:03:08    time: 1.0802  data: 0.0004  max mem: 9511\n",
      "Epoch: [26] Test  [ 70/242]  eta: 0:02:58    time: 1.0893  data: 0.0007  max mem: 9511\n",
      "Epoch: [26] Test  [ 80/242]  eta: 0:02:47    time: 1.0309  data: 0.0005  max mem: 9511\n",
      "Epoch: [26] Test  [ 90/242]  eta: 0:02:35    time: 0.9813  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [100/242]  eta: 0:02:26    time: 1.0157  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [110/242]  eta: 0:02:15    time: 1.0325  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [120/242]  eta: 0:02:05    time: 1.0434  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [130/242]  eta: 0:01:55    time: 1.0321  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Test  [140/242]  eta: 0:01:44    time: 0.9835  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [150/242]  eta: 0:01:34    time: 0.9910  data: 0.0002  max mem: 9511\n",
      "Epoch: [26] Test  [160/242]  eta: 0:01:23    time: 1.0045  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [170/242]  eta: 0:01:13    time: 1.0538  data: 0.0004  max mem: 9511\n",
      "Epoch: [26] Test  [180/242]  eta: 0:01:04    time: 1.1128  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [190/242]  eta: 0:00:53    time: 1.1167  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [200/242]  eta: 0:00:43    time: 1.0632  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [210/242]  eta: 0:00:33    time: 1.0369  data: 0.0004  max mem: 9511\n",
      "Epoch: [26] Test  [220/242]  eta: 0:00:22    time: 1.0453  data: 0.0004  max mem: 9511\n",
      "Epoch: [26] Test  [230/242]  eta: 0:00:12    time: 1.0514  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test  [240/242]  eta: 0:00:02    time: 1.0137  data: 0.0003  max mem: 9511\n",
      "Epoch: [26] Test Total time: 0:04:09\n",
      "global correct: 95.5\n",
      "average row correct: ['97.4', '90.4', '85.5', '95.1', '89.1', '87.5', '98.0', '93.9', '96.6', '74.1', '94.6', '78.7', '83.4', '93.7', '97.1', '94.5', '66.6', '95.7', '65.3', '94.4', '91.6']\n",
      "IoU: ['95.2', '89.3', '67.4', '89.5', '72.5', '74.5', '95.5', '89.6', '83.7', '46.7', '90.2', '68.9', '78.0', '90.2', '88.6', '90.1', '60.2', '86.7', '54.3', '88.1', '75.5']\n",
      "mean IoU: 79.7\n",
      "Epoch: [27] Train  [  0/183]  eta: 0:39:12  lr: 0.000372  loss: 2.5501 (2.5501)  time: 12.8565  data: 0.4520  max mem: 9511\n",
      "Epoch: [27] Train  [ 10/183]  eta: 0:36:04  lr: 0.000370  loss: 2.3917 (2.4283)  time: 12.5131  data: 0.0413  max mem: 9511\n",
      "Epoch: [27] Train  [ 20/183]  eta: 0:33:45  lr: 0.000369  loss: 2.3559 (2.4290)  time: 12.4071  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [ 30/183]  eta: 0:31:43  lr: 0.000368  loss: 2.5601 (2.4090)  time: 12.4003  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [ 40/183]  eta: 0:29:35  lr: 0.000366  loss: 1.9876 (2.3777)  time: 12.3987  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [ 50/183]  eta: 0:27:26  lr: 0.000365  loss: 2.7000 (2.4112)  time: 12.2905  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [ 60/183]  eta: 0:25:25  lr: 0.000363  loss: 2.2436 (2.4015)  time: 12.3859  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [ 70/183]  eta: 0:23:21  lr: 0.000362  loss: 2.6068 (2.3947)  time: 12.4548  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [ 80/183]  eta: 0:21:17  lr: 0.000361  loss: 2.5457 (2.3917)  time: 12.4055  data: 0.0004  max mem: 9511\n",
      "Epoch: [27] Train  [ 90/183]  eta: 0:19:12  lr: 0.000359  loss: 2.8158 (2.4014)  time: 12.3732  data: 0.0006  max mem: 9511\n",
      "Epoch: [27] Train  [100/183]  eta: 0:17:08  lr: 0.000358  loss: 2.4669 (2.4172)  time: 12.3316  data: 0.0004  max mem: 9511\n",
      "Epoch: [27] Train  [110/183]  eta: 0:15:05  lr: 0.000356  loss: 2.1561 (2.4195)  time: 12.4071  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Train  [120/183]  eta: 0:12:59  lr: 0.000355  loss: 2.6000 (2.4127)  time: 12.3273  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [130/183]  eta: 0:10:56  lr: 0.000354  loss: 2.5733 (2.4101)  time: 12.3060  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [140/183]  eta: 0:08:52  lr: 0.000352  loss: 2.3629 (2.4074)  time: 12.4262  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Train  [150/183]  eta: 0:06:48  lr: 0.000351  loss: 2.5024 (2.4071)  time: 12.3978  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Train  [160/183]  eta: 0:04:44  lr: 0.000349  loss: 2.5294 (2.4097)  time: 12.3815  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Train  [170/183]  eta: 0:02:41  lr: 0.000348  loss: 2.2643 (2.4075)  time: 12.4363  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Train  [180/183]  eta: 0:00:37  lr: 0.000346  loss: 2.3970 (2.4068)  time: 12.3472  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Train Total time: 0:37:46\n",
      "Epoch: [27] Test  [  0/242]  eta: 0:05:54    time: 1.4661  data: 0.3955  max mem: 9511\n",
      "Epoch: [27] Test  [ 10/242]  eta: 0:03:51    time: 0.9997  data: 0.0362  max mem: 9511\n",
      "Epoch: [27] Test  [ 20/242]  eta: 0:03:35    time: 0.9442  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [ 30/242]  eta: 0:03:31    time: 0.9955  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Test  [ 40/242]  eta: 0:03:24    time: 1.0546  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Test  [ 50/242]  eta: 0:03:15    time: 1.0489  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [ 60/242]  eta: 0:03:08    time: 1.0816  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [ 70/242]  eta: 0:02:58    time: 1.0898  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [ 80/242]  eta: 0:02:47    time: 1.0330  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [ 90/242]  eta: 0:02:35    time: 0.9828  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [100/242]  eta: 0:02:26    time: 1.0157  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [110/242]  eta: 0:02:15    time: 1.0351  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [120/242]  eta: 0:02:06    time: 1.0493  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [130/242]  eta: 0:01:55    time: 1.0363  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [140/242]  eta: 0:01:44    time: 0.9849  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [150/242]  eta: 0:01:34    time: 0.9922  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Test  [160/242]  eta: 0:01:23    time: 1.0053  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [170/242]  eta: 0:01:13    time: 1.0562  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [180/242]  eta: 0:01:04    time: 1.1182  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [190/242]  eta: 0:00:53    time: 1.1208  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [200/242]  eta: 0:00:43    time: 1.0638  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [210/242]  eta: 0:00:33    time: 1.0355  data: 0.0003  max mem: 9511\n",
      "Epoch: [27] Test  [220/242]  eta: 0:00:22    time: 1.0436  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Test  [230/242]  eta: 0:00:12    time: 1.0511  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Test  [240/242]  eta: 0:00:02    time: 1.0138  data: 0.0002  max mem: 9511\n",
      "Epoch: [27] Test Total time: 0:04:10\n",
      "global correct: 95.8\n",
      "average row correct: ['97.7', '94.4', '87.7', '94.0', '86.0', '87.7', '97.8', '92.9', '95.8', '73.2', '95.1', '84.0', '88.0', '95.1', '97.4', '94.5', '67.4', '97.0', '62.4', '95.5', '87.8']\n",
      "IoU: ['95.5', '92.1', '67.3', '88.7', '78.3', '76.8', '94.9', '89.6', '85.8', '47.6', '90.6', '70.8', '81.7', '90.9', '89.4', '90.2', '61.0', '81.3', '56.2', '89.8', '82.0']\n",
      "mean IoU: 81.0\n",
      "Epoch: [28] Train  [  0/183]  eta: 0:39:45  lr: 0.000346  loss: 2.4398 (2.4398)  time: 13.0362  data: 0.3664  max mem: 9511\n",
      "Epoch: [28] Train  [ 10/183]  eta: 0:35:56  lr: 0.000345  loss: 2.5934 (2.4049)  time: 12.4678  data: 0.0335  max mem: 9511\n",
      "Epoch: [28] Train  [ 20/183]  eta: 0:33:41  lr: 0.000343  loss: 2.4767 (2.4048)  time: 12.3717  data: 0.0002  max mem: 9511\n",
      "Epoch: [28] Train  [ 30/183]  eta: 0:31:26  lr: 0.000342  loss: 2.6625 (2.4144)  time: 12.2567  data: 0.0002  max mem: 9511\n",
      "Epoch: [28] Train  [ 40/183]  eta: 0:29:19  lr: 0.000340  loss: 2.2481 (2.3912)  time: 12.1970  data: 0.0002  max mem: 9511\n",
      "Epoch: [28] Train  [ 50/183]  eta: 0:27:20  lr: 0.000339  loss: 2.8606 (2.4106)  time: 12.3326  data: 0.0004  max mem: 9511\n",
      "Epoch: [28] Train  [ 60/183]  eta: 0:25:20  lr: 0.000338  loss: 3.0027 (2.4046)  time: 12.4763  data: 0.0005  max mem: 9511\n",
      "Epoch: [28] Train  [ 70/183]  eta: 0:23:15  lr: 0.000336  loss: 2.7589 (2.4044)  time: 12.4047  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [ 80/183]  eta: 0:21:15  lr: 0.000335  loss: 2.2553 (2.4075)  time: 12.4738  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [ 90/183]  eta: 0:19:11  lr: 0.000333  loss: 2.2041 (2.4092)  time: 12.5019  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [100/183]  eta: 0:17:07  lr: 0.000332  loss: 2.4327 (2.4171)  time: 12.3685  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [110/183]  eta: 0:15:04  lr: 0.000330  loss: 2.4914 (2.4136)  time: 12.4369  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [120/183]  eta: 0:13:00  lr: 0.000329  loss: 2.3360 (2.4037)  time: 12.4261  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [130/183]  eta: 0:10:57  lr: 0.000328  loss: 2.7254 (2.4027)  time: 12.4217  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [140/183]  eta: 0:08:52  lr: 0.000326  loss: 2.1101 (2.3997)  time: 12.3986  data: 0.0005  max mem: 9511\n",
      "Epoch: [28] Train  [150/183]  eta: 0:06:48  lr: 0.000325  loss: 2.1770 (2.3935)  time: 12.3426  data: 0.0005  max mem: 9511\n",
      "Epoch: [28] Train  [160/183]  eta: 0:04:44  lr: 0.000323  loss: 2.2405 (2.3917)  time: 12.3708  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [170/183]  eta: 0:02:40  lr: 0.000322  loss: 2.3770 (2.3900)  time: 12.3161  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Train  [180/183]  eta: 0:00:37  lr: 0.000320  loss: 2.3279 (2.3931)  time: 12.2494  data: 0.0002  max mem: 9511\n",
      "Epoch: [28] Train Total time: 0:37:43\n",
      "Epoch: [28] Test  [  0/242]  eta: 0:06:02    time: 1.4984  data: 0.4334  max mem: 9511\n",
      "Epoch: [28] Test  [ 10/242]  eta: 0:03:52    time: 1.0019  data: 0.0398  max mem: 9511\n",
      "Epoch: [28] Test  [ 20/242]  eta: 0:03:35    time: 0.9425  data: 0.0004  max mem: 9511\n",
      "Epoch: [28] Test  [ 30/242]  eta: 0:03:31    time: 0.9924  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [ 40/242]  eta: 0:03:23    time: 1.0516  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [ 50/242]  eta: 0:03:14    time: 1.0463  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [ 60/242]  eta: 0:03:08    time: 1.0823  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [ 70/242]  eta: 0:02:58    time: 1.0930  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [ 80/242]  eta: 0:02:47    time: 1.0334  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [ 90/242]  eta: 0:02:35    time: 0.9815  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [100/242]  eta: 0:02:26    time: 1.0149  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [110/242]  eta: 0:02:15    time: 1.0345  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [120/242]  eta: 0:02:06    time: 1.0487  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [130/242]  eta: 0:01:55    time: 1.0357  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [140/242]  eta: 0:01:44    time: 0.9842  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [150/242]  eta: 0:01:34    time: 0.9926  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [160/242]  eta: 0:01:23    time: 1.0075  data: 0.0002  max mem: 9511\n",
      "Epoch: [28] Test  [170/242]  eta: 0:01:13    time: 1.0567  data: 0.0002  max mem: 9511\n",
      "Epoch: [28] Test  [180/242]  eta: 0:01:04    time: 1.1168  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [190/242]  eta: 0:00:53    time: 1.1210  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [200/242]  eta: 0:00:43    time: 1.0665  data: 0.0002  max mem: 9511\n",
      "Epoch: [28] Test  [210/242]  eta: 0:00:33    time: 1.0379  data: 0.0002  max mem: 9511\n",
      "Epoch: [28] Test  [220/242]  eta: 0:00:22    time: 1.0450  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [230/242]  eta: 0:00:12    time: 1.0539  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test  [240/242]  eta: 0:00:02    time: 1.0169  data: 0.0003  max mem: 9511\n",
      "Epoch: [28] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['97.6', '95.4', '87.1', '95.5', '89.3', '86.0', '97.7', '93.8', '96.2', '67.7', '95.3', '76.7', '89.2', '94.9', '95.4', '94.5', '71.8', '96.7', '70.5', '86.8', '88.4']\n",
      "IoU: ['95.3', '93.5', '67.5', '90.0', '76.4', '76.3', '93.8', '89.2', '85.4', '45.3', '90.9', '70.7', '80.9', '90.1', '89.6', '90.2', '63.4', '82.7', '55.8', '84.2', '79.7']\n",
      "mean IoU: 80.5\n",
      "Epoch: [29] Train  [  0/183]  eta: 0:41:16  lr: 0.000320  loss: 2.6793 (2.6793)  time: 13.5310  data: 0.4119  max mem: 9511\n",
      "Epoch: [29] Train  [ 10/183]  eta: 0:36:15  lr: 0.000319  loss: 2.5485 (2.4793)  time: 12.5730  data: 0.0377  max mem: 9511\n",
      "Epoch: [29] Train  [ 20/183]  eta: 0:34:01  lr: 0.000317  loss: 2.2223 (2.4684)  time: 12.4727  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Train  [ 30/183]  eta: 0:31:43  lr: 0.000316  loss: 2.5823 (2.4338)  time: 12.3706  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Train  [ 40/183]  eta: 0:29:42  lr: 0.000314  loss: 2.4707 (2.4085)  time: 12.4054  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Train  [ 50/183]  eta: 0:27:36  lr: 0.000313  loss: 2.0900 (2.3921)  time: 12.4697  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Train  [ 60/183]  eta: 0:25:30  lr: 0.000311  loss: 2.1717 (2.3751)  time: 12.3906  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Train  [ 70/183]  eta: 0:23:21  lr: 0.000310  loss: 2.4224 (2.3798)  time: 12.2843  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Train  [ 80/183]  eta: 0:21:19  lr: 0.000308  loss: 2.2554 (2.3886)  time: 12.3459  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Train  [ 90/183]  eta: 0:19:13  lr: 0.000307  loss: 2.3971 (2.3797)  time: 12.4020  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Train  [100/183]  eta: 0:17:09  lr: 0.000306  loss: 2.3459 (2.3731)  time: 12.3619  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Train  [110/183]  eta: 0:15:05  lr: 0.000304  loss: 2.4659 (2.3751)  time: 12.3995  data: 0.0004  max mem: 9511\n",
      "Epoch: [29] Train  [120/183]  eta: 0:13:01  lr: 0.000303  loss: 2.5273 (2.3849)  time: 12.3678  data: 0.0004  max mem: 9511\n",
      "Epoch: [29] Train  [130/183]  eta: 0:10:57  lr: 0.000301  loss: 2.5801 (2.3830)  time: 12.3807  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Train  [140/183]  eta: 0:08:52  lr: 0.000300  loss: 2.3030 (2.3764)  time: 12.3243  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Train  [150/183]  eta: 0:06:48  lr: 0.000298  loss: 2.1635 (2.3772)  time: 12.3415  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Train  [160/183]  eta: 0:04:45  lr: 0.000297  loss: 2.2666 (2.3816)  time: 12.4432  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Train  [170/183]  eta: 0:02:41  lr: 0.000296  loss: 2.2636 (2.3740)  time: 12.4391  data: 0.0004  max mem: 9511\n",
      "Epoch: [29] Train  [180/183]  eta: 0:00:37  lr: 0.000294  loss: 2.7576 (2.3726)  time: 12.3214  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Train Total time: 0:37:46\n",
      "Epoch: [29] Test  [  0/242]  eta: 0:05:57    time: 1.4788  data: 0.3896  max mem: 9511\n",
      "Epoch: [29] Test  [ 10/242]  eta: 0:03:52    time: 1.0014  data: 0.0356  max mem: 9511\n",
      "Epoch: [29] Test  [ 20/242]  eta: 0:03:34    time: 0.9429  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [ 30/242]  eta: 0:03:31    time: 0.9945  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [ 40/242]  eta: 0:03:24    time: 1.0555  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Test  [ 50/242]  eta: 0:03:15    time: 1.0473  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Test  [ 60/242]  eta: 0:03:08    time: 1.0833  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Test  [ 70/242]  eta: 0:02:58    time: 1.0946  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [ 80/242]  eta: 0:02:47    time: 1.0350  data: 0.0004  max mem: 9511\n",
      "Epoch: [29] Test  [ 90/242]  eta: 0:02:36    time: 0.9835  data: 0.0004  max mem: 9511\n",
      "Epoch: [29] Test  [100/242]  eta: 0:02:26    time: 1.0158  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Test  [110/242]  eta: 0:02:15    time: 1.0354  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [120/242]  eta: 0:02:06    time: 1.0478  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [130/242]  eta: 0:01:55    time: 1.0367  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [140/242]  eta: 0:01:44    time: 0.9865  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [150/242]  eta: 0:01:34    time: 0.9928  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [160/242]  eta: 0:01:24    time: 1.0083  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [170/242]  eta: 0:01:14    time: 1.0579  data: 0.0002  max mem: 9511\n",
      "Epoch: [29] Test  [180/242]  eta: 0:01:04    time: 1.1164  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [190/242]  eta: 0:00:53    time: 1.1188  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [200/242]  eta: 0:00:43    time: 1.0646  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [210/242]  eta: 0:00:33    time: 1.0371  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [220/242]  eta: 0:00:22    time: 1.0458  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [230/242]  eta: 0:00:12    time: 1.0528  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test  [240/242]  eta: 0:00:02    time: 1.0147  data: 0.0003  max mem: 9511\n",
      "Epoch: [29] Test Total time: 0:04:10\n",
      "global correct: 95.8\n",
      "average row correct: ['97.9', '94.9', '87.6', '93.9', '89.1', '89.0', '98.2', '93.0', '96.4', '72.6', '95.1', '79.2', '84.6', '95.6', '96.3', '94.3', '71.2', '96.3', '61.6', '94.0', '86.7']\n",
      "IoU: ['95.6', '92.3', '69.3', '88.3', '77.4', '76.1', '95.2', '89.3', '85.0', '45.8', '89.9', '71.5', '79.7', '88.6', '89.9', '90.3', '64.1', '86.4', '55.7', '89.3', '81.1']\n",
      "mean IoU: 81.0\n",
      "Epoch: [30] Train  [  0/183]  eta: 0:40:35  lr: 0.000294  loss: 2.3217 (2.3217)  time: 13.3115  data: 0.4240  max mem: 9511\n",
      "Epoch: [30] Train  [ 10/183]  eta: 0:35:54  lr: 0.000292  loss: 2.1115 (2.2758)  time: 12.4520  data: 0.0388  max mem: 9511\n",
      "Epoch: [30] Train  [ 20/183]  eta: 0:33:36  lr: 0.000291  loss: 2.0860 (2.2838)  time: 12.3218  data: 0.0002  max mem: 9511\n",
      "Epoch: [30] Train  [ 30/183]  eta: 0:31:30  lr: 0.000289  loss: 2.2449 (2.3029)  time: 12.3041  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Train  [ 40/183]  eta: 0:29:28  lr: 0.000288  loss: 2.2036 (2.3145)  time: 12.3653  data: 0.0004  max mem: 9511\n",
      "Epoch: [30] Train  [ 50/183]  eta: 0:27:24  lr: 0.000286  loss: 2.7261 (2.3351)  time: 12.3822  data: 0.0004  max mem: 9511\n",
      "Epoch: [30] Train  [ 60/183]  eta: 0:25:22  lr: 0.000285  loss: 2.4599 (2.3350)  time: 12.4092  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Train  [ 70/183]  eta: 0:23:20  lr: 0.000284  loss: 1.9305 (2.3116)  time: 12.4648  data: 0.0005  max mem: 9511\n",
      "Epoch: [30] Train  [ 80/183]  eta: 0:21:17  lr: 0.000282  loss: 2.5963 (2.3223)  time: 12.4845  data: 0.0005  max mem: 9511\n",
      "Epoch: [30] Train  [ 90/183]  eta: 0:19:13  lr: 0.000281  loss: 2.2674 (2.3075)  time: 12.4286  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Train  [100/183]  eta: 0:17:10  lr: 0.000279  loss: 2.4177 (2.3048)  time: 12.4475  data: 0.0004  max mem: 9511\n",
      "Epoch: [30] Train  [110/183]  eta: 0:15:06  lr: 0.000278  loss: 2.4431 (2.3058)  time: 12.4870  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Train  [120/183]  eta: 0:13:01  lr: 0.000276  loss: 2.6882 (2.3074)  time: 12.3625  data: 0.0006  max mem: 9511\n",
      "Epoch: [30] Train  [130/183]  eta: 0:10:57  lr: 0.000275  loss: 2.5169 (2.3109)  time: 12.3426  data: 0.0005  max mem: 9511\n",
      "Epoch: [30] Train  [140/183]  eta: 0:08:53  lr: 0.000273  loss: 2.4674 (2.3161)  time: 12.3352  data: 0.0002  max mem: 9511\n",
      "Epoch: [30] Train  [150/183]  eta: 0:06:48  lr: 0.000272  loss: 2.8305 (2.3129)  time: 12.3071  data: 0.0002  max mem: 9511\n",
      "Epoch: [30] Train  [160/183]  eta: 0:04:45  lr: 0.000270  loss: 2.2555 (2.3150)  time: 12.3691  data: 0.0002  max mem: 9511\n",
      "Epoch: [30] Train  [170/183]  eta: 0:02:41  lr: 0.000269  loss: 2.6408 (2.3217)  time: 12.4464  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Train  [180/183]  eta: 0:00:37  lr: 0.000268  loss: 1.9527 (2.3207)  time: 12.4360  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Train Total time: 0:37:48\n",
      "Epoch: [30] Test  [  0/242]  eta: 0:05:53    time: 1.4628  data: 0.3909  max mem: 9511\n",
      "Epoch: [30] Test  [ 10/242]  eta: 0:03:52    time: 1.0033  data: 0.0358  max mem: 9511\n",
      "Epoch: [30] Test  [ 20/242]  eta: 0:03:35    time: 0.9472  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [ 30/242]  eta: 0:03:31    time: 0.9974  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [ 40/242]  eta: 0:03:24    time: 1.0568  data: 0.0002  max mem: 9511\n",
      "Epoch: [30] Test  [ 50/242]  eta: 0:03:15    time: 1.0524  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [ 60/242]  eta: 0:03:08    time: 1.0840  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [ 70/242]  eta: 0:02:59    time: 1.0946  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [ 80/242]  eta: 0:02:47    time: 1.0372  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [ 90/242]  eta: 0:02:36    time: 0.9837  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [100/242]  eta: 0:02:26    time: 1.0188  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [110/242]  eta: 0:02:15    time: 1.0360  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [120/242]  eta: 0:02:06    time: 1.0477  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [130/242]  eta: 0:01:55    time: 1.0363  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [140/242]  eta: 0:01:44    time: 0.9865  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [150/242]  eta: 0:01:34    time: 0.9946  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [160/242]  eta: 0:01:24    time: 1.0100  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [170/242]  eta: 0:01:14    time: 1.0585  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [180/242]  eta: 0:01:04    time: 1.1172  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [190/242]  eta: 0:00:54    time: 1.1212  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [200/242]  eta: 0:00:43    time: 1.0663  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [210/242]  eta: 0:00:33    time: 1.0387  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [220/242]  eta: 0:00:22    time: 1.0457  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [230/242]  eta: 0:00:12    time: 1.0514  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test  [240/242]  eta: 0:00:02    time: 1.0155  data: 0.0003  max mem: 9511\n",
      "Epoch: [30] Test Total time: 0:04:10\n",
      "global correct: 95.7\n",
      "average row correct: ['97.8', '96.0', '88.9', '94.4', '91.4', '87.1', '98.5', '92.8', '96.2', '70.1', '95.3', '75.9', '82.5', '91.0', '97.0', '94.3', '69.0', '96.3', '67.8', '93.4', '89.7']\n",
      "IoU: ['95.5', '93.7', '62.7', '88.8', '69.5', '76.4', '94.4', '88.4', '82.6', '47.7', '89.2', '69.5', '78.3', '87.5', '89.1', '90.4', '63.4', '82.5', '59.4', '89.3', '79.4']\n",
      "mean IoU: 79.9\n",
      "Epoch: [31] Train  [  0/183]  eta: 0:39:50  lr: 0.000267  loss: 2.0389 (2.0389)  time: 13.0639  data: 0.4270  max mem: 9511\n",
      "Epoch: [31] Train  [ 10/183]  eta: 0:35:46  lr: 0.000266  loss: 2.1630 (2.3617)  time: 12.4083  data: 0.0390  max mem: 9511\n",
      "Epoch: [31] Train  [ 20/183]  eta: 0:33:29  lr: 0.000264  loss: 2.2580 (2.3113)  time: 12.2889  data: 0.0002  max mem: 9511\n",
      "Epoch: [31] Train  [ 30/183]  eta: 0:31:31  lr: 0.000263  loss: 2.1948 (2.2868)  time: 12.3368  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [ 40/183]  eta: 0:29:25  lr: 0.000261  loss: 2.8566 (2.2867)  time: 12.3730  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [ 50/183]  eta: 0:27:25  lr: 0.000260  loss: 2.3542 (2.3106)  time: 12.3917  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [ 60/183]  eta: 0:25:17  lr: 0.000258  loss: 2.1473 (2.3135)  time: 12.3095  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [ 70/183]  eta: 0:23:12  lr: 0.000257  loss: 2.2000 (2.3022)  time: 12.2018  data: 0.0002  max mem: 9511\n",
      "Epoch: [31] Train  [ 80/183]  eta: 0:21:06  lr: 0.000255  loss: 2.3995 (2.3046)  time: 12.1732  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [ 90/183]  eta: 0:19:04  lr: 0.000254  loss: 2.4032 (2.3057)  time: 12.2457  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [100/183]  eta: 0:17:01  lr: 0.000252  loss: 2.3179 (2.3028)  time: 12.3384  data: 0.0004  max mem: 9511\n",
      "Epoch: [31] Train  [110/183]  eta: 0:14:58  lr: 0.000251  loss: 2.3394 (2.2974)  time: 12.3050  data: 0.0004  max mem: 9511\n",
      "Epoch: [31] Train  [120/183]  eta: 0:12:54  lr: 0.000249  loss: 2.6291 (2.3017)  time: 12.2869  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [130/183]  eta: 0:10:51  lr: 0.000248  loss: 2.8371 (2.3111)  time: 12.2492  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [140/183]  eta: 0:08:49  lr: 0.000247  loss: 2.3211 (2.3121)  time: 12.3502  data: 0.0002  max mem: 9511\n",
      "Epoch: [31] Train  [150/183]  eta: 0:06:45  lr: 0.000245  loss: 2.4350 (2.3130)  time: 12.3094  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [160/183]  eta: 0:04:42  lr: 0.000244  loss: 2.4063 (2.3143)  time: 12.2472  data: 0.0002  max mem: 9511\n",
      "Epoch: [31] Train  [170/183]  eta: 0:02:39  lr: 0.000242  loss: 2.4055 (2.3134)  time: 12.2755  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train  [180/183]  eta: 0:00:36  lr: 0.000241  loss: 2.1176 (2.3119)  time: 12.2325  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Train Total time: 0:37:30\n",
      "Epoch: [31] Test  [  0/242]  eta: 0:06:04    time: 1.5061  data: 0.4360  max mem: 9511\n",
      "Epoch: [31] Test  [ 10/242]  eta: 0:03:53    time: 1.0046  data: 0.0399  max mem: 9511\n",
      "Epoch: [31] Test  [ 20/242]  eta: 0:03:35    time: 0.9439  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [ 30/242]  eta: 0:03:31    time: 0.9958  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [ 40/242]  eta: 0:03:24    time: 1.0562  data: 0.0004  max mem: 9511\n",
      "Epoch: [31] Test  [ 50/242]  eta: 0:03:15    time: 1.0492  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [ 60/242]  eta: 0:03:08    time: 1.0835  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [ 70/242]  eta: 0:02:58    time: 1.0937  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [ 80/242]  eta: 0:02:47    time: 1.0370  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [ 90/242]  eta: 0:02:36    time: 0.9861  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [100/242]  eta: 0:02:26    time: 1.0199  data: 0.0004  max mem: 9511\n",
      "Epoch: [31] Test  [110/242]  eta: 0:02:15    time: 1.0383  data: 0.0004  max mem: 9511\n",
      "Epoch: [31] Test  [120/242]  eta: 0:02:06    time: 1.0485  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [130/242]  eta: 0:01:55    time: 1.0367  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [140/242]  eta: 0:01:44    time: 0.9865  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [150/242]  eta: 0:01:34    time: 0.9942  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [160/242]  eta: 0:01:24    time: 1.0095  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [170/242]  eta: 0:01:14    time: 1.0587  data: 0.0004  max mem: 9511\n",
      "Epoch: [31] Test  [180/242]  eta: 0:01:04    time: 1.1173  data: 0.0004  max mem: 9511\n",
      "Epoch: [31] Test  [190/242]  eta: 0:00:54    time: 1.1207  data: 0.0002  max mem: 9511\n",
      "Epoch: [31] Test  [200/242]  eta: 0:00:43    time: 1.0656  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [210/242]  eta: 0:00:33    time: 1.0369  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [220/242]  eta: 0:00:22    time: 1.0454  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [230/242]  eta: 0:00:12    time: 1.0544  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test  [240/242]  eta: 0:00:02    time: 1.0168  data: 0.0003  max mem: 9511\n",
      "Epoch: [31] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['97.5', '93.9', '87.9', '95.4', '92.5', '87.8', '98.6', '93.4', '96.5', '76.4', '95.6', '81.0', '84.7', '90.5', '95.6', '94.7', '71.9', '94.2', '65.9', '94.3', '88.9']\n",
      "IoU: ['95.5', '92.2', '68.7', '88.8', '66.0', '77.3', '95.5', '88.2', '83.1', '46.5', '86.1', '71.5', '79.1', '86.8', '90.1', '90.6', '64.4', '85.7', '57.7', '89.9', '76.8']\n",
      "mean IoU: 80.0\n",
      "Epoch: [32] Train  [  0/183]  eta: 0:39:29  lr: 0.000240  loss: 2.2625 (2.2625)  time: 12.9487  data: 0.4653  max mem: 9511\n",
      "Epoch: [32] Train  [ 10/183]  eta: 0:35:42  lr: 0.000239  loss: 2.5930 (2.2445)  time: 12.3815  data: 0.0426  max mem: 9511\n",
      "Epoch: [32] Train  [ 20/183]  eta: 0:33:24  lr: 0.000237  loss: 2.0930 (2.2588)  time: 12.2657  data: 0.0004  max mem: 9511\n",
      "Epoch: [32] Train  [ 30/183]  eta: 0:31:08  lr: 0.000236  loss: 2.4265 (2.2686)  time: 12.1224  data: 0.0004  max mem: 9511\n",
      "Epoch: [32] Train  [ 40/183]  eta: 0:29:15  lr: 0.000234  loss: 2.6004 (2.2686)  time: 12.2552  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train  [ 50/183]  eta: 0:27:12  lr: 0.000233  loss: 2.2255 (2.2695)  time: 12.3623  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train  [ 60/183]  eta: 0:25:11  lr: 0.000231  loss: 2.2545 (2.2776)  time: 12.3208  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train  [ 70/183]  eta: 0:23:10  lr: 0.000230  loss: 2.4556 (2.3040)  time: 12.3933  data: 0.0004  max mem: 9511\n",
      "Epoch: [32] Train  [ 80/183]  eta: 0:21:08  lr: 0.000228  loss: 2.0335 (2.2919)  time: 12.4023  data: 0.0004  max mem: 9511\n",
      "Epoch: [32] Train  [ 90/183]  eta: 0:19:06  lr: 0.000227  loss: 2.3059 (2.2838)  time: 12.4251  data: 0.0004  max mem: 9511\n",
      "Epoch: [32] Train  [100/183]  eta: 0:17:03  lr: 0.000225  loss: 2.4909 (2.2819)  time: 12.3964  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train  [110/183]  eta: 0:15:00  lr: 0.000224  loss: 2.0979 (2.2764)  time: 12.3154  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Train  [120/183]  eta: 0:12:56  lr: 0.000222  loss: 2.1982 (2.2716)  time: 12.2784  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train  [130/183]  eta: 0:10:53  lr: 0.000221  loss: 2.0493 (2.2670)  time: 12.2786  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train  [140/183]  eta: 0:08:50  lr: 0.000219  loss: 2.6758 (2.2775)  time: 12.3666  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train  [150/183]  eta: 0:06:47  lr: 0.000218  loss: 2.1112 (2.2763)  time: 12.4520  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train  [160/183]  eta: 0:04:43  lr: 0.000216  loss: 2.9165 (2.2769)  time: 12.4269  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Train  [170/183]  eta: 0:02:40  lr: 0.000215  loss: 2.4578 (2.2723)  time: 12.4439  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Train  [180/183]  eta: 0:00:37  lr: 0.000213  loss: 2.1828 (2.2709)  time: 12.4548  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Train Total time: 0:37:41\n",
      "Epoch: [32] Test  [  0/242]  eta: 0:05:52    time: 1.4546  data: 0.3766  max mem: 9511\n",
      "Epoch: [32] Test  [ 10/242]  eta: 0:03:52    time: 1.0032  data: 0.0344  max mem: 9511\n",
      "Epoch: [32] Test  [ 20/242]  eta: 0:03:35    time: 0.9472  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Test  [ 30/242]  eta: 0:03:31    time: 0.9970  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [ 40/242]  eta: 0:03:24    time: 1.0589  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [ 50/242]  eta: 0:03:16    time: 1.0554  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [ 60/242]  eta: 0:03:09    time: 1.0885  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [ 70/242]  eta: 0:02:59    time: 1.0960  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Test  [ 80/242]  eta: 0:02:48    time: 1.0354  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [ 90/242]  eta: 0:02:36    time: 0.9859  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [100/242]  eta: 0:02:26    time: 1.0215  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [110/242]  eta: 0:02:16    time: 1.0376  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Test  [120/242]  eta: 0:02:06    time: 1.0481  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [130/242]  eta: 0:01:55    time: 1.0381  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [140/242]  eta: 0:01:45    time: 0.9881  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [150/242]  eta: 0:01:34    time: 0.9940  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [160/242]  eta: 0:01:24    time: 1.0103  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Test  [170/242]  eta: 0:01:14    time: 1.0618  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Test  [180/242]  eta: 0:01:04    time: 1.1196  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [190/242]  eta: 0:00:54    time: 1.1227  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [200/242]  eta: 0:00:43    time: 1.0675  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [210/242]  eta: 0:00:33    time: 1.0395  data: 0.0002  max mem: 9511\n",
      "Epoch: [32] Test  [220/242]  eta: 0:00:22    time: 1.0475  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [230/242]  eta: 0:00:12    time: 1.0537  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test  [240/242]  eta: 0:00:02    time: 1.0157  data: 0.0003  max mem: 9511\n",
      "Epoch: [32] Test Total time: 0:04:11\n",
      "global correct: 95.7\n",
      "average row correct: ['97.3', '94.5', '90.1', '94.7', '91.4', '89.4', '98.5', '95.6', '96.1', '66.5', '95.2', '79.1', '92.2', '94.0', '96.3', '95.4', '80.2', '93.5', '64.8', '97.4', '82.6']\n",
      "IoU: ['95.4', '92.1', '64.1', '88.8', '74.6', '73.1', '95.6', '88.3', '89.1', '44.1', '88.9', '71.8', '84.2', '87.6', '88.9', '89.9', '70.1', '86.4', '54.9', '88.7', '77.2']\n",
      "mean IoU: 80.6\n",
      "Epoch: [33] Train  [  0/183]  eta: 0:37:16  lr: 0.000213  loss: 2.0523 (2.0523)  time: 12.2194  data: 0.4297  max mem: 9511\n",
      "Epoch: [33] Train  [ 10/183]  eta: 0:35:47  lr: 0.000211  loss: 2.0600 (2.2663)  time: 12.4160  data: 0.0393  max mem: 9511\n",
      "Epoch: [33] Train  [ 20/183]  eta: 0:33:50  lr: 0.000210  loss: 2.6587 (2.3659)  time: 12.4663  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Train  [ 30/183]  eta: 0:31:36  lr: 0.000208  loss: 1.9257 (2.3532)  time: 12.3829  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Train  [ 40/183]  eta: 0:29:33  lr: 0.000207  loss: 2.1399 (2.3033)  time: 12.3483  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Train  [ 50/183]  eta: 0:27:31  lr: 0.000205  loss: 2.2511 (2.3210)  time: 12.4464  data: 0.0004  max mem: 9511\n",
      "Epoch: [33] Train  [ 60/183]  eta: 0:25:25  lr: 0.000204  loss: 2.4131 (2.3058)  time: 12.4073  data: 0.0004  max mem: 9511\n",
      "Epoch: [33] Train  [ 70/183]  eta: 0:23:21  lr: 0.000202  loss: 2.1723 (2.2995)  time: 12.3680  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Train  [ 80/183]  eta: 0:21:17  lr: 0.000201  loss: 2.1282 (2.2868)  time: 12.4126  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Train  [ 90/183]  eta: 0:19:14  lr: 0.000199  loss: 2.0041 (2.2774)  time: 12.4598  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Train  [100/183]  eta: 0:17:09  lr: 0.000198  loss: 2.1561 (2.2863)  time: 12.3953  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Train  [110/183]  eta: 0:15:05  lr: 0.000196  loss: 2.4826 (2.2865)  time: 12.3535  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Train  [120/183]  eta: 0:13:00  lr: 0.000195  loss: 2.0023 (2.2825)  time: 12.2994  data: 0.0004  max mem: 9511\n",
      "Epoch: [33] Train  [130/183]  eta: 0:10:56  lr: 0.000193  loss: 2.2474 (2.2704)  time: 12.3230  data: 0.0004  max mem: 9511\n",
      "Epoch: [33] Train  [140/183]  eta: 0:08:52  lr: 0.000192  loss: 1.9343 (2.2632)  time: 12.3791  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Train  [150/183]  eta: 0:06:48  lr: 0.000190  loss: 2.4754 (2.2637)  time: 12.2563  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Train  [160/183]  eta: 0:04:44  lr: 0.000189  loss: 2.0307 (2.2616)  time: 12.2994  data: 0.0004  max mem: 9511\n",
      "Epoch: [33] Train  [170/183]  eta: 0:02:40  lr: 0.000187  loss: 2.2263 (2.2622)  time: 12.3838  data: 0.0004  max mem: 9511\n",
      "Epoch: [33] Train  [180/183]  eta: 0:00:37  lr: 0.000186  loss: 2.0835 (2.2625)  time: 12.3731  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Train Total time: 0:37:43\n",
      "Epoch: [33] Test  [  0/242]  eta: 0:06:04    time: 1.5071  data: 0.4260  max mem: 9511\n",
      "Epoch: [33] Test  [ 10/242]  eta: 0:03:53    time: 1.0062  data: 0.0390  max mem: 9511\n",
      "Epoch: [33] Test  [ 20/242]  eta: 0:03:35    time: 0.9447  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [ 30/242]  eta: 0:03:31    time: 0.9954  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [ 40/242]  eta: 0:03:24    time: 1.0564  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [ 50/242]  eta: 0:03:15    time: 1.0534  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [ 60/242]  eta: 0:03:08    time: 1.0880  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Test  [ 70/242]  eta: 0:02:59    time: 1.0960  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [ 80/242]  eta: 0:02:48    time: 1.0380  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [ 90/242]  eta: 0:02:36    time: 0.9865  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [100/242]  eta: 0:02:26    time: 1.0207  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [110/242]  eta: 0:02:16    time: 1.0380  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [120/242]  eta: 0:02:06    time: 1.0497  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Test  [130/242]  eta: 0:01:55    time: 1.0394  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Test  [140/242]  eta: 0:01:45    time: 0.9886  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Test  [150/242]  eta: 0:01:34    time: 0.9958  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [160/242]  eta: 0:01:24    time: 1.0106  data: 0.0005  max mem: 9511\n",
      "Epoch: [33] Test  [170/242]  eta: 0:01:14    time: 1.0604  data: 0.0005  max mem: 9511\n",
      "Epoch: [33] Test  [180/242]  eta: 0:01:04    time: 1.1198  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [190/242]  eta: 0:00:54    time: 1.1229  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [200/242]  eta: 0:00:43    time: 1.0670  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [210/242]  eta: 0:00:33    time: 1.0388  data: 0.0002  max mem: 9511\n",
      "Epoch: [33] Test  [220/242]  eta: 0:00:22    time: 1.0482  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [230/242]  eta: 0:00:12    time: 1.0550  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test  [240/242]  eta: 0:00:02    time: 1.0162  data: 0.0003  max mem: 9511\n",
      "Epoch: [33] Test Total time: 0:04:11\n",
      "global correct: 95.5\n",
      "average row correct: ['97.9', '92.5', '87.8', '92.9', '89.6', '89.1', '98.1', '94.7', '96.9', '65.6', '95.1', '80.0', '76.3', '89.1', '96.1', '95.0', '59.4', '96.0', '60.4', '94.7', '87.9']\n",
      "IoU: ['95.5', '91.1', '65.3', '89.0', '75.2', '75.7', '95.6', '88.6', '79.3', '44.1', '87.6', '70.4', '73.5', '85.6', '89.7', '90.4', '56.0', '84.6', '54.9', '89.9', '79.6']\n",
      "mean IoU: 79.1\n",
      "Epoch: [34] Train  [  0/183]  eta: 0:41:14  lr: 0.000185  loss: 1.9714 (1.9714)  time: 13.5195  data: 0.4344  max mem: 9511\n",
      "Epoch: [34] Train  [ 10/183]  eta: 0:35:57  lr: 0.000184  loss: 2.7117 (2.1953)  time: 12.4682  data: 0.0397  max mem: 9511\n",
      "Epoch: [34] Train  [ 20/183]  eta: 0:33:43  lr: 0.000182  loss: 1.8574 (2.1687)  time: 12.3567  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [ 30/183]  eta: 0:31:33  lr: 0.000181  loss: 3.2260 (2.2483)  time: 12.3279  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [ 40/183]  eta: 0:29:32  lr: 0.000179  loss: 2.0333 (2.2716)  time: 12.3841  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Train  [ 50/183]  eta: 0:27:28  lr: 0.000178  loss: 2.0445 (2.2803)  time: 12.4288  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Train  [ 60/183]  eta: 0:25:23  lr: 0.000176  loss: 2.4710 (2.2684)  time: 12.3665  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [ 70/183]  eta: 0:23:20  lr: 0.000175  loss: 2.0018 (2.2643)  time: 12.3768  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [ 80/183]  eta: 0:21:17  lr: 0.000173  loss: 2.4548 (2.2718)  time: 12.4399  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [ 90/183]  eta: 0:19:12  lr: 0.000172  loss: 1.8342 (2.2692)  time: 12.3870  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [100/183]  eta: 0:17:08  lr: 0.000170  loss: 2.1583 (2.2596)  time: 12.3829  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [110/183]  eta: 0:15:05  lr: 0.000169  loss: 1.9416 (2.2519)  time: 12.4684  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [120/183]  eta: 0:13:00  lr: 0.000167  loss: 2.1015 (2.2471)  time: 12.3393  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [130/183]  eta: 0:10:55  lr: 0.000165  loss: 2.2806 (2.2451)  time: 12.1977  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Train  [140/183]  eta: 0:08:51  lr: 0.000164  loss: 2.2080 (2.2379)  time: 12.2246  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Train  [150/183]  eta: 0:06:47  lr: 0.000162  loss: 2.3286 (2.2358)  time: 12.2415  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [160/183]  eta: 0:04:44  lr: 0.000161  loss: 2.1834 (2.2304)  time: 12.2488  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [170/183]  eta: 0:02:40  lr: 0.000159  loss: 1.8566 (2.2312)  time: 12.2833  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Train  [180/183]  eta: 0:00:37  lr: 0.000158  loss: 2.4806 (2.2311)  time: 12.3090  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Train Total time: 0:37:39\n",
      "Epoch: [34] Test  [  0/242]  eta: 0:05:56    time: 1.4727  data: 0.3999  max mem: 9511\n",
      "Epoch: [34] Test  [ 10/242]  eta: 0:03:52    time: 1.0025  data: 0.0366  max mem: 9511\n",
      "Epoch: [34] Test  [ 20/242]  eta: 0:03:35    time: 0.9457  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [ 30/242]  eta: 0:03:31    time: 0.9965  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [ 40/242]  eta: 0:03:24    time: 1.0573  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [ 50/242]  eta: 0:03:15    time: 1.0536  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [ 60/242]  eta: 0:03:08    time: 1.0850  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [ 70/242]  eta: 0:02:58    time: 1.0928  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [ 80/242]  eta: 0:02:47    time: 1.0349  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Test  [ 90/242]  eta: 0:02:36    time: 0.9831  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Test  [100/242]  eta: 0:02:26    time: 1.0179  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [110/242]  eta: 0:02:15    time: 1.0360  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [120/242]  eta: 0:02:06    time: 1.0496  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [130/242]  eta: 0:01:55    time: 1.0372  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [140/242]  eta: 0:01:44    time: 0.9870  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [150/242]  eta: 0:01:34    time: 0.9957  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [160/242]  eta: 0:01:24    time: 1.0083  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [170/242]  eta: 0:01:14    time: 1.0577  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [180/242]  eta: 0:01:04    time: 1.1198  data: 0.0002  max mem: 9511\n",
      "Epoch: [34] Test  [190/242]  eta: 0:00:54    time: 1.1236  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [200/242]  eta: 0:00:43    time: 1.0674  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [210/242]  eta: 0:00:33    time: 1.0394  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [220/242]  eta: 0:00:22    time: 1.0478  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [230/242]  eta: 0:00:12    time: 1.0563  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test  [240/242]  eta: 0:00:02    time: 1.0183  data: 0.0003  max mem: 9511\n",
      "Epoch: [34] Test Total time: 0:04:10\n",
      "global correct: 95.7\n",
      "average row correct: ['97.5', '96.5', '88.1', '94.9', '91.0', '88.9', '98.7', '94.0', '96.1', '69.7', '94.8', '77.1', '90.2', '94.8', '94.7', '95.9', '67.5', '96.2', '63.0', '93.9', '89.4']\n",
      "IoU: ['95.5', '93.0', '63.0', '89.7', '68.8', '77.6', '95.8', '87.8', '88.5', '44.6', '89.8', '71.0', '82.3', '88.8', '88.7', '89.4', '60.9', '82.6', '55.2', '90.2', '77.4']\n",
      "mean IoU: 80.0\n",
      "Epoch: [35] Train  [  0/183]  eta: 0:40:42  lr: 0.000157  loss: 2.0340 (2.0340)  time: 13.3456  data: 0.4189  max mem: 9511\n",
      "Epoch: [35] Train  [ 10/183]  eta: 0:35:31  lr: 0.000156  loss: 2.3893 (2.2450)  time: 12.3219  data: 0.0383  max mem: 9511\n",
      "Epoch: [35] Train  [ 20/183]  eta: 0:33:17  lr: 0.000154  loss: 2.3725 (2.2799)  time: 12.1973  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Train  [ 30/183]  eta: 0:31:19  lr: 0.000153  loss: 2.1667 (2.2309)  time: 12.2675  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [ 40/183]  eta: 0:29:19  lr: 0.000151  loss: 2.0586 (2.2134)  time: 12.3659  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [ 50/183]  eta: 0:27:16  lr: 0.000150  loss: 2.0850 (2.2024)  time: 12.3277  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [ 60/183]  eta: 0:25:14  lr: 0.000148  loss: 2.0863 (2.2022)  time: 12.3344  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Train  [ 70/183]  eta: 0:23:09  lr: 0.000146  loss: 2.2490 (2.2092)  time: 12.2950  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [ 80/183]  eta: 0:21:07  lr: 0.000145  loss: 2.4070 (2.2221)  time: 12.2678  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [ 90/183]  eta: 0:19:04  lr: 0.000143  loss: 2.8686 (2.2184)  time: 12.3321  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [100/183]  eta: 0:17:02  lr: 0.000142  loss: 1.9647 (2.2090)  time: 12.3689  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [110/183]  eta: 0:15:01  lr: 0.000140  loss: 2.2888 (2.2166)  time: 12.5072  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [120/183]  eta: 0:12:57  lr: 0.000139  loss: 2.2925 (2.2128)  time: 12.4949  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Train  [130/183]  eta: 0:10:53  lr: 0.000137  loss: 2.3165 (2.2172)  time: 12.3067  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [140/183]  eta: 0:08:50  lr: 0.000135  loss: 2.8257 (2.2222)  time: 12.2565  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Train  [150/183]  eta: 0:06:47  lr: 0.000134  loss: 2.3183 (2.2189)  time: 12.3410  data: 0.0006  max mem: 9511\n",
      "Epoch: [35] Train  [160/183]  eta: 0:04:43  lr: 0.000132  loss: 2.2666 (2.2128)  time: 12.3600  data: 0.0006  max mem: 9511\n",
      "Epoch: [35] Train  [170/183]  eta: 0:02:40  lr: 0.000131  loss: 2.2075 (2.2110)  time: 12.2673  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Train  [180/183]  eta: 0:00:37  lr: 0.000129  loss: 2.0759 (2.2071)  time: 12.3423  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Train Total time: 0:37:38\n",
      "Epoch: [35] Test  [  0/242]  eta: 0:06:16    time: 1.5555  data: 0.4675  max mem: 9511\n",
      "Epoch: [35] Test  [ 10/242]  eta: 0:03:54    time: 1.0088  data: 0.0427  max mem: 9511\n",
      "Epoch: [35] Test  [ 20/242]  eta: 0:03:36    time: 0.9442  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [ 30/242]  eta: 0:03:32    time: 0.9963  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [ 40/242]  eta: 0:03:24    time: 1.0571  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [ 50/242]  eta: 0:03:15    time: 1.0507  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [ 60/242]  eta: 0:03:08    time: 1.0857  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [ 70/242]  eta: 0:02:59    time: 1.0964  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [ 80/242]  eta: 0:02:48    time: 1.0377  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [ 90/242]  eta: 0:02:36    time: 0.9859  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [100/242]  eta: 0:02:26    time: 1.0191  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [110/242]  eta: 0:02:16    time: 1.0368  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [120/242]  eta: 0:02:06    time: 1.0496  data: 0.0002  max mem: 9511\n",
      "Epoch: [35] Test  [130/242]  eta: 0:01:55    time: 1.0397  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [140/242]  eta: 0:01:45    time: 0.9879  data: 0.0004  max mem: 9511\n",
      "Epoch: [35] Test  [150/242]  eta: 0:01:34    time: 0.9942  data: 0.0004  max mem: 9511\n",
      "Epoch: [35] Test  [160/242]  eta: 0:01:24    time: 1.0104  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [170/242]  eta: 0:01:14    time: 1.0607  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [180/242]  eta: 0:01:04    time: 1.1182  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [190/242]  eta: 0:00:54    time: 1.1195  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [200/242]  eta: 0:00:43    time: 1.0669  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [210/242]  eta: 0:00:33    time: 1.0383  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [220/242]  eta: 0:00:22    time: 1.0449  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [230/242]  eta: 0:00:12    time: 1.0545  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test  [240/242]  eta: 0:00:02    time: 1.0184  data: 0.0003  max mem: 9511\n",
      "Epoch: [35] Test Total time: 0:04:10\n",
      "global correct: 95.7\n",
      "average row correct: ['97.5', '97.1', '90.1', '94.4', '89.9', '88.0', '98.7', '93.9', '96.6', '67.0', '95.2', '80.3', '85.7', '91.8', '94.4', '94.9', '65.0', '95.9', '70.1', '96.8', '89.8']\n",
      "IoU: ['95.5', '93.4', '63.7', '89.3', '75.7', '77.6', '96.3', '86.8', '84.8', '44.9', '87.9', '73.4', '79.9', '86.6', '88.0', '90.4', '59.7', '84.2', '55.4', '90.9', '77.2']\n",
      "mean IoU: 80.1\n",
      "Epoch: [36] Train  [  0/183]  eta: 0:40:39  lr: 0.000129  loss: 2.0009 (2.0009)  time: 13.3331  data: 0.4664  max mem: 9511\n",
      "Epoch: [36] Train  [ 10/183]  eta: 0:35:34  lr: 0.000127  loss: 2.1528 (2.1628)  time: 12.3392  data: 0.0426  max mem: 9511\n",
      "Epoch: [36] Train  [ 20/183]  eta: 0:33:21  lr: 0.000125  loss: 2.0155 (2.2344)  time: 12.2248  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Train  [ 30/183]  eta: 0:31:21  lr: 0.000124  loss: 2.5637 (2.2830)  time: 12.2721  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [ 40/183]  eta: 0:29:16  lr: 0.000122  loss: 2.4457 (2.2638)  time: 12.2829  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [ 50/183]  eta: 0:27:17  lr: 0.000121  loss: 2.2435 (2.2486)  time: 12.3412  data: 0.0004  max mem: 9511\n",
      "Epoch: [36] Train  [ 60/183]  eta: 0:25:16  lr: 0.000119  loss: 2.1697 (2.2421)  time: 12.4263  data: 0.0004  max mem: 9511\n",
      "Epoch: [36] Train  [ 70/183]  eta: 0:23:12  lr: 0.000117  loss: 2.2405 (2.2467)  time: 12.3355  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [ 80/183]  eta: 0:21:08  lr: 0.000116  loss: 2.3212 (2.2405)  time: 12.2774  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [ 90/183]  eta: 0:19:05  lr: 0.000114  loss: 2.0738 (2.2333)  time: 12.2913  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [100/183]  eta: 0:17:02  lr: 0.000113  loss: 2.0819 (2.2264)  time: 12.3551  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [110/183]  eta: 0:15:00  lr: 0.000111  loss: 2.4410 (2.2270)  time: 12.4157  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [120/183]  eta: 0:12:57  lr: 0.000109  loss: 1.9386 (2.2243)  time: 12.4296  data: 0.0004  max mem: 9511\n",
      "Epoch: [36] Train  [130/183]  eta: 0:10:53  lr: 0.000108  loss: 2.2826 (2.2318)  time: 12.3722  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Train  [140/183]  eta: 0:08:50  lr: 0.000106  loss: 2.5703 (2.2240)  time: 12.2831  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [150/183]  eta: 0:06:47  lr: 0.000105  loss: 2.2984 (2.2163)  time: 12.3682  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [160/183]  eta: 0:04:43  lr: 0.000103  loss: 2.3431 (2.2146)  time: 12.3432  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [170/183]  eta: 0:02:40  lr: 0.000101  loss: 2.0780 (2.2133)  time: 12.2345  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train  [180/183]  eta: 0:00:36  lr: 0.000100  loss: 2.0888 (2.2114)  time: 12.2312  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Train Total time: 0:37:35\n",
      "Epoch: [36] Test  [  0/242]  eta: 0:06:05    time: 1.5112  data: 0.4370  max mem: 9511\n",
      "Epoch: [36] Test  [ 10/242]  eta: 0:03:53    time: 1.0067  data: 0.0400  max mem: 9511\n",
      "Epoch: [36] Test  [ 20/242]  eta: 0:03:35    time: 0.9455  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [ 30/242]  eta: 0:03:31    time: 0.9961  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [ 40/242]  eta: 0:03:24    time: 1.0576  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [ 50/242]  eta: 0:03:15    time: 1.0519  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [ 60/242]  eta: 0:03:08    time: 1.0858  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [ 70/242]  eta: 0:02:59    time: 1.0960  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [ 80/242]  eta: 0:02:48    time: 1.0363  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [ 90/242]  eta: 0:02:36    time: 0.9862  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [100/242]  eta: 0:02:26    time: 1.0207  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [110/242]  eta: 0:02:16    time: 1.0369  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [120/242]  eta: 0:02:06    time: 1.0502  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [130/242]  eta: 0:01:55    time: 1.0373  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [140/242]  eta: 0:01:45    time: 0.9864  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [150/242]  eta: 0:01:34    time: 0.9952  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [160/242]  eta: 0:01:24    time: 1.0084  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [170/242]  eta: 0:01:14    time: 1.0578  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [180/242]  eta: 0:01:04    time: 1.1179  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [190/242]  eta: 0:00:54    time: 1.1225  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [200/242]  eta: 0:00:43    time: 1.0668  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [210/242]  eta: 0:00:33    time: 1.0414  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [220/242]  eta: 0:00:22    time: 1.0503  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [230/242]  eta: 0:00:12    time: 1.0538  data: 0.0003  max mem: 9511\n",
      "Epoch: [36] Test  [240/242]  eta: 0:00:02    time: 1.0167  data: 0.0002  max mem: 9511\n",
      "Epoch: [36] Test Total time: 0:04:10\n",
      "global correct: 96.0\n",
      "average row correct: ['97.8', '96.9', '88.7', '94.8', '89.5', '86.6', '98.5', '93.2', '96.3', '68.9', '94.8', '81.3', '90.1', '93.9', '95.7', '95.0', '66.6', '94.4', '68.8', '94.1', '86.4']\n",
      "IoU: ['95.7', '94.0', '65.4', '89.0', '74.0', '77.0', '96.0', '88.8', '87.6', '48.3', '89.9', '72.6', '82.9', '88.7', '89.0', '90.4', '61.1', '86.1', '58.1', '90.2', '79.7']\n",
      "mean IoU: 81.2\n",
      "Epoch: [37] Train  [  0/183]  eta: 0:39:12  lr: 0.000099  loss: 1.9695 (1.9695)  time: 12.8576  data: 0.4845  max mem: 9511\n",
      "Epoch: [37] Train  [ 10/183]  eta: 0:35:35  lr: 0.000098  loss: 2.1800 (2.2057)  time: 12.3416  data: 0.0443  max mem: 9511\n",
      "Epoch: [37] Train  [ 20/183]  eta: 0:33:24  lr: 0.000096  loss: 2.1474 (2.1592)  time: 12.2680  data: 0.0002  max mem: 9511\n",
      "Epoch: [37] Train  [ 30/183]  eta: 0:31:30  lr: 0.000094  loss: 1.9513 (2.1754)  time: 12.3602  data: 0.0002  max mem: 9511\n",
      "Epoch: [37] Train  [ 40/183]  eta: 0:29:32  lr: 0.000093  loss: 2.1678 (2.1556)  time: 12.4978  data: 0.0002  max mem: 9511\n",
      "Epoch: [37] Train  [ 50/183]  eta: 0:27:32  lr: 0.000091  loss: 2.2195 (2.1629)  time: 12.5280  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train  [ 60/183]  eta: 0:25:26  lr: 0.000089  loss: 2.3094 (2.1602)  time: 12.4424  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train  [ 70/183]  eta: 0:23:19  lr: 0.000088  loss: 1.9912 (2.1664)  time: 12.2953  data: 0.0002  max mem: 9511\n",
      "Epoch: [37] Train  [ 80/183]  eta: 0:21:12  lr: 0.000086  loss: 2.1087 (2.1637)  time: 12.1808  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train  [ 90/183]  eta: 0:19:09  lr: 0.000084  loss: 2.0913 (2.1587)  time: 12.2518  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train  [100/183]  eta: 0:17:05  lr: 0.000083  loss: 2.1815 (2.1674)  time: 12.3357  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train  [110/183]  eta: 0:15:00  lr: 0.000081  loss: 1.9974 (2.1713)  time: 12.2530  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train  [120/183]  eta: 0:12:57  lr: 0.000079  loss: 2.0042 (2.1702)  time: 12.3024  data: 0.0002  max mem: 9511\n",
      "Epoch: [37] Train  [130/183]  eta: 0:10:54  lr: 0.000078  loss: 2.0885 (2.1699)  time: 12.3950  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train  [140/183]  eta: 0:08:50  lr: 0.000076  loss: 1.8985 (2.1693)  time: 12.3823  data: 0.0005  max mem: 9511\n",
      "Epoch: [37] Train  [150/183]  eta: 0:06:47  lr: 0.000074  loss: 1.9413 (2.1665)  time: 12.3815  data: 0.0005  max mem: 9511\n",
      "Epoch: [37] Train  [160/183]  eta: 0:04:44  lr: 0.000073  loss: 2.0381 (2.1729)  time: 12.4432  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train  [170/183]  eta: 0:02:40  lr: 0.000071  loss: 1.9619 (2.1744)  time: 12.4361  data: 0.0002  max mem: 9511\n",
      "Epoch: [37] Train  [180/183]  eta: 0:00:37  lr: 0.000069  loss: 2.0463 (2.1773)  time: 12.3158  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Train Total time: 0:37:41\n",
      "Epoch: [37] Test  [  0/242]  eta: 0:06:10    time: 1.5303  data: 0.4537  max mem: 9511\n",
      "Epoch: [37] Test  [ 10/242]  eta: 0:03:53    time: 1.0082  data: 0.0416  max mem: 9511\n",
      "Epoch: [37] Test  [ 20/242]  eta: 0:03:36    time: 0.9451  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [ 30/242]  eta: 0:03:32    time: 0.9974  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [ 40/242]  eta: 0:03:24    time: 1.0582  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [ 50/242]  eta: 0:03:15    time: 1.0505  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [ 60/242]  eta: 0:03:08    time: 1.0839  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [ 70/242]  eta: 0:02:59    time: 1.0955  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [ 80/242]  eta: 0:02:48    time: 1.0373  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [ 90/242]  eta: 0:02:36    time: 0.9842  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [100/242]  eta: 0:02:26    time: 1.0170  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [110/242]  eta: 0:02:16    time: 1.0365  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [120/242]  eta: 0:02:06    time: 1.0500  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [130/242]  eta: 0:01:55    time: 1.0370  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [140/242]  eta: 0:01:44    time: 0.9854  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [150/242]  eta: 0:01:34    time: 0.9938  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [160/242]  eta: 0:01:24    time: 1.0110  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [170/242]  eta: 0:01:14    time: 1.0598  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [180/242]  eta: 0:01:04    time: 1.1161  data: 0.0002  max mem: 9511\n",
      "Epoch: [37] Test  [190/242]  eta: 0:00:54    time: 1.1207  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [200/242]  eta: 0:00:43    time: 1.0684  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [210/242]  eta: 0:00:33    time: 1.0399  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [220/242]  eta: 0:00:22    time: 1.0476  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [230/242]  eta: 0:00:12    time: 1.0554  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test  [240/242]  eta: 0:00:02    time: 1.0173  data: 0.0003  max mem: 9511\n",
      "Epoch: [37] Test Total time: 0:04:10\n",
      "global correct: 95.8\n",
      "average row correct: ['97.9', '96.8', '89.8', '94.0', '88.8', '90.2', '98.2', '93.3', '96.4', '63.6', '94.3', '77.9', '84.0', '94.2', '95.2', '95.1', '64.2', '96.0', '67.9', '94.0', '86.4']\n",
      "IoU: ['95.7', '93.2', '62.2', '88.6', '70.6', '77.0', '96.0', '88.7', '83.8', '47.5', '90.5', '71.8', '78.1', '89.7', '89.2', '90.4', '59.0', '82.4', '59.3', '90.7', '80.0']\n",
      "mean IoU: 80.2\n",
      "Epoch: [38] Train  [  0/183]  eta: 0:39:04  lr: 0.000069  loss: 2.0025 (2.0025)  time: 12.8134  data: 0.4046  max mem: 9511\n",
      "Epoch: [38] Train  [ 10/183]  eta: 0:35:34  lr: 0.000067  loss: 2.2689 (2.1924)  time: 12.3409  data: 0.0371  max mem: 9511\n",
      "Epoch: [38] Train  [ 20/183]  eta: 0:33:27  lr: 0.000065  loss: 2.5587 (2.1804)  time: 12.2889  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Train  [ 30/183]  eta: 0:31:32  lr: 0.000064  loss: 2.4230 (2.1707)  time: 12.3837  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [ 40/183]  eta: 0:29:22  lr: 0.000062  loss: 2.3118 (2.1806)  time: 12.3342  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [ 50/183]  eta: 0:27:16  lr: 0.000060  loss: 2.1318 (2.1894)  time: 12.2111  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [ 60/183]  eta: 0:25:12  lr: 0.000059  loss: 2.2150 (2.1854)  time: 12.2499  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [ 70/183]  eta: 0:23:10  lr: 0.000057  loss: 2.4523 (2.1845)  time: 12.2935  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [ 80/183]  eta: 0:21:06  lr: 0.000055  loss: 2.4791 (2.1812)  time: 12.2986  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [ 90/183]  eta: 0:19:04  lr: 0.000053  loss: 1.8998 (2.1650)  time: 12.3368  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [100/183]  eta: 0:17:01  lr: 0.000052  loss: 2.0664 (2.1619)  time: 12.3566  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [110/183]  eta: 0:14:59  lr: 0.000050  loss: 2.3829 (2.1688)  time: 12.3919  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [120/183]  eta: 0:12:55  lr: 0.000048  loss: 1.9499 (2.1821)  time: 12.3320  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [130/183]  eta: 0:10:52  lr: 0.000046  loss: 2.0931 (2.1778)  time: 12.2851  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train  [140/183]  eta: 0:08:49  lr: 0.000045  loss: 2.0506 (2.1848)  time: 12.3680  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Train  [150/183]  eta: 0:06:46  lr: 0.000043  loss: 2.0577 (2.1901)  time: 12.2598  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Train  [160/183]  eta: 0:04:43  lr: 0.000041  loss: 2.1781 (2.1947)  time: 12.1988  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Train  [170/183]  eta: 0:02:39  lr: 0.000039  loss: 2.2689 (2.1984)  time: 12.2249  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Train  [180/183]  eta: 0:00:36  lr: 0.000037  loss: 1.9639 (2.1953)  time: 12.2972  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Train Total time: 0:37:32\n",
      "Epoch: [38] Test  [  0/242]  eta: 0:06:09    time: 1.5282  data: 0.4549  max mem: 9511\n",
      "Epoch: [38] Test  [ 10/242]  eta: 0:03:54    time: 1.0104  data: 0.0416  max mem: 9511\n",
      "Epoch: [38] Test  [ 20/242]  eta: 0:03:36    time: 0.9469  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [ 30/242]  eta: 0:03:32    time: 0.9982  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [ 40/242]  eta: 0:03:25    time: 1.0595  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [ 50/242]  eta: 0:03:16    time: 1.0531  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [ 60/242]  eta: 0:03:08    time: 1.0843  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [ 70/242]  eta: 0:02:59    time: 1.0934  data: 0.0004  max mem: 9511\n",
      "Epoch: [38] Test  [ 80/242]  eta: 0:02:48    time: 1.0363  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [ 90/242]  eta: 0:02:36    time: 0.9846  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [100/242]  eta: 0:02:26    time: 1.0180  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [110/242]  eta: 0:02:16    time: 1.0360  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [120/242]  eta: 0:02:06    time: 1.0493  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [130/242]  eta: 0:01:55    time: 1.0376  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [140/242]  eta: 0:01:44    time: 0.9859  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [150/242]  eta: 0:01:34    time: 0.9938  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [160/242]  eta: 0:01:24    time: 1.0082  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [170/242]  eta: 0:01:14    time: 1.0575  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [180/242]  eta: 0:01:04    time: 1.1178  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [190/242]  eta: 0:00:54    time: 1.1205  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [200/242]  eta: 0:00:43    time: 1.0649  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [210/242]  eta: 0:00:33    time: 1.0367  data: 0.0002  max mem: 9511\n",
      "Epoch: [38] Test  [220/242]  eta: 0:00:22    time: 1.0456  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [230/242]  eta: 0:00:12    time: 1.0533  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test  [240/242]  eta: 0:00:02    time: 1.0163  data: 0.0003  max mem: 9511\n",
      "Epoch: [38] Test Total time: 0:04:10\n",
      "global correct: 95.8\n",
      "average row correct: ['97.9', '96.5', '87.6', '95.0', '88.5', '89.4', '98.5', '93.8', '96.2', '69.4', '94.4', '76.6', '82.3', '94.1', '96.0', '94.8', '65.1', '93.9', '62.1', '95.7', '88.3']\n",
      "IoU: ['95.6', '93.5', '64.5', '88.0', '74.3', '76.8', '96.1', '89.5', '82.2', '46.7', '89.7', '70.6', '77.7', '89.6', '89.3', '90.6', '59.9', '84.4', '56.3', '90.3', '79.4']\n",
      "mean IoU: 80.2\n",
      "Epoch: [39] Train  [  0/183]  eta: 0:41:03  lr: 0.000037  loss: 2.0989 (2.0989)  time: 13.4600  data: 0.4083  max mem: 9511\n",
      "Epoch: [39] Train  [ 10/183]  eta: 0:36:07  lr: 0.000035  loss: 2.1680 (2.1801)  time: 12.5288  data: 0.0373  max mem: 9511\n",
      "Epoch: [39] Train  [ 20/183]  eta: 0:33:43  lr: 0.000033  loss: 2.0219 (2.1924)  time: 12.3605  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [ 30/183]  eta: 0:31:39  lr: 0.000031  loss: 2.3145 (2.1960)  time: 12.3544  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [ 40/183]  eta: 0:29:39  lr: 0.000029  loss: 2.2246 (2.1782)  time: 12.4764  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [ 50/183]  eta: 0:27:26  lr: 0.000028  loss: 1.8899 (2.1525)  time: 12.3209  data: 0.0004  max mem: 9511\n",
      "Epoch: [39] Train  [ 60/183]  eta: 0:25:22  lr: 0.000026  loss: 2.2444 (2.1690)  time: 12.2321  data: 0.0004  max mem: 9511\n",
      "Epoch: [39] Train  [ 70/183]  eta: 0:23:21  lr: 0.000024  loss: 2.6398 (2.1730)  time: 12.4514  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [ 80/183]  eta: 0:21:17  lr: 0.000022  loss: 2.2001 (2.1741)  time: 12.5087  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [ 90/183]  eta: 0:19:11  lr: 0.000020  loss: 1.9754 (2.1686)  time: 12.3226  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [100/183]  eta: 0:17:07  lr: 0.000018  loss: 1.9001 (2.1603)  time: 12.2629  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [110/183]  eta: 0:15:03  lr: 0.000016  loss: 1.9421 (2.1671)  time: 12.3423  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [120/183]  eta: 0:13:00  lr: 0.000014  loss: 2.2070 (2.1636)  time: 12.4059  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [130/183]  eta: 0:10:56  lr: 0.000012  loss: 2.5402 (2.1604)  time: 12.4537  data: 0.0005  max mem: 9511\n",
      "Epoch: [39] Train  [140/183]  eta: 0:08:52  lr: 0.000010  loss: 2.0869 (2.1574)  time: 12.4374  data: 0.0004  max mem: 9511\n",
      "Epoch: [39] Train  [150/183]  eta: 0:06:48  lr: 0.000008  loss: 2.3722 (2.1623)  time: 12.3433  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [160/183]  eta: 0:04:44  lr: 0.000005  loss: 1.9783 (2.1612)  time: 12.2700  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train  [170/183]  eta: 0:02:40  lr: 0.000003  loss: 2.0321 (2.1586)  time: 12.3493  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Train  [180/183]  eta: 0:00:37  lr: 0.000001  loss: 2.2068 (2.1611)  time: 12.4417  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Train Total time: 0:37:46\n",
      "Epoch: [39] Test  [  0/242]  eta: 0:06:00    time: 1.4877  data: 0.4051  max mem: 9511\n",
      "Epoch: [39] Test  [ 10/242]  eta: 0:03:53    time: 1.0054  data: 0.0371  max mem: 9511\n",
      "Epoch: [39] Test  [ 20/242]  eta: 0:03:35    time: 0.9463  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [ 30/242]  eta: 0:03:32    time: 0.9971  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [ 40/242]  eta: 0:03:24    time: 1.0576  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Test  [ 50/242]  eta: 0:03:15    time: 1.0522  data: 0.0002  max mem: 9511\n",
      "Epoch: [39] Test  [ 60/242]  eta: 0:03:08    time: 1.0872  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [ 70/242]  eta: 0:02:59    time: 1.0968  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [ 80/242]  eta: 0:02:48    time: 1.0367  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [ 90/242]  eta: 0:02:36    time: 0.9883  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [100/242]  eta: 0:02:26    time: 1.0226  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [110/242]  eta: 0:02:16    time: 1.0380  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [120/242]  eta: 0:02:06    time: 1.0503  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [130/242]  eta: 0:01:55    time: 1.0366  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [140/242]  eta: 0:01:45    time: 0.9863  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [150/242]  eta: 0:01:34    time: 0.9961  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [160/242]  eta: 0:01:24    time: 1.0100  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [170/242]  eta: 0:01:14    time: 1.0592  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [180/242]  eta: 0:01:04    time: 1.1187  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [190/242]  eta: 0:00:54    time: 1.1217  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [200/242]  eta: 0:00:43    time: 1.0674  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [210/242]  eta: 0:00:33    time: 1.0389  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test  [220/242]  eta: 0:00:22    time: 1.0467  data: 0.0005  max mem: 9511\n",
      "Epoch: [39] Test  [230/242]  eta: 0:00:12    time: 1.0544  data: 0.0005  max mem: 9511\n",
      "Epoch: [39] Test  [240/242]  eta: 0:00:02    time: 1.0172  data: 0.0003  max mem: 9511\n",
      "Epoch: [39] Test Total time: 0:04:11\n",
      "global correct: 95.6\n",
      "average row correct: ['97.3', '96.8', '89.8', '96.0', '92.6', '90.0', '98.3', '94.0', '96.8', '72.5', '94.9', '79.4', '82.9', '94.7', '96.0', '95.0', '70.5', '96.5', '65.9', '96.2', '91.0']\n",
      "IoU: ['95.4', '93.4', '60.6', '88.8', '66.2', '76.8', '96.1', '88.6', '82.4', '47.0', '89.5', '71.9', '77.3', '88.9', '89.8', '90.5', '63.9', '79.2', '57.3', '89.9', '76.0']\n",
      "mean IoU: 79.5\n",
      "Training time 1 day, 4:04:23\n"
     ]
    }
   ],
   "source": [
    "# simsiam 8\n",
    "!experiment_name=\"temp\";cd ../ ;\\\n",
    "    name_date=\"${experiment_name}/$(date +%Y-%m%d-%H%M%S)\";\\\n",
    "    dir=\"./results/${name_date}\";mkdir -p ${dir};dir_log=\"${dir}/output.log\";\\\n",
    "CUDA_VISIBLE_DEVICES=2 torchrun --nproc_per_node=1 --master_port=12347 train_multi_GPU.py \\\n",
    "    --wandb False --wandb_model dryrun --sync_bn False --amp True --aux False \\\n",
    "    --model_name aspp_contrast_resnet101 --pre_trained deeplabv3_resnet101_coco.pth \\\n",
    "    --weight_only_backbone False --lr 0.001 \\\n",
    "    --data_path pascal-voc-2012 --num_classes 21 --data_train_type train.txt \\\n",
    "    --epochs 40 --batch_size 8 --batch_size_val 6 --memory_size 16384 \\\n",
    "    --contrast 0 --L1_loss 0.1 --L2_loss 0.1 --L3_loss 0.1\\\n",
    "    --loss_name aspp_loss --sample adapt_excite_8 \\\n",
    "    --name_date $name_date \\\n",
    "    2>&1 | tee $dir_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
