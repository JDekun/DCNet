{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| distributed init (rank 0): env://\n",
            "debug/2023-0406-095621\n",
            "Namespace(data_path='pascal-voc-2012', data_train_type='train.txt', device='cuda', num_classes=21, batch_size=8, batch_size_val=6, aux=False, start_epoch=0, epochs=40, sync_bn=False, workers=1, lr=0.0001, momentum=0.9, weight_decay=0.0001, print_freq=10, checkpoint_dir='./results/debug/2023-0406-095621', resume='', test_only=False, world_size=1, dist_url='env://', amp=True, seed=304, name_date='debug/2023-0406-095621', wandb=True, wandb_model='dryrun', run_name='', model_name='aspp_contrast_resnet101', project_dim=128, loss_name='aspp_loss', contrast=0, pre_trained='deeplabv3_resnet101_coco.pth', L3_loss=0.1, L2_loss=0.1, L1_loss=0.1, GAcc=1, memory_size=32768, proj_dim=128, network_stride=8, pixel_update_freq=10, ddp=False, weight_only_backbone=False, sample='self_pace_ploy', rank=0, gpu=0, distributed=True, dist_backend='nccl')\n",
            "Creating data loaders\n",
            "Creating model\n",
            "missing_keys:  ['encode3_queue', 'encode3_queue_ptr', 'code3_queue_label', 'encode2_queue', 'encode2_queue_ptr', 'code2_queue_label', 'encode1_queue', 'encode1_queue_ptr', 'code1_queue_label', 'contrast.convs.0.0.weight', 'contrast.convs.0.1.weight', 'contrast.convs.0.1.bias', 'contrast.convs.0.1.running_mean', 'contrast.convs.0.1.running_var', 'contrast.convs.0.3.weight', 'contrast.convs.0.4.weight', 'contrast.convs.0.4.bias', 'contrast.convs.0.4.running_mean', 'contrast.convs.0.4.running_var', 'contrast.convs.1.0.weight', 'contrast.convs.1.1.weight', 'contrast.convs.1.1.bias', 'contrast.convs.1.1.running_mean', 'contrast.convs.1.1.running_var', 'contrast.convs.1.3.weight', 'contrast.convs.1.4.weight', 'contrast.convs.1.4.bias', 'contrast.convs.1.4.running_mean', 'contrast.convs.1.4.running_var', 'contrast.convs.2.0.weight', 'contrast.convs.2.1.weight', 'contrast.convs.2.1.bias', 'contrast.convs.2.1.running_mean', 'contrast.convs.2.1.running_var', 'contrast.convs.2.3.weight', 'contrast.convs.2.4.weight', 'contrast.convs.2.4.bias', 'contrast.convs.2.4.running_mean', 'contrast.convs.2.4.running_var']\n",
            "unexpected_keys:  ['aux_classifier.0.weight', 'aux_classifier.1.weight', 'aux_classifier.1.bias', 'aux_classifier.1.running_mean', 'aux_classifier.1.running_var', 'aux_classifier.1.num_batches_tracked', 'aux_classifier.4.weight', 'aux_classifier.4.bias']\n",
            "wandb: Tracking run with wandb version 0.13.5\n",
            "wandb: W&B syncing is set to `offline` in this directory.  \n",
            "wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "DistributedDataParallel(\n",
            "  (module): DeepLabV3(\n",
            "    (backbone): IntermediateLayerGetter(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (6): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (7): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (8): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (9): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (10): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (11): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (12): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (13): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (14): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (15): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (16): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (17): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (18): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (19): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (20): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (21): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (22): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (classifier): DeepLabHead(\n",
            "      (0): ASPP(\n",
            "        (convs): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): ASPPConv(\n",
            "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): ASPPConv(\n",
            "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): ASPPConv(\n",
            "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): ASPPPooling(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (3): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (project): Sequential(\n",
            "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (contrast): contrast_head(\n",
            "      (convs): ModuleList(\n",
            "        (0): ASPPContrast(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ASPPContrast(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): ASPPContrast(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Start training\n",
            "Epoch: [0] Train  [  0/183]  eta: 0:46:37  lr: 0.000001  loss: 2.3454 (2.3454)  time: 15.2894  data: 0.4694  max mem: 9064\n",
            "Epoch: [0] Train  [ 10/183]  eta: 0:37:17  lr: 0.000006  loss: 2.7916 (2.6856)  time: 12.9312  data: 0.0430  max mem: 9536\n",
            "Epoch: [0] Train  [ 20/183]  eta: 0:35:00  lr: 0.000012  loss: 3.4351 (2.7760)  time: 12.7661  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Train  [ 30/183]  eta: 0:32:46  lr: 0.000017  loss: 2.6870 (2.8168)  time: 12.8127  data: 0.0005  max mem: 9536\n",
            "Epoch: [0] Train  [ 40/183]  eta: 0:30:29  lr: 0.000022  loss: 3.1333 (2.8919)  time: 12.7020  data: 0.0005  max mem: 9536\n",
            "Epoch: [0] Train  [ 50/183]  eta: 0:28:17  lr: 0.000028  loss: 3.2935 (2.9270)  time: 12.6266  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Train  [ 60/183]  eta: 0:26:08  lr: 0.000033  loss: 3.1882 (2.9910)  time: 12.6663  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Train  [ 70/183]  eta: 0:23:59  lr: 0.000039  loss: 3.2112 (3.0463)  time: 12.6794  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Train  [ 80/183]  eta: 0:21:49  lr: 0.000044  loss: 3.0783 (3.0570)  time: 12.6084  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Train  [ 90/183]  eta: 0:19:43  lr: 0.000050  loss: 2.8973 (3.0605)  time: 12.6634  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Train  [100/183]  eta: 0:17:35  lr: 0.000055  loss: 3.5885 (3.0942)  time: 12.7171  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Train  [110/183]  eta: 0:15:28  lr: 0.000061  loss: 3.3702 (3.1268)  time: 12.6803  data: 0.0005  max mem: 9536\n",
            "Epoch: [0] Train  [120/183]  eta: 0:13:20  lr: 0.000066  loss: 2.9644 (3.1641)  time: 12.6968  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Train  [130/183]  eta: 0:11:13  lr: 0.000072  loss: 3.0241 (3.1827)  time: 12.7111  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Train  [140/183]  eta: 0:09:06  lr: 0.000077  loss: 3.0933 (3.1898)  time: 12.7353  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Train  [150/183]  eta: 0:06:59  lr: 0.000083  loss: 3.0259 (3.1900)  time: 12.7560  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Train  [160/183]  eta: 0:04:52  lr: 0.000088  loss: 3.5815 (3.2106)  time: 12.7012  data: 0.0005  max mem: 9536\n",
            "Epoch: [0] Train  [170/183]  eta: 0:02:45  lr: 0.000093  loss: 3.1840 (3.2132)  time: 12.7018  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Train  [180/183]  eta: 0:00:38  lr: 0.000099  loss: 2.9722 (3.2248)  time: 12.7261  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Train Total time: 0:38:46\n",
            "Epoch: [0] Test  [  0/242]  eta: 0:07:56    time: 1.9698  data: 0.4315  max mem: 9536\n",
            "Epoch: [0] Test  [ 10/242]  eta: 0:04:15    time: 1.1017  data: 0.0395  max mem: 9536\n",
            "Epoch: [0] Test  [ 20/242]  eta: 0:03:53    time: 1.0056  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [ 30/242]  eta: 0:03:48    time: 1.0616  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [ 40/242]  eta: 0:03:40    time: 1.1335  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [ 50/242]  eta: 0:03:30    time: 1.1228  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [ 60/242]  eta: 0:03:21    time: 1.1449  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [ 70/242]  eta: 0:03:11    time: 1.1607  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [ 80/242]  eta: 0:02:59    time: 1.1123  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [ 90/242]  eta: 0:02:47    time: 1.0606  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [100/242]  eta: 0:02:37    time: 1.0889  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [110/242]  eta: 0:02:25    time: 1.1034  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [120/242]  eta: 0:02:15    time: 1.1129  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [130/242]  eta: 0:02:03    time: 1.1044  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [140/242]  eta: 0:01:52    time: 1.0637  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [150/242]  eta: 0:01:41    time: 1.0701  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [160/242]  eta: 0:01:30    time: 1.1268  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [170/242]  eta: 0:01:19    time: 1.1924  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [180/242]  eta: 0:01:09    time: 1.2024  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [190/242]  eta: 0:00:58    time: 1.1897  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [200/242]  eta: 0:00:46    time: 1.1421  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [210/242]  eta: 0:00:35    time: 1.1109  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [220/242]  eta: 0:00:24    time: 1.1133  data: 0.0004  max mem: 9536\n",
            "Epoch: [0] Test  [230/242]  eta: 0:00:13    time: 1.1177  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test  [240/242]  eta: 0:00:02    time: 1.0772  data: 0.0003  max mem: 9536\n",
            "Epoch: [0] Test Total time: 0:04:29\n",
            "global correct: 95.3\n",
            "average row correct: ['97.4', '94.1', '79.8', '94.3', '81.0', '71.2', '97.4', '81.6', '96.1', '65.8', '94.9', '60.8', '92.0', '93.9', '92.7', '96.8', '70.5', '94.7', '83.3', '93.9', '84.6']\n",
            "IoU: ['94.5', '91.3', '40.7', '89.4', '72.6', '66.3', '96.1', '78.2', '91.9', '50.5', '92.7', '55.2', '88.8', '89.7', '88.3', '88.7', '62.2', '90.2', '62.7', '90.0', '81.6']\n",
            "mean IoU: 79.1\n",
            "Epoch: [1] Train  [  0/183]  eta: 0:41:31  lr: 0.000100  loss: 3.1269 (3.1269)  time: 13.6128  data: 0.3996  max mem: 9536\n",
            "Epoch: [1] Train  [ 10/183]  eta: 0:36:52  lr: 0.000100  loss: 3.0309 (3.2147)  time: 12.7865  data: 0.0368  max mem: 9536\n",
            "Epoch: [1] Train  [ 20/183]  eta: 0:34:36  lr: 0.000100  loss: 4.2436 (3.3054)  time: 12.6939  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Train  [ 30/183]  eta: 0:32:27  lr: 0.000100  loss: 4.5856 (3.3464)  time: 12.7003  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train  [ 40/183]  eta: 0:30:21  lr: 0.000099  loss: 3.1266 (3.3436)  time: 12.7392  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train  [ 50/183]  eta: 0:28:15  lr: 0.000099  loss: 3.1033 (3.3349)  time: 12.7697  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train  [ 60/183]  eta: 0:26:06  lr: 0.000099  loss: 3.7778 (3.3832)  time: 12.7216  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train  [ 70/183]  eta: 0:23:57  lr: 0.000099  loss: 3.1852 (3.3567)  time: 12.6624  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Train  [ 80/183]  eta: 0:21:50  lr: 0.000099  loss: 3.0872 (3.3660)  time: 12.7024  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train  [ 90/183]  eta: 0:19:42  lr: 0.000099  loss: 3.1929 (3.3576)  time: 12.7014  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train  [100/183]  eta: 0:17:34  lr: 0.000099  loss: 3.0998 (3.3565)  time: 12.6287  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Train  [110/183]  eta: 0:15:26  lr: 0.000099  loss: 3.2566 (3.3498)  time: 12.5879  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Train  [120/183]  eta: 0:13:18  lr: 0.000098  loss: 3.1085 (3.3450)  time: 12.5488  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Train  [130/183]  eta: 0:11:12  lr: 0.000098  loss: 3.4207 (3.3451)  time: 12.6207  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Train  [140/183]  eta: 0:09:05  lr: 0.000098  loss: 3.4051 (3.3393)  time: 12.6450  data: 0.0007  max mem: 9536\n",
            "Epoch: [1] Train  [150/183]  eta: 0:06:58  lr: 0.000098  loss: 3.3167 (3.3305)  time: 12.5911  data: 0.0006  max mem: 9536\n",
            "Epoch: [1] Train  [160/183]  eta: 0:04:51  lr: 0.000098  loss: 3.0909 (3.3182)  time: 12.6634  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train  [170/183]  eta: 0:02:44  lr: 0.000098  loss: 3.1491 (3.3143)  time: 12.6583  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train  [180/183]  eta: 0:00:37  lr: 0.000098  loss: 3.2548 (3.3147)  time: 12.6018  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Train Total time: 0:38:37\n",
            "Epoch: [1] Test  [  0/242]  eta: 0:06:00    time: 1.4910  data: 0.4272  max mem: 9536\n",
            "Epoch: [1] Test  [ 10/242]  eta: 0:04:06    time: 1.0614  data: 0.0391  max mem: 9536\n",
            "Epoch: [1] Test  [ 20/242]  eta: 0:03:49    time: 1.0104  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Test  [ 30/242]  eta: 0:03:46    time: 1.0697  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Test  [ 40/242]  eta: 0:03:38    time: 1.1278  data: 0.0003  max mem: 9536\n",
            "Epoch: [1] Test  [ 50/242]  eta: 0:03:28    time: 1.1107  data: 0.0003  max mem: 9536\n",
            "Epoch: [1] Test  [ 60/242]  eta: 0:03:19    time: 1.1376  data: 0.0003  max mem: 9536\n",
            "Epoch: [1] Test  [ 70/242]  eta: 0:03:09    time: 1.1511  data: 0.0003  max mem: 9536\n",
            "Epoch: [1] Test  [ 80/242]  eta: 0:02:57    time: 1.0994  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [ 90/242]  eta: 0:02:45    time: 1.0465  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [100/242]  eta: 0:02:35    time: 1.0780  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [110/242]  eta: 0:02:24    time: 1.0955  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [120/242]  eta: 0:02:13    time: 1.1095  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [130/242]  eta: 0:02:02    time: 1.1122  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [140/242]  eta: 0:01:51    time: 1.0862  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [150/242]  eta: 0:01:40    time: 1.0844  data: 0.0003  max mem: 9536\n",
            "Epoch: [1] Test  [160/242]  eta: 0:01:29    time: 1.0822  data: 0.0003  max mem: 9536\n",
            "Epoch: [1] Test  [170/242]  eta: 0:01:19    time: 1.1352  data: 0.0003  max mem: 9536\n",
            "Epoch: [1] Test  [180/242]  eta: 0:01:08    time: 1.1904  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [190/242]  eta: 0:00:57    time: 1.1928  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [200/242]  eta: 0:00:46    time: 1.1355  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [210/242]  eta: 0:00:35    time: 1.0989  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test  [220/242]  eta: 0:00:24    time: 1.1024  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Test  [230/242]  eta: 0:00:13    time: 1.1097  data: 0.0005  max mem: 9536\n",
            "Epoch: [1] Test  [240/242]  eta: 0:00:02    time: 1.0761  data: 0.0004  max mem: 9536\n",
            "Epoch: [1] Test Total time: 0:04:27\n",
            "global correct: 95.4\n",
            "average row correct: ['97.1', '95.6', '84.1', '94.7', '83.1', '81.7', '98.5', '86.1', '97.1', '67.7', '95.3', '62.0', '92.7', '92.4', '95.5', '95.9', '71.1', '95.5', '84.8', '96.6', '86.9']\n",
            "IoU: ['94.7', '91.4', '42.6', '89.7', '75.4', '73.7', '96.9', '80.4', '92.1', '48.2', '90.6', '56.5', '88.6', '88.5', '90.2', '89.9', '62.2', '87.4', '62.3', '90.3', '80.8']\n",
            "mean IoU: 79.6\n",
            "Epoch: [2] Train  [  0/183]  eta: 0:37:38  lr: 0.000098  loss: 2.9126 (2.9126)  time: 12.3404  data: 0.4261  max mem: 9536\n",
            "Epoch: [2] Train  [ 10/183]  eta: 0:36:51  lr: 0.000098  loss: 3.1049 (3.2440)  time: 12.7848  data: 0.0392  max mem: 9536\n",
            "Epoch: [2] Train  [ 20/183]  eta: 0:34:33  lr: 0.000097  loss: 3.0676 (3.1953)  time: 12.7382  data: 0.0004  max mem: 9536\n",
            "Epoch: [2] Train  [ 30/183]  eta: 0:32:18  lr: 0.000097  loss: 3.6526 (3.2114)  time: 12.6065  data: 0.0004  max mem: 9536\n",
            "Epoch: [2] Train  [ 40/183]  eta: 0:30:06  lr: 0.000097  loss: 3.3017 (3.2241)  time: 12.5352  data: 0.0004  max mem: 9536\n",
            "Epoch: [2] Train  [ 50/183]  eta: 0:28:00  lr: 0.000097  loss: 3.0728 (3.2503)  time: 12.5854  data: 0.0005  max mem: 9536\n",
            "Epoch: [2] Train  [ 60/183]  eta: 0:25:52  lr: 0.000097  loss: 3.0689 (3.2561)  time: 12.6034  data: 0.0005  max mem: 9536\n",
            "Epoch: [2] Train  [ 70/183]  eta: 0:23:47  lr: 0.000097  loss: 3.1732 (3.2650)  time: 12.6127  data: 0.0005  max mem: 9536\n",
            "Epoch: [2] Train  [ 80/183]  eta: 0:21:40  lr: 0.000097  loss: 3.5316 (3.2763)  time: 12.6372  data: 0.0004  max mem: 9536\n",
            "Epoch: [2] Train  [ 90/183]  eta: 0:19:33  lr: 0.000097  loss: 3.0101 (3.3000)  time: 12.5666  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Train  [100/183]  eta: 0:17:27  lr: 0.000096  loss: 3.1733 (3.2989)  time: 12.5837  data: 0.0004  max mem: 9536\n",
            "Epoch: [2] Train  [110/183]  eta: 0:15:21  lr: 0.000096  loss: 3.6597 (3.2992)  time: 12.6297  data: 0.0006  max mem: 9536\n",
            "Epoch: [2] Train  [120/183]  eta: 0:13:15  lr: 0.000096  loss: 3.0556 (3.3016)  time: 12.6419  data: 0.0006  max mem: 9536\n",
            "Epoch: [2] Train  [130/183]  eta: 0:11:09  lr: 0.000096  loss: 3.3125 (3.2945)  time: 12.6592  data: 0.0005  max mem: 9536\n",
            "Epoch: [2] Train  [140/183]  eta: 0:09:02  lr: 0.000096  loss: 3.0680 (3.2874)  time: 12.5949  data: 0.0005  max mem: 9536\n",
            "Epoch: [2] Train  [150/183]  eta: 0:06:56  lr: 0.000096  loss: 4.1938 (3.2894)  time: 12.5275  data: 0.0006  max mem: 9536\n",
            "Epoch: [2] Train  [160/183]  eta: 0:04:49  lr: 0.000096  loss: 3.2788 (3.2961)  time: 12.5044  data: 0.0007  max mem: 9536\n",
            "Epoch: [2] Train  [170/183]  eta: 0:02:43  lr: 0.000096  loss: 3.1771 (3.2917)  time: 12.4662  data: 0.0006  max mem: 9536\n",
            "Epoch: [2] Train  [180/183]  eta: 0:00:37  lr: 0.000095  loss: 3.2064 (3.2909)  time: 12.5740  data: 0.0006  max mem: 9536\n",
            "Epoch: [2] Train Total time: 0:38:25\n",
            "Epoch: [2] Test  [  0/242]  eta: 0:05:51    time: 1.4538  data: 0.3884  max mem: 9536\n",
            "Epoch: [2] Test  [ 10/242]  eta: 0:04:03    time: 1.0516  data: 0.0356  max mem: 9536\n",
            "Epoch: [2] Test  [ 20/242]  eta: 0:03:47    time: 1.0052  data: 0.0004  max mem: 9536\n",
            "Epoch: [2] Test  [ 30/242]  eta: 0:03:43    time: 1.0544  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [ 40/242]  eta: 0:03:35    time: 1.1093  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [ 50/242]  eta: 0:03:26    time: 1.1074  data: 0.0002  max mem: 9536\n",
            "Epoch: [2] Test  [ 60/242]  eta: 0:03:18    time: 1.1428  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [ 70/242]  eta: 0:03:08    time: 1.1518  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [ 80/242]  eta: 0:02:56    time: 1.0916  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [ 90/242]  eta: 0:02:44    time: 1.0408  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [100/242]  eta: 0:02:34    time: 1.0764  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [110/242]  eta: 0:02:23    time: 1.0989  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [120/242]  eta: 0:02:13    time: 1.1197  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [130/242]  eta: 0:02:02    time: 1.1134  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [140/242]  eta: 0:01:51    time: 1.0578  data: 0.0004  max mem: 9536\n",
            "Epoch: [2] Test  [150/242]  eta: 0:01:39    time: 1.0569  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [160/242]  eta: 0:01:29    time: 1.0672  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [170/242]  eta: 0:01:18    time: 1.1138  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [180/242]  eta: 0:01:08    time: 1.1853  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [190/242]  eta: 0:00:57    time: 1.1886  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [200/242]  eta: 0:00:46    time: 1.1328  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [210/242]  eta: 0:00:35    time: 1.1163  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [220/242]  eta: 0:00:24    time: 1.1142  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test  [230/242]  eta: 0:00:13    time: 1.1085  data: 0.0004  max mem: 9536\n",
            "Epoch: [2] Test  [240/242]  eta: 0:00:02    time: 1.0806  data: 0.0003  max mem: 9536\n",
            "Epoch: [2] Test Total time: 0:04:25\n",
            "global correct: 95.5\n",
            "average row correct: ['96.9', '96.5', '83.4', '96.0', '88.0', '89.4', '99.0', '89.8', '96.6', '67.9', '95.7', '65.3', '95.0', '93.8', '93.6', '95.7', '78.6', '95.7', '84.4', '97.0', '87.6']\n",
            "IoU: ['94.8', '93.0', '42.4', '89.2', '72.9', '74.6', '96.9', '81.9', '92.9', '48.0', '91.7', '59.0', '89.8', '90.1', '89.7', '90.6', '64.6', '88.9', '62.7', '90.0', '80.9']\n",
            "mean IoU: 80.2\n",
            "Epoch: [3] Train  [  0/183]  eta: 0:42:04  lr: 0.000095  loss: 3.2702 (3.2702)  time: 13.7932  data: 0.4374  max mem: 9536\n",
            "Epoch: [3] Train  [ 10/183]  eta: 0:36:38  lr: 0.000095  loss: 3.4724 (3.2549)  time: 12.7075  data: 0.0401  max mem: 9536\n",
            "Epoch: [3] Train  [ 20/183]  eta: 0:34:10  lr: 0.000095  loss: 3.2254 (3.2152)  time: 12.5218  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [ 30/183]  eta: 0:32:09  lr: 0.000095  loss: 3.1988 (3.2006)  time: 12.5552  data: 0.0005  max mem: 9536\n",
            "Epoch: [3] Train  [ 40/183]  eta: 0:30:00  lr: 0.000095  loss: 3.4497 (3.2198)  time: 12.5991  data: 0.0005  max mem: 9536\n",
            "Epoch: [3] Train  [ 50/183]  eta: 0:27:54  lr: 0.000095  loss: 4.3325 (3.2354)  time: 12.5649  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [ 60/183]  eta: 0:25:50  lr: 0.000095  loss: 3.2563 (3.2632)  time: 12.6471  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [ 70/183]  eta: 0:23:44  lr: 0.000094  loss: 3.3905 (3.2820)  time: 12.6371  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [ 80/183]  eta: 0:21:36  lr: 0.000094  loss: 3.0567 (3.2631)  time: 12.5220  data: 0.0005  max mem: 9536\n",
            "Epoch: [3] Train  [ 90/183]  eta: 0:19:31  lr: 0.000094  loss: 3.1140 (3.2672)  time: 12.5908  data: 0.0005  max mem: 9536\n",
            "Epoch: [3] Train  [100/183]  eta: 0:17:25  lr: 0.000094  loss: 3.0803 (3.2718)  time: 12.6206  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [110/183]  eta: 0:15:19  lr: 0.000094  loss: 3.7458 (3.2876)  time: 12.6064  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [120/183]  eta: 0:13:13  lr: 0.000094  loss: 3.0996 (3.3042)  time: 12.6263  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [130/183]  eta: 0:11:07  lr: 0.000094  loss: 3.0508 (3.3023)  time: 12.5464  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [140/183]  eta: 0:09:01  lr: 0.000094  loss: 3.1018 (3.2985)  time: 12.5667  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Train  [150/183]  eta: 0:06:55  lr: 0.000093  loss: 3.0911 (3.2951)  time: 12.5654  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [160/183]  eta: 0:04:49  lr: 0.000093  loss: 3.2193 (3.2935)  time: 12.5728  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [170/183]  eta: 0:02:43  lr: 0.000093  loss: 3.0877 (3.2947)  time: 12.6040  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train  [180/183]  eta: 0:00:37  lr: 0.000093  loss: 3.1885 (3.2976)  time: 12.5766  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Train Total time: 0:38:23\n",
            "Epoch: [3] Test  [  0/242]  eta: 0:06:04    time: 1.5059  data: 0.4391  max mem: 9536\n",
            "Epoch: [3] Test  [ 10/242]  eta: 0:04:08    time: 1.0709  data: 0.0403  max mem: 9536\n",
            "Epoch: [3] Test  [ 20/242]  eta: 0:03:50    time: 1.0166  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [ 30/242]  eta: 0:03:47    time: 1.0734  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [ 40/242]  eta: 0:03:39    time: 1.1356  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [ 50/242]  eta: 0:03:29    time: 1.1200  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [ 60/242]  eta: 0:03:21    time: 1.1539  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [ 70/242]  eta: 0:03:11    time: 1.1746  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [ 80/242]  eta: 0:02:59    time: 1.1105  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [ 90/242]  eta: 0:02:47    time: 1.0510  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [100/242]  eta: 0:02:36    time: 1.0851  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [110/242]  eta: 0:02:25    time: 1.0973  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [120/242]  eta: 0:02:14    time: 1.1080  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [130/242]  eta: 0:02:03    time: 1.0995  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [140/242]  eta: 0:01:51    time: 1.0530  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [150/242]  eta: 0:01:40    time: 1.0666  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [160/242]  eta: 0:01:29    time: 1.0830  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [170/242]  eta: 0:01:19    time: 1.1259  data: 0.0003  max mem: 9536\n",
            "Epoch: [3] Test  [180/242]  eta: 0:01:08    time: 1.1835  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [190/242]  eta: 0:00:57    time: 1.1859  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [200/242]  eta: 0:00:46    time: 1.1303  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [210/242]  eta: 0:00:35    time: 1.1077  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test  [220/242]  eta: 0:00:24    time: 1.1181  data: 0.0005  max mem: 9536\n",
            "Epoch: [3] Test  [230/242]  eta: 0:00:13    time: 1.1241  data: 0.0005  max mem: 9536\n",
            "Epoch: [3] Test  [240/242]  eta: 0:00:02    time: 1.0808  data: 0.0004  max mem: 9536\n",
            "Epoch: [3] Test Total time: 0:04:28\n",
            "global correct: 95.5\n",
            "average row correct: ['96.9', '96.3', '78.4', '95.5', '88.3', '85.4', '98.8', '91.2', '97.3', '66.8', '96.6', '64.3', '95.0', '93.6', '94.5', '96.1', '78.8', '95.5', '86.8', '96.8', '88.5']\n",
            "IoU: ['94.8', '92.2', '41.4', '89.7', '74.7', '75.1', '96.9', '82.8', '93.2', '48.0', '91.9', '58.3', '90.0', '89.5', '90.3', '90.3', '63.7', '89.4', '62.0', '89.2', '80.5']\n",
            "mean IoU: 80.2\n",
            "Epoch: [4] Train  [  0/183]  eta: 0:38:36  lr: 0.000093  loss: 3.0126 (3.0126)  time: 12.6610  data: 0.3861  max mem: 9536\n",
            "Epoch: [4] Train  [ 10/183]  eta: 0:36:40  lr: 0.000093  loss: 3.2218 (3.1541)  time: 12.7191  data: 0.0354  max mem: 9536\n",
            "Epoch: [4] Train  [ 20/183]  eta: 0:34:10  lr: 0.000093  loss: 3.1100 (3.2005)  time: 12.5758  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Train  [ 30/183]  eta: 0:32:03  lr: 0.000093  loss: 3.2675 (3.1864)  time: 12.4878  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Train  [ 40/183]  eta: 0:29:55  lr: 0.000093  loss: 3.1887 (3.2010)  time: 12.5303  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Train  [ 50/183]  eta: 0:27:52  lr: 0.000092  loss: 3.1974 (3.2140)  time: 12.5828  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Train  [ 60/183]  eta: 0:25:49  lr: 0.000092  loss: 3.4076 (3.2336)  time: 12.6761  data: 0.0005  max mem: 9536\n",
            "Epoch: [4] Train  [ 70/183]  eta: 0:23:43  lr: 0.000092  loss: 3.5131 (3.2306)  time: 12.6453  data: 0.0006  max mem: 9536\n",
            "Epoch: [4] Train  [ 80/183]  eta: 0:21:36  lr: 0.000092  loss: 3.0992 (3.2291)  time: 12.5585  data: 0.0006  max mem: 9536\n",
            "Epoch: [4] Train  [ 90/183]  eta: 0:19:31  lr: 0.000092  loss: 3.0610 (3.2366)  time: 12.5977  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Train  [100/183]  eta: 0:17:24  lr: 0.000092  loss: 3.3404 (3.2415)  time: 12.5730  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Train  [110/183]  eta: 0:15:18  lr: 0.000092  loss: 3.1534 (3.2552)  time: 12.5261  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Train  [120/183]  eta: 0:13:12  lr: 0.000092  loss: 3.3477 (3.2690)  time: 12.5742  data: 0.0005  max mem: 9536\n",
            "Epoch: [4] Train  [130/183]  eta: 0:11:06  lr: 0.000091  loss: 3.4099 (3.2720)  time: 12.5608  data: 0.0005  max mem: 9536\n",
            "Epoch: [4] Train  [140/183]  eta: 0:09:00  lr: 0.000091  loss: 3.8019 (3.2832)  time: 12.5607  data: 0.0006  max mem: 9536\n",
            "Epoch: [4] Train  [150/183]  eta: 0:06:55  lr: 0.000091  loss: 3.4038 (3.2808)  time: 12.5698  data: 0.0006  max mem: 9536\n",
            "Epoch: [4] Train  [160/183]  eta: 0:04:49  lr: 0.000091  loss: 3.1168 (3.2759)  time: 12.5394  data: 0.0005  max mem: 9536\n",
            "Epoch: [4] Train  [170/183]  eta: 0:02:43  lr: 0.000091  loss: 3.6849 (3.2757)  time: 12.5827  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Train  [180/183]  eta: 0:00:37  lr: 0.000091  loss: 3.2118 (3.2756)  time: 12.6309  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Train Total time: 0:38:21\n",
            "Epoch: [4] Test  [  0/242]  eta: 0:05:56    time: 1.4720  data: 0.3893  max mem: 9536\n",
            "Epoch: [4] Test  [ 10/242]  eta: 0:04:04    time: 1.0556  data: 0.0358  max mem: 9536\n",
            "Epoch: [4] Test  [ 20/242]  eta: 0:03:49    time: 1.0119  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Test  [ 30/242]  eta: 0:03:45    time: 1.0704  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [ 40/242]  eta: 0:03:37    time: 1.1258  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [ 50/242]  eta: 0:03:29    time: 1.1295  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Test  [ 60/242]  eta: 0:03:21    time: 1.1611  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Test  [ 70/242]  eta: 0:03:11    time: 1.1727  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Test  [ 80/242]  eta: 0:02:59    time: 1.1154  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [ 90/242]  eta: 0:02:46    time: 1.0458  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [100/242]  eta: 0:02:36    time: 1.0745  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [110/242]  eta: 0:02:24    time: 1.0949  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [120/242]  eta: 0:02:14    time: 1.1098  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Test  [130/242]  eta: 0:02:03    time: 1.1086  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Test  [140/242]  eta: 0:01:52    time: 1.0731  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [150/242]  eta: 0:01:40    time: 1.0662  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [160/242]  eta: 0:01:29    time: 1.0672  data: 0.0004  max mem: 9536\n",
            "Epoch: [4] Test  [170/242]  eta: 0:01:19    time: 1.1190  data: 0.0005  max mem: 9536\n",
            "Epoch: [4] Test  [180/242]  eta: 0:01:08    time: 1.1771  data: 0.0005  max mem: 9536\n",
            "Epoch: [4] Test  [190/242]  eta: 0:00:57    time: 1.1761  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [200/242]  eta: 0:00:46    time: 1.1253  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [210/242]  eta: 0:00:35    time: 1.1089  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [220/242]  eta: 0:00:24    time: 1.1242  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [230/242]  eta: 0:00:13    time: 1.1267  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test  [240/242]  eta: 0:00:02    time: 1.0817  data: 0.0003  max mem: 9536\n",
            "Epoch: [4] Test Total time: 0:04:27\n",
            "global correct: 95.4\n",
            "average row correct: ['96.5', '97.0', '83.2', '96.1', '87.9', '90.0', '98.8', '91.2', '97.4', '69.5', '95.5', '65.6', '94.7', '93.6', '95.6', '96.4', '82.5', '95.7', '86.5', '96.3', '89.4']\n",
            "IoU: ['94.7', '93.8', '43.6', '90.4', '74.4', '73.1', '97.0', '82.2', '92.0', '47.7', '91.4', '59.3', '89.3', '90.5', '90.9', '90.3', '64.4', '88.7', '61.1', '90.2', '78.5']\n",
            "mean IoU: 80.2\n",
            "Epoch: [5] Train  [  0/183]  eta: 0:39:49  lr: 0.000091  loss: 3.0401 (3.0401)  time: 13.0591  data: 0.4759  max mem: 9536\n",
            "Epoch: [5] Train  [ 10/183]  eta: 0:36:43  lr: 0.000091  loss: 3.2241 (3.1564)  time: 12.7362  data: 0.0436  max mem: 9536\n",
            "Epoch: [5] Train  [ 20/183]  eta: 0:34:21  lr: 0.000090  loss: 3.4168 (3.1594)  time: 12.6238  data: 0.0004  max mem: 9536\n",
            "Epoch: [5] Train  [ 30/183]  eta: 0:32:14  lr: 0.000090  loss: 3.1041 (3.2057)  time: 12.5976  data: 0.0006  max mem: 9536\n",
            "Epoch: [5] Train  [ 40/183]  eta: 0:30:05  lr: 0.000090  loss: 3.3620 (3.2322)  time: 12.6087  data: 0.0006  max mem: 9536\n",
            "Epoch: [5] Train  [ 50/183]  eta: 0:28:01  lr: 0.000090  loss: 2.9681 (3.2254)  time: 12.6365  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Train  [ 60/183]  eta: 0:25:54  lr: 0.000090  loss: 3.0411 (3.2474)  time: 12.6730  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Train  [ 70/183]  eta: 0:23:47  lr: 0.000090  loss: 3.0167 (3.2679)  time: 12.6135  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Train  [ 80/183]  eta: 0:21:39  lr: 0.000090  loss: 3.2065 (3.2899)  time: 12.5575  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Train  [ 90/183]  eta: 0:19:33  lr: 0.000090  loss: 3.2887 (3.2868)  time: 12.5757  data: 0.0004  max mem: 9536\n",
            "Epoch: [5] Train  [100/183]  eta: 0:17:28  lr: 0.000089  loss: 3.4981 (3.2898)  time: 12.6660  data: 0.0004  max mem: 9536\n",
            "Epoch: [5] Train  [110/183]  eta: 0:15:21  lr: 0.000089  loss: 3.0683 (3.2825)  time: 12.6089  data: 0.0005  max mem: 9536\n",
            "Epoch: [5] Train  [120/183]  eta: 0:13:14  lr: 0.000089  loss: 3.2186 (3.2750)  time: 12.5302  data: 0.0004  max mem: 9536\n",
            "Epoch: [5] Train  [130/183]  eta: 0:11:08  lr: 0.000089  loss: 3.4200 (3.2656)  time: 12.6046  data: 0.0004  max mem: 9536\n",
            "Epoch: [5] Train  [140/183]  eta: 0:09:02  lr: 0.000089  loss: 3.4275 (3.2611)  time: 12.6288  data: 0.0005  max mem: 9536\n",
            "Epoch: [5] Train  [150/183]  eta: 0:06:56  lr: 0.000089  loss: 3.0022 (3.2599)  time: 12.5983  data: 0.0006  max mem: 9536\n",
            "Epoch: [5] Train  [160/183]  eta: 0:04:50  lr: 0.000089  loss: 3.0303 (3.2608)  time: 12.5967  data: 0.0005  max mem: 9536\n",
            "Epoch: [5] Train  [170/183]  eta: 0:02:44  lr: 0.000089  loss: 3.4802 (3.2605)  time: 12.6306  data: 0.0005  max mem: 9536\n",
            "Epoch: [5] Train  [180/183]  eta: 0:00:37  lr: 0.000088  loss: 3.4851 (3.2602)  time: 12.5891  data: 0.0004  max mem: 9536\n",
            "Epoch: [5] Train Total time: 0:38:27\n",
            "Epoch: [5] Test  [  0/242]  eta: 0:05:52    time: 1.4563  data: 0.3848  max mem: 9536\n",
            "Epoch: [5] Test  [ 10/242]  eta: 0:04:16    time: 1.1075  data: 0.0352  max mem: 9536\n",
            "Epoch: [5] Test  [ 20/242]  eta: 0:03:55    time: 1.0415  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [ 30/242]  eta: 0:03:49    time: 1.0707  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [ 40/242]  eta: 0:03:41    time: 1.1376  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [ 50/242]  eta: 0:03:30    time: 1.1195  data: 0.0004  max mem: 9536\n",
            "Epoch: [5] Test  [ 60/242]  eta: 0:03:22    time: 1.1383  data: 0.0004  max mem: 9536\n",
            "Epoch: [5] Test  [ 70/242]  eta: 0:03:11    time: 1.1581  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [ 80/242]  eta: 0:02:59    time: 1.0998  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [ 90/242]  eta: 0:02:46    time: 1.0408  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [100/242]  eta: 0:02:36    time: 1.0743  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [110/242]  eta: 0:02:24    time: 1.0945  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [120/242]  eta: 0:02:14    time: 1.1150  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [130/242]  eta: 0:02:03    time: 1.1047  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [140/242]  eta: 0:01:51    time: 1.0484  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [150/242]  eta: 0:01:40    time: 1.0637  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [160/242]  eta: 0:01:29    time: 1.0767  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [170/242]  eta: 0:01:19    time: 1.1261  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [180/242]  eta: 0:01:08    time: 1.1901  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [190/242]  eta: 0:00:57    time: 1.1871  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [200/242]  eta: 0:00:46    time: 1.1261  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [210/242]  eta: 0:00:35    time: 1.1053  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [220/242]  eta: 0:00:24    time: 1.1150  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [230/242]  eta: 0:00:13    time: 1.1206  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test  [240/242]  eta: 0:00:02    time: 1.1062  data: 0.0003  max mem: 9536\n",
            "Epoch: [5] Test Total time: 0:04:28\n",
            "global correct: 95.5\n",
            "average row correct: ['96.8', '96.1', '81.8', '95.3', '85.3', '88.7', '98.5', '90.5', '97.5', '67.4', '96.0', '70.0', '92.2', '94.3', '94.4', '96.5', '82.6', '95.5', '86.0', '96.0', '89.9']\n",
            "IoU: ['94.9', '93.9', '43.7', '90.4', '77.0', '75.3', '96.8', '83.9', '91.4', '46.7', '91.8', '61.5', '88.0', '89.9', '89.7', '90.8', '66.1', '89.5', '61.9', '89.7', '77.6']\n",
            "mean IoU: 80.5\n",
            "Epoch: [6] Train  [  0/183]  eta: 0:40:47  lr: 0.000088  loss: 2.9897 (2.9897)  time: 13.3752  data: 0.3894  max mem: 9536\n",
            "Epoch: [6] Train  [ 10/183]  eta: 0:36:43  lr: 0.000088  loss: 3.7776 (3.6336)  time: 12.7365  data: 0.0358  max mem: 9536\n",
            "Epoch: [6] Train  [ 20/183]  eta: 0:34:22  lr: 0.000088  loss: 3.2128 (3.4600)  time: 12.6148  data: 0.0005  max mem: 9536\n",
            "Epoch: [6] Train  [ 30/183]  eta: 0:32:14  lr: 0.000088  loss: 3.2873 (3.4016)  time: 12.5882  data: 0.0006  max mem: 9536\n",
            "Epoch: [6] Train  [ 40/183]  eta: 0:30:09  lr: 0.000088  loss: 3.0104 (3.3692)  time: 12.6583  data: 0.0005  max mem: 9536\n",
            "Epoch: [6] Train  [ 50/183]  eta: 0:27:58  lr: 0.000088  loss: 3.3787 (3.3436)  time: 12.5851  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [ 60/183]  eta: 0:25:56  lr: 0.000088  loss: 3.1095 (3.3332)  time: 12.6590  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [ 70/183]  eta: 0:23:49  lr: 0.000087  loss: 3.2463 (3.3504)  time: 12.7189  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [ 80/183]  eta: 0:21:42  lr: 0.000087  loss: 2.9332 (3.3377)  time: 12.6117  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [ 90/183]  eta: 0:19:34  lr: 0.000087  loss: 3.2888 (3.3325)  time: 12.5798  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [100/183]  eta: 0:17:27  lr: 0.000087  loss: 3.1375 (3.3277)  time: 12.5510  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [110/183]  eta: 0:15:22  lr: 0.000087  loss: 3.1774 (3.3177)  time: 12.6356  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [120/183]  eta: 0:13:15  lr: 0.000087  loss: 3.3357 (3.3043)  time: 12.6653  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [130/183]  eta: 0:11:09  lr: 0.000087  loss: 3.0753 (3.2940)  time: 12.5754  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Train  [140/183]  eta: 0:09:02  lr: 0.000087  loss: 3.1542 (3.2847)  time: 12.5942  data: 0.0005  max mem: 9536\n",
            "Epoch: [6] Train  [150/183]  eta: 0:06:56  lr: 0.000086  loss: 2.9371 (3.2799)  time: 12.6468  data: 0.0005  max mem: 9536\n",
            "Epoch: [6] Train  [160/183]  eta: 0:04:50  lr: 0.000086  loss: 3.0221 (3.2759)  time: 12.7140  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Train  [170/183]  eta: 0:02:44  lr: 0.000086  loss: 3.3020 (3.2703)  time: 12.6507  data: 0.0006  max mem: 9536\n",
            "Epoch: [6] Train  [180/183]  eta: 0:00:37  lr: 0.000086  loss: 3.8399 (3.2763)  time: 12.5452  data: 0.0006  max mem: 9536\n",
            "Epoch: [6] Train Total time: 0:38:31\n",
            "Epoch: [6] Test  [  0/242]  eta: 0:06:04    time: 1.5073  data: 0.4400  max mem: 9536\n",
            "Epoch: [6] Test  [ 10/242]  eta: 0:04:05    time: 1.0602  data: 0.0403  max mem: 9536\n",
            "Epoch: [6] Test  [ 20/242]  eta: 0:03:49    time: 1.0101  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Test  [ 30/242]  eta: 0:03:44    time: 1.0559  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Test  [ 40/242]  eta: 0:03:36    time: 1.1159  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [ 50/242]  eta: 0:03:27    time: 1.1192  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [ 60/242]  eta: 0:03:19    time: 1.1434  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [ 70/242]  eta: 0:03:09    time: 1.1506  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [ 80/242]  eta: 0:02:58    time: 1.1070  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [ 90/242]  eta: 0:02:45    time: 1.0536  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [100/242]  eta: 0:02:35    time: 1.0829  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [110/242]  eta: 0:02:24    time: 1.1155  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Test  [120/242]  eta: 0:02:14    time: 1.1331  data: 0.0005  max mem: 9536\n",
            "Epoch: [6] Test  [130/242]  eta: 0:02:02    time: 1.1075  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Test  [140/242]  eta: 0:01:51    time: 1.0533  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [150/242]  eta: 0:01:40    time: 1.0674  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [160/242]  eta: 0:01:29    time: 1.0794  data: 0.0003  max mem: 9536\n",
            "Epoch: [6] Test  [170/242]  eta: 0:01:18    time: 1.1243  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Test  [180/242]  eta: 0:01:08    time: 1.1780  data: 0.0005  max mem: 9536\n",
            "Epoch: [6] Test  [190/242]  eta: 0:00:57    time: 1.1831  data: 0.0006  max mem: 9536\n",
            "Epoch: [6] Test  [200/242]  eta: 0:00:46    time: 1.1306  data: 0.0005  max mem: 9536\n",
            "Epoch: [6] Test  [210/242]  eta: 0:00:35    time: 1.1134  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Test  [220/242]  eta: 0:00:24    time: 1.1192  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Test  [230/242]  eta: 0:00:13    time: 1.1185  data: 0.0005  max mem: 9536\n",
            "Epoch: [6] Test  [240/242]  eta: 0:00:02    time: 1.0788  data: 0.0004  max mem: 9536\n",
            "Epoch: [6] Test Total time: 0:04:26\n",
            "global correct: 95.4\n",
            "average row correct: ['96.5', '96.3', '81.6', '96.3', '82.5', '91.5', '99.1', '92.5', '98.5', '74.5', '95.8', '71.1', '93.3', '93.5', '94.6', '96.5', '83.6', '96.1', '83.3', '95.6', '89.0']\n",
            "IoU: ['94.7', '94.5', '43.8', '90.5', '75.8', '72.5', '96.1', '83.5', '90.7', '48.4', '90.5', '61.6', '88.3', '89.7', '90.2', '90.7', '64.8', '88.2', '63.3', '90.6', '76.5']\n",
            "mean IoU: 80.2\n",
            "Epoch: [7] Train  [  0/183]  eta: 0:39:40  lr: 0.000086  loss: 3.3010 (3.3010)  time: 13.0088  data: 0.4217  max mem: 9536\n",
            "Epoch: [7] Train  [ 10/183]  eta: 0:36:52  lr: 0.000086  loss: 3.3182 (3.2596)  time: 12.7893  data: 0.0387  max mem: 9536\n",
            "Epoch: [7] Train  [ 20/183]  eta: 0:34:26  lr: 0.000086  loss: 3.1877 (3.2514)  time: 12.6638  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [ 30/183]  eta: 0:32:24  lr: 0.000086  loss: 3.3014 (3.2378)  time: 12.6640  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Train  [ 40/183]  eta: 0:30:19  lr: 0.000086  loss: 3.1899 (3.2421)  time: 12.7738  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Train  [ 50/183]  eta: 0:28:12  lr: 0.000085  loss: 3.2344 (3.2645)  time: 12.7528  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [ 60/183]  eta: 0:26:02  lr: 0.000085  loss: 3.5414 (3.2709)  time: 12.6497  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [ 70/183]  eta: 0:23:52  lr: 0.000085  loss: 3.0860 (3.2671)  time: 12.5641  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [ 80/183]  eta: 0:21:44  lr: 0.000085  loss: 3.1284 (3.2737)  time: 12.5707  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [ 90/183]  eta: 0:19:36  lr: 0.000085  loss: 3.0549 (3.2682)  time: 12.5419  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Train  [100/183]  eta: 0:17:29  lr: 0.000085  loss: 3.0688 (3.2699)  time: 12.5394  data: 0.0006  max mem: 9536\n",
            "Epoch: [7] Train  [110/183]  eta: 0:15:22  lr: 0.000085  loss: 3.2468 (3.2672)  time: 12.5567  data: 0.0005  max mem: 9536\n",
            "Epoch: [7] Train  [120/183]  eta: 0:13:15  lr: 0.000084  loss: 3.3155 (3.2694)  time: 12.5284  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Train  [130/183]  eta: 0:11:08  lr: 0.000084  loss: 3.6046 (3.2634)  time: 12.5547  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Train  [140/183]  eta: 0:09:02  lr: 0.000084  loss: 3.0601 (3.2602)  time: 12.5889  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [150/183]  eta: 0:06:56  lr: 0.000084  loss: 2.9822 (3.2626)  time: 12.6047  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [160/183]  eta: 0:04:50  lr: 0.000084  loss: 3.2558 (3.2613)  time: 12.5837  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [170/183]  eta: 0:02:44  lr: 0.000084  loss: 3.2681 (3.2641)  time: 12.5977  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train  [180/183]  eta: 0:00:37  lr: 0.000084  loss: 3.4741 (3.2752)  time: 12.6286  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Train Total time: 0:38:28\n",
            "Epoch: [7] Test  [  0/242]  eta: 0:06:03    time: 1.5007  data: 0.4168  max mem: 9536\n",
            "Epoch: [7] Test  [ 10/242]  eta: 0:04:06    time: 1.0621  data: 0.0382  max mem: 9536\n",
            "Epoch: [7] Test  [ 20/242]  eta: 0:03:48    time: 1.0050  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [ 30/242]  eta: 0:03:44    time: 1.0602  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Test  [ 40/242]  eta: 0:03:37    time: 1.1286  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [ 50/242]  eta: 0:03:28    time: 1.1222  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [ 60/242]  eta: 0:03:20    time: 1.1545  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Test  [ 70/242]  eta: 0:03:10    time: 1.1601  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Test  [ 80/242]  eta: 0:02:58    time: 1.0992  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [ 90/242]  eta: 0:02:46    time: 1.0503  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [100/242]  eta: 0:02:36    time: 1.0867  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Test  [110/242]  eta: 0:02:24    time: 1.1077  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Test  [120/242]  eta: 0:02:14    time: 1.1207  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [130/242]  eta: 0:02:03    time: 1.1158  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [140/242]  eta: 0:01:51    time: 1.0664  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [150/242]  eta: 0:01:40    time: 1.0639  data: 0.0005  max mem: 9536\n",
            "Epoch: [7] Test  [160/242]  eta: 0:01:29    time: 1.0748  data: 0.0005  max mem: 9536\n",
            "Epoch: [7] Test  [170/242]  eta: 0:01:19    time: 1.1274  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [180/242]  eta: 0:01:08    time: 1.1862  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [190/242]  eta: 0:00:57    time: 1.1877  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Test  [200/242]  eta: 0:00:46    time: 1.1357  data: 0.0004  max mem: 9536\n",
            "Epoch: [7] Test  [210/242]  eta: 0:00:35    time: 1.1088  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [220/242]  eta: 0:00:24    time: 1.1185  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [230/242]  eta: 0:00:13    time: 1.1220  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test  [240/242]  eta: 0:00:02    time: 1.0857  data: 0.0003  max mem: 9536\n",
            "Epoch: [7] Test Total time: 0:04:28\n",
            "global correct: 95.6\n",
            "average row correct: ['96.7', '97.4', '82.1', '95.4', '89.4', '89.2', '98.9', '92.5', '97.0', '68.1', '96.1', '71.2', '94.0', '95.5', '95.4', '96.5', '84.3', '96.0', '84.6', '97.0', '89.4']\n",
            "IoU: ['94.9', '93.1', '44.4', '90.1', '75.7', '74.4', '96.5', '83.1', '93.0', '50.5', '92.4', '62.5', '89.5', '89.2', '90.6', '90.4', '65.7', '89.2', '62.7', '88.8', '75.4']\n",
            "mean IoU: 80.6\n",
            "Epoch: [8] Train  [  0/183]  eta: 0:39:46  lr: 0.000084  loss: 3.3999 (3.3999)  time: 13.0393  data: 0.4340  max mem: 9536\n",
            "Epoch: [8] Train  [ 10/183]  eta: 0:36:44  lr: 0.000084  loss: 3.2450 (3.3191)  time: 12.7439  data: 0.0398  max mem: 9536\n",
            "Epoch: [8] Train  [ 20/183]  eta: 0:34:17  lr: 0.000083  loss: 3.0276 (3.2477)  time: 12.5988  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Train  [ 30/183]  eta: 0:32:08  lr: 0.000083  loss: 3.9911 (3.2829)  time: 12.5282  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Train  [ 40/183]  eta: 0:30:01  lr: 0.000083  loss: 3.8445 (3.2970)  time: 12.5711  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Train  [ 50/183]  eta: 0:27:55  lr: 0.000083  loss: 3.1292 (3.2825)  time: 12.5902  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Train  [ 60/183]  eta: 0:25:51  lr: 0.000083  loss: 2.9629 (3.2884)  time: 12.6609  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Train  [ 70/183]  eta: 0:23:45  lr: 0.000083  loss: 3.1531 (3.2885)  time: 12.6587  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Train  [ 80/183]  eta: 0:21:39  lr: 0.000083  loss: 3.0481 (3.2797)  time: 12.6163  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Train  [ 90/183]  eta: 0:19:32  lr: 0.000083  loss: 3.1597 (3.2800)  time: 12.5601  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Train  [100/183]  eta: 0:17:25  lr: 0.000082  loss: 3.0386 (3.2679)  time: 12.5295  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Train  [110/183]  eta: 0:15:21  lr: 0.000082  loss: 3.2754 (3.2607)  time: 12.7470  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Train  [120/183]  eta: 0:13:16  lr: 0.000082  loss: 3.4893 (3.2646)  time: 12.8364  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Train  [130/183]  eta: 0:11:09  lr: 0.000082  loss: 3.2613 (3.2727)  time: 12.6463  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Train  [140/183]  eta: 0:09:03  lr: 0.000082  loss: 3.2596 (3.2792)  time: 12.5797  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Train  [150/183]  eta: 0:06:56  lr: 0.000082  loss: 3.3708 (3.2827)  time: 12.4456  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Train  [160/183]  eta: 0:04:50  lr: 0.000082  loss: 3.0388 (3.2905)  time: 12.5420  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Train  [170/183]  eta: 0:02:43  lr: 0.000081  loss: 3.2788 (3.2905)  time: 12.6515  data: 0.0002  max mem: 9536\n",
            "Epoch: [8] Train  [180/183]  eta: 0:00:37  lr: 0.000081  loss: 3.7688 (3.2938)  time: 12.5150  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Train Total time: 0:38:27\n",
            "Epoch: [8] Test  [  0/242]  eta: 0:05:49    time: 1.4447  data: 0.3672  max mem: 9536\n",
            "Epoch: [8] Test  [ 10/242]  eta: 0:04:09    time: 1.0751  data: 0.0336  max mem: 9536\n",
            "Epoch: [8] Test  [ 20/242]  eta: 0:03:54    time: 1.0373  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Test  [ 30/242]  eta: 0:03:47    time: 1.0729  data: 0.0005  max mem: 9536\n",
            "Epoch: [8] Test  [ 40/242]  eta: 0:03:38    time: 1.1089  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [ 50/242]  eta: 0:03:28    time: 1.1063  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [ 60/242]  eta: 0:03:20    time: 1.1408  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [ 70/242]  eta: 0:03:09    time: 1.1509  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [ 80/242]  eta: 0:02:58    time: 1.1010  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [ 90/242]  eta: 0:02:45    time: 1.0469  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [100/242]  eta: 0:02:35    time: 1.0766  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [110/242]  eta: 0:02:24    time: 1.0933  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [120/242]  eta: 0:02:13    time: 1.1041  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [130/242]  eta: 0:02:02    time: 1.0916  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [140/242]  eta: 0:01:51    time: 1.0534  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [150/242]  eta: 0:01:40    time: 1.0677  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [160/242]  eta: 0:01:29    time: 1.0673  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [170/242]  eta: 0:01:18    time: 1.1154  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Test  [180/242]  eta: 0:01:08    time: 1.1784  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [190/242]  eta: 0:00:57    time: 1.1882  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [200/242]  eta: 0:00:46    time: 1.1369  data: 0.0004  max mem: 9536\n",
            "Epoch: [8] Test  [210/242]  eta: 0:00:35    time: 1.1047  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [220/242]  eta: 0:00:24    time: 1.1076  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [230/242]  eta: 0:00:13    time: 1.1107  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test  [240/242]  eta: 0:00:02    time: 1.0735  data: 0.0003  max mem: 9536\n",
            "Epoch: [8] Test Total time: 0:04:25\n",
            "global correct: 95.5\n",
            "average row correct: ['96.2', '97.5', '85.0', '95.6', '89.6', '92.6', '99.2', '92.2', '98.3', '74.9', '96.5', '74.9', '95.5', '96.0', '95.5', '95.7', '84.4', '96.6', '85.7', '97.5', '89.5']\n",
            "IoU: ['94.7', '94.4', '45.0', '90.7', '72.6', '73.4', '96.7', '83.2', '91.4', '48.9', '92.0', '64.9', '88.7', '91.4', '90.5', '90.8', '67.8', '83.8', '63.4', '88.7', '76.9']\n",
            "mean IoU: 80.5\n",
            "Epoch: [9] Train  [  0/183]  eta: 0:39:51  lr: 0.000081  loss: 3.2486 (3.2486)  time: 13.0665  data: 0.3893  max mem: 9536\n",
            "Epoch: [9] Train  [ 10/183]  eta: 0:36:51  lr: 0.000081  loss: 3.2701 (3.2118)  time: 12.7821  data: 0.0358  max mem: 9536\n",
            "Epoch: [9] Train  [ 20/183]  eta: 0:34:25  lr: 0.000081  loss: 3.3134 (3.3181)  time: 12.6539  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Train  [ 30/183]  eta: 0:32:18  lr: 0.000081  loss: 3.0562 (3.2747)  time: 12.6078  data: 0.0005  max mem: 9536\n",
            "Epoch: [9] Train  [ 40/183]  eta: 0:30:05  lr: 0.000081  loss: 3.3091 (3.3051)  time: 12.5733  data: 0.0005  max mem: 9536\n",
            "Epoch: [9] Train  [ 50/183]  eta: 0:27:57  lr: 0.000081  loss: 3.4592 (3.3103)  time: 12.5217  data: 0.0005  max mem: 9536\n",
            "Epoch: [9] Train  [ 60/183]  eta: 0:25:50  lr: 0.000081  loss: 3.2217 (3.3062)  time: 12.5589  data: 0.0006  max mem: 9536\n",
            "Epoch: [9] Train  [ 70/183]  eta: 0:23:44  lr: 0.000080  loss: 3.1859 (3.2921)  time: 12.5823  data: 0.0005  max mem: 9536\n",
            "Epoch: [9] Train  [ 80/183]  eta: 0:21:38  lr: 0.000080  loss: 3.1894 (3.2887)  time: 12.6192  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Train  [ 90/183]  eta: 0:19:31  lr: 0.000080  loss: 3.0708 (3.2853)  time: 12.5715  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Train  [100/183]  eta: 0:17:25  lr: 0.000080  loss: 3.1676 (3.2813)  time: 12.5427  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Train  [110/183]  eta: 0:15:19  lr: 0.000080  loss: 3.3007 (3.2852)  time: 12.5723  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Train  [120/183]  eta: 0:13:13  lr: 0.000080  loss: 3.2157 (3.2886)  time: 12.6138  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Train  [130/183]  eta: 0:11:07  lr: 0.000080  loss: 3.3885 (3.2834)  time: 12.6088  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Train  [140/183]  eta: 0:09:01  lr: 0.000080  loss: 3.3486 (3.2745)  time: 12.5843  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Train  [150/183]  eta: 0:06:55  lr: 0.000079  loss: 3.3412 (3.2786)  time: 12.6217  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Train  [160/183]  eta: 0:04:49  lr: 0.000079  loss: 3.3408 (3.2743)  time: 12.6472  data: 0.0002  max mem: 9536\n",
            "Epoch: [9] Train  [170/183]  eta: 0:02:43  lr: 0.000079  loss: 3.1917 (3.2754)  time: 12.6365  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Train  [180/183]  eta: 0:00:37  lr: 0.000079  loss: 3.1204 (3.2723)  time: 12.6633  data: 0.0005  max mem: 9536\n",
            "Epoch: [9] Train Total time: 0:38:27\n",
            "Epoch: [9] Test  [  0/242]  eta: 0:06:00    time: 1.4899  data: 0.4235  max mem: 9536\n",
            "Epoch: [9] Test  [ 10/242]  eta: 0:04:12    time: 1.0870  data: 0.0388  max mem: 9536\n",
            "Epoch: [9] Test  [ 20/242]  eta: 0:03:51    time: 1.0187  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [ 30/242]  eta: 0:03:46    time: 1.0578  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [ 40/242]  eta: 0:03:38    time: 1.1232  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [ 50/242]  eta: 0:03:28    time: 1.1129  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [ 60/242]  eta: 0:03:20    time: 1.1419  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [ 70/242]  eta: 0:03:09    time: 1.1483  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [ 80/242]  eta: 0:02:58    time: 1.0965  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [ 90/242]  eta: 0:02:45    time: 1.0454  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [100/242]  eta: 0:02:35    time: 1.0680  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [110/242]  eta: 0:02:23    time: 1.0911  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [120/242]  eta: 0:02:13    time: 1.1079  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [130/242]  eta: 0:02:02    time: 1.0987  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Test  [140/242]  eta: 0:01:51    time: 1.0655  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Test  [150/242]  eta: 0:01:40    time: 1.0669  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [160/242]  eta: 0:01:29    time: 1.0836  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [170/242]  eta: 0:01:18    time: 1.1475  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [180/242]  eta: 0:01:08    time: 1.1915  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [190/242]  eta: 0:00:57    time: 1.1777  data: 0.0003  max mem: 9536\n",
            "Epoch: [9] Test  [200/242]  eta: 0:00:46    time: 1.1213  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Test  [210/242]  eta: 0:00:35    time: 1.0993  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Test  [220/242]  eta: 0:00:24    time: 1.1050  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Test  [230/242]  eta: 0:00:13    time: 1.1141  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Test  [240/242]  eta: 0:00:02    time: 1.0787  data: 0.0004  max mem: 9536\n",
            "Epoch: [9] Test Total time: 0:04:26\n",
            "global correct: 95.6\n",
            "average row correct: ['96.7', '96.8', '78.8', '95.6', '87.7', '91.0', '98.9', '94.0', '97.9', '68.3', '97.2', '75.1', '93.7', '95.1', '95.8', '96.0', '82.9', '94.3', '86.3', '96.3', '89.4']\n",
            "IoU: ['94.9', '94.2', '44.4', '90.1', '75.2', '74.2', '96.7', '83.4', '92.3', '50.7', '92.2', '64.3', '89.1', '90.5', '90.9', '90.8', '68.2', '89.8', '62.2', '88.8', '76.1']\n",
            "mean IoU: 80.9\n",
            "Epoch: [10] Train  [  0/183]  eta: 0:39:50  lr: 0.000079  loss: 3.0400 (3.0400)  time: 13.0616  data: 0.4473  max mem: 9536\n",
            "Epoch: [10] Train  [ 10/183]  eta: 0:36:28  lr: 0.000079  loss: 2.9676 (3.2580)  time: 12.6514  data: 0.0410  max mem: 9536\n",
            "Epoch: [10] Train  [ 20/183]  eta: 0:34:31  lr: 0.000079  loss: 3.0949 (3.2447)  time: 12.6897  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Train  [ 30/183]  eta: 0:32:20  lr: 0.000079  loss: 3.3783 (3.2160)  time: 12.7017  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Train  [ 40/183]  eta: 0:30:13  lr: 0.000078  loss: 3.9425 (3.2563)  time: 12.6483  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Train  [ 50/183]  eta: 0:28:10  lr: 0.000078  loss: 3.6281 (3.2453)  time: 12.7449  data: 0.0005  max mem: 9536\n",
            "Epoch: [10] Train  [ 60/183]  eta: 0:25:59  lr: 0.000078  loss: 3.1468 (3.2504)  time: 12.6902  data: 0.0006  max mem: 9536\n",
            "Epoch: [10] Train  [ 70/183]  eta: 0:23:49  lr: 0.000078  loss: 2.8525 (3.2260)  time: 12.4946  data: 0.0006  max mem: 9536\n",
            "Epoch: [10] Train  [ 80/183]  eta: 0:21:43  lr: 0.000078  loss: 3.1423 (3.2094)  time: 12.5552  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Train  [ 90/183]  eta: 0:19:36  lr: 0.000078  loss: 2.8606 (3.1972)  time: 12.6390  data: 0.0005  max mem: 9536\n",
            "Epoch: [10] Train  [100/183]  eta: 0:17:29  lr: 0.000078  loss: 3.1220 (3.2065)  time: 12.5948  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Train  [110/183]  eta: 0:15:22  lr: 0.000078  loss: 3.0371 (3.2078)  time: 12.6130  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Train  [120/183]  eta: 0:13:15  lr: 0.000077  loss: 3.7461 (3.2088)  time: 12.5881  data: 0.0006  max mem: 9536\n",
            "Epoch: [10] Train  [130/183]  eta: 0:11:09  lr: 0.000077  loss: 2.7453 (3.2004)  time: 12.6052  data: 0.0005  max mem: 9536\n",
            "Epoch: [10] Train  [140/183]  eta: 0:09:03  lr: 0.000077  loss: 2.9627 (3.1999)  time: 12.6246  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Train  [150/183]  eta: 0:06:56  lr: 0.000077  loss: 3.0319 (3.2000)  time: 12.5581  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Train  [160/183]  eta: 0:04:50  lr: 0.000077  loss: 2.9822 (3.1936)  time: 12.5110  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Train  [170/183]  eta: 0:02:43  lr: 0.000077  loss: 3.0361 (3.1904)  time: 12.5396  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Train  [180/183]  eta: 0:00:37  lr: 0.000077  loss: 3.1931 (3.1938)  time: 12.6236  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Train Total time: 0:38:29\n",
            "Epoch: [10] Test  [  0/242]  eta: 0:06:10    time: 1.5321  data: 0.4591  max mem: 9536\n",
            "Epoch: [10] Test  [ 10/242]  eta: 0:04:10    time: 1.0785  data: 0.0420  max mem: 9536\n",
            "Epoch: [10] Test  [ 20/242]  eta: 0:03:57    time: 1.0472  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [ 30/242]  eta: 0:03:50    time: 1.0927  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [ 40/242]  eta: 0:03:41    time: 1.1264  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [ 50/242]  eta: 0:03:31    time: 1.1233  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [ 60/242]  eta: 0:03:23    time: 1.1573  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [ 70/242]  eta: 0:03:12    time: 1.1716  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Test  [ 80/242]  eta: 0:03:00    time: 1.1130  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Test  [ 90/242]  eta: 0:02:48    time: 1.0640  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [100/242]  eta: 0:02:38    time: 1.1010  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [110/242]  eta: 0:02:26    time: 1.1087  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [120/242]  eta: 0:02:15    time: 1.1199  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [130/242]  eta: 0:02:04    time: 1.1126  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [140/242]  eta: 0:01:52    time: 1.0546  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [150/242]  eta: 0:01:41    time: 1.0629  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Test  [160/242]  eta: 0:01:30    time: 1.0889  data: 0.0004  max mem: 9536\n",
            "Epoch: [10] Test  [170/242]  eta: 0:01:19    time: 1.1461  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [180/242]  eta: 0:01:09    time: 1.1993  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [190/242]  eta: 0:00:58    time: 1.1881  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [200/242]  eta: 0:00:46    time: 1.1404  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [210/242]  eta: 0:00:35    time: 1.1205  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [220/242]  eta: 0:00:24    time: 1.1224  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [230/242]  eta: 0:00:13    time: 1.1226  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test  [240/242]  eta: 0:00:02    time: 1.0831  data: 0.0003  max mem: 9536\n",
            "Epoch: [10] Test Total time: 0:04:29\n",
            "global correct: 95.7\n",
            "average row correct: ['96.9', '96.8', '80.4', '95.8', '87.8', '90.9', '98.7', '92.8', '98.6', '64.2', '95.7', '70.9', '93.1', '95.6', '95.9', '96.0', '82.5', '95.1', '85.5', '96.0', '90.6']\n",
            "IoU: ['95.0', '93.4', '46.0', '90.1', '76.7', '74.6', '96.6', '83.3', '90.3', '51.9', '92.6', '63.6', '88.2', '91.0', '90.4', '90.4', '67.0', '89.9', '62.4', '89.7', '74.0']\n",
            "mean IoU: 80.8\n",
            "Epoch: [11] Train  [  0/183]  eta: 0:39:19  lr: 0.000077  loss: 3.0309 (3.0309)  time: 12.8911  data: 0.4700  max mem: 9536\n",
            "Epoch: [11] Train  [ 10/183]  eta: 0:36:30  lr: 0.000076  loss: 2.9192 (3.1166)  time: 12.6639  data: 0.0432  max mem: 9536\n",
            "Epoch: [11] Train  [ 20/183]  eta: 0:34:20  lr: 0.000076  loss: 2.9888 (3.1506)  time: 12.6278  data: 0.0005  max mem: 9536\n",
            "Epoch: [11] Train  [ 30/183]  eta: 0:32:14  lr: 0.000076  loss: 3.3582 (3.1606)  time: 12.6356  data: 0.0004  max mem: 9536\n",
            "Epoch: [11] Train  [ 40/183]  eta: 0:30:04  lr: 0.000076  loss: 3.3765 (3.1822)  time: 12.5954  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [ 50/183]  eta: 0:28:02  lr: 0.000076  loss: 2.9294 (3.1666)  time: 12.6671  data: 0.0002  max mem: 9536\n",
            "Epoch: [11] Train  [ 60/183]  eta: 0:25:53  lr: 0.000076  loss: 3.0995 (3.1564)  time: 12.6561  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [ 70/183]  eta: 0:23:46  lr: 0.000076  loss: 3.0608 (3.1565)  time: 12.5467  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [ 80/183]  eta: 0:21:41  lr: 0.000076  loss: 3.0161 (3.1435)  time: 12.6407  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [ 90/183]  eta: 0:19:35  lr: 0.000075  loss: 3.7280 (3.1494)  time: 12.6790  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [100/183]  eta: 0:17:28  lr: 0.000075  loss: 3.1226 (3.1557)  time: 12.6418  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [110/183]  eta: 0:15:21  lr: 0.000075  loss: 3.1984 (3.1541)  time: 12.5930  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [120/183]  eta: 0:13:16  lr: 0.000075  loss: 3.0756 (3.1519)  time: 12.6794  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [130/183]  eta: 0:11:10  lr: 0.000075  loss: 2.7926 (3.1398)  time: 12.8015  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [140/183]  eta: 0:09:04  lr: 0.000075  loss: 2.9872 (3.1336)  time: 12.7322  data: 0.0006  max mem: 9536\n",
            "Epoch: [11] Train  [150/183]  eta: 0:06:57  lr: 0.000075  loss: 3.0945 (3.1336)  time: 12.6772  data: 0.0006  max mem: 9536\n",
            "Epoch: [11] Train  [160/183]  eta: 0:04:51  lr: 0.000075  loss: 3.0987 (3.1304)  time: 12.6916  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [170/183]  eta: 0:02:44  lr: 0.000074  loss: 3.0049 (3.1254)  time: 12.6657  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train  [180/183]  eta: 0:00:37  lr: 0.000074  loss: 3.2743 (3.1254)  time: 12.6474  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Train Total time: 0:38:36\n",
            "Epoch: [11] Test  [  0/242]  eta: 0:05:56    time: 1.4712  data: 0.4016  max mem: 9536\n",
            "Epoch: [11] Test  [ 10/242]  eta: 0:04:07    time: 1.0648  data: 0.0368  max mem: 9536\n",
            "Epoch: [11] Test  [ 20/242]  eta: 0:03:52    time: 1.0245  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [ 30/242]  eta: 0:03:47    time: 1.0798  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [ 40/242]  eta: 0:03:39    time: 1.1273  data: 0.0002  max mem: 9536\n",
            "Epoch: [11] Test  [ 50/242]  eta: 0:03:29    time: 1.1212  data: 0.0002  max mem: 9536\n",
            "Epoch: [11] Test  [ 60/242]  eta: 0:03:21    time: 1.1471  data: 0.0002  max mem: 9536\n",
            "Epoch: [11] Test  [ 70/242]  eta: 0:03:11    time: 1.1596  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [ 80/242]  eta: 0:02:59    time: 1.1189  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [ 90/242]  eta: 0:02:47    time: 1.0642  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [100/242]  eta: 0:02:36    time: 1.0843  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [110/242]  eta: 0:02:25    time: 1.1128  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [120/242]  eta: 0:02:15    time: 1.1379  data: 0.0002  max mem: 9536\n",
            "Epoch: [11] Test  [130/242]  eta: 0:02:04    time: 1.1785  data: 0.0002  max mem: 9536\n",
            "Epoch: [11] Test  [140/242]  eta: 0:01:53    time: 1.1448  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [150/242]  eta: 0:01:42    time: 1.0960  data: 0.0002  max mem: 9536\n",
            "Epoch: [11] Test  [160/242]  eta: 0:01:31    time: 1.0891  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [170/242]  eta: 0:01:20    time: 1.1344  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [180/242]  eta: 0:01:09    time: 1.2124  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [190/242]  eta: 0:00:58    time: 1.2274  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [200/242]  eta: 0:00:47    time: 1.1678  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [210/242]  eta: 0:00:36    time: 1.1443  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [220/242]  eta: 0:00:24    time: 1.1482  data: 0.0002  max mem: 9536\n",
            "Epoch: [11] Test  [230/242]  eta: 0:00:13    time: 1.1395  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test  [240/242]  eta: 0:00:02    time: 1.0852  data: 0.0003  max mem: 9536\n",
            "Epoch: [11] Test Total time: 0:04:32\n",
            "global correct: 95.7\n",
            "average row correct: ['96.7', '97.1', '85.8', '96.1', '88.4', '90.9', '98.7', '93.3', '98.2', '69.9', '96.3', '74.8', '96.6', '94.5', '95.1', '95.8', '83.2', '96.4', '85.2', '96.3', '89.1']\n",
            "IoU: ['95.0', '94.9', '46.9', '90.7', '75.2', '73.6', '96.2', '83.6', '92.5', '52.4', '90.9', '66.0', '89.4', '90.2', '89.8', '90.7', '66.5', '86.1', '64.9', '89.9', '75.8']\n",
            "mean IoU: 81.0\n",
            "Epoch: [12] Train  [  0/183]  eta: 0:39:32  lr: 0.000074  loss: 2.8238 (2.8238)  time: 12.9650  data: 0.3836  max mem: 9536\n",
            "Epoch: [12] Train  [ 10/183]  eta: 0:36:45  lr: 0.000074  loss: 2.9022 (2.9786)  time: 12.7505  data: 0.0352  max mem: 9536\n",
            "Epoch: [12] Train  [ 20/183]  eta: 0:34:27  lr: 0.000074  loss: 3.1175 (3.0666)  time: 12.6708  data: 0.0006  max mem: 9536\n",
            "Epoch: [12] Train  [ 30/183]  eta: 0:32:15  lr: 0.000074  loss: 3.2097 (3.0497)  time: 12.5941  data: 0.0006  max mem: 9536\n",
            "Epoch: [12] Train  [ 40/183]  eta: 0:30:05  lr: 0.000074  loss: 2.8579 (3.0475)  time: 12.5608  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train  [ 50/183]  eta: 0:27:59  lr: 0.000074  loss: 2.7892 (3.0397)  time: 12.5942  data: 0.0002  max mem: 9536\n",
            "Epoch: [12] Train  [ 60/183]  eta: 0:25:52  lr: 0.000073  loss: 3.1821 (3.0574)  time: 12.6059  data: 0.0002  max mem: 9536\n",
            "Epoch: [12] Train  [ 70/183]  eta: 0:23:45  lr: 0.000073  loss: 3.1212 (3.0457)  time: 12.5863  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train  [ 80/183]  eta: 0:21:38  lr: 0.000073  loss: 3.2146 (3.0603)  time: 12.5822  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train  [ 90/183]  eta: 0:19:32  lr: 0.000073  loss: 2.9099 (3.0546)  time: 12.5554  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train  [100/183]  eta: 0:17:27  lr: 0.000073  loss: 2.9777 (3.0777)  time: 12.6724  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train  [110/183]  eta: 0:15:21  lr: 0.000073  loss: 3.2079 (3.0733)  time: 12.6853  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train  [120/183]  eta: 0:13:15  lr: 0.000073  loss: 3.2664 (3.0725)  time: 12.6716  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train  [130/183]  eta: 0:11:09  lr: 0.000073  loss: 2.9315 (3.0734)  time: 12.6619  data: 0.0004  max mem: 9536\n",
            "Epoch: [12] Train  [140/183]  eta: 0:09:03  lr: 0.000072  loss: 3.0689 (3.0670)  time: 12.6264  data: 0.0004  max mem: 9536\n",
            "Epoch: [12] Train  [150/183]  eta: 0:06:56  lr: 0.000072  loss: 2.9851 (3.0545)  time: 12.6958  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train  [160/183]  eta: 0:04:50  lr: 0.000072  loss: 2.8617 (3.0541)  time: 12.7226  data: 0.0004  max mem: 9536\n",
            "Epoch: [12] Train  [170/183]  eta: 0:02:44  lr: 0.000072  loss: 2.8647 (3.0547)  time: 12.6290  data: 0.0004  max mem: 9536\n",
            "Epoch: [12] Train  [180/183]  eta: 0:00:37  lr: 0.000072  loss: 3.3193 (3.0589)  time: 12.5830  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Train Total time: 0:38:31\n",
            "Epoch: [12] Test  [  0/242]  eta: 0:05:53    time: 1.4623  data: 0.3876  max mem: 9536\n",
            "Epoch: [12] Test  [ 10/242]  eta: 0:04:04    time: 1.0535  data: 0.0356  max mem: 9536\n",
            "Epoch: [12] Test  [ 20/242]  eta: 0:03:48    time: 1.0072  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [ 30/242]  eta: 0:03:44    time: 1.0583  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [ 40/242]  eta: 0:03:36    time: 1.1174  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [ 50/242]  eta: 0:03:26    time: 1.1101  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [ 60/242]  eta: 0:03:19    time: 1.1382  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [ 70/242]  eta: 0:03:08    time: 1.1487  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [ 80/242]  eta: 0:02:57    time: 1.0901  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [ 90/242]  eta: 0:02:44    time: 1.0362  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [100/242]  eta: 0:02:34    time: 1.0757  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [110/242]  eta: 0:02:23    time: 1.0963  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [120/242]  eta: 0:02:13    time: 1.1091  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [130/242]  eta: 0:02:01    time: 1.1012  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [140/242]  eta: 0:01:50    time: 1.0516  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [150/242]  eta: 0:01:39    time: 1.0547  data: 0.0002  max mem: 9536\n",
            "Epoch: [12] Test  [160/242]  eta: 0:01:28    time: 1.0643  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [170/242]  eta: 0:01:18    time: 1.1087  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [180/242]  eta: 0:01:07    time: 1.1623  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [190/242]  eta: 0:00:56    time: 1.1655  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [200/242]  eta: 0:00:45    time: 1.1126  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [210/242]  eta: 0:00:35    time: 1.0884  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [220/242]  eta: 0:00:24    time: 1.1149  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [230/242]  eta: 0:00:13    time: 1.1322  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test  [240/242]  eta: 0:00:02    time: 1.0823  data: 0.0003  max mem: 9536\n",
            "Epoch: [12] Test Total time: 0:04:24\n",
            "global correct: 95.6\n",
            "average row correct: ['96.7', '97.0', '81.9', '96.5', '89.3', '92.2', '99.1', '91.9', '98.5', '75.1', '95.9', '71.2', '93.2', '95.7', '95.3', '96.0', '82.0', '96.4', '83.0', '97.3', '92.4']\n",
            "IoU: ['94.9', '94.7', '47.9', '90.2', '75.9', '74.2', '96.5', '83.7', '90.8', '52.4', '92.0', '64.0', '88.4', '90.9', '90.0', '90.8', '67.6', '87.5', '63.5', '89.3', '73.6']\n",
            "mean IoU: 80.9\n",
            "Epoch: [13] Train  [  0/183]  eta: 0:41:50  lr: 0.000072  loss: 3.5169 (3.5169)  time: 13.7164  data: 0.4275  max mem: 9536\n",
            "Epoch: [13] Train  [ 10/183]  eta: 0:36:52  lr: 0.000072  loss: 2.9803 (3.0622)  time: 12.7875  data: 0.0391  max mem: 9536\n",
            "Epoch: [13] Train  [ 20/183]  eta: 0:34:30  lr: 0.000072  loss: 3.1594 (3.0489)  time: 12.6515  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Train  [ 30/183]  eta: 0:32:23  lr: 0.000071  loss: 2.9860 (3.0660)  time: 12.6556  data: 0.0004  max mem: 9536\n",
            "Epoch: [13] Train  [ 40/183]  eta: 0:30:12  lr: 0.000071  loss: 3.0581 (3.0486)  time: 12.6413  data: 0.0005  max mem: 9536\n",
            "Epoch: [13] Train  [ 50/183]  eta: 0:28:05  lr: 0.000071  loss: 2.7447 (3.0415)  time: 12.6278  data: 0.0004  max mem: 9536\n",
            "Epoch: [13] Train  [ 60/183]  eta: 0:26:00  lr: 0.000071  loss: 3.2522 (3.0384)  time: 12.7066  data: 0.0004  max mem: 9536\n",
            "Epoch: [13] Train  [ 70/183]  eta: 0:23:54  lr: 0.000071  loss: 3.0570 (3.0185)  time: 12.7586  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Train  [ 80/183]  eta: 0:21:47  lr: 0.000071  loss: 2.7556 (3.0155)  time: 12.7317  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Train  [ 90/183]  eta: 0:19:40  lr: 0.000071  loss: 2.9608 (3.0167)  time: 12.6636  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Train  [100/183]  eta: 0:17:33  lr: 0.000071  loss: 3.0203 (3.0137)  time: 12.6541  data: 0.0004  max mem: 9536\n",
            "Epoch: [13] Train  [110/183]  eta: 0:15:25  lr: 0.000070  loss: 2.9861 (3.0085)  time: 12.6098  data: 0.0004  max mem: 9536\n",
            "Epoch: [13] Train  [120/183]  eta: 0:13:19  lr: 0.000070  loss: 3.1312 (3.0040)  time: 12.6751  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Train  [130/183]  eta: 0:11:11  lr: 0.000070  loss: 4.2109 (3.0237)  time: 12.6956  data: 0.0002  max mem: 9536\n",
            "Epoch: [13] Train  [140/183]  eta: 0:09:04  lr: 0.000070  loss: 3.0143 (3.0230)  time: 12.6024  data: 0.0002  max mem: 9536\n",
            "Epoch: [13] Train  [150/183]  eta: 0:06:58  lr: 0.000070  loss: 3.0763 (3.0211)  time: 12.6860  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Train  [160/183]  eta: 0:04:51  lr: 0.000070  loss: 3.1411 (3.0176)  time: 12.6325  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Train  [170/183]  eta: 0:02:44  lr: 0.000070  loss: 2.9185 (3.0139)  time: 12.5466  data: 0.0004  max mem: 9536\n",
            "Epoch: [13] Train  [180/183]  eta: 0:00:37  lr: 0.000069  loss: 2.6060 (3.0148)  time: 12.6153  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Train Total time: 0:38:37\n",
            "Epoch: [13] Test  [  0/242]  eta: 0:05:48    time: 1.4419  data: 0.3666  max mem: 9536\n",
            "Epoch: [13] Test  [ 10/242]  eta: 0:04:16    time: 1.1039  data: 0.0336  max mem: 9536\n",
            "Epoch: [13] Test  [ 20/242]  eta: 0:03:54    time: 1.0360  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [ 30/242]  eta: 0:03:47    time: 1.0596  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [ 40/242]  eta: 0:03:39    time: 1.1220  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [ 50/242]  eta: 0:03:29    time: 1.1208  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [ 60/242]  eta: 0:03:23    time: 1.1747  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [ 70/242]  eta: 0:03:12    time: 1.1901  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [ 80/242]  eta: 0:03:01    time: 1.1279  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [ 90/242]  eta: 0:02:48    time: 1.0806  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [100/242]  eta: 0:02:38    time: 1.1014  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [110/242]  eta: 0:02:26    time: 1.1139  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [120/242]  eta: 0:02:16    time: 1.1284  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [130/242]  eta: 0:02:04    time: 1.1307  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [140/242]  eta: 0:01:53    time: 1.0809  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [150/242]  eta: 0:01:42    time: 1.0818  data: 0.0004  max mem: 9536\n",
            "Epoch: [13] Test  [160/242]  eta: 0:01:31    time: 1.0937  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [170/242]  eta: 0:01:20    time: 1.1521  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [180/242]  eta: 0:01:09    time: 1.2084  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [190/242]  eta: 0:00:58    time: 1.1949  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [200/242]  eta: 0:00:47    time: 1.1509  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [210/242]  eta: 0:00:35    time: 1.1236  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [220/242]  eta: 0:00:24    time: 1.1252  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [230/242]  eta: 0:00:13    time: 1.1340  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test  [240/242]  eta: 0:00:02    time: 1.0891  data: 0.0003  max mem: 9536\n",
            "Epoch: [13] Test Total time: 0:04:31\n",
            "global correct: 95.8\n",
            "average row correct: ['96.9', '96.8', '80.7', '96.4', '86.6', '92.2', '98.8', '94.4', '98.3', '72.5', '94.8', '73.2', '94.8', '96.4', '95.7', '96.1', '80.3', '96.1', '81.7', '96.5', '87.8']\n",
            "IoU: ['95.1', '94.7', '48.5', '90.3', '76.0', '73.2', '95.6', '84.0', '92.5', '52.7', '91.8', '64.4', '89.0', '90.2', '90.4', '90.3', '67.1', '87.5', '63.6', '90.3', '80.1']\n",
            "mean IoU: 81.3\n",
            "Epoch: [14] Train  [  0/183]  eta: 0:38:59  lr: 0.000069  loss: 2.8297 (2.8297)  time: 12.7835  data: 0.4306  max mem: 9536\n",
            "Epoch: [14] Train  [ 10/183]  eta: 0:36:24  lr: 0.000069  loss: 3.1471 (3.0314)  time: 12.6252  data: 0.0395  max mem: 9536\n",
            "Epoch: [14] Train  [ 20/183]  eta: 0:34:36  lr: 0.000069  loss: 3.1387 (3.0103)  time: 12.7365  data: 0.0004  max mem: 9536\n",
            "Epoch: [14] Train  [ 30/183]  eta: 0:32:23  lr: 0.000069  loss: 2.8630 (3.0305)  time: 12.7463  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train  [ 40/183]  eta: 0:30:17  lr: 0.000069  loss: 3.1025 (3.0286)  time: 12.6849  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train  [ 50/183]  eta: 0:28:09  lr: 0.000069  loss: 3.0600 (2.9913)  time: 12.7112  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train  [ 60/183]  eta: 0:25:58  lr: 0.000069  loss: 2.7435 (2.9716)  time: 12.5875  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train  [ 70/183]  eta: 0:23:54  lr: 0.000068  loss: 2.8623 (2.9698)  time: 12.6539  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train  [ 80/183]  eta: 0:21:46  lr: 0.000068  loss: 3.1357 (2.9748)  time: 12.7134  data: 0.0002  max mem: 9536\n",
            "Epoch: [14] Train  [ 90/183]  eta: 0:19:39  lr: 0.000068  loss: 3.1407 (2.9662)  time: 12.6661  data: 0.0004  max mem: 9536\n",
            "Epoch: [14] Train  [100/183]  eta: 0:17:31  lr: 0.000068  loss: 2.8016 (2.9600)  time: 12.5935  data: 0.0005  max mem: 9536\n",
            "Epoch: [14] Train  [110/183]  eta: 0:15:23  lr: 0.000068  loss: 2.7320 (2.9553)  time: 12.4569  data: 0.0004  max mem: 9536\n",
            "Epoch: [14] Train  [120/183]  eta: 0:13:15  lr: 0.000068  loss: 2.9131 (2.9654)  time: 12.4844  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train  [130/183]  eta: 0:11:09  lr: 0.000068  loss: 2.8611 (2.9615)  time: 12.6063  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train  [140/183]  eta: 0:09:03  lr: 0.000068  loss: 3.0491 (2.9660)  time: 12.6271  data: 0.0004  max mem: 9536\n",
            "Epoch: [14] Train  [150/183]  eta: 0:06:57  lr: 0.000067  loss: 2.8278 (2.9699)  time: 12.6337  data: 0.0005  max mem: 9536\n",
            "Epoch: [14] Train  [160/183]  eta: 0:04:50  lr: 0.000067  loss: 2.8239 (2.9792)  time: 12.7263  data: 0.0004  max mem: 9536\n",
            "Epoch: [14] Train  [170/183]  eta: 0:02:44  lr: 0.000067  loss: 2.7288 (2.9755)  time: 12.7147  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train  [180/183]  eta: 0:00:37  lr: 0.000067  loss: 3.2781 (2.9738)  time: 12.6533  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Train Total time: 0:38:33\n",
            "Epoch: [14] Test  [  0/242]  eta: 0:05:47    time: 1.4375  data: 0.3578  max mem: 9536\n",
            "Epoch: [14] Test  [ 10/242]  eta: 0:04:05    time: 1.0572  data: 0.0328  max mem: 9536\n",
            "Epoch: [14] Test  [ 20/242]  eta: 0:03:50    time: 1.0190  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [ 30/242]  eta: 0:03:47    time: 1.0807  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [ 40/242]  eta: 0:03:38    time: 1.1283  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [ 50/242]  eta: 0:03:30    time: 1.1297  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [ 60/242]  eta: 0:03:21    time: 1.1632  data: 0.0002  max mem: 9536\n",
            "Epoch: [14] Test  [ 70/242]  eta: 0:03:11    time: 1.1671  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [ 80/242]  eta: 0:03:00    time: 1.1200  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [ 90/242]  eta: 0:02:47    time: 1.0565  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [100/242]  eta: 0:02:36    time: 1.0785  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [110/242]  eta: 0:02:25    time: 1.0938  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [120/242]  eta: 0:02:15    time: 1.1144  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [130/242]  eta: 0:02:03    time: 1.1074  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [140/242]  eta: 0:01:52    time: 1.0549  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [150/242]  eta: 0:01:40    time: 1.0566  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [160/242]  eta: 0:01:29    time: 1.0852  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [170/242]  eta: 0:01:19    time: 1.1374  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [180/242]  eta: 0:01:08    time: 1.1760  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [190/242]  eta: 0:00:57    time: 1.1794  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [200/242]  eta: 0:00:46    time: 1.1236  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [210/242]  eta: 0:00:35    time: 1.0931  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [220/242]  eta: 0:00:24    time: 1.1050  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [230/242]  eta: 0:00:13    time: 1.1180  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test  [240/242]  eta: 0:00:02    time: 1.0989  data: 0.0003  max mem: 9536\n",
            "Epoch: [14] Test Total time: 0:04:27\n",
            "global correct: 95.8\n",
            "average row correct: ['96.8', '96.9', '80.4', '95.0', '87.1', '88.4', '98.6', '93.5', '97.6', '72.0', '96.1', '78.5', '96.2', '96.1', '95.5', '96.5', '79.3', '96.3', '84.6', '95.8', '89.3']\n",
            "IoU: ['95.1', '94.2', '50.3', '90.8', '75.4', '76.9', '95.4', '84.1', '93.0', '51.9', '92.1', '66.6', '89.6', '90.0', '90.3', '90.7', '68.3', '86.0', '63.8', '89.9', '76.2']\n",
            "mean IoU: 81.5\n",
            "Epoch: [15] Train  [  0/183]  eta: 0:39:24  lr: 0.000067  loss: 3.0366 (3.0366)  time: 12.9199  data: 0.3978  max mem: 9536\n",
            "Epoch: [15] Train  [ 10/183]  eta: 0:36:30  lr: 0.000067  loss: 2.7369 (2.8925)  time: 12.6627  data: 0.0364  max mem: 9536\n",
            "Epoch: [15] Train  [ 20/183]  eta: 0:34:22  lr: 0.000067  loss: 3.0017 (2.9309)  time: 12.6385  data: 0.0005  max mem: 9536\n",
            "Epoch: [15] Train  [ 30/183]  eta: 0:32:10  lr: 0.000067  loss: 2.5523 (2.9755)  time: 12.5958  data: 0.0005  max mem: 9536\n",
            "Epoch: [15] Train  [ 40/183]  eta: 0:30:04  lr: 0.000066  loss: 3.1153 (2.9716)  time: 12.5828  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [ 50/183]  eta: 0:27:56  lr: 0.000066  loss: 2.8638 (2.9641)  time: 12.5749  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [ 60/183]  eta: 0:25:47  lr: 0.000066  loss: 2.6775 (2.9631)  time: 12.5142  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [ 70/183]  eta: 0:23:40  lr: 0.000066  loss: 2.9932 (2.9629)  time: 12.4960  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [ 80/183]  eta: 0:21:35  lr: 0.000066  loss: 2.5562 (2.9468)  time: 12.5392  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [ 90/183]  eta: 0:19:28  lr: 0.000066  loss: 3.4236 (2.9624)  time: 12.5361  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [100/183]  eta: 0:17:23  lr: 0.000066  loss: 2.8966 (2.9585)  time: 12.5707  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [110/183]  eta: 0:15:18  lr: 0.000066  loss: 2.7140 (2.9603)  time: 12.7008  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [120/183]  eta: 0:13:13  lr: 0.000065  loss: 2.5446 (2.9348)  time: 12.7372  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [130/183]  eta: 0:11:08  lr: 0.000065  loss: 2.6250 (2.9364)  time: 12.7000  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [140/183]  eta: 0:09:01  lr: 0.000065  loss: 2.7120 (2.9371)  time: 12.5267  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [150/183]  eta: 0:06:55  lr: 0.000065  loss: 2.7306 (2.9402)  time: 12.5641  data: 0.0005  max mem: 9536\n",
            "Epoch: [15] Train  [160/183]  eta: 0:04:50  lr: 0.000065  loss: 3.2202 (2.9425)  time: 12.7607  data: 0.0005  max mem: 9536\n",
            "Epoch: [15] Train  [170/183]  eta: 0:02:43  lr: 0.000065  loss: 3.1060 (2.9450)  time: 12.6429  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train  [180/183]  eta: 0:00:37  lr: 0.000065  loss: 3.0989 (2.9466)  time: 12.5361  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Train Total time: 0:38:26\n",
            "Epoch: [15] Test  [  0/242]  eta: 0:05:58    time: 1.4800  data: 0.4164  max mem: 9536\n",
            "Epoch: [15] Test  [ 10/242]  eta: 0:04:10    time: 1.0787  data: 0.0382  max mem: 9536\n",
            "Epoch: [15] Test  [ 20/242]  eta: 0:03:56    time: 1.0456  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [ 30/242]  eta: 0:03:50    time: 1.0922  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [ 40/242]  eta: 0:03:42    time: 1.1357  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [ 50/242]  eta: 0:03:33    time: 1.1440  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [ 60/242]  eta: 0:03:24    time: 1.1689  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [ 70/242]  eta: 0:03:16    time: 1.2254  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [ 80/242]  eta: 0:03:03    time: 1.1679  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [ 90/242]  eta: 0:02:50    time: 1.0469  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [100/242]  eta: 0:02:39    time: 1.0971  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [110/242]  eta: 0:02:27    time: 1.1177  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [120/242]  eta: 0:02:17    time: 1.1078  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [130/242]  eta: 0:02:05    time: 1.1119  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [140/242]  eta: 0:01:54    time: 1.0938  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [150/242]  eta: 0:01:42    time: 1.1013  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [160/242]  eta: 0:01:31    time: 1.0924  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [170/242]  eta: 0:01:20    time: 1.1229  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [180/242]  eta: 0:01:09    time: 1.1844  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [190/242]  eta: 0:00:58    time: 1.1977  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [200/242]  eta: 0:00:47    time: 1.1404  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [210/242]  eta: 0:00:35    time: 1.1065  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [220/242]  eta: 0:00:24    time: 1.1265  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [230/242]  eta: 0:00:13    time: 1.1296  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test  [240/242]  eta: 0:00:02    time: 1.0778  data: 0.0003  max mem: 9536\n",
            "Epoch: [15] Test Total time: 0:04:31\n",
            "global correct: 95.7\n",
            "average row correct: ['96.8', '97.4', '77.0', '95.9', '90.0', '90.7', '99.1', '91.0', '98.1', '68.0', '97.8', '73.1', '95.9', '95.1', '94.4', '96.4', '79.7', '96.6', '84.5', '96.8', '91.9']\n",
            "IoU: ['95.0', '92.2', '50.5', '90.8', '76.0', '74.5', '96.1', '84.4', '92.7', '52.1', '91.5', '64.4', '89.1', '89.0', '90.0', '90.8', '67.6', '86.5', '62.6', '89.2', '72.7']\n",
            "mean IoU: 80.8\n",
            "Epoch: [16] Train  [  0/183]  eta: 0:40:13  lr: 0.000065  loss: 2.7241 (2.7241)  time: 13.1886  data: 0.3689  max mem: 9536\n",
            "Epoch: [16] Train  [ 10/183]  eta: 0:36:21  lr: 0.000064  loss: 2.9535 (2.8052)  time: 12.6095  data: 0.0338  max mem: 9536\n",
            "Epoch: [16] Train  [ 20/183]  eta: 0:34:15  lr: 0.000064  loss: 2.9649 (2.8433)  time: 12.5810  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [ 30/183]  eta: 0:32:05  lr: 0.000064  loss: 2.7627 (2.8232)  time: 12.5753  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [ 40/183]  eta: 0:29:54  lr: 0.000064  loss: 3.2897 (2.8415)  time: 12.4894  data: 0.0002  max mem: 9536\n",
            "Epoch: [16] Train  [ 50/183]  eta: 0:27:52  lr: 0.000064  loss: 3.3495 (2.8686)  time: 12.5632  data: 0.0002  max mem: 9536\n",
            "Epoch: [16] Train  [ 60/183]  eta: 0:25:48  lr: 0.000064  loss: 2.9184 (2.8686)  time: 12.6643  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [ 70/183]  eta: 0:23:43  lr: 0.000064  loss: 3.1182 (2.8771)  time: 12.6355  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [ 80/183]  eta: 0:21:37  lr: 0.000064  loss: 2.6161 (2.8782)  time: 12.6116  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [ 90/183]  eta: 0:19:30  lr: 0.000063  loss: 2.8582 (2.8760)  time: 12.5704  data: 0.0002  max mem: 9536\n",
            "Epoch: [16] Train  [100/183]  eta: 0:17:24  lr: 0.000063  loss: 3.0836 (2.8852)  time: 12.5469  data: 0.0004  max mem: 9536\n",
            "Epoch: [16] Train  [110/183]  eta: 0:15:19  lr: 0.000063  loss: 3.2340 (2.8813)  time: 12.5899  data: 0.0005  max mem: 9536\n",
            "Epoch: [16] Train  [120/183]  eta: 0:13:13  lr: 0.000063  loss: 2.7204 (2.8833)  time: 12.6113  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [130/183]  eta: 0:11:07  lr: 0.000063  loss: 2.9867 (2.8946)  time: 12.5810  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [140/183]  eta: 0:09:01  lr: 0.000063  loss: 3.2282 (2.8994)  time: 12.6525  data: 0.0002  max mem: 9536\n",
            "Epoch: [16] Train  [150/183]  eta: 0:06:56  lr: 0.000063  loss: 3.0382 (2.9013)  time: 12.7337  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [160/183]  eta: 0:04:50  lr: 0.000062  loss: 2.9579 (2.8991)  time: 12.6969  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [170/183]  eta: 0:02:43  lr: 0.000062  loss: 2.7476 (2.8985)  time: 12.6014  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train  [180/183]  eta: 0:00:37  lr: 0.000062  loss: 2.7504 (2.9041)  time: 12.5149  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Train Total time: 0:38:25\n",
            "Epoch: [16] Test  [  0/242]  eta: 0:06:01    time: 1.4943  data: 0.4220  max mem: 9536\n",
            "Epoch: [16] Test  [ 10/242]  eta: 0:04:04    time: 1.0554  data: 0.0389  max mem: 9536\n",
            "Epoch: [16] Test  [ 20/242]  eta: 0:03:47    time: 1.0022  data: 0.0004  max mem: 9536\n",
            "Epoch: [16] Test  [ 30/242]  eta: 0:03:44    time: 1.0631  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [ 40/242]  eta: 0:03:37    time: 1.1268  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [ 50/242]  eta: 0:03:28    time: 1.1190  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [ 60/242]  eta: 0:03:21    time: 1.1744  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [ 70/242]  eta: 0:03:11    time: 1.1971  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [ 80/242]  eta: 0:03:00    time: 1.1251  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [ 90/242]  eta: 0:02:47    time: 1.0559  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [100/242]  eta: 0:02:37    time: 1.0845  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [110/242]  eta: 0:02:26    time: 1.1378  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [120/242]  eta: 0:02:15    time: 1.1516  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [130/242]  eta: 0:02:04    time: 1.1055  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [140/242]  eta: 0:01:52    time: 1.0495  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [150/242]  eta: 0:01:41    time: 1.0655  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [160/242]  eta: 0:01:30    time: 1.0831  data: 0.0004  max mem: 9536\n",
            "Epoch: [16] Test  [170/242]  eta: 0:01:19    time: 1.1228  data: 0.0004  max mem: 9536\n",
            "Epoch: [16] Test  [180/242]  eta: 0:01:08    time: 1.1909  data: 0.0006  max mem: 9536\n",
            "Epoch: [16] Test  [190/242]  eta: 0:00:57    time: 1.2022  data: 0.0006  max mem: 9536\n",
            "Epoch: [16] Test  [200/242]  eta: 0:00:46    time: 1.1415  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [210/242]  eta: 0:00:35    time: 1.1191  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [220/242]  eta: 0:00:24    time: 1.1316  data: 0.0003  max mem: 9536\n",
            "Epoch: [16] Test  [230/242]  eta: 0:00:13    time: 1.1282  data: 0.0005  max mem: 9536\n",
            "Epoch: [16] Test  [240/242]  eta: 0:00:02    time: 1.0965  data: 0.0005  max mem: 9536\n",
            "Epoch: [16] Test Total time: 0:04:29\n",
            "global correct: 95.8\n",
            "average row correct: ['96.8', '97.8', '81.9', '95.2', '88.8', '91.3', '99.1', '92.7', '98.3', '72.6', '96.0', '74.4', '95.0', '96.6', '95.7', '96.0', '81.2', '96.2', '82.7', '96.5', '90.8']\n",
            "IoU: ['95.1', '92.7', '52.0', '90.3', '76.9', '73.4', '95.8', '84.8', '92.8', '50.5', '92.5', '66.2', '89.6', '90.1', '90.7', '90.8', '67.9', '87.2', '62.4', '89.6', '76.0']\n",
            "mean IoU: 81.3\n",
            "Epoch: [17] Train  [  0/183]  eta: 0:42:52  lr: 0.000062  loss: 2.6894 (2.6894)  time: 14.0548  data: 0.4756  max mem: 9536\n",
            "Epoch: [17] Train  [ 10/183]  eta: 0:36:53  lr: 0.000062  loss: 2.9615 (2.8521)  time: 12.7935  data: 0.0435  max mem: 9536\n",
            "Epoch: [17] Train  [ 20/183]  eta: 0:34:31  lr: 0.000062  loss: 2.7724 (2.9196)  time: 12.6383  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [ 30/183]  eta: 0:32:12  lr: 0.000062  loss: 3.2215 (2.9003)  time: 12.5389  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [ 40/183]  eta: 0:30:07  lr: 0.000062  loss: 2.7738 (2.8683)  time: 12.5701  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [ 50/183]  eta: 0:27:59  lr: 0.000061  loss: 2.8651 (2.8684)  time: 12.6242  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [ 60/183]  eta: 0:25:53  lr: 0.000061  loss: 3.1287 (2.8778)  time: 12.6073  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [ 70/183]  eta: 0:23:44  lr: 0.000061  loss: 2.6539 (2.8732)  time: 12.5679  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [ 80/183]  eta: 0:21:37  lr: 0.000061  loss: 2.4724 (2.8618)  time: 12.4919  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [ 90/183]  eta: 0:19:31  lr: 0.000061  loss: 3.0789 (2.8669)  time: 12.5554  data: 0.0004  max mem: 9536\n",
            "Epoch: [17] Train  [100/183]  eta: 0:17:25  lr: 0.000061  loss: 2.7223 (2.8621)  time: 12.5909  data: 0.0004  max mem: 9536\n",
            "Epoch: [17] Train  [110/183]  eta: 0:15:19  lr: 0.000061  loss: 2.5281 (2.8527)  time: 12.5589  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [120/183]  eta: 0:13:14  lr: 0.000061  loss: 2.8097 (2.8555)  time: 12.6683  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [130/183]  eta: 0:11:08  lr: 0.000060  loss: 2.8284 (2.8574)  time: 12.7277  data: 0.0004  max mem: 9536\n",
            "Epoch: [17] Train  [140/183]  eta: 0:09:02  lr: 0.000060  loss: 3.1092 (2.8661)  time: 12.6018  data: 0.0005  max mem: 9536\n",
            "Epoch: [17] Train  [150/183]  eta: 0:06:55  lr: 0.000060  loss: 3.2240 (2.8811)  time: 12.5426  data: 0.0004  max mem: 9536\n",
            "Epoch: [17] Train  [160/183]  eta: 0:04:50  lr: 0.000060  loss: 2.7174 (2.8745)  time: 12.6405  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [170/183]  eta: 0:02:44  lr: 0.000060  loss: 2.6911 (2.8748)  time: 12.7211  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Train  [180/183]  eta: 0:00:37  lr: 0.000060  loss: 2.6009 (2.8760)  time: 12.6950  data: 0.0004  max mem: 9536\n",
            "Epoch: [17] Train Total time: 0:38:28\n",
            "Epoch: [17] Test  [  0/242]  eta: 0:05:49    time: 1.4441  data: 0.3709  max mem: 9536\n",
            "Epoch: [17] Test  [ 10/242]  eta: 0:04:08    time: 1.0733  data: 0.0340  max mem: 9536\n",
            "Epoch: [17] Test  [ 20/242]  eta: 0:03:49    time: 1.0141  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [ 30/242]  eta: 0:03:45    time: 1.0589  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [ 40/242]  eta: 0:03:37    time: 1.1227  data: 0.0004  max mem: 9536\n",
            "Epoch: [17] Test  [ 50/242]  eta: 0:03:28    time: 1.1158  data: 0.0004  max mem: 9536\n",
            "Epoch: [17] Test  [ 60/242]  eta: 0:03:20    time: 1.1477  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [ 70/242]  eta: 0:03:10    time: 1.1627  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [ 80/242]  eta: 0:02:58    time: 1.1014  data: 0.0005  max mem: 9536\n",
            "Epoch: [17] Test  [ 90/242]  eta: 0:02:46    time: 1.0453  data: 0.0005  max mem: 9536\n",
            "Epoch: [17] Test  [100/242]  eta: 0:02:35    time: 1.0823  data: 0.0002  max mem: 9536\n",
            "Epoch: [17] Test  [110/242]  eta: 0:02:24    time: 1.0940  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [120/242]  eta: 0:02:14    time: 1.1069  data: 0.0005  max mem: 9536\n",
            "Epoch: [17] Test  [130/242]  eta: 0:02:02    time: 1.1019  data: 0.0005  max mem: 9536\n",
            "Epoch: [17] Test  [140/242]  eta: 0:01:51    time: 1.0491  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [150/242]  eta: 0:01:40    time: 1.0574  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [160/242]  eta: 0:01:29    time: 1.0711  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [170/242]  eta: 0:01:18    time: 1.1190  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [180/242]  eta: 0:01:08    time: 1.1857  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [190/242]  eta: 0:00:57    time: 1.1965  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [200/242]  eta: 0:00:46    time: 1.1435  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [210/242]  eta: 0:00:35    time: 1.1035  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [220/242]  eta: 0:00:24    time: 1.1061  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [230/242]  eta: 0:00:13    time: 1.1118  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test  [240/242]  eta: 0:00:02    time: 1.0752  data: 0.0003  max mem: 9536\n",
            "Epoch: [17] Test Total time: 0:04:27\n",
            "global correct: 95.6\n",
            "average row correct: ['96.5', '97.9', '82.8', '96.4', '89.6', '91.6', '99.2', '93.6', '98.4', '74.6', '97.1', '78.3', '93.0', '95.4', '96.8', '95.9', '80.1', '96.3', '81.8', '97.6', '90.8']\n",
            "IoU: ['95.0', '90.9', '52.5', '90.4', '75.9', '72.1', '95.8', '84.1', '91.8', '49.0', '91.8', '68.8', '88.0', '89.1', '90.9', '91.2', '68.2', '88.4', '61.5', '88.1', '73.4']\n",
            "mean IoU: 80.8\n",
            "Epoch: [18] Train  [  0/183]  eta: 0:39:13  lr: 0.000060  loss: 2.7817 (2.7817)  time: 12.8582  data: 0.4127  max mem: 9536\n",
            "Epoch: [18] Train  [ 10/183]  eta: 0:36:39  lr: 0.000060  loss: 2.8690 (2.8289)  time: 12.7122  data: 0.0378  max mem: 9536\n",
            "Epoch: [18] Train  [ 20/183]  eta: 0:34:25  lr: 0.000059  loss: 2.4798 (2.8688)  time: 12.6631  data: 0.0004  max mem: 9536\n",
            "Epoch: [18] Train  [ 30/183]  eta: 0:32:06  lr: 0.000059  loss: 2.5604 (2.8174)  time: 12.5266  data: 0.0005  max mem: 9536\n",
            "Epoch: [18] Train  [ 40/183]  eta: 0:30:02  lr: 0.000059  loss: 2.7384 (2.8208)  time: 12.5346  data: 0.0004  max mem: 9536\n",
            "Epoch: [18] Train  [ 50/183]  eta: 0:27:56  lr: 0.000059  loss: 2.6744 (2.8017)  time: 12.6335  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [ 60/183]  eta: 0:25:52  lr: 0.000059  loss: 2.7379 (2.8253)  time: 12.6558  data: 0.0004  max mem: 9536\n",
            "Epoch: [18] Train  [ 70/183]  eta: 0:23:44  lr: 0.000059  loss: 3.4461 (2.8468)  time: 12.6047  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [ 80/183]  eta: 0:21:39  lr: 0.000059  loss: 2.9464 (2.8688)  time: 12.5992  data: 0.0002  max mem: 9536\n",
            "Epoch: [18] Train  [ 90/183]  eta: 0:19:33  lr: 0.000059  loss: 2.5979 (2.8615)  time: 12.6400  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [100/183]  eta: 0:17:26  lr: 0.000058  loss: 4.3790 (2.8709)  time: 12.5983  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [110/183]  eta: 0:15:20  lr: 0.000058  loss: 2.7773 (2.8703)  time: 12.6122  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [120/183]  eta: 0:13:14  lr: 0.000058  loss: 2.5918 (2.8695)  time: 12.5708  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [130/183]  eta: 0:11:07  lr: 0.000058  loss: 2.8067 (2.8625)  time: 12.4822  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [140/183]  eta: 0:09:01  lr: 0.000058  loss: 2.7188 (2.8620)  time: 12.5293  data: 0.0004  max mem: 9536\n",
            "Epoch: [18] Train  [150/183]  eta: 0:06:55  lr: 0.000058  loss: 2.8833 (2.8719)  time: 12.6066  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [160/183]  eta: 0:04:49  lr: 0.000058  loss: 2.6744 (2.8696)  time: 12.5996  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [170/183]  eta: 0:02:43  lr: 0.000057  loss: 2.6854 (2.8642)  time: 12.5690  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train  [180/183]  eta: 0:00:37  lr: 0.000057  loss: 2.7919 (2.8587)  time: 12.6005  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Train Total time: 0:38:24\n",
            "Epoch: [18] Test  [  0/242]  eta: 0:05:57    time: 1.4759  data: 0.4062  max mem: 9536\n",
            "Epoch: [18] Test  [ 10/242]  eta: 0:04:06    time: 1.0637  data: 0.0371  max mem: 9536\n",
            "Epoch: [18] Test  [ 20/242]  eta: 0:03:54    time: 1.0342  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [ 30/242]  eta: 0:03:52    time: 1.1113  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [ 40/242]  eta: 0:03:42    time: 1.1507  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [ 50/242]  eta: 0:03:33    time: 1.1393  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [ 60/242]  eta: 0:03:25    time: 1.1844  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [ 70/242]  eta: 0:03:15    time: 1.1917  data: 0.0004  max mem: 9536\n",
            "Epoch: [18] Test  [ 80/242]  eta: 0:03:03    time: 1.1456  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [ 90/242]  eta: 0:02:51    time: 1.1109  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [100/242]  eta: 0:02:41    time: 1.1406  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [110/242]  eta: 0:02:29    time: 1.1419  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [120/242]  eta: 0:02:18    time: 1.1528  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [130/242]  eta: 0:02:07    time: 1.1694  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [140/242]  eta: 0:01:55    time: 1.1161  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [150/242]  eta: 0:01:44    time: 1.1142  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [160/242]  eta: 0:01:33    time: 1.1577  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [170/242]  eta: 0:01:22    time: 1.1858  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [180/242]  eta: 0:01:10    time: 1.2073  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [190/242]  eta: 0:00:59    time: 1.2134  data: 0.0004  max mem: 9536\n",
            "Epoch: [18] Test  [200/242]  eta: 0:00:48    time: 1.1659  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [210/242]  eta: 0:00:36    time: 1.1434  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [220/242]  eta: 0:00:25    time: 1.1344  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test  [230/242]  eta: 0:00:13    time: 1.1324  data: 0.0004  max mem: 9536\n",
            "Epoch: [18] Test  [240/242]  eta: 0:00:02    time: 1.0970  data: 0.0003  max mem: 9536\n",
            "Epoch: [18] Test Total time: 0:04:35\n",
            "global correct: 95.8\n",
            "average row correct: ['96.8', '97.7', '85.7', '96.2', '89.8', '90.1', '99.0', '92.6', '97.8', '68.5', '96.3', '75.9', '96.1', '95.8', '95.6', '95.6', '82.1', '96.5', '84.4', '97.7', '88.9']\n",
            "IoU: ['95.2', '92.1', '52.2', '89.9', '76.7', '74.8', '96.1', '84.7', '93.1', '51.0', '92.2', '67.7', '88.6', '90.4', '90.0', '90.6', '67.9', '86.2', '63.3', '88.1', '77.4']\n",
            "mean IoU: 81.3\n",
            "Epoch: [19] Train  [  0/183]  eta: 0:40:25  lr: 0.000057  loss: 3.0024 (3.0024)  time: 13.2530  data: 0.4503  max mem: 9536\n",
            "Epoch: [19] Train  [ 10/183]  eta: 0:36:35  lr: 0.000057  loss: 2.9433 (2.7793)  time: 12.6923  data: 0.0414  max mem: 9536\n",
            "Epoch: [19] Train  [ 20/183]  eta: 0:34:23  lr: 0.000057  loss: 2.7820 (2.7742)  time: 12.6328  data: 0.0004  max mem: 9536\n",
            "Epoch: [19] Train  [ 30/183]  eta: 0:32:12  lr: 0.000057  loss: 2.8490 (2.7988)  time: 12.5919  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [ 40/183]  eta: 0:30:04  lr: 0.000057  loss: 2.9920 (2.8187)  time: 12.5749  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [ 50/183]  eta: 0:27:54  lr: 0.000057  loss: 2.7466 (2.8300)  time: 12.5339  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [ 60/183]  eta: 0:25:47  lr: 0.000056  loss: 2.6821 (2.8227)  time: 12.4958  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [ 70/183]  eta: 0:23:38  lr: 0.000056  loss: 2.6945 (2.8217)  time: 12.4639  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [ 80/183]  eta: 0:21:34  lr: 0.000056  loss: 2.8937 (2.8106)  time: 12.5243  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [ 90/183]  eta: 0:19:28  lr: 0.000056  loss: 2.7161 (2.8055)  time: 12.6071  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [100/183]  eta: 0:17:22  lr: 0.000056  loss: 3.1754 (2.8152)  time: 12.5359  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [110/183]  eta: 0:15:15  lr: 0.000056  loss: 2.7027 (2.8056)  time: 12.4250  data: 0.0004  max mem: 9536\n",
            "Epoch: [19] Train  [120/183]  eta: 0:13:11  lr: 0.000056  loss: 2.8883 (2.8019)  time: 12.5468  data: 0.0004  max mem: 9536\n",
            "Epoch: [19] Train  [130/183]  eta: 0:11:05  lr: 0.000056  loss: 2.6140 (2.7932)  time: 12.6144  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Train  [140/183]  eta: 0:09:00  lr: 0.000055  loss: 2.8395 (2.7923)  time: 12.5674  data: 0.0004  max mem: 9536\n",
            "Epoch: [19] Train  [150/183]  eta: 0:06:54  lr: 0.000055  loss: 2.5123 (2.7874)  time: 12.6312  data: 0.0004  max mem: 9536\n",
            "Epoch: [19] Train  [160/183]  eta: 0:04:49  lr: 0.000055  loss: 3.0652 (2.7892)  time: 12.6392  data: 0.0004  max mem: 9536\n",
            "Epoch: [19] Train  [170/183]  eta: 0:02:43  lr: 0.000055  loss: 2.7133 (2.7871)  time: 12.5982  data: 0.0004  max mem: 9536\n",
            "Epoch: [19] Train  [180/183]  eta: 0:00:37  lr: 0.000055  loss: 3.0692 (2.7912)  time: 12.5124  data: 0.0005  max mem: 9536\n",
            "Epoch: [19] Train Total time: 0:38:19\n",
            "Epoch: [19] Test  [  0/242]  eta: 0:06:19    time: 1.5676  data: 0.4915  max mem: 9536\n",
            "Epoch: [19] Test  [ 10/242]  eta: 0:04:06    time: 1.0641  data: 0.0449  max mem: 9536\n",
            "Epoch: [19] Test  [ 20/242]  eta: 0:03:49    time: 1.0050  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [ 30/242]  eta: 0:03:44    time: 1.0598  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [ 40/242]  eta: 0:03:36    time: 1.1175  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [ 50/242]  eta: 0:03:27    time: 1.1090  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [ 60/242]  eta: 0:03:19    time: 1.1485  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [ 70/242]  eta: 0:03:09    time: 1.1561  data: 0.0002  max mem: 9536\n",
            "Epoch: [19] Test  [ 80/242]  eta: 0:02:57    time: 1.0931  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [ 90/242]  eta: 0:02:45    time: 1.0503  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [100/242]  eta: 0:02:35    time: 1.0848  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [110/242]  eta: 0:02:24    time: 1.0966  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [120/242]  eta: 0:02:13    time: 1.1090  data: 0.0004  max mem: 9536\n",
            "Epoch: [19] Test  [130/242]  eta: 0:02:02    time: 1.1057  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [140/242]  eta: 0:01:51    time: 1.0553  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [150/242]  eta: 0:01:40    time: 1.0584  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [160/242]  eta: 0:01:29    time: 1.0746  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [170/242]  eta: 0:01:18    time: 1.1187  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [180/242]  eta: 0:01:08    time: 1.1823  data: 0.0002  max mem: 9536\n",
            "Epoch: [19] Test  [190/242]  eta: 0:00:57    time: 1.2028  data: 0.0002  max mem: 9536\n",
            "Epoch: [19] Test  [200/242]  eta: 0:00:46    time: 1.1426  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [210/242]  eta: 0:00:35    time: 1.1015  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [220/242]  eta: 0:00:24    time: 1.1123  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [230/242]  eta: 0:00:13    time: 1.1233  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test  [240/242]  eta: 0:00:02    time: 1.0826  data: 0.0003  max mem: 9536\n",
            "Epoch: [19] Test Total time: 0:04:26\n",
            "global correct: 95.8\n",
            "average row correct: ['96.8', '97.2', '80.2', '95.4', '89.8', '91.5', '99.1', '93.7', '98.6', '72.0', '95.5', '78.6', '93.2', '97.0', '96.6', '96.0', '79.4', '96.5', '81.2', '97.1', '89.8']\n",
            "IoU: ['95.2', '92.8', '53.8', '90.8', '76.4', '74.4', '95.8', '83.8', '90.1', '53.5', '92.2', '69.0', '87.1', '90.7', '90.6', '90.7', '68.6', '84.4', '63.4', '88.5', '78.3']\n",
            "mean IoU: 81.4\n",
            "Epoch: [20] Train  [  0/183]  eta: 0:40:11  lr: 0.000055  loss: 2.8249 (2.8249)  time: 13.1755  data: 0.4973  max mem: 9536\n",
            "Epoch: [20] Train  [ 10/183]  eta: 0:36:45  lr: 0.000055  loss: 2.7835 (2.7057)  time: 12.7481  data: 0.0455  max mem: 9536\n",
            "Epoch: [20] Train  [ 20/183]  eta: 0:34:19  lr: 0.000055  loss: 3.0610 (2.7570)  time: 12.6110  data: 0.0004  max mem: 9536\n",
            "Epoch: [20] Train  [ 30/183]  eta: 0:32:08  lr: 0.000054  loss: 2.9121 (2.7703)  time: 12.5244  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [ 40/183]  eta: 0:29:58  lr: 0.000054  loss: 2.8746 (2.7518)  time: 12.5119  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [ 50/183]  eta: 0:27:51  lr: 0.000054  loss: 3.0514 (2.7586)  time: 12.5103  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [ 60/183]  eta: 0:25:45  lr: 0.000054  loss: 2.6758 (2.7534)  time: 12.5402  data: 0.0002  max mem: 9536\n",
            "Epoch: [20] Train  [ 70/183]  eta: 0:23:41  lr: 0.000054  loss: 2.5637 (2.7536)  time: 12.6196  data: 0.0004  max mem: 9536\n",
            "Epoch: [20] Train  [ 80/183]  eta: 0:21:34  lr: 0.000054  loss: 2.5999 (2.7490)  time: 12.5692  data: 0.0004  max mem: 9536\n",
            "Epoch: [20] Train  [ 90/183]  eta: 0:19:27  lr: 0.000054  loss: 2.5937 (2.7408)  time: 12.4715  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [100/183]  eta: 0:17:23  lr: 0.000053  loss: 2.7039 (2.7496)  time: 12.5882  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [110/183]  eta: 0:15:17  lr: 0.000053  loss: 3.0589 (2.7574)  time: 12.6323  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [120/183]  eta: 0:13:11  lr: 0.000053  loss: 2.5704 (2.7480)  time: 12.5733  data: 0.0002  max mem: 9536\n",
            "Epoch: [20] Train  [130/183]  eta: 0:11:05  lr: 0.000053  loss: 2.8972 (2.7519)  time: 12.4632  data: 0.0002  max mem: 9536\n",
            "Epoch: [20] Train  [140/183]  eta: 0:09:00  lr: 0.000053  loss: 2.6498 (2.7585)  time: 12.5192  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [150/183]  eta: 0:06:54  lr: 0.000053  loss: 2.9865 (2.7570)  time: 12.6186  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [160/183]  eta: 0:04:49  lr: 0.000053  loss: 2.9143 (2.7639)  time: 12.6850  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [170/183]  eta: 0:02:43  lr: 0.000053  loss: 3.0905 (2.7657)  time: 12.6920  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train  [180/183]  eta: 0:00:37  lr: 0.000052  loss: 2.5579 (2.7658)  time: 12.5919  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Train Total time: 0:38:21\n",
            "Epoch: [20] Test  [  0/242]  eta: 0:05:57    time: 1.4774  data: 0.4051  max mem: 9536\n",
            "Epoch: [20] Test  [ 10/242]  eta: 0:04:07    time: 1.0680  data: 0.0373  max mem: 9536\n",
            "Epoch: [20] Test  [ 20/242]  eta: 0:03:50    time: 1.0171  data: 0.0004  max mem: 9536\n",
            "Epoch: [20] Test  [ 30/242]  eta: 0:03:48    time: 1.0807  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [ 40/242]  eta: 0:03:41    time: 1.1608  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [ 50/242]  eta: 0:03:30    time: 1.1311  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [ 60/242]  eta: 0:03:22    time: 1.1345  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [ 70/242]  eta: 0:03:11    time: 1.1530  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [ 80/242]  eta: 0:02:59    time: 1.1012  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [ 90/242]  eta: 0:02:47    time: 1.0513  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [100/242]  eta: 0:02:36    time: 1.0824  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [110/242]  eta: 0:02:25    time: 1.0972  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [120/242]  eta: 0:02:14    time: 1.1104  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [130/242]  eta: 0:02:03    time: 1.0984  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [140/242]  eta: 0:01:51    time: 1.0521  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [150/242]  eta: 0:01:40    time: 1.0594  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [160/242]  eta: 0:01:29    time: 1.0726  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [170/242]  eta: 0:01:18    time: 1.1228  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [180/242]  eta: 0:01:08    time: 1.1803  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [190/242]  eta: 0:00:57    time: 1.1859  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [200/242]  eta: 0:00:46    time: 1.1376  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [210/242]  eta: 0:00:35    time: 1.1082  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [220/242]  eta: 0:00:24    time: 1.1089  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [230/242]  eta: 0:00:13    time: 1.1171  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test  [240/242]  eta: 0:00:02    time: 1.1273  data: 0.0003  max mem: 9536\n",
            "Epoch: [20] Test Total time: 0:04:27\n",
            "global correct: 95.7\n",
            "average row correct: ['96.8', '97.7', '75.8', '96.7', '86.9', '89.8', '98.7', '94.1', '98.1', '67.4', '96.3', '76.7', '96.3', '93.3', '96.6', '95.6', '78.5', '96.8', '85.9', '96.2', '90.7']\n",
            "IoU: ['95.1', '91.4', '54.0', '90.7', '77.4', '75.9', '96.0', '84.3', '92.6', '50.9', '90.3', '68.7', '88.6', '89.5', '90.7', '90.9', '67.9', '83.7', '61.6', '89.1', '71.5']\n",
            "mean IoU: 81.0\n",
            "Epoch: [21] Train  [  0/183]  eta: 0:39:16  lr: 0.000052  loss: 2.8481 (2.8481)  time: 12.8772  data: 0.4264  max mem: 9536\n",
            "Epoch: [21] Train  [ 10/183]  eta: 0:36:19  lr: 0.000052  loss: 2.4975 (2.7265)  time: 12.5977  data: 0.0391  max mem: 9536\n",
            "Epoch: [21] Train  [ 20/183]  eta: 0:33:57  lr: 0.000052  loss: 2.8221 (2.7231)  time: 12.4783  data: 0.0004  max mem: 9536\n",
            "Epoch: [21] Train  [ 30/183]  eta: 0:31:43  lr: 0.000052  loss: 2.5167 (2.7694)  time: 12.3536  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Train  [ 40/183]  eta: 0:29:44  lr: 0.000052  loss: 2.8080 (2.7885)  time: 12.4560  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Train  [ 50/183]  eta: 0:27:40  lr: 0.000052  loss: 2.7789 (2.7816)  time: 12.5627  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Train  [ 60/183]  eta: 0:25:40  lr: 0.000052  loss: 2.8236 (2.7799)  time: 12.6227  data: 0.0002  max mem: 9536\n",
            "Epoch: [21] Train  [ 70/183]  eta: 0:23:37  lr: 0.000051  loss: 2.8560 (2.7795)  time: 12.6779  data: 0.0004  max mem: 9536\n",
            "Epoch: [21] Train  [ 80/183]  eta: 0:21:33  lr: 0.000051  loss: 2.6618 (2.7762)  time: 12.6539  data: 0.0004  max mem: 9536\n",
            "Epoch: [21] Train  [ 90/183]  eta: 0:19:27  lr: 0.000051  loss: 2.9604 (2.7767)  time: 12.6175  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Train  [100/183]  eta: 0:17:22  lr: 0.000051  loss: 2.8319 (2.7679)  time: 12.5790  data: 0.0002  max mem: 9536\n",
            "Epoch: [21] Train  [110/183]  eta: 0:15:16  lr: 0.000051  loss: 2.6932 (2.7708)  time: 12.5587  data: 0.0002  max mem: 9536\n",
            "Epoch: [21] Train  [120/183]  eta: 0:13:11  lr: 0.000051  loss: 2.9496 (2.7767)  time: 12.5724  data: 0.0002  max mem: 9536\n",
            "Epoch: [21] Train  [130/183]  eta: 0:11:05  lr: 0.000051  loss: 2.3185 (2.7729)  time: 12.5581  data: 0.0002  max mem: 9536\n",
            "Epoch: [21] Train  [140/183]  eta: 0:09:00  lr: 0.000050  loss: 2.8204 (2.7692)  time: 12.5373  data: 0.0002  max mem: 9536\n",
            "Epoch: [21] Train  [150/183]  eta: 0:06:54  lr: 0.000050  loss: 2.7463 (2.7674)  time: 12.5709  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Train  [160/183]  eta: 0:04:48  lr: 0.000050  loss: 2.7685 (2.7727)  time: 12.5300  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Train  [170/183]  eta: 0:02:43  lr: 0.000050  loss: 2.7163 (2.7705)  time: 12.5223  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Train  [180/183]  eta: 0:00:37  lr: 0.000050  loss: 2.8553 (2.7676)  time: 12.6219  data: 0.0002  max mem: 9536\n",
            "Epoch: [21] Train Total time: 0:38:19\n",
            "Epoch: [21] Test  [  0/242]  eta: 0:05:55    time: 1.4694  data: 0.3972  max mem: 9536\n",
            "Epoch: [21] Test  [ 10/242]  eta: 0:04:07    time: 1.0655  data: 0.0364  max mem: 9536\n",
            "Epoch: [21] Test  [ 20/242]  eta: 0:03:52    time: 1.0275  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [ 30/242]  eta: 0:03:49    time: 1.0887  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [ 40/242]  eta: 0:03:40    time: 1.1395  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [ 50/242]  eta: 0:03:31    time: 1.1372  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [ 60/242]  eta: 0:03:24    time: 1.1804  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [ 70/242]  eta: 0:03:13    time: 1.1847  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [ 80/242]  eta: 0:03:01    time: 1.1276  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [ 90/242]  eta: 0:02:49    time: 1.0815  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [100/242]  eta: 0:02:39    time: 1.1224  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [110/242]  eta: 0:02:27    time: 1.1359  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [120/242]  eta: 0:02:17    time: 1.1308  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [130/242]  eta: 0:02:05    time: 1.1247  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [140/242]  eta: 0:01:54    time: 1.1028  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [150/242]  eta: 0:01:43    time: 1.1167  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [160/242]  eta: 0:01:31    time: 1.0969  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [170/242]  eta: 0:01:20    time: 1.1259  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [180/242]  eta: 0:01:09    time: 1.2040  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [190/242]  eta: 0:00:58    time: 1.2151  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [200/242]  eta: 0:00:47    time: 1.1887  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [210/242]  eta: 0:00:36    time: 1.1696  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [220/242]  eta: 0:00:24    time: 1.1300  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [230/242]  eta: 0:00:13    time: 1.1526  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test  [240/242]  eta: 0:00:02    time: 1.1299  data: 0.0003  max mem: 9536\n",
            "Epoch: [21] Test Total time: 0:04:34\n",
            "global correct: 95.8\n",
            "average row correct: ['96.9', '97.1', '80.0', '94.9', '89.2', '91.5', '99.1', '88.9', '98.5', '76.6', '94.8', '78.5', '95.0', '95.6', '95.8', '95.6', '82.0', '96.4', '77.6', '96.3', '91.1']\n",
            "IoU: ['95.2', '93.7', '52.9', '90.6', '75.5', '74.4', '96.0', '84.3', '91.8', '46.9', '91.9', '70.5', '89.1', '91.5', '90.0', '91.2', '68.7', '86.2', '61.8', '89.5', '73.0']\n",
            "mean IoU: 81.2\n",
            "Epoch: [22] Train  [  0/183]  eta: 0:39:48  lr: 0.000050  loss: 2.6520 (2.6520)  time: 13.0541  data: 0.3825  max mem: 9536\n",
            "Epoch: [22] Train  [ 10/183]  eta: 0:36:35  lr: 0.000050  loss: 2.6213 (2.8191)  time: 12.6894  data: 0.0351  max mem: 9536\n",
            "Epoch: [22] Train  [ 20/183]  eta: 0:34:22  lr: 0.000050  loss: 3.8639 (2.8324)  time: 12.6353  data: 0.0004  max mem: 9536\n",
            "Epoch: [22] Train  [ 30/183]  eta: 0:32:04  lr: 0.000049  loss: 2.6203 (2.7711)  time: 12.5192  data: 0.0004  max mem: 9536\n",
            "Epoch: [22] Train  [ 40/183]  eta: 0:29:56  lr: 0.000049  loss: 3.1270 (2.7551)  time: 12.4640  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [ 50/183]  eta: 0:27:48  lr: 0.000049  loss: 2.5782 (2.7603)  time: 12.4948  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [ 60/183]  eta: 0:25:42  lr: 0.000049  loss: 2.5015 (2.7877)  time: 12.4921  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [ 70/183]  eta: 0:23:37  lr: 0.000049  loss: 3.1896 (2.7829)  time: 12.5431  data: 0.0002  max mem: 9536\n",
            "Epoch: [22] Train  [ 80/183]  eta: 0:21:34  lr: 0.000049  loss: 2.6849 (2.7913)  time: 12.6443  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [ 90/183]  eta: 0:19:27  lr: 0.000049  loss: 2.5869 (2.7731)  time: 12.5811  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [100/183]  eta: 0:17:21  lr: 0.000048  loss: 2.8202 (2.7543)  time: 12.4500  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [110/183]  eta: 0:15:15  lr: 0.000048  loss: 2.5447 (2.7578)  time: 12.4988  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [120/183]  eta: 0:13:10  lr: 0.000048  loss: 2.7729 (2.7468)  time: 12.5726  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [130/183]  eta: 0:11:05  lr: 0.000048  loss: 3.0633 (2.7494)  time: 12.6644  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [140/183]  eta: 0:09:00  lr: 0.000048  loss: 2.6702 (2.7432)  time: 12.6722  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [150/183]  eta: 0:06:54  lr: 0.000048  loss: 2.6303 (2.7366)  time: 12.5684  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Train  [160/183]  eta: 0:04:48  lr: 0.000048  loss: 2.5334 (2.7382)  time: 12.4920  data: 0.0004  max mem: 9536\n",
            "Epoch: [22] Train  [170/183]  eta: 0:02:43  lr: 0.000048  loss: 2.6299 (2.7367)  time: 12.4763  data: 0.0005  max mem: 9536\n",
            "Epoch: [22] Train  [180/183]  eta: 0:00:37  lr: 0.000047  loss: 2.9769 (2.7410)  time: 12.5369  data: 0.0004  max mem: 9536\n",
            "Epoch: [22] Train Total time: 0:38:16\n",
            "Epoch: [22] Test  [  0/242]  eta: 0:06:03    time: 1.5039  data: 0.4342  max mem: 9536\n",
            "Epoch: [22] Test  [ 10/242]  eta: 0:04:06    time: 1.0614  data: 0.0397  max mem: 9536\n",
            "Epoch: [22] Test  [ 20/242]  eta: 0:03:48    time: 1.0064  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [ 30/242]  eta: 0:03:45    time: 1.0619  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [ 40/242]  eta: 0:03:37    time: 1.1234  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [ 50/242]  eta: 0:03:28    time: 1.1254  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [ 60/242]  eta: 0:03:20    time: 1.1575  data: 0.0004  max mem: 9536\n",
            "Epoch: [22] Test  [ 70/242]  eta: 0:03:10    time: 1.1580  data: 0.0005  max mem: 9536\n",
            "Epoch: [22] Test  [ 80/242]  eta: 0:02:58    time: 1.0974  data: 0.0004  max mem: 9536\n",
            "Epoch: [22] Test  [ 90/242]  eta: 0:02:46    time: 1.0403  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [100/242]  eta: 0:02:35    time: 1.0719  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [110/242]  eta: 0:02:24    time: 1.0891  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [120/242]  eta: 0:02:13    time: 1.1029  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [130/242]  eta: 0:02:02    time: 1.0915  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [140/242]  eta: 0:01:51    time: 1.0431  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [150/242]  eta: 0:01:39    time: 1.0517  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [160/242]  eta: 0:01:29    time: 1.0694  data: 0.0004  max mem: 9536\n",
            "Epoch: [22] Test  [170/242]  eta: 0:01:18    time: 1.1195  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [180/242]  eta: 0:01:07    time: 1.1734  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [190/242]  eta: 0:00:57    time: 1.1834  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [200/242]  eta: 0:00:46    time: 1.1321  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [210/242]  eta: 0:00:35    time: 1.0973  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [220/242]  eta: 0:00:24    time: 1.1028  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [230/242]  eta: 0:00:13    time: 1.1156  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test  [240/242]  eta: 0:00:02    time: 1.0828  data: 0.0003  max mem: 9536\n",
            "Epoch: [22] Test Total time: 0:04:25\n",
            "global correct: 95.8\n",
            "average row correct: ['96.9', '97.4', '82.6', '95.0', '89.5', '91.8', '98.8', '93.9', '98.2', '72.2', '95.8', '77.9', '95.3', '95.6', '96.7', '95.6', '81.1', '96.0', '80.8', '94.8', '90.2']\n",
            "IoU: ['95.2', '93.1', '55.1', '90.7', '76.4', '73.9', '95.5', '84.5', '92.5', '50.6', '92.2', '69.9', '88.0', '91.7', '90.1', '90.6', '68.7', '89.3', '62.0', '89.2', '75.4']\n",
            "mean IoU: 81.6\n",
            "Epoch: [23] Train  [  0/183]  eta: 0:41:02  lr: 0.000047  loss: 2.6731 (2.6731)  time: 13.4555  data: 0.4056  max mem: 9536\n",
            "Epoch: [23] Train  [ 10/183]  eta: 0:36:40  lr: 0.000047  loss: 2.4579 (2.7964)  time: 12.7221  data: 0.0372  max mem: 9536\n",
            "Epoch: [23] Train  [ 20/183]  eta: 0:34:19  lr: 0.000047  loss: 2.6934 (2.8008)  time: 12.5941  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [ 30/183]  eta: 0:32:03  lr: 0.000047  loss: 2.5562 (2.7824)  time: 12.4893  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [ 40/183]  eta: 0:29:59  lr: 0.000047  loss: 2.7994 (2.7697)  time: 12.5239  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Train  [ 50/183]  eta: 0:27:57  lr: 0.000047  loss: 2.8205 (2.7517)  time: 12.6715  data: 0.0005  max mem: 9536\n",
            "Epoch: [23] Train  [ 60/183]  eta: 0:25:51  lr: 0.000047  loss: 3.7156 (2.7635)  time: 12.6878  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Train  [ 70/183]  eta: 0:23:46  lr: 0.000046  loss: 2.7872 (2.7626)  time: 12.6687  data: 0.0005  max mem: 9536\n",
            "Epoch: [23] Train  [ 80/183]  eta: 0:21:38  lr: 0.000046  loss: 2.6019 (2.7448)  time: 12.5864  data: 0.0005  max mem: 9536\n",
            "Epoch: [23] Train  [ 90/183]  eta: 0:19:31  lr: 0.000046  loss: 2.3576 (2.7397)  time: 12.4892  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [100/183]  eta: 0:17:24  lr: 0.000046  loss: 2.6248 (2.7379)  time: 12.4967  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [110/183]  eta: 0:15:17  lr: 0.000046  loss: 2.5696 (2.7238)  time: 12.4672  data: 0.0002  max mem: 9536\n",
            "Epoch: [23] Train  [120/183]  eta: 0:13:10  lr: 0.000046  loss: 2.8297 (2.7153)  time: 12.3501  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [130/183]  eta: 0:11:04  lr: 0.000046  loss: 2.4745 (2.7076)  time: 12.3631  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [140/183]  eta: 0:08:59  lr: 0.000045  loss: 2.7312 (2.7147)  time: 12.5165  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [150/183]  eta: 0:06:53  lr: 0.000045  loss: 2.5563 (2.7109)  time: 12.5695  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [160/183]  eta: 0:04:48  lr: 0.000045  loss: 2.9271 (2.7093)  time: 12.5352  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Train  [170/183]  eta: 0:02:42  lr: 0.000045  loss: 3.0694 (2.7050)  time: 12.4742  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Train  [180/183]  eta: 0:00:37  lr: 0.000045  loss: 2.9231 (2.7071)  time: 12.4266  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Train Total time: 0:38:12\n",
            "Epoch: [23] Test  [  0/242]  eta: 0:06:03    time: 1.5009  data: 0.4312  max mem: 9536\n",
            "Epoch: [23] Test  [ 10/242]  eta: 0:04:07    time: 1.0677  data: 0.0395  max mem: 9536\n",
            "Epoch: [23] Test  [ 20/242]  eta: 0:03:52    time: 1.0268  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [ 30/242]  eta: 0:03:48    time: 1.0829  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Test  [ 40/242]  eta: 0:03:39    time: 1.1289  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Test  [ 50/242]  eta: 0:03:29    time: 1.1145  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [ 60/242]  eta: 0:03:21    time: 1.1443  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [ 70/242]  eta: 0:03:10    time: 1.1535  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [ 80/242]  eta: 0:02:59    time: 1.1117  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [ 90/242]  eta: 0:02:47    time: 1.0682  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [100/242]  eta: 0:02:36    time: 1.0852  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [110/242]  eta: 0:02:25    time: 1.0953  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Test  [120/242]  eta: 0:02:15    time: 1.1262  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Test  [130/242]  eta: 0:02:03    time: 1.1291  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [140/242]  eta: 0:01:53    time: 1.1132  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [150/242]  eta: 0:01:41    time: 1.1182  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [160/242]  eta: 0:01:30    time: 1.0880  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [170/242]  eta: 0:01:19    time: 1.1380  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [180/242]  eta: 0:01:09    time: 1.2095  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [190/242]  eta: 0:00:58    time: 1.2153  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [200/242]  eta: 0:00:47    time: 1.1461  data: 0.0004  max mem: 9536\n",
            "Epoch: [23] Test  [210/242]  eta: 0:00:35    time: 1.1074  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [220/242]  eta: 0:00:24    time: 1.1216  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [230/242]  eta: 0:00:13    time: 1.1271  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test  [240/242]  eta: 0:00:02    time: 1.1110  data: 0.0003  max mem: 9536\n",
            "Epoch: [23] Test Total time: 0:04:31\n",
            "global correct: 96.0\n",
            "average row correct: ['97.4', '96.8', '71.1', '95.1', '86.9', '91.0', '98.9', '91.5', '98.2', '72.3', '96.2', '76.4', '92.7', '95.6', '95.1', '96.0', '79.0', '95.7', '75.5', '96.4', '90.9']\n",
            "IoU: ['95.4', '94.1', '53.6', '90.5', '77.5', '74.1', '96.1', '85.5', '91.6', '49.5', '92.6', '69.3', '88.8', '91.3', '90.4', '91.2', '68.4', '90.6', '62.5', '89.3', '72.0']\n",
            "mean IoU: 81.6\n",
            "Epoch: [24] Train  [  0/183]  eta: 0:38:42  lr: 0.000045  loss: 2.7923 (2.7923)  time: 12.6914  data: 0.4299  max mem: 9536\n",
            "Epoch: [24] Train  [ 10/183]  eta: 0:36:36  lr: 0.000045  loss: 2.5418 (2.6359)  time: 12.6942  data: 0.0393  max mem: 9536\n",
            "Epoch: [24] Train  [ 20/183]  eta: 0:34:10  lr: 0.000045  loss: 2.6456 (2.6662)  time: 12.5716  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Train  [ 30/183]  eta: 0:31:59  lr: 0.000044  loss: 2.4492 (2.6353)  time: 12.4624  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Train  [ 40/183]  eta: 0:29:49  lr: 0.000044  loss: 2.6255 (2.6310)  time: 12.4422  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Train  [ 50/183]  eta: 0:27:41  lr: 0.000044  loss: 2.6972 (2.6284)  time: 12.4032  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Train  [ 60/183]  eta: 0:25:38  lr: 0.000044  loss: 2.5848 (2.6376)  time: 12.4974  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Train  [ 70/183]  eta: 0:23:32  lr: 0.000044  loss: 2.6708 (2.6533)  time: 12.5352  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Train  [ 80/183]  eta: 0:21:25  lr: 0.000044  loss: 2.8197 (2.6556)  time: 12.4134  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Train  [ 90/183]  eta: 0:19:21  lr: 0.000044  loss: 2.5147 (2.6611)  time: 12.4388  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Train  [100/183]  eta: 0:17:16  lr: 0.000043  loss: 2.8730 (2.6706)  time: 12.5316  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Train  [110/183]  eta: 0:15:11  lr: 0.000043  loss: 2.5895 (2.6675)  time: 12.4644  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Train  [120/183]  eta: 0:13:06  lr: 0.000043  loss: 2.7039 (2.6651)  time: 12.4200  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Train  [130/183]  eta: 0:11:01  lr: 0.000043  loss: 3.0496 (2.6634)  time: 12.4449  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Train  [140/183]  eta: 0:08:56  lr: 0.000043  loss: 2.6021 (2.6660)  time: 12.4571  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Train  [150/183]  eta: 0:06:51  lr: 0.000043  loss: 2.4809 (2.6710)  time: 12.4682  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Train  [160/183]  eta: 0:04:46  lr: 0.000043  loss: 2.5771 (2.6763)  time: 12.4304  data: 0.0004  max mem: 9536\n",
            "Epoch: [24] Train  [170/183]  eta: 0:02:42  lr: 0.000042  loss: 2.7020 (2.6756)  time: 12.4117  data: 0.0004  max mem: 9536\n",
            "Epoch: [24] Train  [180/183]  eta: 0:00:37  lr: 0.000042  loss: 2.3823 (2.6742)  time: 12.3986  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Train Total time: 0:38:01\n",
            "Epoch: [24] Test  [  0/242]  eta: 0:05:54    time: 1.4637  data: 0.3932  max mem: 9536\n",
            "Epoch: [24] Test  [ 10/242]  eta: 0:04:03    time: 1.0498  data: 0.0360  max mem: 9536\n",
            "Epoch: [24] Test  [ 20/242]  eta: 0:03:46    time: 0.9996  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [ 30/242]  eta: 0:03:41    time: 1.0455  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [ 40/242]  eta: 0:03:34    time: 1.1040  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [ 50/242]  eta: 0:03:25    time: 1.1042  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [ 60/242]  eta: 0:03:17    time: 1.1371  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [ 70/242]  eta: 0:03:07    time: 1.1451  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [ 80/242]  eta: 0:02:56    time: 1.0890  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Test  [ 90/242]  eta: 0:02:44    time: 1.0374  data: 0.0002  max mem: 9536\n",
            "Epoch: [24] Test  [100/242]  eta: 0:02:33    time: 1.0696  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [110/242]  eta: 0:02:22    time: 1.0861  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [120/242]  eta: 0:02:12    time: 1.0987  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [130/242]  eta: 0:02:01    time: 1.0921  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [140/242]  eta: 0:01:50    time: 1.0416  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [150/242]  eta: 0:01:39    time: 1.0484  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [160/242]  eta: 0:01:28    time: 1.0624  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [170/242]  eta: 0:01:17    time: 1.1082  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [180/242]  eta: 0:01:07    time: 1.1706  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [190/242]  eta: 0:00:56    time: 1.1772  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [200/242]  eta: 0:00:45    time: 1.1232  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [210/242]  eta: 0:00:34    time: 1.0954  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [220/242]  eta: 0:00:24    time: 1.0971  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [230/242]  eta: 0:00:13    time: 1.1107  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test  [240/242]  eta: 0:00:02    time: 1.0788  data: 0.0003  max mem: 9536\n",
            "Epoch: [24] Test Total time: 0:04:23\n",
            "global correct: 95.8\n",
            "average row correct: ['97.0', '97.6', '80.7', '96.4', '88.6', '87.4', '99.0', '93.8', '98.8', '71.9', '95.8', '75.7', '94.7', '96.0', '94.2', '95.1', '78.0', '96.5', '79.9', '96.8', '90.8']\n",
            "IoU: ['95.2', '93.2', '55.3', '90.4', '76.2', '76.7', '95.6', '83.5', '90.6', '50.7', '91.9', '67.6', '87.5', '91.7', '89.7', '90.9', '68.5', '87.6', '62.5', '89.7', '73.5']\n",
            "mean IoU: 81.4\n",
            "Epoch: [25] Train  [  0/183]  eta: 0:39:17  lr: 0.000042  loss: 2.3407 (2.3407)  time: 12.8843  data: 0.3750  max mem: 9536\n",
            "Epoch: [25] Train  [ 10/183]  eta: 0:36:02  lr: 0.000042  loss: 2.6885 (2.6709)  time: 12.5026  data: 0.0343  max mem: 9536\n",
            "Epoch: [25] Train  [ 20/183]  eta: 0:33:57  lr: 0.000042  loss: 2.5542 (2.6781)  time: 12.4797  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [ 30/183]  eta: 0:31:50  lr: 0.000042  loss: 2.6576 (2.6644)  time: 12.4765  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [ 40/183]  eta: 0:29:43  lr: 0.000042  loss: 3.2777 (2.6950)  time: 12.4461  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Train  [ 50/183]  eta: 0:27:37  lr: 0.000042  loss: 2.7795 (2.7189)  time: 12.4312  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Train  [ 60/183]  eta: 0:25:30  lr: 0.000041  loss: 2.3076 (2.7063)  time: 12.3842  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Train  [ 70/183]  eta: 0:23:26  lr: 0.000041  loss: 2.7807 (2.7037)  time: 12.3948  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [ 80/183]  eta: 0:21:21  lr: 0.000041  loss: 2.7178 (2.7098)  time: 12.4301  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [ 90/183]  eta: 0:19:16  lr: 0.000041  loss: 3.1609 (2.7167)  time: 12.4166  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [100/183]  eta: 0:17:12  lr: 0.000041  loss: 3.0120 (2.7113)  time: 12.4157  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Train  [110/183]  eta: 0:15:08  lr: 0.000041  loss: 2.9745 (2.7093)  time: 12.4630  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Train  [120/183]  eta: 0:13:04  lr: 0.000041  loss: 2.5260 (2.7041)  time: 12.5161  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [130/183]  eta: 0:10:59  lr: 0.000040  loss: 2.6298 (2.7051)  time: 12.4954  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [140/183]  eta: 0:08:55  lr: 0.000040  loss: 2.7471 (2.6971)  time: 12.4302  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [150/183]  eta: 0:06:50  lr: 0.000040  loss: 2.6047 (2.6962)  time: 12.3417  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [160/183]  eta: 0:04:45  lr: 0.000040  loss: 2.4936 (2.6893)  time: 12.2514  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [170/183]  eta: 0:02:41  lr: 0.000040  loss: 2.7440 (2.6927)  time: 12.2989  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train  [180/183]  eta: 0:00:37  lr: 0.000040  loss: 2.5616 (2.6928)  time: 12.3703  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Train Total time: 0:37:52\n",
            "Epoch: [25] Test  [  0/242]  eta: 0:05:58    time: 1.4810  data: 0.4115  max mem: 9536\n",
            "Epoch: [25] Test  [ 10/242]  eta: 0:04:01    time: 1.0427  data: 0.0376  max mem: 9536\n",
            "Epoch: [25] Test  [ 20/242]  eta: 0:03:44    time: 0.9877  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [ 30/242]  eta: 0:03:40    time: 1.0400  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [ 40/242]  eta: 0:03:33    time: 1.1002  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [ 50/242]  eta: 0:03:23    time: 1.0913  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [ 60/242]  eta: 0:03:16    time: 1.1287  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [ 70/242]  eta: 0:03:06    time: 1.1417  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [ 80/242]  eta: 0:02:54    time: 1.0842  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [ 90/242]  eta: 0:02:42    time: 1.0325  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [100/242]  eta: 0:02:32    time: 1.0636  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [110/242]  eta: 0:02:21    time: 1.0814  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [120/242]  eta: 0:02:11    time: 1.0982  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [130/242]  eta: 0:02:00    time: 1.0882  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [140/242]  eta: 0:01:49    time: 1.0346  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [150/242]  eta: 0:01:38    time: 1.0415  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [160/242]  eta: 0:01:27    time: 1.0552  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [170/242]  eta: 0:01:17    time: 1.1010  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test  [180/242]  eta: 0:01:07    time: 1.1631  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [190/242]  eta: 0:00:56    time: 1.1702  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [200/242]  eta: 0:00:45    time: 1.1144  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [210/242]  eta: 0:00:34    time: 1.0843  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [220/242]  eta: 0:00:23    time: 1.0937  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [230/242]  eta: 0:00:13    time: 1.1035  data: 0.0003  max mem: 9536\n",
            "Epoch: [25] Test  [240/242]  eta: 0:00:02    time: 1.0644  data: 0.0002  max mem: 9536\n",
            "Epoch: [25] Test Total time: 0:04:22\n",
            "global correct: 95.9\n",
            "average row correct: ['97.0', '97.6', '78.9', '96.8', '88.7', '90.1', '98.9', '93.3', '98.1', '71.9', '96.0', '77.2', '95.2', '92.6', '95.4', '95.9', '79.0', '96.6', '82.3', '95.6', '90.4']\n",
            "IoU: ['95.3', '93.9', '57.8', '90.7', '76.6', '75.9', '95.8', '84.1', '92.3', '51.8', '89.8', '69.1', '89.4', '89.4', '90.5', '90.9', '68.9', '86.3', '62.0', '89.5', '75.7']\n",
            "mean IoU: 81.7\n",
            "Epoch: [26] Train  [  0/183]  eta: 0:39:43  lr: 0.000040  loss: 2.4351 (2.4351)  time: 13.0250  data: 0.3991  max mem: 9536\n",
            "Epoch: [26] Train  [ 10/183]  eta: 0:36:21  lr: 0.000040  loss: 3.0640 (2.6857)  time: 12.6076  data: 0.0366  max mem: 9536\n",
            "Epoch: [26] Train  [ 20/183]  eta: 0:33:54  lr: 0.000039  loss: 2.5294 (2.6796)  time: 12.4571  data: 0.0004  max mem: 9536\n",
            "Epoch: [26] Train  [ 30/183]  eta: 0:31:45  lr: 0.000039  loss: 3.0545 (2.6763)  time: 12.3705  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Train  [ 40/183]  eta: 0:29:37  lr: 0.000039  loss: 2.8763 (2.6785)  time: 12.3736  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Train  [ 50/183]  eta: 0:27:34  lr: 0.000039  loss: 2.8917 (2.6738)  time: 12.4141  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Train  [ 60/183]  eta: 0:25:32  lr: 0.000039  loss: 2.7004 (2.6649)  time: 12.5128  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Train  [ 70/183]  eta: 0:23:29  lr: 0.000039  loss: 2.4586 (2.6431)  time: 12.5490  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Train  [ 80/183]  eta: 0:21:25  lr: 0.000039  loss: 2.6184 (2.6478)  time: 12.5618  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train  [ 90/183]  eta: 0:19:20  lr: 0.000038  loss: 2.7772 (2.6401)  time: 12.5146  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train  [100/183]  eta: 0:17:14  lr: 0.000038  loss: 2.4005 (2.6293)  time: 12.3985  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train  [110/183]  eta: 0:15:10  lr: 0.000038  loss: 2.6158 (2.6351)  time: 12.4256  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train  [120/183]  eta: 0:13:05  lr: 0.000038  loss: 2.2320 (2.6326)  time: 12.4853  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train  [130/183]  eta: 0:11:01  lr: 0.000038  loss: 2.4113 (2.6349)  time: 12.4962  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train  [140/183]  eta: 0:08:56  lr: 0.000038  loss: 3.3212 (2.6501)  time: 12.5324  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Train  [150/183]  eta: 0:06:51  lr: 0.000038  loss: 2.5719 (2.6553)  time: 12.5068  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Train  [160/183]  eta: 0:04:47  lr: 0.000038  loss: 2.5079 (2.6471)  time: 12.5677  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train  [170/183]  eta: 0:02:42  lr: 0.000037  loss: 2.6982 (2.6487)  time: 12.5646  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train  [180/183]  eta: 0:00:37  lr: 0.000037  loss: 2.7771 (2.6523)  time: 12.4581  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Train Total time: 0:38:05\n",
            "Epoch: [26] Test  [  0/242]  eta: 0:05:44    time: 1.4217  data: 0.3489  max mem: 9536\n",
            "Epoch: [26] Test  [ 10/242]  eta: 0:04:01    time: 1.0399  data: 0.0319  max mem: 9536\n",
            "Epoch: [26] Test  [ 20/242]  eta: 0:03:45    time: 0.9960  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [ 30/242]  eta: 0:03:41    time: 1.0495  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [ 40/242]  eta: 0:03:34    time: 1.1080  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [ 50/242]  eta: 0:03:25    time: 1.1041  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [ 60/242]  eta: 0:03:17    time: 1.1362  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [ 70/242]  eta: 0:03:07    time: 1.1459  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [ 80/242]  eta: 0:02:55    time: 1.0871  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [ 90/242]  eta: 0:02:43    time: 1.0346  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [100/242]  eta: 0:02:33    time: 1.0699  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [110/242]  eta: 0:02:22    time: 1.0851  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [120/242]  eta: 0:02:12    time: 1.0978  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [130/242]  eta: 0:02:01    time: 1.0883  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [140/242]  eta: 0:01:49    time: 1.0365  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [150/242]  eta: 0:01:38    time: 1.0438  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [160/242]  eta: 0:01:28    time: 1.0596  data: 0.0003  max mem: 9536\n",
            "Epoch: [26] Test  [170/242]  eta: 0:01:17    time: 1.1085  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [180/242]  eta: 0:01:07    time: 1.1679  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [190/242]  eta: 0:00:56    time: 1.1710  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [200/242]  eta: 0:00:45    time: 1.1149  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [210/242]  eta: 0:00:34    time: 1.0899  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [220/242]  eta: 0:00:23    time: 1.0994  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [230/242]  eta: 0:00:13    time: 1.1017  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test  [240/242]  eta: 0:00:02    time: 1.0632  data: 0.0002  max mem: 9536\n",
            "Epoch: [26] Test Total time: 0:04:22\n",
            "global correct: 96.0\n",
            "average row correct: ['97.2', '96.9', '77.4', '95.8', '86.8', '89.9', '98.6', '91.7', '98.3', '70.2', '95.9', '77.2', '95.5', '95.5', '95.2', '95.9', '79.3', '96.1', '81.9', '96.0', '90.5']\n",
            "IoU: ['95.4', '94.7', '57.7', '90.6', '76.7', '77.2', '95.9', '85.0', '92.7', '50.4', '91.9', '69.2', '89.8', '91.9', '89.9', '90.9', '68.6', '89.4', '63.0', '89.6', '75.4']\n",
            "mean IoU: 82.2\n",
            "Epoch: [27] Train  [  0/183]  eta: 0:39:33  lr: 0.000037  loss: 2.4189 (2.4189)  time: 12.9690  data: 0.3954  max mem: 9536\n",
            "Epoch: [27] Train  [ 10/183]  eta: 0:36:17  lr: 0.000037  loss: 2.3912 (2.6409)  time: 12.5844  data: 0.0364  max mem: 9536\n",
            "Epoch: [27] Train  [ 20/183]  eta: 0:33:46  lr: 0.000037  loss: 2.4322 (2.6294)  time: 12.4061  data: 0.0004  max mem: 9536\n",
            "Epoch: [27] Train  [ 30/183]  eta: 0:31:39  lr: 0.000037  loss: 2.4839 (2.6091)  time: 12.3265  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Train  [ 40/183]  eta: 0:29:38  lr: 0.000037  loss: 2.1891 (2.5840)  time: 12.4468  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Train  [ 50/183]  eta: 0:27:34  lr: 0.000036  loss: 2.6832 (2.6220)  time: 12.4824  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Train  [ 60/183]  eta: 0:25:30  lr: 0.000036  loss: 2.4429 (2.6166)  time: 12.4483  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [ 70/183]  eta: 0:23:27  lr: 0.000036  loss: 2.5210 (2.6237)  time: 12.4996  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Train  [ 80/183]  eta: 0:21:22  lr: 0.000036  loss: 2.7676 (2.6176)  time: 12.4676  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [ 90/183]  eta: 0:19:17  lr: 0.000036  loss: 2.5203 (2.6157)  time: 12.3882  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [100/183]  eta: 0:17:12  lr: 0.000036  loss: 2.7403 (2.6093)  time: 12.4323  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [110/183]  eta: 0:15:07  lr: 0.000036  loss: 2.3761 (2.6307)  time: 12.4081  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [120/183]  eta: 0:13:03  lr: 0.000035  loss: 2.9432 (2.6317)  time: 12.3810  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [130/183]  eta: 0:10:59  lr: 0.000035  loss: 2.6537 (2.6360)  time: 12.4611  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [140/183]  eta: 0:08:55  lr: 0.000035  loss: 2.4839 (2.6422)  time: 12.5010  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Train  [150/183]  eta: 0:06:50  lr: 0.000035  loss: 2.6632 (2.6394)  time: 12.5227  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Train  [160/183]  eta: 0:04:46  lr: 0.000035  loss: 2.3769 (2.6372)  time: 12.5042  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [170/183]  eta: 0:02:41  lr: 0.000035  loss: 2.6445 (2.6395)  time: 12.4949  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train  [180/183]  eta: 0:00:37  lr: 0.000035  loss: 2.7485 (2.6362)  time: 12.5561  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Train Total time: 0:38:00\n",
            "Epoch: [27] Test  [  0/242]  eta: 0:05:55    time: 1.4687  data: 0.4005  max mem: 9536\n",
            "Epoch: [27] Test  [ 10/242]  eta: 0:04:02    time: 1.0471  data: 0.0366  max mem: 9536\n",
            "Epoch: [27] Test  [ 20/242]  eta: 0:03:46    time: 0.9985  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [ 30/242]  eta: 0:03:42    time: 1.0500  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [ 40/242]  eta: 0:03:34    time: 1.1076  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [ 50/242]  eta: 0:03:25    time: 1.1014  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [ 60/242]  eta: 0:03:17    time: 1.1320  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Test  [ 70/242]  eta: 0:03:07    time: 1.1427  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Test  [ 80/242]  eta: 0:02:55    time: 1.0868  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [ 90/242]  eta: 0:02:43    time: 1.0369  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [100/242]  eta: 0:02:33    time: 1.0693  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [110/242]  eta: 0:02:22    time: 1.0885  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [120/242]  eta: 0:02:12    time: 1.1051  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Test  [130/242]  eta: 0:02:01    time: 1.0901  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Test  [140/242]  eta: 0:01:50    time: 1.0374  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [150/242]  eta: 0:01:39    time: 1.0431  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [160/242]  eta: 0:01:28    time: 1.0571  data: 0.0002  max mem: 9536\n",
            "Epoch: [27] Test  [170/242]  eta: 0:01:17    time: 1.1062  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [180/242]  eta: 0:01:07    time: 1.1664  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [190/242]  eta: 0:00:56    time: 1.1751  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [200/242]  eta: 0:00:45    time: 1.1184  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [210/242]  eta: 0:00:34    time: 1.0908  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [220/242]  eta: 0:00:23    time: 1.1003  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [230/242]  eta: 0:00:13    time: 1.1125  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test  [240/242]  eta: 0:00:02    time: 1.0771  data: 0.0003  max mem: 9536\n",
            "Epoch: [27] Test Total time: 0:04:23\n",
            "global correct: 95.9\n",
            "average row correct: ['97.0', '98.1', '77.2', '96.5', '87.4', '91.0', '98.9', '93.4', '98.6', '73.7', '95.4', '78.8', '94.3', '96.0', '97.3', '95.3', '76.7', '96.7', '80.1', '96.9', '90.5']\n",
            "IoU: ['95.3', '92.5', '55.4', '90.2', '75.9', '74.7', '95.8', '84.5', '91.1', '50.8', '92.2', '71.5', '88.4', '91.8', '90.5', '90.9', '68.4', '87.0', '63.3', '89.2', '75.2']\n",
            "mean IoU: 81.6\n",
            "Epoch: [28] Train  [  0/183]  eta: 0:41:39  lr: 0.000035  loss: 2.8076 (2.8076)  time: 13.6590  data: 0.3760  max mem: 9536\n",
            "Epoch: [28] Train  [ 10/183]  eta: 0:36:32  lr: 0.000034  loss: 2.6498 (2.6817)  time: 12.6708  data: 0.0345  max mem: 9536\n",
            "Epoch: [28] Train  [ 20/183]  eta: 0:34:24  lr: 0.000034  loss: 2.8173 (2.6555)  time: 12.6129  data: 0.0004  max mem: 9536\n",
            "Epoch: [28] Train  [ 30/183]  eta: 0:32:03  lr: 0.000034  loss: 2.8295 (2.6548)  time: 12.5211  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [ 40/183]  eta: 0:29:45  lr: 0.000034  loss: 2.4796 (2.6369)  time: 12.3001  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [ 50/183]  eta: 0:27:38  lr: 0.000034  loss: 2.5234 (2.6375)  time: 12.3072  data: 0.0002  max mem: 9536\n",
            "Epoch: [28] Train  [ 60/183]  eta: 0:25:35  lr: 0.000034  loss: 3.1683 (2.6376)  time: 12.4913  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [ 70/183]  eta: 0:23:28  lr: 0.000034  loss: 2.9808 (2.6363)  time: 12.4396  data: 0.0002  max mem: 9536\n",
            "Epoch: [28] Train  [ 80/183]  eta: 0:21:24  lr: 0.000033  loss: 2.8830 (2.6528)  time: 12.4020  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [ 90/183]  eta: 0:19:19  lr: 0.000033  loss: 2.4907 (2.6465)  time: 12.4824  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [100/183]  eta: 0:17:13  lr: 0.000033  loss: 2.8464 (2.6473)  time: 12.3688  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [110/183]  eta: 0:15:09  lr: 0.000033  loss: 3.0894 (2.6511)  time: 12.4178  data: 0.0002  max mem: 9536\n",
            "Epoch: [28] Train  [120/183]  eta: 0:13:04  lr: 0.000033  loss: 2.7259 (2.6531)  time: 12.4905  data: 0.0002  max mem: 9536\n",
            "Epoch: [28] Train  [130/183]  eta: 0:11:00  lr: 0.000033  loss: 2.7337 (2.6523)  time: 12.4514  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [140/183]  eta: 0:08:55  lr: 0.000033  loss: 2.1753 (2.6548)  time: 12.5042  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [150/183]  eta: 0:06:51  lr: 0.000032  loss: 2.8497 (2.6498)  time: 12.5345  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [160/183]  eta: 0:04:46  lr: 0.000032  loss: 2.4181 (2.6425)  time: 12.4630  data: 0.0002  max mem: 9536\n",
            "Epoch: [28] Train  [170/183]  eta: 0:02:41  lr: 0.000032  loss: 2.7373 (2.6417)  time: 12.3736  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Train  [180/183]  eta: 0:00:37  lr: 0.000032  loss: 2.5346 (2.6395)  time: 12.3763  data: 0.0004  max mem: 9536\n",
            "Epoch: [28] Train Total time: 0:37:58\n",
            "Epoch: [28] Test  [  0/242]  eta: 0:05:53    time: 1.4602  data: 0.3769  max mem: 9536\n",
            "Epoch: [28] Test  [ 10/242]  eta: 0:04:01    time: 1.0428  data: 0.0345  max mem: 9536\n",
            "Epoch: [28] Test  [ 20/242]  eta: 0:03:44    time: 0.9883  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [ 30/242]  eta: 0:03:41    time: 1.0435  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [ 40/242]  eta: 0:03:33    time: 1.1075  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [ 50/242]  eta: 0:03:24    time: 1.0956  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [ 60/242]  eta: 0:03:16    time: 1.1276  data: 0.0002  max mem: 9536\n",
            "Epoch: [28] Test  [ 70/242]  eta: 0:03:06    time: 1.1397  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [ 80/242]  eta: 0:02:55    time: 1.0843  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [ 90/242]  eta: 0:02:43    time: 1.0331  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [100/242]  eta: 0:02:33    time: 1.0628  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [110/242]  eta: 0:02:21    time: 1.0814  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [120/242]  eta: 0:02:11    time: 1.0961  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [130/242]  eta: 0:02:00    time: 1.0850  data: 0.0002  max mem: 9536\n",
            "Epoch: [28] Test  [140/242]  eta: 0:01:49    time: 1.0444  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [150/242]  eta: 0:01:38    time: 1.0516  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [160/242]  eta: 0:01:28    time: 1.0573  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [170/242]  eta: 0:01:17    time: 1.1055  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [180/242]  eta: 0:01:07    time: 1.1650  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [190/242]  eta: 0:00:56    time: 1.1716  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [200/242]  eta: 0:00:45    time: 1.1186  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [210/242]  eta: 0:00:34    time: 1.0890  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [220/242]  eta: 0:00:23    time: 1.0940  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [230/242]  eta: 0:00:13    time: 1.1017  data: 0.0003  max mem: 9536\n",
            "Epoch: [28] Test  [240/242]  eta: 0:00:02    time: 1.0629  data: 0.0002  max mem: 9536\n",
            "Epoch: [28] Test Total time: 0:04:22\n",
            "global correct: 95.8\n",
            "average row correct: ['97.1', '97.2', '82.1', '95.7', '90.1', '90.9', '98.9', '91.6', '98.6', '71.9', '95.6', '73.3', '93.5', '95.7', '94.7', '95.8', '78.4', '96.4', '80.0', '96.1', '90.5']\n",
            "IoU: ['95.2', '94.2', '57.3', '90.7', '76.0', '75.5', '96.5', '84.9', '89.9', '49.0', '91.4', '67.4', '87.8', '91.9', '89.9', '90.9', '68.4', '87.8', '61.4', '89.4', '74.8']\n",
            "mean IoU: 81.4\n",
            "Epoch: [29] Train  [  0/183]  eta: 0:39:56  lr: 0.000032  loss: 3.1855 (3.1855)  time: 13.0935  data: 0.4015  max mem: 9536\n",
            "Epoch: [29] Train  [ 10/183]  eta: 0:36:10  lr: 0.000032  loss: 2.5362 (2.6949)  time: 12.5454  data: 0.0368  max mem: 9536\n",
            "Epoch: [29] Train  [ 20/183]  eta: 0:34:00  lr: 0.000032  loss: 2.3787 (2.6675)  time: 12.4871  data: 0.0004  max mem: 9536\n",
            "Epoch: [29] Train  [ 30/183]  eta: 0:31:49  lr: 0.000032  loss: 2.5938 (2.6423)  time: 12.4432  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [ 40/183]  eta: 0:29:43  lr: 0.000031  loss: 2.4141 (2.6085)  time: 12.4328  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Train  [ 50/183]  eta: 0:27:38  lr: 0.000031  loss: 2.3663 (2.5905)  time: 12.4553  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Train  [ 60/183]  eta: 0:25:31  lr: 0.000031  loss: 2.9038 (2.6201)  time: 12.3976  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [ 70/183]  eta: 0:23:26  lr: 0.000031  loss: 3.0220 (2.6149)  time: 12.3791  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [ 80/183]  eta: 0:21:23  lr: 0.000031  loss: 2.4467 (2.6167)  time: 12.4924  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [ 90/183]  eta: 0:19:18  lr: 0.000031  loss: 3.1291 (2.6038)  time: 12.5063  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [100/183]  eta: 0:17:13  lr: 0.000031  loss: 2.7592 (2.6031)  time: 12.4184  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [110/183]  eta: 0:15:09  lr: 0.000030  loss: 2.3712 (2.6101)  time: 12.4519  data: 0.0005  max mem: 9536\n",
            "Epoch: [29] Train  [120/183]  eta: 0:13:04  lr: 0.000030  loss: 2.9609 (2.6196)  time: 12.5005  data: 0.0005  max mem: 9536\n",
            "Epoch: [29] Train  [130/183]  eta: 0:11:00  lr: 0.000030  loss: 2.5888 (2.6169)  time: 12.4774  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [140/183]  eta: 0:08:55  lr: 0.000030  loss: 2.5709 (2.6201)  time: 12.4805  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [150/183]  eta: 0:06:51  lr: 0.000030  loss: 2.3458 (2.6161)  time: 12.4241  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Train  [160/183]  eta: 0:04:46  lr: 0.000030  loss: 2.5820 (2.6090)  time: 12.4448  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [170/183]  eta: 0:02:42  lr: 0.000030  loss: 2.5836 (2.6128)  time: 12.5135  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train  [180/183]  eta: 0:00:37  lr: 0.000029  loss: 2.9393 (2.6187)  time: 12.4357  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Train Total time: 0:38:00\n",
            "Epoch: [29] Test  [  0/242]  eta: 0:05:56    time: 1.4712  data: 0.3976  max mem: 9536\n",
            "Epoch: [29] Test  [ 10/242]  eta: 0:04:02    time: 1.0451  data: 0.0363  max mem: 9536\n",
            "Epoch: [29] Test  [ 20/242]  eta: 0:03:45    time: 0.9941  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [ 30/242]  eta: 0:03:41    time: 1.0454  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [ 40/242]  eta: 0:03:33    time: 1.1037  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [ 50/242]  eta: 0:03:24    time: 1.0995  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [ 60/242]  eta: 0:03:17    time: 1.1323  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [ 70/242]  eta: 0:03:07    time: 1.1427  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [ 80/242]  eta: 0:02:55    time: 1.0867  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [ 90/242]  eta: 0:02:43    time: 1.0335  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [100/242]  eta: 0:02:33    time: 1.0657  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [110/242]  eta: 0:02:22    time: 1.0847  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [120/242]  eta: 0:02:12    time: 1.0993  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [130/242]  eta: 0:02:00    time: 1.0884  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [140/242]  eta: 0:01:49    time: 1.0376  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [150/242]  eta: 0:01:38    time: 1.0430  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [160/242]  eta: 0:01:28    time: 1.0592  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [170/242]  eta: 0:01:17    time: 1.1067  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [180/242]  eta: 0:01:07    time: 1.1630  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [190/242]  eta: 0:00:56    time: 1.1692  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [200/242]  eta: 0:00:45    time: 1.1175  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [210/242]  eta: 0:00:34    time: 1.0856  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test  [220/242]  eta: 0:00:23    time: 1.0896  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [230/242]  eta: 0:00:13    time: 1.0984  data: 0.0003  max mem: 9536\n",
            "Epoch: [29] Test  [240/242]  eta: 0:00:02    time: 1.0621  data: 0.0002  max mem: 9536\n",
            "Epoch: [29] Test Total time: 0:04:22\n",
            "global correct: 96.0\n",
            "average row correct: ['97.2', '97.4', '80.0', '95.5', '87.6', '91.5', '99.0', '92.0', '98.6', '70.1', '96.2', '74.8', '94.0', '96.1', '96.0', '95.6', '78.4', '96.3', '82.0', '95.7', '90.6']\n",
            "IoU: ['95.4', '94.7', '58.2', '90.5', '76.2', '74.7', '96.2', '86.0', '91.3', '52.0', '91.9', '69.1', '87.6', '90.8', '90.5', '90.8', '69.1', '88.6', '62.8', '88.9', '76.2']\n",
            "mean IoU: 82.0\n",
            "Epoch: [30] Train  [  0/183]  eta: 0:38:46  lr: 0.000029  loss: 2.5317 (2.5317)  time: 12.7108  data: 0.3214  max mem: 9536\n",
            "Epoch: [30] Train  [ 10/183]  eta: 0:36:20  lr: 0.000029  loss: 2.6732 (2.6255)  time: 12.6054  data: 0.0295  max mem: 9536\n",
            "Epoch: [30] Train  [ 20/183]  eta: 0:33:54  lr: 0.000029  loss: 2.2518 (2.5822)  time: 12.4727  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Train  [ 30/183]  eta: 0:31:51  lr: 0.000029  loss: 2.3862 (2.6078)  time: 12.4275  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [ 40/183]  eta: 0:29:53  lr: 0.000029  loss: 2.8761 (2.6433)  time: 12.5957  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [ 50/183]  eta: 0:27:48  lr: 0.000029  loss: 2.7357 (2.6423)  time: 12.6271  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [ 60/183]  eta: 0:25:42  lr: 0.000028  loss: 3.1899 (2.6337)  time: 12.5523  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [ 70/183]  eta: 0:23:35  lr: 0.000028  loss: 2.4219 (2.6263)  time: 12.4813  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [ 80/183]  eta: 0:21:31  lr: 0.000028  loss: 2.3493 (2.6098)  time: 12.5314  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Train  [ 90/183]  eta: 0:19:24  lr: 0.000028  loss: 2.9687 (2.6055)  time: 12.5066  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Train  [100/183]  eta: 0:17:20  lr: 0.000028  loss: 2.3415 (2.5996)  time: 12.5434  data: 0.0004  max mem: 9536\n",
            "Epoch: [30] Train  [110/183]  eta: 0:15:14  lr: 0.000028  loss: 2.3867 (2.5936)  time: 12.5738  data: 0.0004  max mem: 9536\n",
            "Epoch: [30] Train  [120/183]  eta: 0:13:08  lr: 0.000028  loss: 2.6980 (2.5907)  time: 12.3908  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Train  [130/183]  eta: 0:11:03  lr: 0.000027  loss: 2.5231 (2.5894)  time: 12.4732  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Train  [140/183]  eta: 0:08:58  lr: 0.000027  loss: 2.6679 (2.5918)  time: 12.5637  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [150/183]  eta: 0:06:53  lr: 0.000027  loss: 2.5779 (2.5868)  time: 12.5111  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [160/183]  eta: 0:04:47  lr: 0.000027  loss: 2.4440 (2.5907)  time: 12.4044  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [170/183]  eta: 0:02:42  lr: 0.000027  loss: 2.7264 (2.5990)  time: 12.4145  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Train  [180/183]  eta: 0:00:37  lr: 0.000027  loss: 2.7260 (2.5973)  time: 12.4854  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Train Total time: 0:38:08\n",
            "Epoch: [30] Test  [  0/242]  eta: 0:06:03    time: 1.5018  data: 0.4266  max mem: 9536\n",
            "Epoch: [30] Test  [ 10/242]  eta: 0:04:03    time: 1.0498  data: 0.0390  max mem: 9536\n",
            "Epoch: [30] Test  [ 20/242]  eta: 0:03:46    time: 0.9941  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [ 30/242]  eta: 0:03:41    time: 1.0443  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [ 40/242]  eta: 0:03:34    time: 1.1042  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [ 50/242]  eta: 0:03:24    time: 1.0979  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [ 60/242]  eta: 0:03:17    time: 1.1328  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [ 70/242]  eta: 0:03:07    time: 1.1420  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [ 80/242]  eta: 0:02:55    time: 1.0839  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [ 90/242]  eta: 0:02:43    time: 1.0345  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [100/242]  eta: 0:02:33    time: 1.0640  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [110/242]  eta: 0:02:22    time: 1.0827  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [120/242]  eta: 0:02:12    time: 1.0977  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [130/242]  eta: 0:02:00    time: 1.0843  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [140/242]  eta: 0:01:49    time: 1.0368  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [150/242]  eta: 0:01:38    time: 1.0442  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [160/242]  eta: 0:01:28    time: 1.0564  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [170/242]  eta: 0:01:17    time: 1.1083  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [180/242]  eta: 0:01:07    time: 1.1671  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [190/242]  eta: 0:00:56    time: 1.1700  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [200/242]  eta: 0:00:45    time: 1.1163  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [210/242]  eta: 0:00:34    time: 1.0891  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [220/242]  eta: 0:00:23    time: 1.0978  data: 0.0003  max mem: 9536\n",
            "Epoch: [30] Test  [230/242]  eta: 0:00:13    time: 1.1022  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test  [240/242]  eta: 0:00:02    time: 1.0633  data: 0.0002  max mem: 9536\n",
            "Epoch: [30] Test Total time: 0:04:22\n",
            "global correct: 95.7\n",
            "average row correct: ['96.5', '97.6', '82.8', '97.3', '90.7', '90.4', '99.0', '93.1', '98.4', '75.3', '96.4', '80.2', '94.3', '94.7', '96.0', '96.3', '82.7', '96.6', '82.5', '96.9', '91.3']\n",
            "IoU: ['95.1', '94.0', '57.4', '90.1', '74.8', '75.7', '95.9', '85.2', '91.4', '47.1', '91.3', '70.4', '89.3', '90.3', '90.0', '91.2', '68.9', '87.1', '61.0', '89.5', '70.1']\n",
            "mean IoU: 81.2\n",
            "Epoch: [31] Train  [  0/183]  eta: 0:41:20  lr: 0.000027  loss: 2.5070 (2.5070)  time: 13.5562  data: 0.3936  max mem: 9536\n",
            "Epoch: [31] Train  [ 10/183]  eta: 0:36:24  lr: 0.000027  loss: 2.3149 (2.6759)  time: 12.6274  data: 0.0361  max mem: 9536\n",
            "Epoch: [31] Train  [ 20/183]  eta: 0:33:50  lr: 0.000026  loss: 2.6035 (2.5974)  time: 12.4010  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [ 30/183]  eta: 0:31:45  lr: 0.000026  loss: 2.7536 (2.5903)  time: 12.3593  data: 0.0004  max mem: 9536\n",
            "Epoch: [31] Train  [ 40/183]  eta: 0:29:44  lr: 0.000026  loss: 2.8101 (2.5853)  time: 12.5019  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [ 50/183]  eta: 0:27:43  lr: 0.000026  loss: 2.7084 (2.5935)  time: 12.5819  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [ 60/183]  eta: 0:25:40  lr: 0.000026  loss: 2.1859 (2.5912)  time: 12.6132  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [ 70/183]  eta: 0:23:34  lr: 0.000026  loss: 2.5538 (2.5901)  time: 12.5396  data: 0.0004  max mem: 9536\n",
            "Epoch: [31] Train  [ 80/183]  eta: 0:21:27  lr: 0.000026  loss: 2.4537 (2.5895)  time: 12.4399  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [ 90/183]  eta: 0:19:23  lr: 0.000025  loss: 2.8239 (2.5807)  time: 12.4947  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [100/183]  eta: 0:17:18  lr: 0.000025  loss: 3.1287 (2.5756)  time: 12.5576  data: 0.0002  max mem: 9536\n",
            "Epoch: [31] Train  [110/183]  eta: 0:15:12  lr: 0.000025  loss: 3.5045 (2.5835)  time: 12.4891  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [120/183]  eta: 0:13:08  lr: 0.000025  loss: 2.5523 (2.5805)  time: 12.4856  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [130/183]  eta: 0:11:03  lr: 0.000025  loss: 2.6978 (2.5769)  time: 12.5317  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [140/183]  eta: 0:08:57  lr: 0.000025  loss: 2.9691 (2.5777)  time: 12.5091  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [150/183]  eta: 0:06:52  lr: 0.000025  loss: 2.7754 (2.5790)  time: 12.5115  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train  [160/183]  eta: 0:04:47  lr: 0.000024  loss: 2.6440 (2.5812)  time: 12.5033  data: 0.0004  max mem: 9536\n",
            "Epoch: [31] Train  [170/183]  eta: 0:02:42  lr: 0.000024  loss: 2.6850 (2.5890)  time: 12.5340  data: 0.0004  max mem: 9536\n",
            "Epoch: [31] Train  [180/183]  eta: 0:00:37  lr: 0.000024  loss: 2.3536 (2.5899)  time: 12.5724  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Train Total time: 0:38:10\n",
            "Epoch: [31] Test  [  0/242]  eta: 0:06:00    time: 1.4887  data: 0.4123  max mem: 9536\n",
            "Epoch: [31] Test  [ 10/242]  eta: 0:04:02    time: 1.0459  data: 0.0377  max mem: 9536\n",
            "Epoch: [31] Test  [ 20/242]  eta: 0:03:44    time: 0.9893  data: 0.0007  max mem: 9536\n",
            "Epoch: [31] Test  [ 30/242]  eta: 0:03:42    time: 1.0512  data: 0.0007  max mem: 9536\n",
            "Epoch: [31] Test  [ 40/242]  eta: 0:03:35    time: 1.1251  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [ 50/242]  eta: 0:03:26    time: 1.1102  data: 0.0002  max mem: 9536\n",
            "Epoch: [31] Test  [ 60/242]  eta: 0:03:18    time: 1.1323  data: 0.0004  max mem: 9536\n",
            "Epoch: [31] Test  [ 70/242]  eta: 0:03:07    time: 1.1420  data: 0.0004  max mem: 9536\n",
            "Epoch: [31] Test  [ 80/242]  eta: 0:02:56    time: 1.0826  data: 0.0004  max mem: 9536\n",
            "Epoch: [31] Test  [ 90/242]  eta: 0:02:44    time: 1.0361  data: 0.0006  max mem: 9536\n",
            "Epoch: [31] Test  [100/242]  eta: 0:02:33    time: 1.0716  data: 0.0004  max mem: 9536\n",
            "Epoch: [31] Test  [110/242]  eta: 0:02:22    time: 1.0842  data: 0.0002  max mem: 9536\n",
            "Epoch: [31] Test  [120/242]  eta: 0:02:12    time: 1.0952  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [130/242]  eta: 0:02:01    time: 1.0819  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [140/242]  eta: 0:01:50    time: 1.0339  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [150/242]  eta: 0:01:38    time: 1.0430  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [160/242]  eta: 0:01:28    time: 1.0597  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [170/242]  eta: 0:01:17    time: 1.1103  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [180/242]  eta: 0:01:07    time: 1.1661  data: 0.0002  max mem: 9536\n",
            "Epoch: [31] Test  [190/242]  eta: 0:00:56    time: 1.1662  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [200/242]  eta: 0:00:45    time: 1.1098  data: 0.0002  max mem: 9536\n",
            "Epoch: [31] Test  [210/242]  eta: 0:00:34    time: 1.0830  data: 0.0002  max mem: 9536\n",
            "Epoch: [31] Test  [220/242]  eta: 0:00:23    time: 1.0898  data: 0.0002  max mem: 9536\n",
            "Epoch: [31] Test  [230/242]  eta: 0:00:13    time: 1.0950  data: 0.0003  max mem: 9536\n",
            "Epoch: [31] Test  [240/242]  eta: 0:00:02    time: 1.0583  data: 0.0002  max mem: 9536\n",
            "Epoch: [31] Test Total time: 0:04:22\n",
            "global correct: 95.8\n",
            "average row correct: ['96.8', '97.3', '82.2', '96.7', '90.5', '90.6', '99.1', '92.9', '98.6', '76.1', '95.8', '80.7', '94.8', '95.3', '95.5', '95.7', '80.8', '96.4', '79.2', '95.8', '90.6']\n",
            "IoU: ['95.3', '94.3', '59.8', '90.1', '75.4', '77.0', '96.0', '84.3', '91.0', '47.9', '91.5', '71.1', '87.7', '91.6', '90.2', '90.8', '68.4', '88.6', '60.7', '90.5', '74.4']\n",
            "mean IoU: 81.7\n",
            "Epoch: [32] Train  [  0/183]  eta: 0:41:25  lr: 0.000024  loss: 2.5000 (2.5000)  time: 13.5806  data: 0.3811  max mem: 9536\n",
            "Epoch: [32] Train  [ 10/183]  eta: 0:36:40  lr: 0.000024  loss: 2.9507 (2.6842)  time: 12.7219  data: 0.0349  max mem: 9536\n",
            "Epoch: [32] Train  [ 20/183]  eta: 0:34:20  lr: 0.000024  loss: 2.7484 (2.6065)  time: 12.5915  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [ 30/183]  eta: 0:32:07  lr: 0.000024  loss: 2.5325 (2.5980)  time: 12.5323  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [ 40/183]  eta: 0:30:02  lr: 0.000023  loss: 2.7621 (2.5935)  time: 12.5688  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [ 50/183]  eta: 0:27:53  lr: 0.000023  loss: 2.7860 (2.5925)  time: 12.5605  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Train  [ 60/183]  eta: 0:25:47  lr: 0.000023  loss: 2.6263 (2.5851)  time: 12.5235  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [ 70/183]  eta: 0:23:43  lr: 0.000023  loss: 2.7421 (2.5953)  time: 12.6292  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [ 80/183]  eta: 0:21:36  lr: 0.000023  loss: 2.5512 (2.5942)  time: 12.6255  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [ 90/183]  eta: 0:19:28  lr: 0.000023  loss: 2.8314 (2.5843)  time: 12.4427  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [100/183]  eta: 0:17:22  lr: 0.000023  loss: 2.4407 (2.5912)  time: 12.4127  data: 0.0004  max mem: 9536\n",
            "Epoch: [32] Train  [110/183]  eta: 0:15:15  lr: 0.000022  loss: 2.8847 (2.5926)  time: 12.4755  data: 0.0004  max mem: 9536\n",
            "Epoch: [32] Train  [120/183]  eta: 0:13:10  lr: 0.000022  loss: 2.6037 (2.5898)  time: 12.5471  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [130/183]  eta: 0:11:04  lr: 0.000022  loss: 2.6832 (2.5855)  time: 12.5114  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [140/183]  eta: 0:08:59  lr: 0.000022  loss: 3.0070 (2.5939)  time: 12.4449  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [150/183]  eta: 0:06:53  lr: 0.000022  loss: 2.3895 (2.5898)  time: 12.4885  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [160/183]  eta: 0:04:48  lr: 0.000022  loss: 3.2612 (2.5906)  time: 12.4291  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [170/183]  eta: 0:02:42  lr: 0.000021  loss: 2.2454 (2.5815)  time: 12.4091  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Train  [180/183]  eta: 0:00:37  lr: 0.000021  loss: 2.6415 (2.5809)  time: 12.4340  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Train Total time: 0:38:10\n",
            "Epoch: [32] Test  [  0/242]  eta: 0:06:05    time: 1.5092  data: 0.4289  max mem: 9536\n",
            "Epoch: [32] Test  [ 10/242]  eta: 0:04:04    time: 1.0550  data: 0.0393  max mem: 9536\n",
            "Epoch: [32] Test  [ 20/242]  eta: 0:03:47    time: 1.0025  data: 0.0004  max mem: 9536\n",
            "Epoch: [32] Test  [ 30/242]  eta: 0:03:42    time: 1.0494  data: 0.0005  max mem: 9536\n",
            "Epoch: [32] Test  [ 40/242]  eta: 0:03:35    time: 1.1046  data: 0.0004  max mem: 9536\n",
            "Epoch: [32] Test  [ 50/242]  eta: 0:03:25    time: 1.0974  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Test  [ 60/242]  eta: 0:03:17    time: 1.1304  data: 0.0004  max mem: 9536\n",
            "Epoch: [32] Test  [ 70/242]  eta: 0:03:07    time: 1.1427  data: 0.0004  max mem: 9536\n",
            "Epoch: [32] Test  [ 80/242]  eta: 0:02:55    time: 1.0834  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Test  [ 90/242]  eta: 0:02:43    time: 1.0304  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Test  [100/242]  eta: 0:02:33    time: 1.0666  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Test  [110/242]  eta: 0:02:22    time: 1.0979  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Test  [120/242]  eta: 0:02:12    time: 1.1157  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Test  [130/242]  eta: 0:02:01    time: 1.1093  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Test  [140/242]  eta: 0:01:50    time: 1.0507  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Test  [150/242]  eta: 0:01:39    time: 1.0400  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Test  [160/242]  eta: 0:01:28    time: 1.0524  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Test  [170/242]  eta: 0:01:17    time: 1.1033  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Test  [180/242]  eta: 0:01:07    time: 1.1633  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Test  [190/242]  eta: 0:00:56    time: 1.1670  data: 0.0004  max mem: 9536\n",
            "Epoch: [32] Test  [200/242]  eta: 0:00:45    time: 1.1224  data: 0.0005  max mem: 9536\n",
            "Epoch: [32] Test  [210/242]  eta: 0:00:34    time: 1.0961  data: 0.0004  max mem: 9536\n",
            "Epoch: [32] Test  [220/242]  eta: 0:00:24    time: 1.0939  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Test  [230/242]  eta: 0:00:13    time: 1.1002  data: 0.0002  max mem: 9536\n",
            "Epoch: [32] Test  [240/242]  eta: 0:00:02    time: 1.0701  data: 0.0003  max mem: 9536\n",
            "Epoch: [32] Test Total time: 0:04:23\n",
            "global correct: 95.8\n",
            "average row correct: ['96.9', '97.8', '82.8', '96.4', '89.0', '92.0', '98.9', '94.1', '98.7', '71.7', '95.8', '78.8', '94.2', '95.5', '96.2', '95.6', '81.8', '96.1', '80.2', '96.7', '90.8']\n",
            "IoU: ['95.3', '94.0', '58.6', '89.8', '75.9', '74.6', '95.6', '84.1', '90.3', '49.8', '91.8', '71.2', '87.4', '91.6', '90.8', '90.8', '68.1', '89.8', '62.4', '89.6', '73.9']\n",
            "mean IoU: 81.7\n",
            "Epoch: [33] Train  [  0/183]  eta: 0:40:55  lr: 0.000021  loss: 2.4052 (2.4052)  time: 13.4178  data: 0.3870  max mem: 9536\n",
            "Epoch: [33] Train  [ 10/183]  eta: 0:36:38  lr: 0.000021  loss: 2.6128 (2.5433)  time: 12.7064  data: 0.0359  max mem: 9536\n",
            "Epoch: [33] Train  [ 20/183]  eta: 0:34:21  lr: 0.000021  loss: 2.8374 (2.6229)  time: 12.6095  data: 0.0006  max mem: 9536\n",
            "Epoch: [33] Train  [ 30/183]  eta: 0:32:15  lr: 0.000021  loss: 2.3152 (2.5855)  time: 12.6183  data: 0.0004  max mem: 9536\n",
            "Epoch: [33] Train  [ 40/183]  eta: 0:30:01  lr: 0.000021  loss: 2.4758 (2.5667)  time: 12.5421  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Train  [ 50/183]  eta: 0:27:51  lr: 0.000021  loss: 2.6594 (2.6105)  time: 12.4448  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train  [ 60/183]  eta: 0:25:43  lr: 0.000020  loss: 2.9207 (2.6069)  time: 12.4493  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train  [ 70/183]  eta: 0:23:38  lr: 0.000020  loss: 2.5579 (2.5869)  time: 12.5143  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train  [ 80/183]  eta: 0:21:32  lr: 0.000020  loss: 2.6629 (2.5772)  time: 12.5499  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train  [ 90/183]  eta: 0:19:25  lr: 0.000020  loss: 2.7262 (2.5657)  time: 12.4500  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train  [100/183]  eta: 0:17:20  lr: 0.000020  loss: 2.3577 (2.5675)  time: 12.4697  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Train  [110/183]  eta: 0:15:14  lr: 0.000020  loss: 2.2534 (2.5755)  time: 12.5378  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Train  [120/183]  eta: 0:13:09  lr: 0.000019  loss: 2.1545 (2.5648)  time: 12.4925  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Train  [130/183]  eta: 0:11:04  lr: 0.000019  loss: 2.7024 (2.5575)  time: 12.5475  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Train  [140/183]  eta: 0:08:58  lr: 0.000019  loss: 2.4379 (2.5494)  time: 12.5501  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Train  [150/183]  eta: 0:06:53  lr: 0.000019  loss: 2.7840 (2.5526)  time: 12.4273  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train  [160/183]  eta: 0:04:48  lr: 0.000019  loss: 2.6687 (2.5562)  time: 12.4913  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train  [170/183]  eta: 0:02:42  lr: 0.000019  loss: 2.6168 (2.5566)  time: 12.5556  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train  [180/183]  eta: 0:00:37  lr: 0.000019  loss: 2.2009 (2.5578)  time: 12.5191  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Train Total time: 0:38:11\n",
            "Epoch: [33] Test  [  0/242]  eta: 0:05:57    time: 1.4755  data: 0.3931  max mem: 9536\n",
            "Epoch: [33] Test  [ 10/242]  eta: 0:04:02    time: 1.0469  data: 0.0360  max mem: 9536\n",
            "Epoch: [33] Test  [ 20/242]  eta: 0:03:46    time: 0.9953  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [ 30/242]  eta: 0:03:41    time: 1.0434  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [ 40/242]  eta: 0:03:33    time: 1.0986  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [ 50/242]  eta: 0:03:24    time: 1.0935  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [ 60/242]  eta: 0:03:16    time: 1.1294  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [ 70/242]  eta: 0:03:06    time: 1.1433  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [ 80/242]  eta: 0:02:55    time: 1.0856  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [ 90/242]  eta: 0:02:43    time: 1.0317  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [100/242]  eta: 0:02:33    time: 1.0626  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [110/242]  eta: 0:02:21    time: 1.0783  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [120/242]  eta: 0:02:11    time: 1.0941  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [130/242]  eta: 0:02:00    time: 1.0817  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [140/242]  eta: 0:01:49    time: 1.0275  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [150/242]  eta: 0:01:38    time: 1.0383  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [160/242]  eta: 0:01:27    time: 1.0567  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [170/242]  eta: 0:01:17    time: 1.1021  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [180/242]  eta: 0:01:07    time: 1.1616  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [190/242]  eta: 0:00:56    time: 1.1669  data: 0.0002  max mem: 9536\n",
            "Epoch: [33] Test  [200/242]  eta: 0:00:45    time: 1.1152  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [210/242]  eta: 0:00:34    time: 1.0905  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [220/242]  eta: 0:00:23    time: 1.0936  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [230/242]  eta: 0:00:13    time: 1.1028  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test  [240/242]  eta: 0:00:02    time: 1.0652  data: 0.0003  max mem: 9536\n",
            "Epoch: [33] Test Total time: 0:04:22\n",
            "global correct: 95.8\n",
            "average row correct: ['96.8', '97.6', '82.1', '95.7', '88.8', '92.5', '98.7', '94.6', '98.6', '72.5', '96.1', '79.5', '93.8', '94.5', '96.3', '95.6', '79.7', '96.3', '81.4', '96.1', '90.8']\n",
            "IoU: ['95.2', '94.2', '57.5', '90.8', '76.0', '73.2', '96.2', '84.2', '90.7', '49.4', '90.6', '72.0', '88.1', '90.5', '90.6', '90.6', '69.0', '88.4', '61.8', '88.9', '73.0']\n",
            "mean IoU: 81.5\n",
            "Epoch: [34] Train  [  0/183]  eta: 0:39:25  lr: 0.000019  loss: 2.4577 (2.4577)  time: 12.9277  data: 0.3671  max mem: 9536\n",
            "Epoch: [34] Train  [ 10/183]  eta: 0:36:38  lr: 0.000018  loss: 2.8685 (2.5936)  time: 12.7062  data: 0.0337  max mem: 9536\n",
            "Epoch: [34] Train  [ 20/183]  eta: 0:34:16  lr: 0.000018  loss: 2.2339 (2.5450)  time: 12.5984  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [ 30/183]  eta: 0:32:10  lr: 0.000018  loss: 2.6776 (2.5819)  time: 12.5729  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [ 40/183]  eta: 0:29:58  lr: 0.000018  loss: 2.6100 (2.5880)  time: 12.5385  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [ 50/183]  eta: 0:27:53  lr: 0.000018  loss: 2.3781 (2.6037)  time: 12.5183  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [ 60/183]  eta: 0:25:48  lr: 0.000018  loss: 2.4008 (2.5915)  time: 12.6103  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [ 70/183]  eta: 0:23:40  lr: 0.000017  loss: 2.6166 (2.5953)  time: 12.5388  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [ 80/183]  eta: 0:21:33  lr: 0.000017  loss: 2.6580 (2.5930)  time: 12.4832  data: 0.0002  max mem: 9536\n",
            "Epoch: [34] Train  [ 90/183]  eta: 0:19:26  lr: 0.000017  loss: 2.1858 (2.5899)  time: 12.4355  data: 0.0002  max mem: 9536\n",
            "Epoch: [34] Train  [100/183]  eta: 0:17:20  lr: 0.000017  loss: 2.6063 (2.5868)  time: 12.4141  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [110/183]  eta: 0:15:14  lr: 0.000017  loss: 2.1702 (2.5792)  time: 12.4737  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [120/183]  eta: 0:13:08  lr: 0.000017  loss: 2.3614 (2.5636)  time: 12.4690  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [130/183]  eta: 0:11:03  lr: 0.000017  loss: 2.8152 (2.5650)  time: 12.4709  data: 0.0002  max mem: 9536\n",
            "Epoch: [34] Train  [140/183]  eta: 0:08:57  lr: 0.000016  loss: 2.4812 (2.5518)  time: 12.4131  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [150/183]  eta: 0:06:52  lr: 0.000016  loss: 2.1818 (2.5424)  time: 12.3419  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [160/183]  eta: 0:04:47  lr: 0.000016  loss: 2.4333 (2.5412)  time: 12.4087  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train  [170/183]  eta: 0:02:42  lr: 0.000016  loss: 2.5626 (2.5439)  time: 12.5230  data: 0.0002  max mem: 9536\n",
            "Epoch: [34] Train  [180/183]  eta: 0:00:37  lr: 0.000016  loss: 2.7231 (2.5496)  time: 12.4881  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Train Total time: 0:38:06\n",
            "Epoch: [34] Test  [  0/242]  eta: 0:05:48    time: 1.4402  data: 0.3664  max mem: 9536\n",
            "Epoch: [34] Test  [ 10/242]  eta: 0:04:01    time: 1.0423  data: 0.0335  max mem: 9536\n",
            "Epoch: [34] Test  [ 20/242]  eta: 0:03:45    time: 0.9940  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [ 30/242]  eta: 0:03:41    time: 1.0441  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [ 40/242]  eta: 0:03:33    time: 1.1009  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [ 50/242]  eta: 0:03:24    time: 1.0985  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [ 60/242]  eta: 0:03:17    time: 1.1441  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [ 70/242]  eta: 0:03:07    time: 1.1533  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [ 80/242]  eta: 0:02:56    time: 1.0962  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [ 90/242]  eta: 0:02:44    time: 1.0469  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [100/242]  eta: 0:02:34    time: 1.0739  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [110/242]  eta: 0:02:22    time: 1.0945  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [120/242]  eta: 0:02:12    time: 1.1108  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [130/242]  eta: 0:02:01    time: 1.0999  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [140/242]  eta: 0:01:50    time: 1.0566  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [150/242]  eta: 0:01:39    time: 1.0607  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [160/242]  eta: 0:01:28    time: 1.0670  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [170/242]  eta: 0:01:18    time: 1.1183  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [180/242]  eta: 0:01:07    time: 1.1843  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [190/242]  eta: 0:00:57    time: 1.1915  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [200/242]  eta: 0:00:46    time: 1.1372  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [210/242]  eta: 0:00:35    time: 1.1163  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [220/242]  eta: 0:00:24    time: 1.1362  data: 0.0003  max mem: 9536\n",
            "Epoch: [34] Test  [230/242]  eta: 0:00:13    time: 1.1317  data: 0.0002  max mem: 9536\n",
            "Epoch: [34] Test  [240/242]  eta: 0:00:02    time: 1.0808  data: 0.0002  max mem: 9536\n",
            "Epoch: [34] Test Total time: 0:04:25\n",
            "global correct: 95.9\n",
            "average row correct: ['97.0', '97.9', '82.4', '96.1', '90.3', '89.8', '99.1', '93.7', '98.2', '69.4', '95.8', '78.5', '94.9', '95.9', '96.3', '95.7', '78.3', '96.5', '82.7', '96.5', '90.7']\n",
            "IoU: ['95.3', '93.1', '59.3', '89.6', '77.0', '76.1', '95.6', '84.5', '91.9', '52.6', '92.1', '70.6', '88.5', '91.6', '90.2', '90.7', '68.4', '87.1', '62.8', '89.3', '73.0']\n",
            "mean IoU: 81.9\n",
            "Epoch: [35] Train  [  0/183]  eta: 0:40:17  lr: 0.000016  loss: 2.6457 (2.6457)  time: 13.2103  data: 0.4391  max mem: 9536\n",
            "Epoch: [35] Train  [ 10/183]  eta: 0:36:13  lr: 0.000016  loss: 2.4446 (2.4646)  time: 12.5646  data: 0.0402  max mem: 9536\n",
            "Epoch: [35] Train  [ 20/183]  eta: 0:34:03  lr: 0.000015  loss: 2.4843 (2.5210)  time: 12.5013  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [ 30/183]  eta: 0:31:55  lr: 0.000015  loss: 2.5957 (2.5222)  time: 12.4973  data: 0.0002  max mem: 9536\n",
            "Epoch: [35] Train  [ 40/183]  eta: 0:29:47  lr: 0.000015  loss: 2.2863 (2.5363)  time: 12.4698  data: 0.0005  max mem: 9536\n",
            "Epoch: [35] Train  [ 50/183]  eta: 0:27:43  lr: 0.000015  loss: 2.5869 (2.5346)  time: 12.4945  data: 0.0005  max mem: 9536\n",
            "Epoch: [35] Train  [ 60/183]  eta: 0:25:39  lr: 0.000015  loss: 2.3245 (2.5380)  time: 12.5469  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [ 70/183]  eta: 0:23:37  lr: 0.000015  loss: 2.6771 (2.5557)  time: 12.6294  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [ 80/183]  eta: 0:21:31  lr: 0.000014  loss: 3.0829 (2.5720)  time: 12.6029  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [ 90/183]  eta: 0:19:27  lr: 0.000014  loss: 3.0503 (2.5675)  time: 12.5711  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [100/183]  eta: 0:17:22  lr: 0.000014  loss: 2.4630 (2.5499)  time: 12.6430  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [110/183]  eta: 0:15:17  lr: 0.000014  loss: 3.0772 (2.5573)  time: 12.6620  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [120/183]  eta: 0:13:11  lr: 0.000014  loss: 2.6081 (2.5464)  time: 12.6271  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [130/183]  eta: 0:11:05  lr: 0.000014  loss: 2.2045 (2.5376)  time: 12.4837  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [140/183]  eta: 0:08:59  lr: 0.000014  loss: 2.8013 (2.5452)  time: 12.4630  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [150/183]  eta: 0:06:54  lr: 0.000013  loss: 2.5964 (2.5406)  time: 12.5451  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [160/183]  eta: 0:04:48  lr: 0.000013  loss: 2.8762 (2.5433)  time: 12.5235  data: 0.0002  max mem: 9536\n",
            "Epoch: [35] Train  [170/183]  eta: 0:02:43  lr: 0.000013  loss: 2.7305 (2.5418)  time: 12.4532  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train  [180/183]  eta: 0:00:37  lr: 0.000013  loss: 2.5484 (2.5435)  time: 12.4182  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Train Total time: 0:38:14\n",
            "Epoch: [35] Test  [  0/242]  eta: 0:05:59    time: 1.4855  data: 0.4136  max mem: 9536\n",
            "Epoch: [35] Test  [ 10/242]  eta: 0:04:04    time: 1.0553  data: 0.0379  max mem: 9536\n",
            "Epoch: [35] Test  [ 20/242]  eta: 0:03:48    time: 1.0069  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [ 30/242]  eta: 0:03:43    time: 1.0538  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [ 40/242]  eta: 0:03:35    time: 1.1062  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [ 50/242]  eta: 0:03:26    time: 1.1038  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [ 60/242]  eta: 0:03:18    time: 1.1368  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [ 70/242]  eta: 0:03:08    time: 1.1448  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [ 80/242]  eta: 0:02:56    time: 1.0880  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [ 90/242]  eta: 0:02:44    time: 1.0386  data: 0.0004  max mem: 9536\n",
            "Epoch: [35] Test  [100/242]  eta: 0:02:34    time: 1.0723  data: 0.0004  max mem: 9536\n",
            "Epoch: [35] Test  [110/242]  eta: 0:02:22    time: 1.0862  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [120/242]  eta: 0:02:12    time: 1.1001  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [130/242]  eta: 0:02:01    time: 1.0901  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [140/242]  eta: 0:01:50    time: 1.0426  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [150/242]  eta: 0:01:39    time: 1.0532  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [160/242]  eta: 0:01:28    time: 1.0635  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [170/242]  eta: 0:01:17    time: 1.1103  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [180/242]  eta: 0:01:07    time: 1.1689  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [190/242]  eta: 0:00:56    time: 1.1780  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [200/242]  eta: 0:00:45    time: 1.1230  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [210/242]  eta: 0:00:34    time: 1.0900  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [220/242]  eta: 0:00:24    time: 1.1013  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [230/242]  eta: 0:00:13    time: 1.1123  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test  [240/242]  eta: 0:00:02    time: 1.0726  data: 0.0003  max mem: 9536\n",
            "Epoch: [35] Test Total time: 0:04:24\n",
            "global correct: 95.8\n",
            "average row correct: ['96.9', '97.6', '80.7', '95.5', '86.9', '91.6', '99.0', '91.6', '98.5', '72.6', '97.3', '77.6', '95.8', '95.0', '95.8', '95.2', '78.7', '96.5', '82.2', '96.2', '90.2']\n",
            "IoU: ['95.2', '94.0', '59.1', '90.5', '76.8', '75.2', '96.0', '84.5', '91.3', '50.1', '90.6', '69.7', '87.2', '89.9', '90.1', '90.5', '68.0', '86.6', '62.2', '89.4', '78.1']\n",
            "mean IoU: 81.7\n",
            "Epoch: [36] Train  [  0/183]  eta: 0:39:53  lr: 0.000013  loss: 2.2317 (2.2317)  time: 13.0815  data: 0.5039  max mem: 9536\n",
            "Epoch: [36] Train  [ 10/183]  eta: 0:36:17  lr: 0.000013  loss: 2.6563 (2.6268)  time: 12.5861  data: 0.0461  max mem: 9536\n",
            "Epoch: [36] Train  [ 20/183]  eta: 0:34:08  lr: 0.000013  loss: 2.2674 (2.5929)  time: 12.5439  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [ 30/183]  eta: 0:31:55  lr: 0.000012  loss: 2.3568 (2.5978)  time: 12.4783  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [ 40/183]  eta: 0:29:51  lr: 0.000012  loss: 2.4839 (2.5729)  time: 12.4883  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [ 50/183]  eta: 0:27:48  lr: 0.000012  loss: 2.4375 (2.5644)  time: 12.5980  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [ 60/183]  eta: 0:25:43  lr: 0.000012  loss: 2.6571 (2.5355)  time: 12.5831  data: 0.0002  max mem: 9536\n",
            "Epoch: [36] Train  [ 70/183]  eta: 0:23:35  lr: 0.000012  loss: 2.9858 (2.5264)  time: 12.4762  data: 0.0002  max mem: 9536\n",
            "Epoch: [36] Train  [ 80/183]  eta: 0:21:31  lr: 0.000012  loss: 2.3535 (2.5281)  time: 12.4959  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [ 90/183]  eta: 0:19:26  lr: 0.000011  loss: 2.1926 (2.5149)  time: 12.5949  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Train  [100/183]  eta: 0:17:21  lr: 0.000011  loss: 2.6662 (2.5157)  time: 12.6112  data: 0.0005  max mem: 9536\n",
            "Epoch: [36] Train  [110/183]  eta: 0:15:15  lr: 0.000011  loss: 2.7065 (2.5109)  time: 12.5154  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Train  [120/183]  eta: 0:13:10  lr: 0.000011  loss: 2.4050 (2.5161)  time: 12.5033  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [130/183]  eta: 0:11:04  lr: 0.000011  loss: 2.9798 (2.5324)  time: 12.5356  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [140/183]  eta: 0:08:58  lr: 0.000011  loss: 2.8871 (2.5330)  time: 12.4669  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [150/183]  eta: 0:06:53  lr: 0.000010  loss: 2.3335 (2.5344)  time: 12.4689  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [160/183]  eta: 0:04:48  lr: 0.000010  loss: 2.7343 (2.5354)  time: 12.5117  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [170/183]  eta: 0:02:42  lr: 0.000010  loss: 2.2890 (2.5264)  time: 12.5001  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Train  [180/183]  eta: 0:00:37  lr: 0.000010  loss: 2.2767 (2.5268)  time: 12.5412  data: 0.0002  max mem: 9536\n",
            "Epoch: [36] Train Total time: 0:38:13\n",
            "Epoch: [36] Test  [  0/242]  eta: 0:05:57    time: 1.4765  data: 0.4030  max mem: 9536\n",
            "Epoch: [36] Test  [ 10/242]  eta: 0:04:04    time: 1.0528  data: 0.0369  max mem: 9536\n",
            "Epoch: [36] Test  [ 20/242]  eta: 0:03:47    time: 1.0007  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [ 30/242]  eta: 0:03:42    time: 1.0502  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [ 40/242]  eta: 0:03:34    time: 1.1069  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [ 50/242]  eta: 0:03:25    time: 1.1031  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [ 60/242]  eta: 0:03:18    time: 1.1425  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [ 70/242]  eta: 0:03:07    time: 1.1478  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [ 80/242]  eta: 0:02:56    time: 1.0838  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [ 90/242]  eta: 0:02:44    time: 1.0365  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [100/242]  eta: 0:02:34    time: 1.0724  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [110/242]  eta: 0:02:22    time: 1.0890  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [120/242]  eta: 0:02:12    time: 1.1000  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [130/242]  eta: 0:02:01    time: 1.0922  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [140/242]  eta: 0:01:50    time: 1.0515  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [150/242]  eta: 0:01:39    time: 1.0568  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [160/242]  eta: 0:01:28    time: 1.0630  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [170/242]  eta: 0:01:18    time: 1.1139  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [180/242]  eta: 0:01:07    time: 1.1738  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [190/242]  eta: 0:00:56    time: 1.1768  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [200/242]  eta: 0:00:45    time: 1.1252  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [210/242]  eta: 0:00:35    time: 1.1019  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [220/242]  eta: 0:00:24    time: 1.1106  data: 0.0004  max mem: 9536\n",
            "Epoch: [36] Test  [230/242]  eta: 0:00:13    time: 1.1140  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test  [240/242]  eta: 0:00:02    time: 1.0815  data: 0.0003  max mem: 9536\n",
            "Epoch: [36] Test Total time: 0:04:24\n",
            "global correct: 96.0\n",
            "average row correct: ['97.2', '96.2', '75.1', '95.5', '87.1', '88.0', '98.8', '90.8', '98.1', '72.5', '96.8', '77.4', '95.3', '96.0', '96.1', '96.0', '77.0', '96.0', '82.2', '95.8', '90.7']\n",
            "IoU: ['95.4', '93.4', '58.8', '90.1', '77.3', '76.0', '96.4', '85.1', '92.3', '51.1', '92.6', '69.6', '88.9', '91.0', '90.3', '90.7', '68.1', '89.8', '62.9', '88.8', '73.6']\n",
            "mean IoU: 82.0\n",
            "Epoch: [37] Train  [  0/183]  eta: 0:39:49  lr: 0.000010  loss: 2.5106 (2.5106)  time: 13.0580  data: 0.4059  max mem: 9536\n",
            "Epoch: [37] Train  [ 10/183]  eta: 0:36:21  lr: 0.000010  loss: 2.4089 (2.5916)  time: 12.6101  data: 0.0372  max mem: 9536\n",
            "Epoch: [37] Train  [ 20/183]  eta: 0:34:12  lr: 0.000010  loss: 2.8426 (2.5462)  time: 12.5691  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Train  [ 30/183]  eta: 0:32:05  lr: 0.000009  loss: 2.3595 (2.5246)  time: 12.5720  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Train  [ 40/183]  eta: 0:29:52  lr: 0.000009  loss: 2.5178 (2.5002)  time: 12.4683  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Train  [ 50/183]  eta: 0:27:47  lr: 0.000009  loss: 2.7011 (2.4905)  time: 12.4708  data: 0.0002  max mem: 9536\n",
            "Epoch: [37] Train  [ 60/183]  eta: 0:25:41  lr: 0.000009  loss: 2.4392 (2.4846)  time: 12.5398  data: 0.0002  max mem: 9536\n",
            "Epoch: [37] Train  [ 70/183]  eta: 0:23:35  lr: 0.000009  loss: 2.8937 (2.4943)  time: 12.4867  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Train  [ 80/183]  eta: 0:21:30  lr: 0.000009  loss: 2.3336 (2.4817)  time: 12.4964  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Train  [ 90/183]  eta: 0:19:25  lr: 0.000008  loss: 2.3630 (2.4976)  time: 12.5732  data: 0.0002  max mem: 9536\n",
            "Epoch: [37] Train  [100/183]  eta: 0:17:20  lr: 0.000008  loss: 2.9064 (2.5207)  time: 12.6005  data: 0.0002  max mem: 9536\n",
            "Epoch: [37] Train  [110/183]  eta: 0:15:14  lr: 0.000008  loss: 2.5134 (2.5176)  time: 12.5192  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Train  [120/183]  eta: 0:13:08  lr: 0.000008  loss: 2.2828 (2.5141)  time: 12.4294  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Train  [130/183]  eta: 0:11:03  lr: 0.000008  loss: 2.4088 (2.5111)  time: 12.4319  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Train  [140/183]  eta: 0:08:58  lr: 0.000008  loss: 2.3388 (2.5174)  time: 12.4602  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Train  [150/183]  eta: 0:06:52  lr: 0.000007  loss: 2.2092 (2.5184)  time: 12.4672  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Train  [160/183]  eta: 0:04:47  lr: 0.000007  loss: 2.1955 (2.5279)  time: 12.4373  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Train  [170/183]  eta: 0:02:42  lr: 0.000007  loss: 2.3875 (2.5318)  time: 12.4242  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Train  [180/183]  eta: 0:00:37  lr: 0.000007  loss: 2.5428 (2.5298)  time: 12.4196  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Train Total time: 0:38:06\n",
            "Epoch: [37] Test  [  0/242]  eta: 0:06:02    time: 1.4966  data: 0.4232  max mem: 9536\n",
            "Epoch: [37] Test  [ 10/242]  eta: 0:04:05    time: 1.0594  data: 0.0388  max mem: 9536\n",
            "Epoch: [37] Test  [ 20/242]  eta: 0:03:47    time: 1.0035  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [ 30/242]  eta: 0:03:43    time: 1.0489  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Test  [ 40/242]  eta: 0:03:36    time: 1.1137  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Test  [ 50/242]  eta: 0:03:26    time: 1.1144  data: 0.0005  max mem: 9536\n",
            "Epoch: [37] Test  [ 60/242]  eta: 0:03:19    time: 1.1429  data: 0.0005  max mem: 9536\n",
            "Epoch: [37] Test  [ 70/242]  eta: 0:03:08    time: 1.1445  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [ 80/242]  eta: 0:02:56    time: 1.0857  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [ 90/242]  eta: 0:02:44    time: 1.0376  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Test  [100/242]  eta: 0:02:34    time: 1.0684  data: 0.0005  max mem: 9536\n",
            "Epoch: [37] Test  [110/242]  eta: 0:02:23    time: 1.0863  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [120/242]  eta: 0:02:13    time: 1.1077  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [130/242]  eta: 0:02:01    time: 1.0966  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [140/242]  eta: 0:01:50    time: 1.0446  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [150/242]  eta: 0:01:39    time: 1.0515  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [160/242]  eta: 0:01:28    time: 1.0662  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [170/242]  eta: 0:01:18    time: 1.1219  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [180/242]  eta: 0:01:07    time: 1.1820  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [190/242]  eta: 0:00:57    time: 1.1842  data: 0.0005  max mem: 9536\n",
            "Epoch: [37] Test  [200/242]  eta: 0:00:46    time: 1.1280  data: 0.0005  max mem: 9536\n",
            "Epoch: [37] Test  [210/242]  eta: 0:00:35    time: 1.1001  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test  [220/242]  eta: 0:00:24    time: 1.1102  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Test  [230/242]  eta: 0:00:13    time: 1.1115  data: 0.0004  max mem: 9536\n",
            "Epoch: [37] Test  [240/242]  eta: 0:00:02    time: 1.0687  data: 0.0003  max mem: 9536\n",
            "Epoch: [37] Test Total time: 0:04:25\n",
            "global correct: 95.9\n",
            "average row correct: ['96.9', '97.9', '86.5', '95.9', '90.1', '92.6', '98.9', '94.3', '98.6', '69.3', '96.2', '77.0', '95.2', '95.6', '96.0', '95.3', '81.1', '96.7', '81.0', '97.1', '90.8']\n",
            "IoU: ['95.3', '94.2', '58.5', '90.9', '75.3', '73.1', '95.7', '84.2', '90.8', '52.3', '91.9', '70.8', '86.6', '91.3', '89.8', '90.6', '67.8', '85.1', '63.6', '89.8', '74.7']\n",
            "mean IoU: 81.5\n",
            "Epoch: [38] Train  [  0/183]  eta: 0:39:39  lr: 0.000007  loss: 2.3959 (2.3959)  time: 13.0009  data: 0.3942  max mem: 9536\n",
            "Epoch: [38] Train  [ 10/183]  eta: 0:36:28  lr: 0.000007  loss: 2.3028 (2.5712)  time: 12.6511  data: 0.0362  max mem: 9536\n",
            "Epoch: [38] Train  [ 20/183]  eta: 0:34:09  lr: 0.000007  loss: 2.3924 (2.5342)  time: 12.5543  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Train  [ 30/183]  eta: 0:31:58  lr: 0.000006  loss: 2.5602 (2.5203)  time: 12.4765  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [ 40/183]  eta: 0:29:52  lr: 0.000006  loss: 2.3417 (2.5159)  time: 12.4852  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Train  [ 50/183]  eta: 0:27:47  lr: 0.000006  loss: 2.2887 (2.5261)  time: 12.5335  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Train  [ 60/183]  eta: 0:25:42  lr: 0.000006  loss: 2.7242 (2.5386)  time: 12.5687  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [ 70/183]  eta: 0:23:34  lr: 0.000006  loss: 2.2063 (2.5463)  time: 12.4761  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Train  [ 80/183]  eta: 0:21:28  lr: 0.000006  loss: 2.6537 (2.5303)  time: 12.4189  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [ 90/183]  eta: 0:19:23  lr: 0.000005  loss: 2.5786 (2.5308)  time: 12.4917  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [100/183]  eta: 0:17:16  lr: 0.000005  loss: 2.4651 (2.5344)  time: 12.4138  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [110/183]  eta: 0:15:12  lr: 0.000005  loss: 2.8842 (2.5410)  time: 12.4075  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [120/183]  eta: 0:13:07  lr: 0.000005  loss: 2.5394 (2.5597)  time: 12.5100  data: 0.0002  max mem: 9536\n",
            "Epoch: [38] Train  [130/183]  eta: 0:11:02  lr: 0.000005  loss: 2.5382 (2.5556)  time: 12.5253  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [140/183]  eta: 0:08:57  lr: 0.000004  loss: 2.3855 (2.5571)  time: 12.5060  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Train  [150/183]  eta: 0:06:52  lr: 0.000004  loss: 2.5394 (2.5681)  time: 12.5632  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [160/183]  eta: 0:04:47  lr: 0.000004  loss: 2.5923 (2.5612)  time: 12.6146  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train  [170/183]  eta: 0:02:42  lr: 0.000004  loss: 2.5050 (2.5613)  time: 12.5402  data: 0.0002  max mem: 9536\n",
            "Epoch: [38] Train  [180/183]  eta: 0:00:37  lr: 0.000004  loss: 2.2699 (2.5566)  time: 12.4396  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Train Total time: 0:38:07\n",
            "Epoch: [38] Test  [  0/242]  eta: 0:06:02    time: 1.4973  data: 0.4225  max mem: 9536\n",
            "Epoch: [38] Test  [ 10/242]  eta: 0:04:05    time: 1.0588  data: 0.0388  max mem: 9536\n",
            "Epoch: [38] Test  [ 20/242]  eta: 0:03:48    time: 1.0053  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Test  [ 30/242]  eta: 0:03:44    time: 1.0595  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Test  [ 40/242]  eta: 0:03:36    time: 1.1199  data: 0.0005  max mem: 9536\n",
            "Epoch: [38] Test  [ 50/242]  eta: 0:03:26    time: 1.1068  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Test  [ 60/242]  eta: 0:03:19    time: 1.1362  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [ 70/242]  eta: 0:03:08    time: 1.1463  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [ 80/242]  eta: 0:02:57    time: 1.0935  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [ 90/242]  eta: 0:02:44    time: 1.0428  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Test  [100/242]  eta: 0:02:34    time: 1.0748  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Test  [110/242]  eta: 0:02:23    time: 1.0884  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [120/242]  eta: 0:02:13    time: 1.1030  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [130/242]  eta: 0:02:01    time: 1.0930  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Test  [140/242]  eta: 0:01:50    time: 1.0516  data: 0.0005  max mem: 9536\n",
            "Epoch: [38] Test  [150/242]  eta: 0:01:39    time: 1.0642  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Test  [160/242]  eta: 0:01:28    time: 1.0669  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [170/242]  eta: 0:01:18    time: 1.1196  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [180/242]  eta: 0:01:07    time: 1.1974  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [190/242]  eta: 0:00:57    time: 1.1933  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [200/242]  eta: 0:00:46    time: 1.1298  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [210/242]  eta: 0:00:35    time: 1.1086  data: 0.0004  max mem: 9536\n",
            "Epoch: [38] Test  [220/242]  eta: 0:00:24    time: 1.1029  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [230/242]  eta: 0:00:13    time: 1.1057  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test  [240/242]  eta: 0:00:02    time: 1.0788  data: 0.0003  max mem: 9536\n",
            "Epoch: [38] Test Total time: 0:04:25\n",
            "global correct: 95.9\n",
            "average row correct: ['97.0', '97.7', '78.9', '96.5', '87.3', '91.8', '99.1', '92.3', '98.7', '72.1', '96.5', '76.0', '94.6', '95.8', '96.1', '95.6', '81.8', '96.6', '80.3', '96.7', '91.1']\n",
            "IoU: ['95.3', '94.0', '59.3', '89.7', '76.2', '74.6', '96.1', '85.2', '90.5', '51.9', '91.7', '69.9', '87.5', '91.6', '90.5', '90.8', '67.7', '88.5', '64.0', '88.9', '71.9']\n",
            "mean IoU: 81.7\n",
            "Epoch: [39] Train  [  0/183]  eta: 0:39:45  lr: 0.000004  loss: 2.4314 (2.4314)  time: 13.0329  data: 0.4299  max mem: 9536\n",
            "Epoch: [39] Train  [ 10/183]  eta: 0:36:39  lr: 0.000003  loss: 2.6746 (2.7283)  time: 12.7149  data: 0.0393  max mem: 9536\n",
            "Epoch: [39] Train  [ 20/183]  eta: 0:34:20  lr: 0.000003  loss: 2.1058 (2.6492)  time: 12.6214  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [ 30/183]  eta: 0:32:03  lr: 0.000003  loss: 2.5954 (2.5808)  time: 12.4983  data: 0.0004  max mem: 9536\n",
            "Epoch: [39] Train  [ 40/183]  eta: 0:29:58  lr: 0.000003  loss: 2.7480 (2.6034)  time: 12.5096  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [ 50/183]  eta: 0:27:49  lr: 0.000003  loss: 2.4233 (2.6008)  time: 12.5115  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [ 60/183]  eta: 0:25:43  lr: 0.000003  loss: 2.1966 (2.5789)  time: 12.4840  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [ 70/183]  eta: 0:23:38  lr: 0.000002  loss: 2.7513 (2.5721)  time: 12.5692  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [ 80/183]  eta: 0:21:32  lr: 0.000002  loss: 2.4921 (2.5797)  time: 12.5682  data: 0.0004  max mem: 9536\n",
            "Epoch: [39] Train  [ 90/183]  eta: 0:19:26  lr: 0.000002  loss: 2.5459 (2.5614)  time: 12.4942  data: 0.0004  max mem: 9536\n",
            "Epoch: [39] Train  [100/183]  eta: 0:17:21  lr: 0.000002  loss: 2.2847 (2.5438)  time: 12.5092  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [110/183]  eta: 0:15:14  lr: 0.000002  loss: 2.5214 (2.5450)  time: 12.4715  data: 0.0004  max mem: 9536\n",
            "Epoch: [39] Train  [120/183]  eta: 0:13:10  lr: 0.000001  loss: 2.4932 (2.5351)  time: 12.5278  data: 0.0004  max mem: 9536\n",
            "Epoch: [39] Train  [130/183]  eta: 0:11:04  lr: 0.000001  loss: 3.7411 (2.5363)  time: 12.5423  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [140/183]  eta: 0:08:59  lr: 0.000001  loss: 2.3469 (2.5290)  time: 12.5158  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [150/183]  eta: 0:06:53  lr: 0.000001  loss: 2.7756 (2.5293)  time: 12.5798  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [160/183]  eta: 0:04:48  lr: 0.000001  loss: 2.2381 (2.5342)  time: 12.4540  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Train  [170/183]  eta: 0:02:42  lr: 0.000000  loss: 2.8880 (2.5411)  time: 12.4702  data: 0.0005  max mem: 9536\n",
            "Epoch: [39] Train  [180/183]  eta: 0:00:37  lr: 0.000000  loss: 2.8375 (2.5417)  time: 12.5941  data: 0.0005  max mem: 9536\n",
            "Epoch: [39] Train Total time: 0:38:14\n",
            "Epoch: [39] Test  [  0/242]  eta: 0:06:05    time: 1.5113  data: 0.4182  max mem: 9536\n",
            "Epoch: [39] Test  [ 10/242]  eta: 0:04:05    time: 1.0574  data: 0.0383  max mem: 9536\n",
            "Epoch: [39] Test  [ 20/242]  eta: 0:03:48    time: 1.0030  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [ 30/242]  eta: 0:03:43    time: 1.0522  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [ 40/242]  eta: 0:03:35    time: 1.1071  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [ 50/242]  eta: 0:03:26    time: 1.1027  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [ 60/242]  eta: 0:03:18    time: 1.1377  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [ 70/242]  eta: 0:03:08    time: 1.1458  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [ 80/242]  eta: 0:02:56    time: 1.0872  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [ 90/242]  eta: 0:02:44    time: 1.0344  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [100/242]  eta: 0:02:34    time: 1.0711  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [110/242]  eta: 0:02:22    time: 1.0902  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [120/242]  eta: 0:02:12    time: 1.1010  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [130/242]  eta: 0:02:01    time: 1.0921  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [140/242]  eta: 0:01:50    time: 1.0463  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [150/242]  eta: 0:01:39    time: 1.0620  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [160/242]  eta: 0:01:28    time: 1.0702  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [170/242]  eta: 0:01:18    time: 1.1168  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [180/242]  eta: 0:01:07    time: 1.1805  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [190/242]  eta: 0:00:56    time: 1.1798  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test  [200/242]  eta: 0:00:46    time: 1.1346  data: 0.0004  max mem: 9536\n",
            "Epoch: [39] Test  [210/242]  eta: 0:00:35    time: 1.1049  data: 0.0005  max mem: 9536\n",
            "Epoch: [39] Test  [220/242]  eta: 0:00:24    time: 1.1069  data: 0.0004  max mem: 9536\n",
            "Epoch: [39] Test  [230/242]  eta: 0:00:13    time: 1.1188  data: 0.0004  max mem: 9536\n",
            "Epoch: [39] Test  [240/242]  eta: 0:00:02    time: 1.0787  data: 0.0003  max mem: 9536\n",
            "Epoch: [39] Test Total time: 0:04:25\n",
            "global correct: 95.9\n",
            "average row correct: ['96.9', '97.9', '80.5', '97.2', '88.4', '90.7', '99.0', '93.1', '98.0', '73.7', '95.0', '78.9', '95.3', '96.3', '95.5', '96.0', '81.1', '96.9', '81.1', '96.7', '90.4']\n",
            "IoU: ['95.3', '93.9', '59.2', '90.5', '74.7', '77.2', '95.6', '84.3', '91.7', '49.2', '91.6', '70.7', '88.8', '91.0', '90.4', '90.9', '69.5', '83.8', '61.3', '89.6', '77.0']\n",
            "mean IoU: 81.7\n",
            "Training time 1 day, 4:33:07\n",
            "wandb: Waiting for W&B process to finish... (success).\n",
            "wandb: - 0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\n",
            "wandb: Run history:\n",
            "wandb: acc_global \n",
            "wandb:   best_IOU \n",
            "wandb:      epoch \n",
            "wandb:         lr \n",
            "wandb:       mIOU \n",
            "wandb:  mean_loss \n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb: acc_global 0.95872\n",
            "wandb:   best_IOU 82.17763\n",
            "wandb:      epoch 39\n",
            "wandb:         lr 0.0\n",
            "wandb:       mIOU 81.73599\n",
            "wandb:  mean_loss 2.54139\n",
            "wandb: \n",
            "wandb: You can sync this run to the cloud by running:\n",
            "wandb: wandb sync /home/zk/GIT/working/DCNet/wandb/offline-run-20230406_095632-2cp7o2ib\n",
            "wandb: Find logs at: ./wandb/offline-run-20230406_095632-2cp7o2ib/logs\n"
          ]
        }
      ],
      "source": [
        "# simsiam crop180\n",
        "!experiment_name=\"debug\";cd ../ ;\\\n",
        "    name_date=\"${experiment_name}/$(date +%Y-%m%d-%H%M%S)\";\\\n",
        "    dir=\"./results/${name_date}\";mkdir -p ${dir};dir_log=\"${dir}/output.log\";\\\n",
        "CUDA_VISIBLE_DEVICES=1 torchrun --nproc_per_node=1 --master_port=1234 train_multi_GPU.py \\\n",
        "    --wandb True --wandb_model dryrun --sync_bn False --amp True --aux False \\\n",
        "    --model_name aspp_contrast_resnet101 --pre_trained deeplabv3_resnet101_coco.pth \\\n",
        "    --weight_only_backbone False --lr 0.0001 \\\n",
        "    --data_path pascal-voc-2012 --num_classes 21 --data_train_type train.txt \\\n",
        "    --epochs 40 --batch_size 8 --batch_size_val 6 --memory_size 32768 \\\n",
        "    --contrast 0 --L1_loss 0.1 --L2_loss 0.1 --L3_loss 0.1\\\n",
        "    --loss_name aspp_loss --sample adapt_excite_8 \\\n",
        "    --name_date $name_date \\\n",
        "    2>&1 | tee $dir_log"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
