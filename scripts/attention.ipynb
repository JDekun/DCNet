{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "| distributed init (rank 0): env://\n",
      "| distributed init (rank 1): env://\n",
      "attention/2023-0408-085750\n",
      "Namespace(data_path='pascal-voc-2012', data_train_type='train.txt', device='cuda', num_classes=21, batch_size=6, batch_size_val=6, aux=False, start_epoch=0, epochs=40, sync_bn=False, workers=2, lr=0.0001, momentum=0.9, weight_decay=0.0001, print_freq=10, checkpoint_dir='./results/attention/2023-0408-085750', resume='', test_only=False, world_size=2, dist_url='env://', amp=True, seed=304, name_date='attention/2023-0408-085750', wandb=False, wandb_model='run', run_name='', model_name='aspp_contrast_resnet101', project_dim=128, loss_name='aspp_loss', contrast=0, pre_trained='deeplabv3_resnet101_coco.pth', L3_loss=0.1, L2_loss=0.1, L1_loss=0.1, GAcc=1, memory_size=0, proj_dim=128, network_stride=8, pixel_update_freq=10, ddp=False, weight_only_backbone=False, sample='adapt_excite_8', attention='selfattention', rank=0, gpu=0, distributed=True, dist_backend='nccl')\n",
      "Creating data loaders\n",
      "Creating model\n",
      "missing_keys:  ['contrast.convs.0.0.weight', 'contrast.convs.0.1.weight', 'contrast.convs.0.1.bias', 'contrast.convs.0.1.running_mean', 'contrast.convs.0.1.running_var', 'contrast.convs.0.3.weight', 'contrast.convs.0.4.weight', 'contrast.convs.0.4.bias', 'contrast.convs.0.4.running_mean', 'contrast.convs.0.4.running_var', 'contrast.convs.1.0.weight', 'contrast.convs.1.1.weight', 'contrast.convs.1.1.bias', 'contrast.convs.1.1.running_mean', 'contrast.convs.1.1.running_var', 'contrast.convs.1.3.weight', 'contrast.convs.1.4.weight', 'contrast.convs.1.4.bias', 'contrast.convs.1.4.running_mean', 'contrast.convs.1.4.running_var', 'contrast.convs.2.0.weight', 'contrast.convs.2.1.weight', 'contrast.convs.2.1.bias', 'contrast.convs.2.1.running_mean', 'contrast.convs.2.1.running_var', 'contrast.convs.2.3.weight', 'contrast.convs.2.4.weight', 'contrast.convs.2.4.bias', 'contrast.convs.2.4.running_mean', 'contrast.convs.2.4.running_var', 'attention.fc_q.weight', 'attention.fc_q.bias', 'attention.fc_k.weight', 'attention.fc_k.bias', 'attention.fc_v.weight', 'attention.fc_v.bias', 'attention.fc_o.weight', 'attention.fc_o.bias']\n",
      "unexpected_keys:  ['aux_classifier.0.weight', 'aux_classifier.1.weight', 'aux_classifier.1.bias', 'aux_classifier.1.running_mean', 'aux_classifier.1.running_var', 'aux_classifier.1.num_batches_tracked', 'aux_classifier.4.weight', 'aux_classifier.4.bias']\n",
      "DistributedDataParallel(\n",
      "  (module): DeepLabV3(\n",
      "    (backbone): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (6): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (7): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (8): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (9): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (10): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (11): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (12): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (13): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (14): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (15): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (16): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (17): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (18): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (19): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (20): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (21): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (22): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): DeepLabHead(\n",
      "      (0): ASPP(\n",
      "        (convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): ASPPPooling(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (contrast): contrast_head(\n",
      "      (convs): ModuleList(\n",
      "        (0): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attention): ScaledDotProductAttention(\n",
      "      (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Start training\n",
      "Epoch: [0] Train  [  0/122]  eta: 0:25:19  lr: 0.000001  loss: 0.8275 (0.8275)  time: 12.4521  data: 0.4900  max mem: 8116\n",
      "Epoch: [0] Train  [ 10/122]  eta: 0:18:42  lr: 0.000009  loss: 0.9973 (1.2615)  time: 10.0246  data: 0.0451  max mem: 8593\n",
      "Epoch: [0] Train  [ 20/122]  eta: 0:16:52  lr: 0.000017  loss: 0.6349 (1.1748)  time: 9.7952  data: 0.0004  max mem: 8593\n",
      "Epoch: [0] Train  [ 30/122]  eta: 0:15:02  lr: 0.000025  loss: 0.9844 (1.2713)  time: 9.6879  data: 0.0002  max mem: 8593\n",
      "Epoch: [0] Train  [ 40/122]  eta: 0:13:20  lr: 0.000034  loss: 0.6801 (1.2460)  time: 9.6067  data: 0.0002  max mem: 8593\n",
      "Epoch: [0] Train  [ 50/122]  eta: 0:11:42  lr: 0.000042  loss: 0.8187 (1.1937)  time: 9.6748  data: 0.0004  max mem: 8593\n",
      "Epoch: [0] Train  [ 60/122]  eta: 0:10:04  lr: 0.000050  loss: 1.0468 (1.1367)  time: 9.7282  data: 0.0004  max mem: 8593\n",
      "Epoch: [0] Train  [ 70/122]  eta: 0:08:26  lr: 0.000058  loss: 1.2383 (1.1554)  time: 9.7062  data: 0.0002  max mem: 8593\n",
      "Epoch: [0] Train  [ 80/122]  eta: 0:06:48  lr: 0.000066  loss: 0.5728 (1.1764)  time: 9.6381  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Train  [ 90/122]  eta: 0:05:11  lr: 0.000075  loss: 2.5611 (1.1728)  time: 9.6415  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Train  [100/122]  eta: 0:03:33  lr: 0.000083  loss: 0.6705 (1.1540)  time: 9.6879  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Train  [110/122]  eta: 0:01:56  lr: 0.000091  loss: 0.8859 (1.1533)  time: 9.7053  data: 0.0004  max mem: 8593\n",
      "Epoch: [0] Train  [120/122]  eta: 0:00:19  lr: 0.000099  loss: 0.8906 (1.1336)  time: 9.6672  data: 0.0004  max mem: 8593\n",
      "Epoch: [0] Train Total time: 0:19:45\n",
      "Epoch: [0] Test  [  0/121]  eta: 0:05:10    time: 2.5641  data: 0.6194  max mem: 8593\n",
      "Epoch: [0] Test  [ 10/121]  eta: 0:02:03    time: 1.1103  data: 0.0565  max mem: 8593\n",
      "Epoch: [0] Test  [ 20/121]  eta: 0:01:44    time: 0.9620  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Test  [ 30/121]  eta: 0:01:34    time: 1.0038  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Test  [ 40/121]  eta: 0:01:23    time: 1.0317  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Test  [ 50/121]  eta: 0:01:13    time: 1.0353  data: 0.0002  max mem: 8593\n",
      "Epoch: [0] Test  [ 60/121]  eta: 0:01:02    time: 1.0205  data: 0.0004  max mem: 8593\n",
      "Epoch: [0] Test  [ 70/121]  eta: 0:00:51    time: 0.9272  data: 0.0004  max mem: 8593\n",
      "Epoch: [0] Test  [ 80/121]  eta: 0:00:41    time: 0.9308  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Test  [ 90/121]  eta: 0:00:32    time: 1.1256  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Test  [100/121]  eta: 0:00:21    time: 1.1562  data: 0.0003  max mem: 8593\n",
      "Epoch: [0] Test  [110/121]  eta: 0:00:11    time: 0.9994  data: 0.0002  max mem: 8593\n",
      "Epoch: [0] Test  [120/121]  eta: 0:00:01    time: 0.9786  data: 0.0002  max mem: 8593\n",
      "Epoch: [0] Test Total time: 0:02:04\n",
      "global correct: 95.0\n",
      "average row correct: ['97.7', '93.9', '76.3', '90.8', '76.6', '66.5', '97.0', '77.9', '94.2', '63.0', '93.2', '59.5', '88.4', '92.5', '93.7', '96.3', '68.1', '93.6', '82.5', '92.3', '77.4']\n",
      "IoU: ['94.2', '91.4', '39.8', '88.1', '70.1', '63.0', '95.8', '73.9', '91.4', '50.3', '92.0', '54.8', '86.2', '88.3', '88.7', '89.1', '61.5', '89.5', '61.6', '89.0', '76.1']\n",
      "mean IoU: 77.8\n",
      "Epoch: [1] Train  [  0/122]  eta: 0:20:26  lr: 0.000100  loss: 1.3785 (1.3785)  time: 10.0566  data: 0.3939  max mem: 8593\n",
      "Epoch: [1] Train  [ 10/122]  eta: 0:18:13  lr: 0.000100  loss: 1.8785 (1.0183)  time: 9.7600  data: 0.0360  max mem: 8593\n",
      "Epoch: [1] Train  [ 20/122]  eta: 0:16:30  lr: 0.000100  loss: 1.8937 (0.9845)  time: 9.6914  data: 0.0002  max mem: 8593\n",
      "Epoch: [1] Train  [ 30/122]  eta: 0:14:54  lr: 0.000099  loss: 0.8643 (0.9466)  time: 9.7058  data: 0.0002  max mem: 8593\n",
      "Epoch: [1] Train  [ 40/122]  eta: 0:13:16  lr: 0.000099  loss: 0.9357 (0.9601)  time: 9.7273  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Train  [ 50/122]  eta: 0:11:39  lr: 0.000099  loss: 1.1324 (0.9421)  time: 9.7101  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Train  [ 60/122]  eta: 0:10:01  lr: 0.000099  loss: 0.5312 (0.9357)  time: 9.6884  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Train  [ 70/122]  eta: 0:08:24  lr: 0.000099  loss: 1.0086 (0.9500)  time: 9.6600  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Train  [ 80/122]  eta: 0:06:47  lr: 0.000098  loss: 0.5421 (0.9504)  time: 9.6510  data: 0.0002  max mem: 8593\n",
      "Epoch: [1] Train  [ 90/122]  eta: 0:05:09  lr: 0.000098  loss: 0.4801 (0.9497)  time: 9.6198  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Train  [100/122]  eta: 0:03:33  lr: 0.000098  loss: 0.4968 (0.9315)  time: 9.6325  data: 0.0004  max mem: 8593\n",
      "Epoch: [1] Train  [110/122]  eta: 0:01:56  lr: 0.000098  loss: 1.0472 (0.9125)  time: 9.6505  data: 0.0004  max mem: 8593\n",
      "Epoch: [1] Train  [120/122]  eta: 0:00:19  lr: 0.000098  loss: 0.7045 (0.9100)  time: 9.6617  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Train Total time: 0:19:40\n",
      "Epoch: [1] Test  [  0/121]  eta: 0:04:04    time: 2.0220  data: 0.5809  max mem: 8593\n",
      "Epoch: [1] Test  [ 10/121]  eta: 0:01:57    time: 1.0565  data: 0.0531  max mem: 8593\n",
      "Epoch: [1] Test  [ 20/121]  eta: 0:01:41    time: 0.9551  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Test  [ 30/121]  eta: 0:01:32    time: 1.0002  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Test  [ 40/121]  eta: 0:01:22    time: 1.0299  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Test  [ 50/121]  eta: 0:01:12    time: 1.0336  data: 0.0005  max mem: 8593\n",
      "Epoch: [1] Test  [ 60/121]  eta: 0:01:02    time: 1.0219  data: 0.0005  max mem: 8593\n",
      "Epoch: [1] Test  [ 70/121]  eta: 0:00:50    time: 0.9285  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Test  [ 80/121]  eta: 0:00:40    time: 0.9283  data: 0.0007  max mem: 8593\n",
      "Epoch: [1] Test  [ 90/121]  eta: 0:00:31    time: 1.1120  data: 0.0007  max mem: 8593\n",
      "Epoch: [1] Test  [100/121]  eta: 0:00:21    time: 1.1464  data: 0.0005  max mem: 8593\n",
      "Epoch: [1] Test  [110/121]  eta: 0:00:11    time: 1.0004  data: 0.0005  max mem: 8593\n",
      "Epoch: [1] Test  [120/121]  eta: 0:00:01    time: 0.9799  data: 0.0003  max mem: 8593\n",
      "Epoch: [1] Test Total time: 0:02:03\n",
      "global correct: 95.1\n",
      "average row correct: ['96.7', '96.2', '82.3', '96.2', '83.0', '78.7', '98.3', '83.3', '96.6', '69.8', '95.4', '61.5', '94.8', '92.0', '95.8', '96.0', '72.7', '95.5', '84.8', '97.2', '86.1']\n",
      "IoU: ['94.3', '90.6', '41.9', '87.8', '73.4', '71.1', '96.6', '75.7', '92.6', '47.4', '91.1', '56.3', '90.2', '89.1', '89.2', '89.2', '61.3', '88.0', '60.4', '90.1', '79.4']\n",
      "mean IoU: 78.8\n",
      "Epoch: [2] Train  [  0/122]  eta: 0:19:35  lr: 0.000098  loss: 0.8064 (0.8064)  time: 9.6334  data: 0.4499  max mem: 8593\n",
      "Epoch: [2] Train  [ 10/122]  eta: 0:18:06  lr: 0.000097  loss: 0.6416 (0.7525)  time: 9.7010  data: 0.0413  max mem: 8593\n",
      "Epoch: [2] Train  [ 20/122]  eta: 0:16:26  lr: 0.000097  loss: 0.8059 (0.7039)  time: 9.6761  data: 0.0005  max mem: 8593\n",
      "Epoch: [2] Train  [ 30/122]  eta: 0:14:46  lr: 0.000097  loss: 0.6628 (0.7642)  time: 9.6039  data: 0.0006  max mem: 8593\n",
      "Epoch: [2] Train  [ 40/122]  eta: 0:13:11  lr: 0.000097  loss: 2.2256 (0.8035)  time: 9.6177  data: 0.0005  max mem: 8593\n",
      "Epoch: [2] Train  [ 50/122]  eta: 0:11:34  lr: 0.000097  loss: 0.4642 (0.7819)  time: 9.6575  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Train  [ 60/122]  eta: 0:09:58  lr: 0.000097  loss: 0.5623 (0.7636)  time: 9.6641  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Train  [ 70/122]  eta: 0:08:22  lr: 0.000096  loss: 1.1762 (0.7874)  time: 9.6863  data: 0.0004  max mem: 8593\n",
      "Epoch: [2] Train  [ 80/122]  eta: 0:06:45  lr: 0.000096  loss: 0.4956 (0.7948)  time: 9.7080  data: 0.0004  max mem: 8593\n",
      "Epoch: [2] Train  [ 90/122]  eta: 0:05:09  lr: 0.000096  loss: 0.5409 (0.7932)  time: 9.6869  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Train  [100/122]  eta: 0:03:32  lr: 0.000096  loss: 0.7864 (0.7870)  time: 9.6313  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Train  [110/122]  eta: 0:01:55  lr: 0.000096  loss: 0.9534 (0.7930)  time: 9.6120  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Train  [120/122]  eta: 0:00:19  lr: 0.000095  loss: 0.3775 (0.7778)  time: 9.6779  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Train Total time: 0:19:38\n",
      "Epoch: [2] Test  [  0/121]  eta: 0:03:58    time: 1.9696  data: 0.5447  max mem: 8593\n",
      "Epoch: [2] Test  [ 10/121]  eta: 0:01:56    time: 1.0517  data: 0.0498  max mem: 8593\n",
      "Epoch: [2] Test  [ 20/121]  eta: 0:01:41    time: 0.9561  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test  [ 30/121]  eta: 0:01:32    time: 1.0003  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test  [ 40/121]  eta: 0:01:22    time: 1.0309  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test  [ 50/121]  eta: 0:01:12    time: 1.0376  data: 0.0004  max mem: 8593\n",
      "Epoch: [2] Test  [ 60/121]  eta: 0:01:02    time: 1.0252  data: 0.0004  max mem: 8593\n",
      "Epoch: [2] Test  [ 70/121]  eta: 0:00:50    time: 0.9310  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test  [ 80/121]  eta: 0:00:40    time: 0.9295  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test  [ 90/121]  eta: 0:00:31    time: 1.1119  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test  [100/121]  eta: 0:00:21    time: 1.1447  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test  [110/121]  eta: 0:00:11    time: 0.9987  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test  [120/121]  eta: 0:00:01    time: 0.9795  data: 0.0003  max mem: 8593\n",
      "Epoch: [2] Test Total time: 0:02:03\n",
      "global correct: 95.2\n",
      "average row correct: ['96.7', '95.8', '81.7', '95.6', '83.1', '85.4', '98.7', '86.3', '97.8', '68.3', '94.9', '62.4', '91.5', '92.2', '94.9', '95.7', '74.3', '95.1', '87.3', '96.6', '87.1']\n",
      "IoU: ['94.5', '93.4', '41.9', '88.6', '71.6', '74.7', '96.8', '78.2', '89.5', '45.7', '90.3', '57.5', '86.8', '89.4', '89.1', '90.2', '62.8', '88.7', '60.2', '91.5', '80.8']\n",
      "mean IoU: 79.2\n",
      "Epoch: [3] Train  [  0/122]  eta: 0:20:10  lr: 0.000095  loss: 0.8419 (0.8419)  time: 9.9227  data: 0.3534  max mem: 8593\n",
      "Epoch: [3] Train  [ 10/122]  eta: 0:18:21  lr: 0.000095  loss: 0.9601 (0.8305)  time: 9.8353  data: 0.0323  max mem: 8593\n",
      "Epoch: [3] Train  [ 20/122]  eta: 0:16:35  lr: 0.000095  loss: 1.3171 (0.8813)  time: 9.7467  data: 0.0002  max mem: 8593\n",
      "Epoch: [3] Train  [ 30/122]  eta: 0:14:53  lr: 0.000095  loss: 0.8174 (0.8430)  time: 9.6476  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Train  [ 40/122]  eta: 0:13:15  lr: 0.000095  loss: 1.0416 (0.8439)  time: 9.6424  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Train  [ 50/122]  eta: 0:11:39  lr: 0.000094  loss: 0.4687 (0.8273)  time: 9.7203  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Train  [ 60/122]  eta: 0:10:01  lr: 0.000094  loss: 1.5621 (0.8307)  time: 9.7199  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Train  [ 70/122]  eta: 0:08:24  lr: 0.000094  loss: 0.4206 (0.8283)  time: 9.6777  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Train  [ 80/122]  eta: 0:06:46  lr: 0.000094  loss: 0.4668 (0.8132)  time: 9.6296  data: 0.0002  max mem: 8593\n",
      "Epoch: [3] Train  [ 90/122]  eta: 0:05:09  lr: 0.000094  loss: 0.4966 (0.8062)  time: 9.6173  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Train  [100/122]  eta: 0:03:32  lr: 0.000093  loss: 0.6823 (0.7967)  time: 9.6356  data: 0.0004  max mem: 8593\n",
      "Epoch: [3] Train  [110/122]  eta: 0:01:56  lr: 0.000093  loss: 1.0232 (0.7913)  time: 9.6433  data: 0.0004  max mem: 8593\n",
      "Epoch: [3] Train  [120/122]  eta: 0:00:19  lr: 0.000093  loss: 0.7364 (0.7973)  time: 9.6402  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Train Total time: 0:19:39\n",
      "Epoch: [3] Test  [  0/121]  eta: 0:03:56    time: 1.9556  data: 0.5333  max mem: 8593\n",
      "Epoch: [3] Test  [ 10/121]  eta: 0:01:56    time: 1.0494  data: 0.0487  max mem: 8593\n",
      "Epoch: [3] Test  [ 20/121]  eta: 0:01:41    time: 0.9544  data: 0.0002  max mem: 8593\n",
      "Epoch: [3] Test  [ 30/121]  eta: 0:01:32    time: 1.0006  data: 0.0002  max mem: 8593\n",
      "Epoch: [3] Test  [ 40/121]  eta: 0:01:22    time: 1.0296  data: 0.0002  max mem: 8593\n",
      "Epoch: [3] Test  [ 50/121]  eta: 0:01:12    time: 1.0319  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Test  [ 60/121]  eta: 0:01:02    time: 1.0221  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Test  [ 70/121]  eta: 0:00:50    time: 0.9307  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Test  [ 80/121]  eta: 0:00:40    time: 0.9296  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Test  [ 90/121]  eta: 0:00:31    time: 1.1113  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Test  [100/121]  eta: 0:00:21    time: 1.1451  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Test  [110/121]  eta: 0:00:11    time: 1.0003  data: 0.0003  max mem: 8593\n",
      "Epoch: [3] Test  [120/121]  eta: 0:00:01    time: 0.9797  data: 0.0002  max mem: 8593\n",
      "Epoch: [3] Test Total time: 0:02:03\n",
      "global correct: 95.3\n",
      "average row correct: ['96.9', '94.6', '70.4', '96.1', '84.1', '83.8', '98.5', '88.2', '97.4', '67.4', '96.1', '62.3', '93.8', '94.2', '94.5', '95.6', '79.4', '94.3', '86.5', '95.3', '88.0']\n",
      "IoU: ['94.6', '91.8', '38.3', '89.5', '73.6', '74.8', '96.8', '79.6', '92.2', '46.9', '92.4', '56.9', '88.8', '90.5', '88.9', '90.3', '65.8', '89.6', '60.2', '89.7', '80.8']\n",
      "mean IoU: 79.6\n",
      "Epoch: [4] Train  [  0/122]  eta: 0:20:42  lr: 0.000093  loss: 0.6573 (0.6573)  time: 10.1852  data: 0.4163  max mem: 8593\n",
      "Epoch: [4] Train  [ 10/122]  eta: 0:18:17  lr: 0.000093  loss: 0.5876 (0.7496)  time: 9.7968  data: 0.0382  max mem: 8593\n",
      "Epoch: [4] Train  [ 20/122]  eta: 0:16:29  lr: 0.000093  loss: 1.2492 (0.7157)  time: 9.6797  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train  [ 30/122]  eta: 0:14:49  lr: 0.000092  loss: 0.3722 (0.6775)  time: 9.5973  data: 0.0005  max mem: 8593\n",
      "Epoch: [4] Train  [ 40/122]  eta: 0:13:10  lr: 0.000092  loss: 1.0056 (0.6836)  time: 9.5736  data: 0.0005  max mem: 8593\n",
      "Epoch: [4] Train  [ 50/122]  eta: 0:11:35  lr: 0.000092  loss: 0.7452 (0.6746)  time: 9.6586  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train  [ 60/122]  eta: 0:09:59  lr: 0.000092  loss: 0.5719 (0.7337)  time: 9.7195  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train  [ 70/122]  eta: 0:08:23  lr: 0.000092  loss: 0.5672 (0.7457)  time: 9.7048  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train  [ 80/122]  eta: 0:06:46  lr: 0.000092  loss: 1.1691 (0.7637)  time: 9.6779  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train  [ 90/122]  eta: 0:05:09  lr: 0.000091  loss: 0.4771 (0.7569)  time: 9.5980  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train  [100/122]  eta: 0:03:32  lr: 0.000091  loss: 0.5746 (0.7595)  time: 9.6234  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train  [110/122]  eta: 0:01:56  lr: 0.000091  loss: 0.3682 (0.7577)  time: 9.7170  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train  [120/122]  eta: 0:00:19  lr: 0.000091  loss: 0.7011 (0.7629)  time: 9.6744  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Train Total time: 0:19:38\n",
      "Epoch: [4] Test  [  0/121]  eta: 0:03:56    time: 1.9558  data: 0.5264  max mem: 8593\n",
      "Epoch: [4] Test  [ 10/121]  eta: 0:01:56    time: 1.0505  data: 0.0481  max mem: 8593\n",
      "Epoch: [4] Test  [ 20/121]  eta: 0:01:41    time: 0.9563  data: 0.0002  max mem: 8593\n",
      "Epoch: [4] Test  [ 30/121]  eta: 0:01:32    time: 1.0009  data: 0.0002  max mem: 8593\n",
      "Epoch: [4] Test  [ 40/121]  eta: 0:01:22    time: 1.0305  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Test  [ 50/121]  eta: 0:01:12    time: 1.0345  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Test  [ 60/121]  eta: 0:01:02    time: 1.0223  data: 0.0005  max mem: 8593\n",
      "Epoch: [4] Test  [ 70/121]  eta: 0:00:50    time: 0.9285  data: 0.0005  max mem: 8593\n",
      "Epoch: [4] Test  [ 80/121]  eta: 0:00:40    time: 0.9281  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Test  [ 90/121]  eta: 0:00:31    time: 1.1121  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Test  [100/121]  eta: 0:00:21    time: 1.1444  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Test  [110/121]  eta: 0:00:11    time: 0.9986  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Test  [120/121]  eta: 0:00:01    time: 0.9793  data: 0.0003  max mem: 8593\n",
      "Epoch: [4] Test Total time: 0:02:03\n",
      "global correct: 95.3\n",
      "average row correct: ['96.8', '96.4', '79.6', '95.1', '86.0', '87.7', '98.6', '86.6', '96.7', '70.8', '94.1', '61.7', '94.4', '94.0', '94.7', '96.0', '79.3', '94.7', '85.7', '94.5', '87.2']\n",
      "IoU: ['94.6', '92.6', '41.8', '89.7', '73.8', '75.1', '96.9', '77.6', '92.5', '46.5', '91.9', '56.6', '89.6', '90.1', '89.1', '90.1', '67.3', '89.1', '60.4', '90.0', '81.6']\n",
      "mean IoU: 79.9\n",
      "Epoch: [5] Train  [  0/122]  eta: 0:20:29  lr: 0.000091  loss: 0.5169 (0.5169)  time: 10.0745  data: 0.4217  max mem: 8593\n",
      "Epoch: [5] Train  [ 10/122]  eta: 0:18:01  lr: 0.000091  loss: 1.1306 (0.7313)  time: 9.6557  data: 0.0386  max mem: 8593\n",
      "Epoch: [5] Train  [ 20/122]  eta: 0:16:22  lr: 0.000090  loss: 0.6655 (0.7126)  time: 9.6060  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Train  [ 30/122]  eta: 0:14:48  lr: 0.000090  loss: 1.5242 (0.7487)  time: 9.6652  data: 0.0004  max mem: 8593\n",
      "Epoch: [5] Train  [ 40/122]  eta: 0:13:12  lr: 0.000090  loss: 0.4193 (0.7625)  time: 9.6965  data: 0.0004  max mem: 8593\n",
      "Epoch: [5] Train  [ 50/122]  eta: 0:11:34  lr: 0.000090  loss: 0.9440 (0.7749)  time: 9.6099  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Train  [ 60/122]  eta: 0:09:56  lr: 0.000090  loss: 0.4503 (0.7738)  time: 9.5566  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Train  [ 70/122]  eta: 0:08:20  lr: 0.000089  loss: 0.6741 (0.7445)  time: 9.5864  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Train  [ 80/122]  eta: 0:06:44  lr: 0.000089  loss: 0.9622 (0.7492)  time: 9.6603  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Train  [ 90/122]  eta: 0:05:08  lr: 0.000089  loss: 0.5632 (0.7396)  time: 9.7175  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Train  [100/122]  eta: 0:03:32  lr: 0.000089  loss: 0.7957 (0.7342)  time: 9.6673  data: 0.0004  max mem: 8593\n",
      "Epoch: [5] Train  [110/122]  eta: 0:01:55  lr: 0.000089  loss: 0.8407 (0.7293)  time: 9.6259  data: 0.0004  max mem: 8593\n",
      "Epoch: [5] Train  [120/122]  eta: 0:00:19  lr: 0.000088  loss: 0.6899 (0.7326)  time: 9.6303  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Train Total time: 0:19:36\n",
      "Epoch: [5] Test  [  0/121]  eta: 0:03:55    time: 1.9479  data: 0.5012  max mem: 8593\n",
      "Epoch: [5] Test  [ 10/121]  eta: 0:01:56    time: 1.0515  data: 0.0458  max mem: 8593\n",
      "Epoch: [5] Test  [ 20/121]  eta: 0:01:41    time: 0.9583  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [ 30/121]  eta: 0:01:32    time: 1.0013  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [ 40/121]  eta: 0:01:22    time: 1.0288  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [ 50/121]  eta: 0:01:12    time: 1.0341  data: 0.0004  max mem: 8593\n",
      "Epoch: [5] Test  [ 60/121]  eta: 0:01:02    time: 1.0237  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [ 70/121]  eta: 0:00:50    time: 0.9300  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [ 80/121]  eta: 0:00:40    time: 0.9286  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [ 90/121]  eta: 0:00:31    time: 1.1110  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [100/121]  eta: 0:00:21    time: 1.1435  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [110/121]  eta: 0:00:11    time: 0.9999  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test  [120/121]  eta: 0:00:01    time: 0.9805  data: 0.0003  max mem: 8593\n",
      "Epoch: [5] Test Total time: 0:02:03\n",
      "global correct: 95.2\n",
      "average row correct: ['96.4', '95.6', '76.1', '93.6', '83.6', '90.1', '98.6', '89.0', '98.0', '75.1', '96.3', '67.6', '95.9', '95.1', '95.0', '95.7', '80.1', '95.5', '83.6', '97.1', '89.9']\n",
      "IoU: ['94.4', '92.4', '40.9', '88.7', '72.3', '73.7', '96.9', '79.2', '92.5', '45.6', '91.5', '59.9', '88.5', '90.1', '90.3', '90.3', '66.4', '86.3', '61.8', '88.6', '78.7']\n",
      "mean IoU: 79.5\n",
      "Epoch: [6] Train  [  0/122]  eta: 0:19:21  lr: 0.000088  loss: 0.7457 (0.7457)  time: 9.5173  data: 0.3829  max mem: 8593\n",
      "Epoch: [6] Train  [ 10/122]  eta: 0:18:06  lr: 0.000088  loss: 0.4053 (0.7663)  time: 9.7042  data: 0.0352  max mem: 8593\n",
      "Epoch: [6] Train  [ 20/122]  eta: 0:16:24  lr: 0.000088  loss: 1.0262 (0.7238)  time: 9.6595  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Train  [ 30/122]  eta: 0:14:49  lr: 0.000088  loss: 0.4391 (0.7329)  time: 9.6489  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Train  [ 40/122]  eta: 0:13:11  lr: 0.000088  loss: 0.6323 (0.7279)  time: 9.6495  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Train  [ 50/122]  eta: 0:11:34  lr: 0.000087  loss: 0.7236 (0.7280)  time: 9.6058  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Train  [ 60/122]  eta: 0:09:58  lr: 0.000087  loss: 0.6379 (0.7135)  time: 9.6452  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Train  [ 70/122]  eta: 0:08:22  lr: 0.000087  loss: 0.5540 (0.6989)  time: 9.6892  data: 0.0004  max mem: 8593\n",
      "Epoch: [6] Train  [ 80/122]  eta: 0:06:45  lr: 0.000087  loss: 0.4551 (0.6915)  time: 9.6649  data: 0.0004  max mem: 8593\n",
      "Epoch: [6] Train  [ 90/122]  eta: 0:05:08  lr: 0.000087  loss: 0.8466 (0.6864)  time: 9.5523  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Train  [100/122]  eta: 0:03:32  lr: 0.000086  loss: 0.4592 (0.6764)  time: 9.5749  data: 0.0004  max mem: 8593\n",
      "Epoch: [6] Train  [110/122]  eta: 0:01:55  lr: 0.000086  loss: 0.5862 (0.6705)  time: 9.6434  data: 0.0004  max mem: 8593\n",
      "Epoch: [6] Train  [120/122]  eta: 0:00:19  lr: 0.000086  loss: 0.8049 (0.6775)  time: 9.5799  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Train Total time: 0:19:34\n",
      "Epoch: [6] Test  [  0/121]  eta: 0:03:55    time: 1.9500  data: 0.4955  max mem: 8593\n",
      "Epoch: [6] Test  [ 10/121]  eta: 0:01:56    time: 1.0535  data: 0.0453  max mem: 8593\n",
      "Epoch: [6] Test  [ 20/121]  eta: 0:01:41    time: 0.9591  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test  [ 30/121]  eta: 0:01:32    time: 1.0033  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test  [ 40/121]  eta: 0:01:22    time: 1.0312  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test  [ 50/121]  eta: 0:01:12    time: 1.0319  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test  [ 60/121]  eta: 0:01:02    time: 1.0217  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test  [ 70/121]  eta: 0:00:50    time: 0.9301  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test  [ 80/121]  eta: 0:00:40    time: 0.9287  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test  [ 90/121]  eta: 0:00:31    time: 1.1133  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test  [100/121]  eta: 0:00:21    time: 1.1464  data: 0.0004  max mem: 8593\n",
      "Epoch: [6] Test  [110/121]  eta: 0:00:11    time: 1.0007  data: 0.0004  max mem: 8593\n",
      "Epoch: [6] Test  [120/121]  eta: 0:00:01    time: 0.9806  data: 0.0003  max mem: 8593\n",
      "Epoch: [6] Test Total time: 0:02:03\n",
      "global correct: 95.4\n",
      "average row correct: ['96.6', '95.9', '75.5', '96.0', '86.3', '89.3', '99.0', '91.8', '98.0', '72.8', '94.4', '72.4', '92.7', '93.2', '94.7', '96.1', '81.7', '95.6', '84.4', '96.4', '86.7']\n",
      "IoU: ['94.7', '94.3', '41.2', '90.3', '74.3', '75.4', '96.3', '80.9', '91.0', '46.7', '89.9', '62.2', '88.5', '90.1', '90.2', '90.6', '66.1', '87.2', '62.1', '90.1', '80.9']\n",
      "mean IoU: 80.1\n",
      "Epoch: [7] Train  [  0/122]  eta: 0:19:54  lr: 0.000086  loss: 0.3480 (0.3480)  time: 9.7928  data: 0.3666  max mem: 8593\n",
      "Epoch: [7] Train  [ 10/122]  eta: 0:17:56  lr: 0.000086  loss: 0.5538 (0.6339)  time: 9.6106  data: 0.0337  max mem: 8593\n",
      "Epoch: [7] Train  [ 20/122]  eta: 0:16:17  lr: 0.000086  loss: 0.5624 (0.6502)  time: 9.5754  data: 0.0005  max mem: 8593\n",
      "Epoch: [7] Train  [ 30/122]  eta: 0:14:44  lr: 0.000085  loss: 0.6164 (0.7075)  time: 9.6200  data: 0.0005  max mem: 8593\n",
      "Epoch: [7] Train  [ 40/122]  eta: 0:13:10  lr: 0.000085  loss: 1.0585 (0.7308)  time: 9.7050  data: 0.0004  max mem: 8593\n",
      "Epoch: [7] Train  [ 50/122]  eta: 0:11:34  lr: 0.000085  loss: 0.7272 (0.7464)  time: 9.6851  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Train  [ 60/122]  eta: 0:09:57  lr: 0.000085  loss: 0.8327 (0.7377)  time: 9.6010  data: 0.0004  max mem: 8593\n",
      "Epoch: [7] Train  [ 70/122]  eta: 0:08:20  lr: 0.000085  loss: 0.6922 (0.7320)  time: 9.5903  data: 0.0004  max mem: 8593\n",
      "Epoch: [7] Train  [ 80/122]  eta: 0:06:44  lr: 0.000084  loss: 0.4760 (0.7302)  time: 9.6238  data: 0.0004  max mem: 8593\n",
      "Epoch: [7] Train  [ 90/122]  eta: 0:05:07  lr: 0.000084  loss: 0.4440 (0.7179)  time: 9.5826  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Train  [100/122]  eta: 0:03:31  lr: 0.000084  loss: 0.5725 (0.7138)  time: 9.6374  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Train  [110/122]  eta: 0:01:55  lr: 0.000084  loss: 1.2450 (0.7283)  time: 9.6958  data: 0.0002  max mem: 8593\n",
      "Epoch: [7] Train  [120/122]  eta: 0:00:19  lr: 0.000084  loss: 0.4111 (0.7270)  time: 9.6857  data: 0.0002  max mem: 8593\n",
      "Epoch: [7] Train Total time: 0:19:35\n",
      "Epoch: [7] Test  [  0/121]  eta: 0:03:50    time: 1.9076  data: 0.4824  max mem: 8593\n",
      "Epoch: [7] Test  [ 10/121]  eta: 0:01:56    time: 1.0457  data: 0.0441  max mem: 8593\n",
      "Epoch: [7] Test  [ 20/121]  eta: 0:01:41    time: 0.9568  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [ 30/121]  eta: 0:01:32    time: 1.0034  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [ 40/121]  eta: 0:01:22    time: 1.0319  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [ 50/121]  eta: 0:01:12    time: 1.0336  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [ 60/121]  eta: 0:01:02    time: 1.0225  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [ 70/121]  eta: 0:00:50    time: 0.9304  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [ 80/121]  eta: 0:00:40    time: 0.9298  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [ 90/121]  eta: 0:00:31    time: 1.1138  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [100/121]  eta: 0:00:21    time: 1.1460  data: 0.0002  max mem: 8593\n",
      "Epoch: [7] Test  [110/121]  eta: 0:00:11    time: 0.9999  data: 0.0003  max mem: 8593\n",
      "Epoch: [7] Test  [120/121]  eta: 0:00:01    time: 0.9803  data: 0.0002  max mem: 8593\n",
      "Epoch: [7] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['97.0', '94.6', '76.8', '94.2', '86.5', '89.9', '98.4', '90.9', '96.9', '61.9', '94.8', '67.4', '95.0', '94.5', '93.9', '96.1', '81.1', '94.8', '85.6', '96.5', '89.0']\n",
      "IoU: ['94.9', '93.1', '41.8', '89.1', '75.0', '73.7', '96.8', '80.3', '93.8', '49.0', '92.0', '61.5', '90.1', '89.5', '89.5', '90.2', '66.2', '87.1', '61.6', '89.1', '80.2']\n",
      "mean IoU: 80.2\n",
      "Epoch: [8] Train  [  0/122]  eta: 0:20:03  lr: 0.000084  loss: 0.7588 (0.7588)  time: 9.8634  data: 0.3945  max mem: 8593\n",
      "Epoch: [8] Train  [ 10/122]  eta: 0:17:52  lr: 0.000083  loss: 0.6055 (0.8159)  time: 9.5791  data: 0.0361  max mem: 8593\n",
      "Epoch: [8] Train  [ 20/122]  eta: 0:16:17  lr: 0.000083  loss: 0.7314 (0.7804)  time: 9.5733  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Train  [ 30/122]  eta: 0:14:44  lr: 0.000083  loss: 0.5902 (0.7237)  time: 9.6287  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Train  [ 40/122]  eta: 0:13:08  lr: 0.000083  loss: 0.5180 (0.7032)  time: 9.6549  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Train  [ 50/122]  eta: 0:11:32  lr: 0.000083  loss: 0.4697 (0.7003)  time: 9.6318  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Train  [ 60/122]  eta: 0:09:56  lr: 0.000083  loss: 0.6352 (0.6899)  time: 9.6022  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Train  [ 70/122]  eta: 0:08:19  lr: 0.000082  loss: 0.6555 (0.6819)  time: 9.5860  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Train  [ 80/122]  eta: 0:06:44  lr: 0.000082  loss: 0.5988 (0.6861)  time: 9.6366  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Train  [ 90/122]  eta: 0:05:07  lr: 0.000082  loss: 0.5171 (0.6950)  time: 9.6748  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Train  [100/122]  eta: 0:03:31  lr: 0.000082  loss: 1.1065 (0.6998)  time: 9.6645  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Train  [110/122]  eta: 0:01:55  lr: 0.000082  loss: 0.8554 (0.6981)  time: 9.6560  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Train  [120/122]  eta: 0:00:19  lr: 0.000081  loss: 0.8125 (0.6938)  time: 9.5828  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Train Total time: 0:19:33\n",
      "Epoch: [8] Test  [  0/121]  eta: 0:04:01    time: 1.9950  data: 0.5752  max mem: 8593\n",
      "Epoch: [8] Test  [ 10/121]  eta: 0:01:57    time: 1.0544  data: 0.0525  max mem: 8593\n",
      "Epoch: [8] Test  [ 20/121]  eta: 0:01:41    time: 0.9572  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [ 30/121]  eta: 0:01:32    time: 1.0040  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [ 40/121]  eta: 0:01:22    time: 1.0329  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [ 50/121]  eta: 0:01:12    time: 1.0347  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [ 60/121]  eta: 0:01:02    time: 1.0223  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [ 70/121]  eta: 0:00:50    time: 0.9304  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [ 80/121]  eta: 0:00:40    time: 0.9302  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [ 90/121]  eta: 0:00:31    time: 1.1138  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [100/121]  eta: 0:00:21    time: 1.1463  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [110/121]  eta: 0:00:11    time: 1.0006  data: 0.0003  max mem: 8593\n",
      "Epoch: [8] Test  [120/121]  eta: 0:00:01    time: 0.9804  data: 0.0002  max mem: 8593\n",
      "Epoch: [8] Test Total time: 0:02:03\n",
      "global correct: 95.4\n",
      "average row correct: ['96.3', '96.9', '76.5', '94.8', '87.1', '90.8', '99.1', '90.1', '97.9', '73.7', '96.0', '70.6', '94.6', '95.6', '94.4', '96.5', '83.3', '96.0', '85.4', '97.0', '89.3']\n",
      "IoU: ['94.6', '94.2', '42.5', '89.6', '72.9', '73.7', '96.5', '80.7', '91.6', '47.7', '91.5', '62.2', '89.2', '90.7', '90.1', '90.5', '65.8', '83.5', '61.9', '88.5', '80.8']\n",
      "mean IoU: 79.9\n",
      "Epoch: [9] Train  [  0/122]  eta: 0:19:57  lr: 0.000081  loss: 1.0114 (1.0114)  time: 9.8192  data: 0.3693  max mem: 8593\n",
      "Epoch: [9] Train  [ 10/122]  eta: 0:18:05  lr: 0.000081  loss: 0.6608 (0.6838)  time: 9.6884  data: 0.0339  max mem: 8593\n",
      "Epoch: [9] Train  [ 20/122]  eta: 0:16:23  lr: 0.000081  loss: 0.5824 (0.6802)  time: 9.6327  data: 0.0004  max mem: 8593\n",
      "Epoch: [9] Train  [ 30/122]  eta: 0:14:47  lr: 0.000081  loss: 0.6195 (0.7105)  time: 9.6291  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Train  [ 40/122]  eta: 0:13:11  lr: 0.000081  loss: 0.4395 (0.7203)  time: 9.6591  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train  [ 50/122]  eta: 0:11:34  lr: 0.000080  loss: 0.6184 (0.7198)  time: 9.6392  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train  [ 60/122]  eta: 0:09:57  lr: 0.000080  loss: 0.5589 (0.7020)  time: 9.6262  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train  [ 70/122]  eta: 0:08:20  lr: 0.000080  loss: 0.9043 (0.7229)  time: 9.6038  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train  [ 80/122]  eta: 0:06:45  lr: 0.000080  loss: 0.4047 (0.7436)  time: 9.6831  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train  [ 90/122]  eta: 0:05:08  lr: 0.000080  loss: 0.7302 (0.7288)  time: 9.6624  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train  [100/122]  eta: 0:03:32  lr: 0.000079  loss: 0.7653 (0.7206)  time: 9.5807  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train  [110/122]  eta: 0:01:55  lr: 0.000079  loss: 0.4773 (0.7138)  time: 9.6378  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train  [120/122]  eta: 0:00:19  lr: 0.000079  loss: 0.6152 (0.7147)  time: 9.6844  data: 0.0002  max mem: 8593\n",
      "Epoch: [9] Train Total time: 0:19:36\n",
      "Epoch: [9] Test  [  0/121]  eta: 0:04:00    time: 1.9866  data: 0.5605  max mem: 8593\n",
      "Epoch: [9] Test  [ 10/121]  eta: 0:01:57    time: 1.0541  data: 0.0513  max mem: 8593\n",
      "Epoch: [9] Test  [ 20/121]  eta: 0:01:41    time: 0.9565  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Test  [ 30/121]  eta: 0:01:32    time: 1.0004  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Test  [ 40/121]  eta: 0:01:22    time: 1.0295  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Test  [ 50/121]  eta: 0:01:12    time: 1.0345  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Test  [ 60/121]  eta: 0:01:02    time: 1.0245  data: 0.0004  max mem: 8593\n",
      "Epoch: [9] Test  [ 70/121]  eta: 0:00:50    time: 0.9316  data: 0.0004  max mem: 8593\n",
      "Epoch: [9] Test  [ 80/121]  eta: 0:00:40    time: 0.9290  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Test  [ 90/121]  eta: 0:00:31    time: 1.1110  data: 0.0004  max mem: 8593\n",
      "Epoch: [9] Test  [100/121]  eta: 0:00:21    time: 1.1450  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Test  [110/121]  eta: 0:00:11    time: 0.9988  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Test  [120/121]  eta: 0:00:01    time: 0.9786  data: 0.0003  max mem: 8593\n",
      "Epoch: [9] Test Total time: 0:02:03\n",
      "global correct: 95.7\n",
      "average row correct: ['97.2', '94.8', '77.8', '93.6', '88.7', '86.9', '98.9', '90.8', '96.0', '70.6', '96.0', '68.6', '91.7', '92.2', '93.1', '96.3', '79.1', '95.0', '81.7', '96.2', '88.6']\n",
      "IoU: ['95.0', '93.5', '43.5', '90.0', '75.7', '75.9', '97.1', '80.8', '91.9', '49.7', '92.1', '61.8', '88.0', '88.3', '89.1', '90.5', '67.8', '89.1', '63.1', '89.3', '80.6']\n",
      "mean IoU: 80.6\n",
      "Epoch: [10] Train  [  0/122]  eta: 0:20:02  lr: 0.000079  loss: 0.5846 (0.5846)  time: 9.8568  data: 0.3890  max mem: 8593\n",
      "Epoch: [10] Train  [ 10/122]  eta: 0:18:01  lr: 0.000079  loss: 1.4024 (0.8278)  time: 9.6564  data: 0.0356  max mem: 8593\n",
      "Epoch: [10] Train  [ 20/122]  eta: 0:16:21  lr: 0.000079  loss: 0.9949 (0.7807)  time: 9.6089  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Train  [ 30/122]  eta: 0:14:46  lr: 0.000078  loss: 0.6534 (0.7557)  time: 9.6210  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Train  [ 40/122]  eta: 0:13:09  lr: 0.000078  loss: 0.4144 (0.7554)  time: 9.6264  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Train  [ 50/122]  eta: 0:11:32  lr: 0.000078  loss: 0.2881 (0.7236)  time: 9.6076  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Train  [ 60/122]  eta: 0:09:55  lr: 0.000078  loss: 0.5882 (0.7032)  time: 9.5750  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Train  [ 70/122]  eta: 0:08:19  lr: 0.000078  loss: 0.7372 (0.7179)  time: 9.5637  data: 0.0004  max mem: 8593\n",
      "Epoch: [10] Train  [ 80/122]  eta: 0:06:43  lr: 0.000077  loss: 1.4046 (0.7176)  time: 9.5964  data: 0.0004  max mem: 8593\n",
      "Epoch: [10] Train  [ 90/122]  eta: 0:05:07  lr: 0.000077  loss: 0.5649 (0.7105)  time: 9.6048  data: 0.0004  max mem: 8593\n",
      "Epoch: [10] Train  [100/122]  eta: 0:03:31  lr: 0.000077  loss: 0.5930 (0.7152)  time: 9.6362  data: 0.0002  max mem: 8593\n",
      "Epoch: [10] Train  [110/122]  eta: 0:01:55  lr: 0.000077  loss: 0.8723 (0.7160)  time: 9.5808  data: 0.0002  max mem: 8593\n",
      "Epoch: [10] Train  [120/122]  eta: 0:00:19  lr: 0.000077  loss: 0.7607 (0.7068)  time: 9.6114  data: 0.0002  max mem: 8593\n",
      "Epoch: [10] Train Total time: 0:19:32\n",
      "Epoch: [10] Test  [  0/121]  eta: 0:03:56    time: 1.9582  data: 0.5306  max mem: 8593\n",
      "Epoch: [10] Test  [ 10/121]  eta: 0:01:56    time: 1.0515  data: 0.0485  max mem: 8593\n",
      "Epoch: [10] Test  [ 20/121]  eta: 0:01:41    time: 0.9568  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [ 30/121]  eta: 0:01:32    time: 1.0018  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [ 40/121]  eta: 0:01:22    time: 1.0296  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [ 50/121]  eta: 0:01:12    time: 1.0341  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [ 60/121]  eta: 0:01:02    time: 1.0240  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [ 70/121]  eta: 0:00:50    time: 0.9310  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [ 80/121]  eta: 0:00:40    time: 0.9298  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [ 90/121]  eta: 0:00:31    time: 1.1131  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [100/121]  eta: 0:00:21    time: 1.1469  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [110/121]  eta: 0:00:11    time: 0.9999  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test  [120/121]  eta: 0:00:01    time: 0.9796  data: 0.0003  max mem: 8593\n",
      "Epoch: [10] Test Total time: 0:02:03\n",
      "global correct: 95.4\n",
      "average row correct: ['96.3', '97.1', '81.0', '93.5', '87.5', '90.4', '99.1', '94.1', '97.8', '70.7', '96.4', '74.2', '94.9', '94.7', '94.8', '96.5', '82.2', '96.0', '85.8', '97.6', '90.0']\n",
      "IoU: ['94.7', '93.2', '43.9', '89.5', '74.6', '74.5', '96.6', '81.0', '91.6', '49.4', '91.3', '64.4', '89.2', '91.0', '89.9', '90.4', '66.1', '83.6', '62.3', '86.9', '77.5']\n",
      "mean IoU: 80.1\n",
      "Epoch: [11] Train  [  0/122]  eta: 0:19:44  lr: 0.000077  loss: 0.4083 (0.4083)  time: 9.7105  data: 0.3580  max mem: 8593\n",
      "Epoch: [11] Train  [ 10/122]  eta: 0:18:06  lr: 0.000076  loss: 1.0606 (0.7529)  time: 9.7006  data: 0.0328  max mem: 8593\n",
      "Epoch: [11] Train  [ 20/122]  eta: 0:16:25  lr: 0.000076  loss: 0.3615 (0.6604)  time: 9.6561  data: 0.0004  max mem: 8593\n",
      "Epoch: [11] Train  [ 30/122]  eta: 0:14:49  lr: 0.000076  loss: 0.6692 (0.6657)  time: 9.6590  data: 0.0004  max mem: 8593\n",
      "Epoch: [11] Train  [ 40/122]  eta: 0:13:13  lr: 0.000076  loss: 0.7629 (0.6464)  time: 9.7051  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Train  [ 50/122]  eta: 0:11:35  lr: 0.000076  loss: 0.3970 (0.6416)  time: 9.6538  data: 0.0002  max mem: 8593\n",
      "Epoch: [11] Train  [ 60/122]  eta: 0:09:58  lr: 0.000075  loss: 0.5553 (0.6383)  time: 9.6129  data: 0.0004  max mem: 8593\n",
      "Epoch: [11] Train  [ 70/122]  eta: 0:08:21  lr: 0.000075  loss: 0.8215 (0.6482)  time: 9.6012  data: 0.0004  max mem: 8593\n",
      "Epoch: [11] Train  [ 80/122]  eta: 0:06:44  lr: 0.000075  loss: 0.5241 (0.6617)  time: 9.5649  data: 0.0002  max mem: 8593\n",
      "Epoch: [11] Train  [ 90/122]  eta: 0:05:08  lr: 0.000075  loss: 0.5061 (0.6602)  time: 9.6246  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Train  [100/122]  eta: 0:03:32  lr: 0.000075  loss: 0.4624 (0.6625)  time: 9.6560  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Train  [110/122]  eta: 0:01:55  lr: 0.000074  loss: 0.6641 (0.6519)  time: 9.5663  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Train  [120/122]  eta: 0:00:19  lr: 0.000074  loss: 1.3647 (0.6617)  time: 9.5459  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Train Total time: 0:19:34\n",
      "Epoch: [11] Test  [  0/121]  eta: 0:04:02    time: 2.0037  data: 0.5679  max mem: 8593\n",
      "Epoch: [11] Test  [ 10/121]  eta: 0:01:57    time: 1.0558  data: 0.0519  max mem: 8593\n",
      "Epoch: [11] Test  [ 20/121]  eta: 0:01:41    time: 0.9581  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Test  [ 30/121]  eta: 0:01:33    time: 1.0043  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Test  [ 40/121]  eta: 0:01:22    time: 1.0337  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Test  [ 50/121]  eta: 0:01:13    time: 1.0374  data: 0.0004  max mem: 8593\n",
      "Epoch: [11] Test  [ 60/121]  eta: 0:01:02    time: 1.0259  data: 0.0005  max mem: 8593\n",
      "Epoch: [11] Test  [ 70/121]  eta: 0:00:51    time: 0.9314  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Test  [ 80/121]  eta: 0:00:40    time: 0.9301  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Test  [ 90/121]  eta: 0:00:31    time: 1.1164  data: 0.0004  max mem: 8593\n",
      "Epoch: [11] Test  [100/121]  eta: 0:00:21    time: 1.1473  data: 0.0004  max mem: 8593\n",
      "Epoch: [11] Test  [110/121]  eta: 0:00:11    time: 0.9998  data: 0.0004  max mem: 8593\n",
      "Epoch: [11] Test  [120/121]  eta: 0:00:01    time: 0.9807  data: 0.0003  max mem: 8593\n",
      "Epoch: [11] Test Total time: 0:02:03\n",
      "global correct: 95.5\n",
      "average row correct: ['96.6', '95.9', '83.5', '93.6', '89.7', '90.3', '98.9', '90.7', '97.3', '63.0', '96.9', '71.5', '97.6', '94.7', '94.1', '96.2', '82.0', '95.7', '86.0', '97.0', '88.8']\n",
      "IoU: ['94.8', '94.2', '45.0', '89.3', '74.9', '72.8', '97.0', '81.3', '93.8', '47.5', '91.6', '62.1', '88.7', '90.6', '89.0', '90.0', '66.4', '86.0', '62.3', '89.6', '78.9']\n",
      "mean IoU: 80.3\n",
      "Epoch: [12] Train  [  0/122]  eta: 0:20:19  lr: 0.000074  loss: 0.5370 (0.5370)  time: 9.9990  data: 0.4028  max mem: 8593\n",
      "Epoch: [12] Train  [ 10/122]  eta: 0:17:59  lr: 0.000074  loss: 0.6857 (0.6311)  time: 9.6412  data: 0.0368  max mem: 8593\n",
      "Epoch: [12] Train  [ 20/122]  eta: 0:16:19  lr: 0.000074  loss: 1.1185 (0.6815)  time: 9.5782  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Train  [ 30/122]  eta: 0:14:42  lr: 0.000074  loss: 0.7070 (0.6738)  time: 9.5649  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Train  [ 40/122]  eta: 0:13:07  lr: 0.000073  loss: 0.5786 (0.6873)  time: 9.6131  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Train  [ 50/122]  eta: 0:11:32  lr: 0.000073  loss: 1.0950 (0.6808)  time: 9.6504  data: 0.0002  max mem: 8593\n",
      "Epoch: [12] Train  [ 60/122]  eta: 0:09:55  lr: 0.000073  loss: 0.2710 (0.6736)  time: 9.6092  data: 0.0002  max mem: 8593\n",
      "Epoch: [12] Train  [ 70/122]  eta: 0:08:20  lr: 0.000073  loss: 0.5718 (0.6611)  time: 9.6387  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Train  [ 80/122]  eta: 0:06:44  lr: 0.000073  loss: 1.0444 (0.6817)  time: 9.6750  data: 0.0002  max mem: 8593\n",
      "Epoch: [12] Train  [ 90/122]  eta: 0:05:07  lr: 0.000072  loss: 0.7153 (0.6723)  time: 9.6027  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Train  [100/122]  eta: 0:03:31  lr: 0.000072  loss: 0.7036 (0.6641)  time: 9.5836  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Train  [110/122]  eta: 0:01:55  lr: 0.000072  loss: 0.5300 (0.6607)  time: 9.5658  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Train  [120/122]  eta: 0:00:19  lr: 0.000072  loss: 0.3215 (0.6529)  time: 9.5420  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Train Total time: 0:19:31\n",
      "Epoch: [12] Test  [  0/121]  eta: 0:04:01    time: 1.9984  data: 0.5686  max mem: 8593\n",
      "Epoch: [12] Test  [ 10/121]  eta: 0:01:57    time: 1.0545  data: 0.0520  max mem: 8593\n",
      "Epoch: [12] Test  [ 20/121]  eta: 0:01:41    time: 0.9573  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [ 30/121]  eta: 0:01:32    time: 1.0018  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [ 40/121]  eta: 0:01:22    time: 1.0300  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [ 50/121]  eta: 0:01:12    time: 1.0348  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [ 60/121]  eta: 0:01:02    time: 1.0238  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [ 70/121]  eta: 0:00:50    time: 0.9300  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [ 80/121]  eta: 0:00:40    time: 0.9288  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [ 90/121]  eta: 0:00:31    time: 1.1136  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [100/121]  eta: 0:00:21    time: 1.1465  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [110/121]  eta: 0:00:11    time: 0.9998  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test  [120/121]  eta: 0:00:01    time: 0.9799  data: 0.0003  max mem: 8593\n",
      "Epoch: [12] Test Total time: 0:02:03\n",
      "global correct: 95.4\n",
      "average row correct: ['96.3', '96.6', '78.4', '93.9', '90.2', '91.6', '99.2', '89.4', '98.2', '73.6', '96.6', '71.3', '95.9', '96.5', '94.5', '96.1', '82.0', '96.5', '82.9', '97.4', '90.3']\n",
      "IoU: ['94.7', '94.2', '44.3', '88.8', '72.6', '72.7', '96.6', '80.2', '92.0', '48.6', '91.6', '62.2', '89.2', '90.6', '90.1', '90.5', '67.1', '83.7', '62.4', '86.9', '79.2']\n",
      "mean IoU: 79.9\n",
      "Epoch: [13] Train  [  0/122]  eta: 0:20:16  lr: 0.000072  loss: 0.8353 (0.8353)  time: 9.9703  data: 0.3589  max mem: 8593\n",
      "Epoch: [13] Train  [ 10/122]  eta: 0:17:52  lr: 0.000072  loss: 0.8314 (0.6680)  time: 9.5726  data: 0.0329  max mem: 8593\n",
      "Epoch: [13] Train  [ 20/122]  eta: 0:16:16  lr: 0.000071  loss: 0.3997 (0.6912)  time: 9.5551  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Train  [ 30/122]  eta: 0:14:42  lr: 0.000071  loss: 0.7528 (0.6864)  time: 9.5999  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Train  [ 40/122]  eta: 0:13:05  lr: 0.000071  loss: 0.5374 (0.6604)  time: 9.5903  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Train  [ 50/122]  eta: 0:11:28  lr: 0.000071  loss: 0.7224 (0.6400)  time: 9.5231  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Train  [ 60/122]  eta: 0:09:52  lr: 0.000071  loss: 0.2970 (0.6513)  time: 9.5246  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Train  [ 70/122]  eta: 0:08:17  lr: 0.000070  loss: 0.7899 (0.6553)  time: 9.5761  data: 0.0002  max mem: 8593\n",
      "Epoch: [13] Train  [ 80/122]  eta: 0:06:41  lr: 0.000070  loss: 0.4368 (0.6765)  time: 9.5500  data: 0.0002  max mem: 8593\n",
      "Epoch: [13] Train  [ 90/122]  eta: 0:05:05  lr: 0.000070  loss: 0.4219 (0.6772)  time: 9.5299  data: 0.0002  max mem: 8593\n",
      "Epoch: [13] Train  [100/122]  eta: 0:03:30  lr: 0.000070  loss: 0.8577 (0.6628)  time: 9.6349  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Train  [110/122]  eta: 0:01:54  lr: 0.000070  loss: 0.8313 (0.6547)  time: 9.5954  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Train  [120/122]  eta: 0:00:19  lr: 0.000069  loss: 0.2828 (0.6571)  time: 9.5046  data: 0.0002  max mem: 8593\n",
      "Epoch: [13] Train Total time: 0:19:26\n",
      "Epoch: [13] Test  [  0/121]  eta: 0:03:58    time: 1.9709  data: 0.5494  max mem: 8593\n",
      "Epoch: [13] Test  [ 10/121]  eta: 0:01:57    time: 1.0545  data: 0.0502  max mem: 8593\n",
      "Epoch: [13] Test  [ 20/121]  eta: 0:01:41    time: 0.9575  data: 0.0002  max mem: 8593\n",
      "Epoch: [13] Test  [ 30/121]  eta: 0:01:32    time: 1.0022  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [ 40/121]  eta: 0:01:22    time: 1.0305  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [ 50/121]  eta: 0:01:12    time: 1.0341  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [ 60/121]  eta: 0:01:02    time: 1.0246  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [ 70/121]  eta: 0:00:50    time: 0.9319  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [ 80/121]  eta: 0:00:40    time: 0.9301  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [ 90/121]  eta: 0:00:31    time: 1.1123  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [100/121]  eta: 0:00:21    time: 1.1458  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [110/121]  eta: 0:00:11    time: 1.0007  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test  [120/121]  eta: 0:00:01    time: 0.9812  data: 0.0003  max mem: 8593\n",
      "Epoch: [13] Test Total time: 0:02:03\n",
      "global correct: 95.5\n",
      "average row correct: ['96.6', '96.2', '77.5', '96.4', '86.9', '91.3', '99.1', '92.4', '98.6', '70.7', '92.7', '73.9', '92.0', '95.7', '94.9', '96.2', '83.3', '95.2', '83.5', '96.2', '89.5']\n",
      "IoU: ['94.8', '94.1', '44.7', '90.6', '73.2', '73.3', '96.3', '82.0', '89.7', '48.0', '90.0', '62.3', '87.3', '90.7', '90.3', '90.4', '67.7', '87.9', '62.4', '89.0', '80.1']\n",
      "mean IoU: 80.2\n",
      "Epoch: [14] Train  [  0/122]  eta: 0:20:36  lr: 0.000069  loss: 0.9655 (0.9655)  time: 10.1319  data: 0.3736  max mem: 8593\n",
      "Epoch: [14] Train  [ 10/122]  eta: 0:18:02  lr: 0.000069  loss: 0.6159 (0.8201)  time: 9.6622  data: 0.0342  max mem: 8593\n",
      "Epoch: [14] Train  [ 20/122]  eta: 0:16:19  lr: 0.000069  loss: 0.2930 (0.8278)  time: 9.5772  data: 0.0002  max mem: 8593\n",
      "Epoch: [14] Train  [ 30/122]  eta: 0:14:41  lr: 0.000069  loss: 0.3859 (0.7716)  time: 9.5370  data: 0.0002  max mem: 8593\n",
      "Epoch: [14] Train  [ 40/122]  eta: 0:13:04  lr: 0.000069  loss: 0.4168 (0.7500)  time: 9.5357  data: 0.0002  max mem: 8593\n",
      "Epoch: [14] Train  [ 50/122]  eta: 0:11:29  lr: 0.000068  loss: 0.4573 (0.7323)  time: 9.5532  data: 0.0002  max mem: 8593\n",
      "Epoch: [14] Train  [ 60/122]  eta: 0:09:53  lr: 0.000068  loss: 1.0608 (0.7066)  time: 9.6009  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Train  [ 70/122]  eta: 0:08:19  lr: 0.000068  loss: 0.3934 (0.6881)  time: 9.6713  data: 0.0004  max mem: 8593\n",
      "Epoch: [14] Train  [ 80/122]  eta: 0:06:43  lr: 0.000068  loss: 0.4739 (0.6826)  time: 9.6738  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Train  [ 90/122]  eta: 0:05:07  lr: 0.000068  loss: 0.6331 (0.6757)  time: 9.6007  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Train  [100/122]  eta: 0:03:31  lr: 0.000067  loss: 0.5321 (0.6620)  time: 9.5778  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Train  [110/122]  eta: 0:01:55  lr: 0.000067  loss: 0.5150 (0.6551)  time: 9.6130  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Train  [120/122]  eta: 0:00:19  lr: 0.000067  loss: 0.4323 (0.6473)  time: 9.5969  data: 0.0002  max mem: 8593\n",
      "Epoch: [14] Train Total time: 0:19:30\n",
      "Epoch: [14] Test  [  0/121]  eta: 0:03:48    time: 1.8907  data: 0.4693  max mem: 8593\n",
      "Epoch: [14] Test  [ 10/121]  eta: 0:01:55    time: 1.0430  data: 0.0429  max mem: 8593\n",
      "Epoch: [14] Test  [ 20/121]  eta: 0:01:41    time: 0.9568  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test  [ 30/121]  eta: 0:01:32    time: 1.0037  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test  [ 40/121]  eta: 0:01:22    time: 1.0336  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test  [ 50/121]  eta: 0:01:12    time: 1.0361  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test  [ 60/121]  eta: 0:01:02    time: 1.0222  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test  [ 70/121]  eta: 0:00:50    time: 0.9288  data: 0.0002  max mem: 8593\n",
      "Epoch: [14] Test  [ 80/121]  eta: 0:00:40    time: 0.9296  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test  [ 90/121]  eta: 0:00:31    time: 1.1155  data: 0.0004  max mem: 8593\n",
      "Epoch: [14] Test  [100/121]  eta: 0:00:21    time: 1.1495  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test  [110/121]  eta: 0:00:11    time: 1.0035  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test  [120/121]  eta: 0:00:01    time: 0.9839  data: 0.0003  max mem: 8593\n",
      "Epoch: [14] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.7', '96.0', '72.7', '92.7', '85.9', '89.9', '98.9', '92.1', '97.1', '67.0', '97.2', '73.5', '97.2', '95.2', '93.9', '96.5', '81.8', '95.6', '85.7', '96.2', '90.2']\n",
      "IoU: ['94.9', '94.4', '46.0', '88.9', '74.1', '75.5', '96.3', '82.1', '93.6', '47.4', '92.2', '62.4', '89.9', '90.4', '89.8', '90.2', '68.3', '85.8', '61.3', '89.9', '76.8']\n",
      "mean IoU: 80.5\n",
      "Epoch: [15] Train  [  0/122]  eta: 0:21:33  lr: 0.000067  loss: 0.3987 (0.3987)  time: 10.6055  data: 0.4300  max mem: 8593\n",
      "Epoch: [15] Train  [ 10/122]  eta: 0:18:06  lr: 0.000067  loss: 1.1255 (0.7446)  time: 9.7007  data: 0.0393  max mem: 8593\n",
      "Epoch: [15] Train  [ 20/122]  eta: 0:16:20  lr: 0.000067  loss: 0.6119 (0.8133)  time: 9.5638  data: 0.0002  max mem: 8593\n",
      "Epoch: [15] Train  [ 30/122]  eta: 0:14:42  lr: 0.000066  loss: 0.5330 (0.7886)  time: 9.5348  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Train  [ 40/122]  eta: 0:13:06  lr: 0.000066  loss: 0.9683 (0.7647)  time: 9.5670  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Train  [ 50/122]  eta: 0:11:31  lr: 0.000066  loss: 0.1995 (0.7097)  time: 9.6088  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Train  [ 60/122]  eta: 0:09:53  lr: 0.000066  loss: 0.5146 (0.7025)  time: 9.5556  data: 0.0002  max mem: 8593\n",
      "Epoch: [15] Train  [ 70/122]  eta: 0:08:18  lr: 0.000066  loss: 0.4444 (0.6803)  time: 9.5434  data: 0.0002  max mem: 8593\n",
      "Epoch: [15] Train  [ 80/122]  eta: 0:06:42  lr: 0.000065  loss: 0.6214 (0.6797)  time: 9.5801  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Train  [ 90/122]  eta: 0:05:06  lr: 0.000065  loss: 0.5270 (0.6768)  time: 9.6157  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Train  [100/122]  eta: 0:03:31  lr: 0.000065  loss: 0.2916 (0.6715)  time: 9.6725  data: 0.0004  max mem: 8593\n",
      "Epoch: [15] Train  [110/122]  eta: 0:01:55  lr: 0.000065  loss: 1.4009 (0.6730)  time: 9.6530  data: 0.0004  max mem: 8593\n",
      "Epoch: [15] Train  [120/122]  eta: 0:00:19  lr: 0.000065  loss: 0.5418 (0.6746)  time: 9.5588  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Train Total time: 0:19:30\n",
      "Epoch: [15] Test  [  0/121]  eta: 0:03:58    time: 1.9729  data: 0.5391  max mem: 8593\n",
      "Epoch: [15] Test  [ 10/121]  eta: 0:01:56    time: 1.0526  data: 0.0495  max mem: 8593\n",
      "Epoch: [15] Test  [ 20/121]  eta: 0:01:41    time: 0.9565  data: 0.0005  max mem: 8593\n",
      "Epoch: [15] Test  [ 30/121]  eta: 0:01:32    time: 0.9996  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Test  [ 40/121]  eta: 0:01:22    time: 1.0307  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Test  [ 50/121]  eta: 0:01:12    time: 1.0353  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Test  [ 60/121]  eta: 0:01:02    time: 1.0210  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Test  [ 70/121]  eta: 0:00:50    time: 0.9294  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Test  [ 80/121]  eta: 0:00:40    time: 0.9295  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Test  [ 90/121]  eta: 0:00:31    time: 1.1142  data: 0.0004  max mem: 8593\n",
      "Epoch: [15] Test  [100/121]  eta: 0:00:21    time: 1.1472  data: 0.0004  max mem: 8593\n",
      "Epoch: [15] Test  [110/121]  eta: 0:00:11    time: 1.0002  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Test  [120/121]  eta: 0:00:01    time: 0.9798  data: 0.0003  max mem: 8593\n",
      "Epoch: [15] Test Total time: 0:02:03\n",
      "global correct: 95.4\n",
      "average row correct: ['96.2', '96.8', '74.8', '94.2', '90.2', '91.5', '99.2', '92.2', '98.6', '70.8', '97.5', '73.8', '95.3', '96.6', '93.4', '96.2', '83.7', '96.4', '84.6', '97.4', '91.3']\n",
      "IoU: ['94.6', '93.9', '45.2', '89.8', '73.7', '74.0', '96.8', '81.6', '91.0', '48.6', '92.4', '63.3', '89.4', '91.2', '89.5', '90.7', '67.2', '86.2', '61.4', '86.1', '75.2']\n",
      "mean IoU: 80.1\n",
      "Epoch: [16] Train  [  0/122]  eta: 0:19:57  lr: 0.000065  loss: 0.7731 (0.7731)  time: 9.8184  data: 0.3926  max mem: 8593\n",
      "Epoch: [16] Train  [ 10/122]  eta: 0:18:03  lr: 0.000064  loss: 1.5399 (0.6529)  time: 9.6716  data: 0.0359  max mem: 8593\n",
      "Epoch: [16] Train  [ 20/122]  eta: 0:16:21  lr: 0.000064  loss: 0.6051 (0.6205)  time: 9.6152  data: 0.0002  max mem: 8593\n",
      "Epoch: [16] Train  [ 30/122]  eta: 0:14:43  lr: 0.000064  loss: 0.8016 (0.6290)  time: 9.5643  data: 0.0002  max mem: 8593\n",
      "Epoch: [16] Train  [ 40/122]  eta: 0:13:05  lr: 0.000064  loss: 0.5161 (0.6384)  time: 9.5278  data: 0.0002  max mem: 8593\n",
      "Epoch: [16] Train  [ 50/122]  eta: 0:11:30  lr: 0.000064  loss: 0.4728 (0.6147)  time: 9.5656  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Train  [ 60/122]  eta: 0:09:54  lr: 0.000063  loss: 0.2300 (0.5931)  time: 9.6226  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Train  [ 70/122]  eta: 0:08:19  lr: 0.000063  loss: 0.6394 (0.5911)  time: 9.6198  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Train  [ 80/122]  eta: 0:06:42  lr: 0.000063  loss: 0.7314 (0.5829)  time: 9.5977  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Train  [ 90/122]  eta: 0:05:07  lr: 0.000063  loss: 1.0615 (0.5949)  time: 9.6040  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Train  [100/122]  eta: 0:03:31  lr: 0.000063  loss: 0.4832 (0.5931)  time: 9.6213  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Train  [110/122]  eta: 0:01:55  lr: 0.000062  loss: 0.3649 (0.5909)  time: 9.5396  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Train  [120/122]  eta: 0:00:19  lr: 0.000062  loss: 0.3164 (0.5925)  time: 9.4987  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Train Total time: 0:19:29\n",
      "Epoch: [16] Test  [  0/121]  eta: 0:04:00    time: 1.9875  data: 0.5617  max mem: 8593\n",
      "Epoch: [16] Test  [ 10/121]  eta: 0:01:56    time: 1.0521  data: 0.0514  max mem: 8593\n",
      "Epoch: [16] Test  [ 20/121]  eta: 0:01:41    time: 0.9551  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [ 30/121]  eta: 0:01:32    time: 1.0004  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [ 40/121]  eta: 0:01:22    time: 1.0304  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [ 50/121]  eta: 0:01:12    time: 1.0341  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [ 60/121]  eta: 0:01:02    time: 1.0242  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [ 70/121]  eta: 0:00:50    time: 0.9316  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [ 80/121]  eta: 0:00:40    time: 0.9300  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [ 90/121]  eta: 0:00:31    time: 1.1158  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [100/121]  eta: 0:00:21    time: 1.1469  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test  [110/121]  eta: 0:00:11    time: 0.9992  data: 0.0002  max mem: 8593\n",
      "Epoch: [16] Test  [120/121]  eta: 0:00:01    time: 0.9791  data: 0.0003  max mem: 8593\n",
      "Epoch: [16] Test Total time: 0:02:03\n",
      "global correct: 95.4\n",
      "average row correct: ['96.3', '97.6', '80.7', '91.3', '88.1', '90.7', '99.2', '93.2', '98.3', '71.5', '94.6', '73.4', '94.9', '96.1', '94.2', '96.5', '82.9', '95.9', '82.7', '96.9', '90.9']\n",
      "IoU: ['94.7', '90.7', '47.9', '88.1', '72.7', '74.9', '96.7', '81.9', '92.3', '47.3', '91.6', '61.7', '88.2', '88.9', '90.1', '90.2', '67.7', '84.7', '61.2', '88.4', '74.7']\n",
      "mean IoU: 79.7\n",
      "Epoch: [17] Train  [  0/122]  eta: 0:20:19  lr: 0.000062  loss: 1.1603 (1.1603)  time: 9.9953  data: 0.3794  max mem: 8593\n",
      "Epoch: [17] Train  [ 10/122]  eta: 0:17:50  lr: 0.000062  loss: 0.8486 (0.6334)  time: 9.5619  data: 0.0347  max mem: 8593\n",
      "Epoch: [17] Train  [ 20/122]  eta: 0:16:16  lr: 0.000062  loss: 0.6928 (0.6353)  time: 9.5560  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Train  [ 30/122]  eta: 0:14:39  lr: 0.000062  loss: 0.3149 (0.5861)  time: 9.5625  data: 0.0002  max mem: 8593\n",
      "Epoch: [17] Train  [ 40/122]  eta: 0:13:04  lr: 0.000061  loss: 0.4460 (0.5889)  time: 9.5643  data: 0.0002  max mem: 8593\n",
      "Epoch: [17] Train  [ 50/122]  eta: 0:11:28  lr: 0.000061  loss: 0.2425 (0.6048)  time: 9.5675  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Train  [ 60/122]  eta: 0:09:53  lr: 0.000061  loss: 0.6726 (0.6257)  time: 9.5792  data: 0.0002  max mem: 8593\n",
      "Epoch: [17] Train  [ 70/122]  eta: 0:08:18  lr: 0.000061  loss: 0.4851 (0.6478)  time: 9.6250  data: 0.0002  max mem: 8593\n",
      "Epoch: [17] Train  [ 80/122]  eta: 0:06:42  lr: 0.000061  loss: 0.8032 (0.6528)  time: 9.5965  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Train  [ 90/122]  eta: 0:05:06  lr: 0.000060  loss: 0.4779 (0.6402)  time: 9.5786  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Train  [100/122]  eta: 0:03:30  lr: 0.000060  loss: 0.5310 (0.6466)  time: 9.5151  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Train  [110/122]  eta: 0:01:54  lr: 0.000060  loss: 0.9075 (0.6440)  time: 9.5019  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Train  [120/122]  eta: 0:00:19  lr: 0.000060  loss: 0.5085 (0.6433)  time: 9.5311  data: 0.0002  max mem: 8593\n",
      "Epoch: [17] Train Total time: 0:19:26\n",
      "Epoch: [17] Test  [  0/121]  eta: 0:03:57    time: 1.9614  data: 0.5189  max mem: 8593\n",
      "Epoch: [17] Test  [ 10/121]  eta: 0:01:56    time: 1.0504  data: 0.0477  max mem: 8593\n",
      "Epoch: [17] Test  [ 20/121]  eta: 0:01:41    time: 0.9556  data: 0.0004  max mem: 8593\n",
      "Epoch: [17] Test  [ 30/121]  eta: 0:01:32    time: 1.0000  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test  [ 40/121]  eta: 0:01:22    time: 1.0300  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test  [ 50/121]  eta: 0:01:12    time: 1.0341  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test  [ 60/121]  eta: 0:01:02    time: 1.0222  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test  [ 70/121]  eta: 0:00:50    time: 0.9306  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test  [ 80/121]  eta: 0:00:40    time: 0.9293  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test  [ 90/121]  eta: 0:00:31    time: 1.1130  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test  [100/121]  eta: 0:00:21    time: 1.1472  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test  [110/121]  eta: 0:00:11    time: 1.0011  data: 0.0002  max mem: 8593\n",
      "Epoch: [17] Test  [120/121]  eta: 0:00:01    time: 0.9823  data: 0.0003  max mem: 8593\n",
      "Epoch: [17] Test Total time: 0:02:03\n",
      "global correct: 95.5\n",
      "average row correct: ['96.5', '96.8', '78.6', '94.0', '89.5', '91.9', '99.2', '92.9', '97.8', '75.5', '96.2', '72.1', '95.2', '95.1', '95.2', '96.0', '82.6', '96.2', '81.3', '97.1', '90.6']\n",
      "IoU: ['94.8', '94.1', '48.8', '89.6', '76.2', '72.1', '96.5', '81.6', '92.3', '48.4', '91.6', '63.0', '89.9', '91.3', '90.3', '90.7', '66.6', '84.6', '61.8', '88.3', '76.4']\n",
      "mean IoU: 80.4\n",
      "Epoch: [18] Train  [  0/122]  eta: 0:19:57  lr: 0.000060  loss: 0.4539 (0.4539)  time: 9.8147  data: 0.3671  max mem: 8593\n",
      "Epoch: [18] Train  [ 10/122]  eta: 0:17:51  lr: 0.000060  loss: 0.3877 (0.5292)  time: 9.5704  data: 0.0336  max mem: 8593\n",
      "Epoch: [18] Train  [ 20/122]  eta: 0:16:17  lr: 0.000059  loss: 0.4186 (0.5540)  time: 9.5764  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Train  [ 30/122]  eta: 0:14:39  lr: 0.000059  loss: 0.4307 (0.5738)  time: 9.5583  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Train  [ 40/122]  eta: 0:13:05  lr: 0.000059  loss: 0.8455 (0.5756)  time: 9.5756  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Train  [ 50/122]  eta: 0:11:30  lr: 0.000059  loss: 0.6928 (0.5979)  time: 9.6216  data: 0.0002  max mem: 8593\n",
      "Epoch: [18] Train  [ 60/122]  eta: 0:09:54  lr: 0.000059  loss: 0.4891 (0.5950)  time: 9.5881  data: 0.0002  max mem: 8593\n",
      "Epoch: [18] Train  [ 70/122]  eta: 0:08:17  lr: 0.000058  loss: 1.1291 (0.6187)  time: 9.5494  data: 0.0002  max mem: 8593\n",
      "Epoch: [18] Train  [ 80/122]  eta: 0:06:41  lr: 0.000058  loss: 0.4833 (0.6379)  time: 9.5262  data: 0.0002  max mem: 8593\n",
      "Epoch: [18] Train  [ 90/122]  eta: 0:05:05  lr: 0.000058  loss: 0.6551 (0.6376)  time: 9.4896  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Train  [100/122]  eta: 0:03:30  lr: 0.000058  loss: 0.5293 (0.6370)  time: 9.5309  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Train  [110/122]  eta: 0:01:54  lr: 0.000058  loss: 0.9037 (0.6300)  time: 9.5155  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Train  [120/122]  eta: 0:00:19  lr: 0.000057  loss: 0.8448 (0.6272)  time: 9.5089  data: 0.0002  max mem: 8593\n",
      "Epoch: [18] Train Total time: 0:19:25\n",
      "Epoch: [18] Test  [  0/121]  eta: 0:03:50    time: 1.9055  data: 0.4832  max mem: 8593\n",
      "Epoch: [18] Test  [ 10/121]  eta: 0:01:56    time: 1.0491  data: 0.0442  max mem: 8593\n",
      "Epoch: [18] Test  [ 20/121]  eta: 0:01:41    time: 0.9594  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [ 30/121]  eta: 0:01:32    time: 1.0047  data: 0.0002  max mem: 8593\n",
      "Epoch: [18] Test  [ 40/121]  eta: 0:01:22    time: 1.0333  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [ 50/121]  eta: 0:01:12    time: 1.0356  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [ 60/121]  eta: 0:01:02    time: 1.0261  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [ 70/121]  eta: 0:00:51    time: 0.9341  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [ 80/121]  eta: 0:00:40    time: 0.9309  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [ 90/121]  eta: 0:00:31    time: 1.1140  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [100/121]  eta: 0:00:21    time: 1.1485  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [110/121]  eta: 0:00:11    time: 1.0026  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test  [120/121]  eta: 0:00:01    time: 0.9820  data: 0.0003  max mem: 8593\n",
      "Epoch: [18] Test Total time: 0:02:03\n",
      "global correct: 95.3\n",
      "average row correct: ['96.2', '97.2', '81.8', '93.8', '89.4', '90.4', '99.3', '93.4', '98.4', '70.1', '96.5', '74.5', '94.0', '96.2', '95.4', '96.1', '79.2', '97.0', '84.5', '98.2', '88.8']\n",
      "IoU: ['94.7', '92.9', '48.6', '88.9', '75.2', '75.2', '96.4', '82.0', '90.6', '46.9', '90.8', '63.7', '87.2', '88.9', '90.1', '90.4', '68.6', '81.6', '60.3', '85.8', '79.9']\n",
      "mean IoU: 79.9\n",
      "Epoch: [19] Train  [  0/122]  eta: 0:20:27  lr: 0.000057  loss: 0.5659 (0.5659)  time: 10.0614  data: 0.3853  max mem: 8593\n",
      "Epoch: [19] Train  [ 10/122]  eta: 0:18:01  lr: 0.000057  loss: 0.5800 (0.6377)  time: 9.6549  data: 0.0353  max mem: 8593\n",
      "Epoch: [19] Train  [ 20/122]  eta: 0:16:19  lr: 0.000057  loss: 0.7807 (0.6551)  time: 9.5805  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [ 30/122]  eta: 0:14:43  lr: 0.000057  loss: 0.4270 (0.6612)  time: 9.5719  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [ 40/122]  eta: 0:13:05  lr: 0.000056  loss: 0.2193 (0.6375)  time: 9.5540  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [ 50/122]  eta: 0:11:29  lr: 0.000056  loss: 0.5763 (0.6303)  time: 9.5514  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [ 60/122]  eta: 0:09:53  lr: 0.000056  loss: 0.4268 (0.6031)  time: 9.5594  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [ 70/122]  eta: 0:08:18  lr: 0.000056  loss: 0.4288 (0.5932)  time: 9.5768  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [ 80/122]  eta: 0:06:42  lr: 0.000056  loss: 0.6523 (0.5793)  time: 9.6370  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [ 90/122]  eta: 0:05:06  lr: 0.000055  loss: 0.4891 (0.5727)  time: 9.6203  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [100/122]  eta: 0:03:30  lr: 0.000055  loss: 0.3597 (0.5596)  time: 9.5849  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [110/122]  eta: 0:01:54  lr: 0.000055  loss: 0.4217 (0.5642)  time: 9.4983  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Train  [120/122]  eta: 0:00:19  lr: 0.000055  loss: 0.4637 (0.5697)  time: 9.4677  data: 0.0002  max mem: 8593\n",
      "Epoch: [19] Train Total time: 0:19:27\n",
      "Epoch: [19] Test  [  0/121]  eta: 0:04:03    time: 2.0128  data: 0.5646  max mem: 8593\n",
      "Epoch: [19] Test  [ 10/121]  eta: 0:01:57    time: 1.0565  data: 0.0516  max mem: 8593\n",
      "Epoch: [19] Test  [ 20/121]  eta: 0:01:41    time: 0.9566  data: 0.0002  max mem: 8593\n",
      "Epoch: [19] Test  [ 30/121]  eta: 0:01:32    time: 1.0019  data: 0.0002  max mem: 8593\n",
      "Epoch: [19] Test  [ 40/121]  eta: 0:01:22    time: 1.0336  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Test  [ 50/121]  eta: 0:01:12    time: 1.0373  data: 0.0002  max mem: 8593\n",
      "Epoch: [19] Test  [ 60/121]  eta: 0:01:02    time: 1.0226  data: 0.0002  max mem: 8593\n",
      "Epoch: [19] Test  [ 70/121]  eta: 0:00:51    time: 0.9298  data: 0.0002  max mem: 8593\n",
      "Epoch: [19] Test  [ 80/121]  eta: 0:00:40    time: 0.9303  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Test  [ 90/121]  eta: 0:00:31    time: 1.1163  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Test  [100/121]  eta: 0:00:21    time: 1.1495  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Test  [110/121]  eta: 0:00:11    time: 1.0015  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Test  [120/121]  eta: 0:00:01    time: 0.9809  data: 0.0003  max mem: 8593\n",
      "Epoch: [19] Test Total time: 0:02:03\n",
      "global correct: 95.3\n",
      "average row correct: ['96.1', '97.2', '81.4', '94.1', '92.0', '90.0', '99.3', '92.3', '98.4', '74.7', '96.4', '77.0', '93.2', '96.4', '96.2', '95.9', '84.4', '96.5', '84.9', '97.8', '90.5']\n",
      "IoU: ['94.6', '93.4', '48.6', '90.0', '73.6', '75.6', '96.5', '81.5', '91.3', '47.8', '91.9', '63.7', '87.6', '89.2', '90.9', '90.8', '68.1', '83.7', '60.4', '85.7', '76.6']\n",
      "mean IoU: 80.1\n",
      "Epoch: [20] Train  [  0/122]  eta: 0:20:01  lr: 0.000055  loss: 0.5191 (0.5191)  time: 9.8507  data: 0.3867  max mem: 8593\n",
      "Epoch: [20] Train  [ 10/122]  eta: 0:18:02  lr: 0.000055  loss: 1.1508 (0.5651)  time: 9.6630  data: 0.0356  max mem: 8593\n",
      "Epoch: [20] Train  [ 20/122]  eta: 0:16:19  lr: 0.000054  loss: 0.5851 (0.6407)  time: 9.5928  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Train  [ 30/122]  eta: 0:14:40  lr: 0.000054  loss: 0.5603 (0.6650)  time: 9.5127  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train  [ 40/122]  eta: 0:13:04  lr: 0.000054  loss: 0.5325 (0.6595)  time: 9.5169  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train  [ 50/122]  eta: 0:11:27  lr: 0.000054  loss: 0.4777 (0.6705)  time: 9.5171  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train  [ 60/122]  eta: 0:09:51  lr: 0.000054  loss: 0.5446 (0.6642)  time: 9.5172  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train  [ 70/122]  eta: 0:08:16  lr: 0.000053  loss: 0.3824 (0.6703)  time: 9.5699  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train  [ 80/122]  eta: 0:06:40  lr: 0.000053  loss: 0.5842 (0.6887)  time: 9.5344  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train  [ 90/122]  eta: 0:05:05  lr: 0.000053  loss: 0.3316 (0.6795)  time: 9.5167  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train  [100/122]  eta: 0:03:30  lr: 0.000053  loss: 1.5768 (0.6736)  time: 9.5653  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train  [110/122]  eta: 0:01:54  lr: 0.000053  loss: 0.6689 (0.6783)  time: 9.5685  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Train  [120/122]  eta: 0:00:19  lr: 0.000052  loss: 0.7625 (0.6766)  time: 9.5450  data: 0.0002  max mem: 8593\n",
      "Epoch: [20] Train Total time: 0:19:24\n",
      "Epoch: [20] Test  [  0/121]  eta: 0:04:01    time: 1.9958  data: 0.5683  max mem: 8593\n",
      "Epoch: [20] Test  [ 10/121]  eta: 0:01:57    time: 1.0557  data: 0.0519  max mem: 8593\n",
      "Epoch: [20] Test  [ 20/121]  eta: 0:01:41    time: 0.9586  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [ 30/121]  eta: 0:01:33    time: 1.0036  data: 0.0004  max mem: 8593\n",
      "Epoch: [20] Test  [ 40/121]  eta: 0:01:22    time: 1.0331  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [ 50/121]  eta: 0:01:12    time: 1.0364  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [ 60/121]  eta: 0:01:02    time: 1.0234  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [ 70/121]  eta: 0:00:51    time: 0.9306  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [ 80/121]  eta: 0:00:40    time: 0.9327  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [ 90/121]  eta: 0:00:31    time: 1.1164  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [100/121]  eta: 0:00:21    time: 1.1462  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [110/121]  eta: 0:00:11    time: 1.0001  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test  [120/121]  eta: 0:00:01    time: 0.9805  data: 0.0003  max mem: 8593\n",
      "Epoch: [20] Test Total time: 0:02:03\n",
      "global correct: 95.3\n",
      "average row correct: ['96.1', '97.7', '79.4', '94.0', '86.3', '90.5', '99.3', '93.4', '96.8', '69.9', '96.3', '74.6', '98.3', '96.2', '96.5', '95.9', '81.2', '96.8', '85.0', '97.6', '90.9']\n",
      "IoU: ['94.6', '92.4', '48.9', '88.2', '74.3', '73.3', '96.0', '81.9', '93.4', '48.4', '91.3', '64.1', '87.7', '90.1', '90.4', '89.7', '67.1', '80.0', '61.2', '87.5', '69.5']\n",
      "mean IoU: 79.5\n",
      "Epoch: [21] Train  [  0/122]  eta: 0:18:46  lr: 0.000052  loss: 0.6654 (0.6654)  time: 9.2296  data: 0.3418  max mem: 8593\n",
      "Epoch: [21] Train  [ 10/122]  eta: 0:17:51  lr: 0.000052  loss: 0.5980 (0.5346)  time: 9.5675  data: 0.0313  max mem: 8593\n",
      "Epoch: [21] Train  [ 20/122]  eta: 0:16:14  lr: 0.000052  loss: 0.2868 (0.5692)  time: 9.5693  data: 0.0002  max mem: 8593\n",
      "Epoch: [21] Train  [ 30/122]  eta: 0:14:41  lr: 0.000052  loss: 0.6076 (0.5850)  time: 9.5897  data: 0.0002  max mem: 8593\n",
      "Epoch: [21] Train  [ 40/122]  eta: 0:13:04  lr: 0.000052  loss: 0.4814 (0.5755)  time: 9.5898  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train  [ 50/122]  eta: 0:11:28  lr: 0.000051  loss: 0.2827 (0.5722)  time: 9.5274  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train  [ 60/122]  eta: 0:09:52  lr: 0.000051  loss: 0.5646 (0.5836)  time: 9.5088  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train  [ 70/122]  eta: 0:08:16  lr: 0.000051  loss: 0.7426 (0.5901)  time: 9.5334  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train  [ 80/122]  eta: 0:06:41  lr: 0.000051  loss: 0.6475 (0.5964)  time: 9.6022  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train  [ 90/122]  eta: 0:05:06  lr: 0.000050  loss: 0.4633 (0.5980)  time: 9.6301  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train  [100/122]  eta: 0:03:30  lr: 0.000050  loss: 1.2509 (0.5935)  time: 9.5838  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train  [110/122]  eta: 0:01:54  lr: 0.000050  loss: 0.8381 (0.5985)  time: 9.5629  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train  [120/122]  eta: 0:00:19  lr: 0.000050  loss: 0.4256 (0.5961)  time: 9.5362  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Train Total time: 0:19:26\n",
      "Epoch: [21] Test  [  0/121]  eta: 0:04:00    time: 1.9886  data: 0.5655  max mem: 8593\n",
      "Epoch: [21] Test  [ 10/121]  eta: 0:01:56    time: 1.0517  data: 0.0516  max mem: 8593\n",
      "Epoch: [21] Test  [ 20/121]  eta: 0:01:41    time: 0.9557  data: 0.0002  max mem: 8593\n",
      "Epoch: [21] Test  [ 30/121]  eta: 0:01:32    time: 1.0022  data: 0.0002  max mem: 8593\n",
      "Epoch: [21] Test  [ 40/121]  eta: 0:01:22    time: 1.0325  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test  [ 50/121]  eta: 0:01:12    time: 1.0361  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test  [ 60/121]  eta: 0:01:02    time: 1.0247  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test  [ 70/121]  eta: 0:00:50    time: 0.9332  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test  [ 80/121]  eta: 0:00:40    time: 0.9320  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test  [ 90/121]  eta: 0:00:31    time: 1.1141  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test  [100/121]  eta: 0:00:21    time: 1.1469  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test  [110/121]  eta: 0:00:11    time: 1.0012  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test  [120/121]  eta: 0:00:01    time: 0.9825  data: 0.0003  max mem: 8593\n",
      "Epoch: [21] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.9', '94.8', '78.3', '91.6', '89.5', '90.3', '99.1', '87.7', '97.6', '72.3', '92.3', '71.4', '96.8', '95.4', '93.6', '95.9', '79.1', '95.2', '83.5', '95.6', '90.6']\n",
      "IoU: ['94.9', '93.4', '50.9', '88.3', '73.7', '74.4', '96.6', '80.4', '92.6', '47.9', '90.1', '63.1', '89.3', '90.7', '89.6', '90.0', '67.4', '86.6', '61.7', '90.2', '76.2']\n",
      "mean IoU: 80.4\n",
      "Epoch: [22] Train  [  0/122]  eta: 0:20:11  lr: 0.000050  loss: 0.7235 (0.7235)  time: 9.9288  data: 0.4479  max mem: 8593\n",
      "Epoch: [22] Train  [ 10/122]  eta: 0:17:52  lr: 0.000050  loss: 0.5800 (0.5961)  time: 9.5778  data: 0.0410  max mem: 8593\n",
      "Epoch: [22] Train  [ 20/122]  eta: 0:16:11  lr: 0.000049  loss: 0.6077 (0.6511)  time: 9.5093  data: 0.0002  max mem: 8593\n",
      "Epoch: [22] Train  [ 30/122]  eta: 0:14:35  lr: 0.000049  loss: 0.3137 (0.5938)  time: 9.4897  data: 0.0002  max mem: 8593\n",
      "Epoch: [22] Train  [ 40/122]  eta: 0:13:01  lr: 0.000049  loss: 0.3329 (0.5867)  time: 9.5380  data: 0.0002  max mem: 8593\n",
      "Epoch: [22] Train  [ 50/122]  eta: 0:11:26  lr: 0.000049  loss: 0.4342 (0.5768)  time: 9.5475  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Train  [ 60/122]  eta: 0:09:52  lr: 0.000049  loss: 0.2960 (0.5854)  time: 9.6037  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Train  [ 70/122]  eta: 0:08:16  lr: 0.000048  loss: 0.6330 (0.5921)  time: 9.6008  data: 0.0002  max mem: 8593\n",
      "Epoch: [22] Train  [ 80/122]  eta: 0:06:40  lr: 0.000048  loss: 0.3535 (0.5891)  time: 9.4996  data: 0.0002  max mem: 8593\n",
      "Epoch: [22] Train  [ 90/122]  eta: 0:05:05  lr: 0.000048  loss: 0.8775 (0.6063)  time: 9.4957  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Train  [100/122]  eta: 0:03:29  lr: 0.000048  loss: 0.8010 (0.6090)  time: 9.4933  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Train  [110/122]  eta: 0:01:54  lr: 0.000048  loss: 0.7543 (0.6147)  time: 9.4978  data: 0.0002  max mem: 8593\n",
      "Epoch: [22] Train  [120/122]  eta: 0:00:19  lr: 0.000047  loss: 0.4727 (0.6295)  time: 9.5845  data: 0.0002  max mem: 8593\n",
      "Epoch: [22] Train Total time: 0:19:23\n",
      "Epoch: [22] Test  [  0/121]  eta: 0:04:02    time: 2.0022  data: 0.5749  max mem: 8593\n",
      "Epoch: [22] Test  [ 10/121]  eta: 0:01:57    time: 1.0550  data: 0.0525  max mem: 8593\n",
      "Epoch: [22] Test  [ 20/121]  eta: 0:01:41    time: 0.9573  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [ 30/121]  eta: 0:01:32    time: 1.0016  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [ 40/121]  eta: 0:01:22    time: 1.0302  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [ 50/121]  eta: 0:01:12    time: 1.0356  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [ 60/121]  eta: 0:01:02    time: 1.0240  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [ 70/121]  eta: 0:00:50    time: 0.9297  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [ 80/121]  eta: 0:00:40    time: 0.9298  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [ 90/121]  eta: 0:00:31    time: 1.1159  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [100/121]  eta: 0:00:21    time: 1.1489  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [110/121]  eta: 0:00:11    time: 1.0007  data: 0.0003  max mem: 8593\n",
      "Epoch: [22] Test  [120/121]  eta: 0:00:01    time: 0.9815  data: 0.0002  max mem: 8593\n",
      "Epoch: [22] Test Total time: 0:02:03\n",
      "global correct: 95.4\n",
      "average row correct: ['96.2', '97.8', '78.2', '95.0', '91.4', '91.5', '99.2', '93.4', '97.7', '69.1', '96.5', '75.9', '96.2', '95.9', '95.0', '96.6', '82.8', '96.4', '84.6', '97.5', '90.3']\n",
      "IoU: ['94.7', '92.0', '49.8', '89.2', '73.2', '73.3', '96.7', '82.1', '92.6', '48.4', '91.8', '65.6', '89.8', '91.6', '90.3', '90.2', '67.6', '84.3', '60.2', '86.8', '74.0']\n",
      "mean IoU: 80.2\n",
      "Epoch: [23] Train  [  0/122]  eta: 0:20:16  lr: 0.000047  loss: 1.9092 (1.9092)  time: 9.9690  data: 0.4158  max mem: 8593\n",
      "Epoch: [23] Train  [ 10/122]  eta: 0:18:01  lr: 0.000047  loss: 0.6110 (0.7856)  time: 9.6607  data: 0.0380  max mem: 8593\n",
      "Epoch: [23] Train  [ 20/122]  eta: 0:16:23  lr: 0.000047  loss: 0.5511 (0.6918)  time: 9.6273  data: 0.0002  max mem: 8593\n",
      "Epoch: [23] Train  [ 30/122]  eta: 0:14:42  lr: 0.000047  loss: 0.6367 (0.6800)  time: 9.5612  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Train  [ 40/122]  eta: 0:13:06  lr: 0.000047  loss: 1.3448 (0.6768)  time: 9.5458  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Train  [ 50/122]  eta: 0:11:31  lr: 0.000046  loss: 0.4888 (0.6612)  time: 9.5999  data: 0.0002  max mem: 8593\n",
      "Epoch: [23] Train  [ 60/122]  eta: 0:09:55  lr: 0.000046  loss: 0.3310 (0.6426)  time: 9.6141  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Train  [ 70/122]  eta: 0:08:18  lr: 0.000046  loss: 0.2776 (0.6252)  time: 9.5529  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Train  [ 80/122]  eta: 0:06:41  lr: 0.000046  loss: 0.4714 (0.6247)  time: 9.4699  data: 0.0004  max mem: 8593\n",
      "Epoch: [23] Train  [ 90/122]  eta: 0:05:06  lr: 0.000045  loss: 0.5952 (0.6249)  time: 9.5559  data: 0.0004  max mem: 8593\n",
      "Epoch: [23] Train  [100/122]  eta: 0:03:30  lr: 0.000045  loss: 0.5461 (0.6181)  time: 9.5883  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Train  [110/122]  eta: 0:01:54  lr: 0.000045  loss: 0.4585 (0.6160)  time: 9.5046  data: 0.0004  max mem: 8593\n",
      "Epoch: [23] Train  [120/122]  eta: 0:00:19  lr: 0.000045  loss: 0.8258 (0.6133)  time: 9.4616  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Train Total time: 0:19:25\n",
      "Epoch: [23] Test  [  0/121]  eta: 0:03:58    time: 1.9728  data: 0.5450  max mem: 8593\n",
      "Epoch: [23] Test  [ 10/121]  eta: 0:01:56    time: 1.0531  data: 0.0498  max mem: 8593\n",
      "Epoch: [23] Test  [ 20/121]  eta: 0:01:41    time: 0.9567  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Test  [ 30/121]  eta: 0:01:32    time: 1.0002  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Test  [ 40/121]  eta: 0:01:22    time: 1.0331  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Test  [ 50/121]  eta: 0:01:12    time: 1.0398  data: 0.0002  max mem: 8593\n",
      "Epoch: [23] Test  [ 60/121]  eta: 0:01:02    time: 1.0280  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Test  [ 70/121]  eta: 0:00:51    time: 0.9363  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Test  [ 80/121]  eta: 0:00:40    time: 0.9328  data: 0.0002  max mem: 8593\n",
      "Epoch: [23] Test  [ 90/121]  eta: 0:00:31    time: 1.1159  data: 0.0002  max mem: 8593\n",
      "Epoch: [23] Test  [100/121]  eta: 0:00:21    time: 1.1494  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Test  [110/121]  eta: 0:00:11    time: 1.0023  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Test  [120/121]  eta: 0:00:01    time: 0.9831  data: 0.0003  max mem: 8593\n",
      "Epoch: [23] Test Total time: 0:02:03\n",
      "global correct: 95.5\n",
      "average row correct: ['96.6', '97.2', '75.9', '95.4', '90.8', '91.0', '99.1', '89.4', '98.1', '75.3', '96.2', '70.9', '94.9', '96.3', '95.4', '96.0', '81.7', '95.1', '82.8', '97.3', '90.9']\n",
      "IoU: ['94.8', '93.4', '49.8', '91.0', '74.5', '73.1', '97.0', '81.7', '92.3', '48.3', '93.0', '62.9', '89.5', '91.1', '90.5', '90.6', '68.1', '89.7', '62.1', '88.3', '69.4']\n",
      "mean IoU: 80.5\n",
      "Epoch: [24] Train  [  0/122]  eta: 0:20:05  lr: 0.000045  loss: 0.6580 (0.6580)  time: 9.8826  data: 0.4037  max mem: 8593\n",
      "Epoch: [24] Train  [ 10/122]  eta: 0:18:00  lr: 0.000045  loss: 0.4454 (0.5964)  time: 9.6484  data: 0.0370  max mem: 8593\n",
      "Epoch: [24] Train  [ 20/122]  eta: 0:16:17  lr: 0.000044  loss: 0.4846 (0.6252)  time: 9.5657  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Train  [ 30/122]  eta: 0:14:40  lr: 0.000044  loss: 0.4626 (0.6020)  time: 9.5286  data: 0.0004  max mem: 8593\n",
      "Epoch: [24] Train  [ 40/122]  eta: 0:13:06  lr: 0.000044  loss: 0.7229 (0.6318)  time: 9.6082  data: 0.0011  max mem: 8593\n",
      "Epoch: [24] Train  [ 50/122]  eta: 0:11:31  lr: 0.000044  loss: 0.5355 (0.6331)  time: 9.6430  data: 0.0010  max mem: 8593\n",
      "Epoch: [24] Train  [ 60/122]  eta: 0:09:54  lr: 0.000044  loss: 0.6011 (0.6243)  time: 9.6021  data: 0.0004  max mem: 8593\n",
      "Epoch: [24] Train  [ 70/122]  eta: 0:08:19  lr: 0.000043  loss: 0.3949 (0.6268)  time: 9.6061  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Train  [ 80/122]  eta: 0:06:42  lr: 0.000043  loss: 0.6673 (0.6286)  time: 9.5887  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Train  [ 90/122]  eta: 0:05:07  lr: 0.000043  loss: 0.8565 (0.6358)  time: 9.5930  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Train  [100/122]  eta: 0:03:30  lr: 0.000043  loss: 0.3770 (0.6403)  time: 9.5563  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Train  [110/122]  eta: 0:01:55  lr: 0.000043  loss: 0.4048 (0.6324)  time: 9.5562  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Train  [120/122]  eta: 0:00:19  lr: 0.000042  loss: 0.8819 (0.6407)  time: 9.6002  data: 0.0004  max mem: 8593\n",
      "Epoch: [24] Train Total time: 0:19:30\n",
      "Epoch: [24] Test  [  0/121]  eta: 0:03:55    time: 1.9484  data: 0.5172  max mem: 8593\n",
      "Epoch: [24] Test  [ 10/121]  eta: 0:01:56    time: 1.0520  data: 0.0473  max mem: 8593\n",
      "Epoch: [24] Test  [ 20/121]  eta: 0:01:41    time: 0.9580  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Test  [ 30/121]  eta: 0:01:32    time: 1.0038  data: 0.0004  max mem: 8593\n",
      "Epoch: [24] Test  [ 40/121]  eta: 0:01:22    time: 1.0353  data: 0.0006  max mem: 8593\n",
      "Epoch: [24] Test  [ 50/121]  eta: 0:01:12    time: 1.0373  data: 0.0007  max mem: 8593\n",
      "Epoch: [24] Test  [ 60/121]  eta: 0:01:02    time: 1.0247  data: 0.0005  max mem: 8593\n",
      "Epoch: [24] Test  [ 70/121]  eta: 0:00:51    time: 0.9321  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Test  [ 80/121]  eta: 0:00:40    time: 0.9310  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Test  [ 90/121]  eta: 0:00:31    time: 1.1166  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Test  [100/121]  eta: 0:00:21    time: 1.1500  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Test  [110/121]  eta: 0:00:11    time: 1.0028  data: 0.0003  max mem: 8593\n",
      "Epoch: [24] Test  [120/121]  eta: 0:00:01    time: 0.9825  data: 0.0002  max mem: 8593\n",
      "Epoch: [24] Test Total time: 0:02:03\n",
      "global correct: 95.8\n",
      "average row correct: ['97.1', '96.1', '71.6', '95.9', '86.7', '88.0', '99.3', '92.3', '97.0', '69.9', '95.9', '72.0', '97.0', '95.8', '92.5', '96.1', '76.8', '95.9', '81.5', '96.8', '90.0']\n",
      "IoU: ['95.2', '93.1', '51.4', '90.4', '75.2', '77.1', '96.4', '82.0', '92.4', '49.7', '92.7', '62.8', '90.1', '91.6', '89.1', '90.4', '68.4', '86.7', '63.3', '88.5', '75.8']\n",
      "mean IoU: 81.1\n",
      "Epoch: [25] Train  [  0/122]  eta: 0:20:12  lr: 0.000042  loss: 0.2692 (0.2692)  time: 9.9358  data: 0.3995  max mem: 8593\n",
      "Epoch: [25] Train  [ 10/122]  eta: 0:17:46  lr: 0.000042  loss: 0.3806 (0.5130)  time: 9.5260  data: 0.0366  max mem: 8593\n",
      "Epoch: [25] Train  [ 20/122]  eta: 0:16:13  lr: 0.000042  loss: 0.6506 (0.5812)  time: 9.5196  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Train  [ 30/122]  eta: 0:14:39  lr: 0.000042  loss: 0.9551 (0.6764)  time: 9.5784  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Train  [ 40/122]  eta: 0:13:04  lr: 0.000041  loss: 0.3665 (0.6497)  time: 9.6020  data: 0.0004  max mem: 8593\n",
      "Epoch: [25] Train  [ 50/122]  eta: 0:11:29  lr: 0.000041  loss: 0.5202 (0.6594)  time: 9.5889  data: 0.0004  max mem: 8593\n",
      "Epoch: [25] Train  [ 60/122]  eta: 0:09:53  lr: 0.000041  loss: 0.6939 (0.6679)  time: 9.5735  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Train  [ 70/122]  eta: 0:08:18  lr: 0.000041  loss: 0.6207 (0.6443)  time: 9.5920  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Train  [ 80/122]  eta: 0:06:42  lr: 0.000041  loss: 0.4000 (0.6242)  time: 9.6439  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Train  [ 90/122]  eta: 0:05:06  lr: 0.000040  loss: 0.8387 (0.6315)  time: 9.6385  data: 0.0002  max mem: 8593\n",
      "Epoch: [25] Train  [100/122]  eta: 0:03:30  lr: 0.000040  loss: 0.7226 (0.6281)  time: 9.5520  data: 0.0002  max mem: 8593\n",
      "Epoch: [25] Train  [110/122]  eta: 0:01:54  lr: 0.000040  loss: 0.8745 (0.6427)  time: 9.4895  data: 0.0002  max mem: 8593\n",
      "Epoch: [25] Train  [120/122]  eta: 0:00:19  lr: 0.000040  loss: 0.4586 (0.6478)  time: 9.4927  data: 0.0002  max mem: 8593\n",
      "Epoch: [25] Train Total time: 0:19:27\n",
      "Epoch: [25] Test  [  0/121]  eta: 0:04:01    time: 1.9962  data: 0.5680  max mem: 8593\n",
      "Epoch: [25] Test  [ 10/121]  eta: 0:01:57    time: 1.0588  data: 0.0519  max mem: 8593\n",
      "Epoch: [25] Test  [ 20/121]  eta: 0:01:41    time: 0.9598  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [ 30/121]  eta: 0:01:33    time: 1.0034  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [ 40/121]  eta: 0:01:22    time: 1.0349  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [ 50/121]  eta: 0:01:13    time: 1.0417  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [ 60/121]  eta: 0:01:02    time: 1.0291  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [ 70/121]  eta: 0:00:51    time: 0.9341  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [ 80/121]  eta: 0:00:41    time: 0.9345  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [ 90/121]  eta: 0:00:31    time: 1.1184  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [100/121]  eta: 0:00:21    time: 1.1501  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [110/121]  eta: 0:00:11    time: 1.0041  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test  [120/121]  eta: 0:00:01    time: 0.9838  data: 0.0003  max mem: 8593\n",
      "Epoch: [25] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.9', '97.4', '76.0', '92.8', '89.4', '90.7', '99.3', '92.0', '94.1', '64.4', '96.3', '72.1', '96.3', '93.0', '94.3', '96.3', '78.9', '96.1', '84.5', '96.4', '90.8']\n",
      "IoU: ['95.1', '92.7', '53.0', '88.6', '75.1', '73.8', '95.5', '81.5', '91.6', '50.2', '90.7', '64.5', '91.1', '90.3', '89.9', '89.9', '68.0', '80.9', '60.5', '89.6', '71.4']\n",
      "mean IoU: 80.2\n",
      "Epoch: [26] Train  [  0/122]  eta: 0:19:59  lr: 0.000040  loss: 0.4060 (0.4060)  time: 9.8359  data: 0.4087  max mem: 8593\n",
      "Epoch: [26] Train  [ 10/122]  eta: 0:17:56  lr: 0.000040  loss: 0.5813 (0.5138)  time: 9.6125  data: 0.0374  max mem: 8593\n",
      "Epoch: [26] Train  [ 20/122]  eta: 0:16:23  lr: 0.000039  loss: 0.8554 (0.5569)  time: 9.6300  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Train  [ 30/122]  eta: 0:14:46  lr: 0.000039  loss: 0.6695 (0.5895)  time: 9.6546  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Train  [ 40/122]  eta: 0:13:08  lr: 0.000039  loss: 0.9271 (0.5997)  time: 9.5970  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Train  [ 50/122]  eta: 0:11:31  lr: 0.000039  loss: 0.6103 (0.5863)  time: 9.5461  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Train  [ 60/122]  eta: 0:09:54  lr: 0.000038  loss: 1.0913 (0.6018)  time: 9.5310  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Train  [ 70/122]  eta: 0:08:17  lr: 0.000038  loss: 0.4402 (0.5946)  time: 9.4915  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Train  [ 80/122]  eta: 0:06:42  lr: 0.000038  loss: 0.6573 (0.5835)  time: 9.5385  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Train  [ 90/122]  eta: 0:05:06  lr: 0.000038  loss: 0.2170 (0.5903)  time: 9.5910  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Train  [100/122]  eta: 0:03:30  lr: 0.000038  loss: 0.3823 (0.5947)  time: 9.4857  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Train  [110/122]  eta: 0:01:54  lr: 0.000037  loss: 0.7041 (0.6012)  time: 9.4967  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Train  [120/122]  eta: 0:00:19  lr: 0.000037  loss: 0.3359 (0.5953)  time: 9.5982  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Train Total time: 0:19:27\n",
      "Epoch: [26] Test  [  0/121]  eta: 0:03:55    time: 1.9467  data: 0.5156  max mem: 8593\n",
      "Epoch: [26] Test  [ 10/121]  eta: 0:01:56    time: 1.0504  data: 0.0471  max mem: 8593\n",
      "Epoch: [26] Test  [ 20/121]  eta: 0:01:41    time: 0.9587  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Test  [ 30/121]  eta: 0:01:32    time: 1.0044  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Test  [ 40/121]  eta: 0:01:22    time: 1.0335  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Test  [ 50/121]  eta: 0:01:12    time: 1.0385  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Test  [ 60/121]  eta: 0:01:02    time: 1.0261  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Test  [ 70/121]  eta: 0:00:51    time: 0.9312  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Test  [ 80/121]  eta: 0:00:40    time: 0.9322  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Test  [ 90/121]  eta: 0:00:31    time: 1.1180  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Test  [100/121]  eta: 0:00:21    time: 1.1497  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Test  [110/121]  eta: 0:00:11    time: 1.0035  data: 0.0003  max mem: 8593\n",
      "Epoch: [26] Test  [120/121]  eta: 0:00:01    time: 0.9840  data: 0.0002  max mem: 8593\n",
      "Epoch: [26] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.6', '97.1', '75.8', '94.1', '89.6', '90.6', '99.2', '90.9', '97.9', '76.0', '95.4', '73.8', '95.1', '96.0', '95.0', '95.7', '81.9', '96.0', '83.2', '96.8', '91.5']\n",
      "IoU: ['94.9', '94.3', '51.5', '90.1', '71.5', '75.0', '96.8', '81.7', '92.5', '49.0', '91.8', '63.5', '90.0', '91.7', '90.6', '90.9', '67.9', '85.2', '62.0', '89.4', '70.4']\n",
      "mean IoU: 80.5\n",
      "Epoch: [27] Train  [  0/122]  eta: 0:20:21  lr: 0.000037  loss: 0.5438 (0.5438)  time: 10.0153  data: 0.4139  max mem: 8593\n",
      "Epoch: [27] Train  [ 10/122]  eta: 0:18:09  lr: 0.000037  loss: 0.6369 (0.6286)  time: 9.7320  data: 0.0380  max mem: 8593\n",
      "Epoch: [27] Train  [ 20/122]  eta: 0:16:20  lr: 0.000037  loss: 0.4391 (0.5503)  time: 9.5921  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Train  [ 30/122]  eta: 0:14:43  lr: 0.000037  loss: 1.8133 (0.6178)  time: 9.5259  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Train  [ 40/122]  eta: 0:13:08  lr: 0.000036  loss: 0.3830 (0.6340)  time: 9.6093  data: 0.0004  max mem: 8593\n",
      "Epoch: [27] Train  [ 50/122]  eta: 0:11:31  lr: 0.000036  loss: 0.3826 (0.6428)  time: 9.5981  data: 0.0005  max mem: 8593\n",
      "Epoch: [27] Train  [ 60/122]  eta: 0:09:53  lr: 0.000036  loss: 0.9509 (0.6127)  time: 9.5158  data: 0.0005  max mem: 8593\n",
      "Epoch: [27] Train  [ 70/122]  eta: 0:08:16  lr: 0.000036  loss: 0.5724 (0.6322)  time: 9.4456  data: 0.0005  max mem: 8593\n",
      "Epoch: [27] Train  [ 80/122]  eta: 0:06:41  lr: 0.000035  loss: 1.0803 (0.6590)  time: 9.4985  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Train  [ 90/122]  eta: 0:05:06  lr: 0.000035  loss: 0.2205 (0.6444)  time: 9.6254  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Train  [100/122]  eta: 0:03:30  lr: 0.000035  loss: 0.9027 (0.6508)  time: 9.6489  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Train  [110/122]  eta: 0:01:54  lr: 0.000035  loss: 0.4567 (0.6448)  time: 9.5801  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Train  [120/122]  eta: 0:00:19  lr: 0.000035  loss: 0.8095 (0.6432)  time: 9.5398  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Train Total time: 0:19:27\n",
      "Epoch: [27] Test  [  0/121]  eta: 0:03:59    time: 1.9754  data: 0.5434  max mem: 8593\n",
      "Epoch: [27] Test  [ 10/121]  eta: 0:01:57    time: 1.0559  data: 0.0496  max mem: 8593\n",
      "Epoch: [27] Test  [ 20/121]  eta: 0:01:41    time: 0.9608  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Test  [ 30/121]  eta: 0:01:33    time: 1.0057  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Test  [ 40/121]  eta: 0:01:22    time: 1.0328  data: 0.0002  max mem: 8593\n",
      "Epoch: [27] Test  [ 50/121]  eta: 0:01:13    time: 1.0361  data: 0.0002  max mem: 8593\n",
      "Epoch: [27] Test  [ 60/121]  eta: 0:01:02    time: 1.0244  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Test  [ 70/121]  eta: 0:00:51    time: 0.9312  data: 0.0002  max mem: 8593\n",
      "Epoch: [27] Test  [ 80/121]  eta: 0:00:40    time: 0.9328  data: 0.0002  max mem: 8593\n",
      "Epoch: [27] Test  [ 90/121]  eta: 0:00:31    time: 1.1192  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Test  [100/121]  eta: 0:00:21    time: 1.1509  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Test  [110/121]  eta: 0:00:11    time: 1.0007  data: 0.0003  max mem: 8593\n",
      "Epoch: [27] Test  [120/121]  eta: 0:00:01    time: 0.9832  data: 0.0002  max mem: 8593\n",
      "Epoch: [27] Test Total time: 0:02:03\n",
      "global correct: 95.4\n",
      "average row correct: ['96.2', '97.9', '72.0', '95.8', '87.1', '91.8', '99.3', '93.9', '97.7', '77.7', '95.4', '74.5', '95.6', '96.5', '96.1', '95.7', '81.0', '96.8', '83.5', '97.7', '90.3']\n",
      "IoU: ['94.7', '89.4', '49.7', '90.9', '74.6', '72.5', '96.8', '81.8', '92.3', '48.6', '92.2', '64.8', '89.9', '89.9', '90.5', '90.7', '67.7', '83.8', '62.4', '85.8', '74.0']\n",
      "mean IoU: 80.1\n",
      "Epoch: [28] Train  [  0/122]  eta: 0:20:21  lr: 0.000035  loss: 0.7069 (0.7069)  time: 10.0127  data: 0.3981  max mem: 8593\n",
      "Epoch: [28] Train  [ 10/122]  eta: 0:18:06  lr: 0.000034  loss: 0.4826 (0.6168)  time: 9.7018  data: 0.0364  max mem: 8593\n",
      "Epoch: [28] Train  [ 20/122]  eta: 0:16:19  lr: 0.000034  loss: 0.8007 (0.5958)  time: 9.5869  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Train  [ 30/122]  eta: 0:14:41  lr: 0.000034  loss: 0.4027 (0.5827)  time: 9.5151  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Train  [ 40/122]  eta: 0:13:05  lr: 0.000034  loss: 0.9480 (0.5947)  time: 9.5412  data: 0.0004  max mem: 8593\n",
      "Epoch: [28] Train  [ 50/122]  eta: 0:11:28  lr: 0.000034  loss: 0.5872 (0.6097)  time: 9.5408  data: 0.0004  max mem: 8593\n",
      "Epoch: [28] Train  [ 60/122]  eta: 0:09:52  lr: 0.000033  loss: 0.7986 (0.6106)  time: 9.5118  data: 0.0004  max mem: 8593\n",
      "Epoch: [28] Train  [ 70/122]  eta: 0:08:16  lr: 0.000033  loss: 0.3739 (0.6107)  time: 9.5020  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Train  [ 80/122]  eta: 0:06:40  lr: 0.000033  loss: 0.4925 (0.6331)  time: 9.5195  data: 0.0002  max mem: 8593\n",
      "Epoch: [28] Train  [ 90/122]  eta: 0:05:05  lr: 0.000033  loss: 0.5562 (0.6268)  time: 9.5102  data: 0.0002  max mem: 8593\n",
      "Epoch: [28] Train  [100/122]  eta: 0:03:29  lr: 0.000032  loss: 0.4965 (0.6132)  time: 9.4998  data: 0.0002  max mem: 8593\n",
      "Epoch: [28] Train  [110/122]  eta: 0:01:54  lr: 0.000032  loss: 0.6044 (0.6112)  time: 9.5356  data: 0.0002  max mem: 8593\n",
      "Epoch: [28] Train  [120/122]  eta: 0:00:19  lr: 0.000032  loss: 0.3066 (0.6172)  time: 9.5425  data: 0.0002  max mem: 8593\n",
      "Epoch: [28] Train Total time: 0:19:23\n",
      "Epoch: [28] Test  [  0/121]  eta: 0:03:57    time: 1.9627  data: 0.5358  max mem: 8593\n",
      "Epoch: [28] Test  [ 10/121]  eta: 0:01:56    time: 1.0528  data: 0.0489  max mem: 8593\n",
      "Epoch: [28] Test  [ 20/121]  eta: 0:01:41    time: 0.9579  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [ 30/121]  eta: 0:01:32    time: 1.0046  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [ 40/121]  eta: 0:01:22    time: 1.0362  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [ 50/121]  eta: 0:01:13    time: 1.0412  data: 0.0002  max mem: 8593\n",
      "Epoch: [28] Test  [ 60/121]  eta: 0:01:02    time: 1.0290  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [ 70/121]  eta: 0:00:51    time: 0.9334  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [ 80/121]  eta: 0:00:41    time: 0.9323  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [ 90/121]  eta: 0:00:31    time: 1.1168  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [100/121]  eta: 0:00:21    time: 1.1500  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [110/121]  eta: 0:00:11    time: 1.0034  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test  [120/121]  eta: 0:00:01    time: 0.9838  data: 0.0003  max mem: 8593\n",
      "Epoch: [28] Test Total time: 0:02:03\n",
      "global correct: 95.5\n",
      "average row correct: ['96.6', '97.2', '81.6', '94.0', '91.7', '90.3', '99.3', '90.6', '97.7', '71.0', '94.6', '72.6', '96.3', '96.1', '95.0', '95.9', '80.4', '96.5', '83.9', '97.2', '90.5']\n",
      "IoU: ['94.9', '93.0', '53.6', '89.9', '75.1', '75.7', '96.2', '81.7', '91.9', '49.3', '91.6', '63.7', '89.5', '90.9', '90.2', '90.1', '67.0', '81.7', '62.0', '87.8', '71.6']\n",
      "mean IoU: 80.4\n",
      "Epoch: [29] Train  [  0/122]  eta: 0:20:02  lr: 0.000032  loss: 0.6351 (0.6351)  time: 9.8553  data: 0.3638  max mem: 8593\n",
      "Epoch: [29] Train  [ 10/122]  eta: 0:17:58  lr: 0.000032  loss: 0.6661 (0.6153)  time: 9.6300  data: 0.0333  max mem: 8593\n",
      "Epoch: [29] Train  [ 20/122]  eta: 0:16:15  lr: 0.000032  loss: 0.5674 (0.6591)  time: 9.5509  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Train  [ 30/122]  eta: 0:14:41  lr: 0.000031  loss: 0.3587 (0.6165)  time: 9.5555  data: 0.0004  max mem: 8593\n",
      "Epoch: [29] Train  [ 40/122]  eta: 0:13:05  lr: 0.000031  loss: 0.7398 (0.6394)  time: 9.5912  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Train  [ 50/122]  eta: 0:11:30  lr: 0.000031  loss: 0.7117 (0.6297)  time: 9.5977  data: 0.0004  max mem: 8593\n",
      "Epoch: [29] Train  [ 60/122]  eta: 0:09:52  lr: 0.000031  loss: 0.7100 (0.6248)  time: 9.5339  data: 0.0005  max mem: 8593\n",
      "Epoch: [29] Train  [ 70/122]  eta: 0:08:17  lr: 0.000030  loss: 0.3067 (0.6297)  time: 9.5189  data: 0.0004  max mem: 8593\n",
      "Epoch: [29] Train  [ 80/122]  eta: 0:06:41  lr: 0.000030  loss: 1.0661 (0.6414)  time: 9.5561  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Train  [ 90/122]  eta: 0:05:05  lr: 0.000030  loss: 0.5093 (0.6309)  time: 9.4959  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Train  [100/122]  eta: 0:03:30  lr: 0.000030  loss: 0.5109 (0.6181)  time: 9.5162  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Train  [110/122]  eta: 0:01:54  lr: 0.000030  loss: 0.6254 (0.6196)  time: 9.5743  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Train  [120/122]  eta: 0:00:19  lr: 0.000029  loss: 0.4698 (0.6185)  time: 9.6041  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Train Total time: 0:19:26\n",
      "Epoch: [29] Test  [  0/121]  eta: 0:04:00    time: 1.9842  data: 0.5590  max mem: 8593\n",
      "Epoch: [29] Test  [ 10/121]  eta: 0:01:57    time: 1.0568  data: 0.0511  max mem: 8593\n",
      "Epoch: [29] Test  [ 20/121]  eta: 0:01:41    time: 0.9583  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Test  [ 30/121]  eta: 0:01:32    time: 1.0024  data: 0.0004  max mem: 8593\n",
      "Epoch: [29] Test  [ 40/121]  eta: 0:01:22    time: 1.0338  data: 0.0004  max mem: 8593\n",
      "Epoch: [29] Test  [ 50/121]  eta: 0:01:13    time: 1.0392  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Test  [ 60/121]  eta: 0:01:02    time: 1.0257  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Test  [ 70/121]  eta: 0:00:51    time: 0.9316  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Test  [ 80/121]  eta: 0:00:40    time: 0.9325  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Test  [ 90/121]  eta: 0:00:31    time: 1.1179  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Test  [100/121]  eta: 0:00:21    time: 1.1517  data: 0.0002  max mem: 8593\n",
      "Epoch: [29] Test  [110/121]  eta: 0:00:11    time: 1.0030  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Test  [120/121]  eta: 0:00:01    time: 0.9826  data: 0.0003  max mem: 8593\n",
      "Epoch: [29] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.6', '97.2', '77.4', '95.3', '89.0', '91.3', '99.3', '89.7', '96.7', '73.3', '95.6', '72.9', '94.9', '97.0', '94.9', '96.4', '82.3', '95.7', '82.3', '97.4', '90.3']\n",
      "IoU: ['94.9', '92.7', '52.9', '90.7', '73.7', '73.7', '96.3', '80.6', '91.9', '50.4', '92.0', '64.4', '89.4', '89.1', '90.0', '90.0', '68.4', '86.4', '62.8', '86.8', '74.3']\n",
      "mean IoU: 80.5\n",
      "Epoch: [30] Train  [  0/122]  eta: 0:20:38  lr: 0.000029  loss: 1.8193 (1.8193)  time: 10.1506  data: 0.4114  max mem: 8593\n",
      "Epoch: [30] Train  [ 10/122]  eta: 0:17:56  lr: 0.000029  loss: 0.6453 (0.7225)  time: 9.6100  data: 0.0377  max mem: 8593\n",
      "Epoch: [30] Train  [ 20/122]  eta: 0:16:17  lr: 0.000029  loss: 0.6478 (0.6634)  time: 9.5591  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [ 30/122]  eta: 0:14:43  lr: 0.000029  loss: 0.4203 (0.6454)  time: 9.6073  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [ 40/122]  eta: 0:13:06  lr: 0.000028  loss: 0.7059 (0.6432)  time: 9.6068  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [ 50/122]  eta: 0:11:29  lr: 0.000028  loss: 0.5107 (0.6309)  time: 9.5207  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [ 60/122]  eta: 0:09:53  lr: 0.000028  loss: 1.0012 (0.6086)  time: 9.5166  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [ 70/122]  eta: 0:08:18  lr: 0.000028  loss: 0.4890 (0.6332)  time: 9.6006  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [ 80/122]  eta: 0:06:42  lr: 0.000028  loss: 0.8474 (0.6312)  time: 9.5935  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [ 90/122]  eta: 0:05:06  lr: 0.000027  loss: 0.5052 (0.6240)  time: 9.5169  data: 0.0002  max mem: 8593\n",
      "Epoch: [30] Train  [100/122]  eta: 0:03:30  lr: 0.000027  loss: 0.6231 (0.6129)  time: 9.5398  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [110/122]  eta: 0:01:54  lr: 0.000027  loss: 0.7842 (0.6281)  time: 9.5710  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train  [120/122]  eta: 0:00:19  lr: 0.000027  loss: 0.4058 (0.6276)  time: 9.5882  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Train Total time: 0:19:28\n",
      "Epoch: [30] Test  [  0/121]  eta: 0:03:59    time: 1.9811  data: 0.5484  max mem: 8593\n",
      "Epoch: [30] Test  [ 10/121]  eta: 0:01:57    time: 1.0563  data: 0.0502  max mem: 8593\n",
      "Epoch: [30] Test  [ 20/121]  eta: 0:01:41    time: 0.9595  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [ 30/121]  eta: 0:01:33    time: 1.0033  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [ 40/121]  eta: 0:01:22    time: 1.0318  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [ 50/121]  eta: 0:01:13    time: 1.0380  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [ 60/121]  eta: 0:01:02    time: 1.0284  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [ 70/121]  eta: 0:00:51    time: 0.9338  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [ 80/121]  eta: 0:00:40    time: 0.9307  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [ 90/121]  eta: 0:00:31    time: 1.1163  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [100/121]  eta: 0:00:21    time: 1.1507  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [110/121]  eta: 0:00:11    time: 1.0037  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test  [120/121]  eta: 0:00:01    time: 0.9842  data: 0.0003  max mem: 8593\n",
      "Epoch: [30] Test Total time: 0:02:03\n",
      "global correct: 95.5\n",
      "average row correct: ['96.3', '97.1', '82.7', '95.5', '90.2', '90.0', '99.1', '92.9', '97.9', '75.1', '95.7', '74.3', '95.7', '96.6', '95.0', '96.1', '84.7', '96.3', '83.0', '97.8', '90.7']\n",
      "IoU: ['94.8', '94.9', '53.7', '90.3', '75.2', '75.2', '96.1', '82.5', '92.6', '47.8', '92.0', '64.1', '89.9', '91.0', '89.9', '90.7', '66.8', '83.8', '62.0', '88.1', '70.0']\n",
      "mean IoU: 80.5\n",
      "Epoch: [31] Train  [  0/122]  eta: 0:20:16  lr: 0.000027  loss: 0.7657 (0.7657)  time: 9.9737  data: 0.3694  max mem: 8593\n",
      "Epoch: [31] Train  [ 10/122]  eta: 0:17:51  lr: 0.000026  loss: 0.6907 (0.5468)  time: 9.5710  data: 0.0338  max mem: 8593\n",
      "Epoch: [31] Train  [ 20/122]  eta: 0:16:20  lr: 0.000026  loss: 0.5676 (0.5725)  time: 9.5983  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Train  [ 30/122]  eta: 0:14:47  lr: 0.000026  loss: 0.4022 (0.5886)  time: 9.6837  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Train  [ 40/122]  eta: 0:13:09  lr: 0.000026  loss: 0.5333 (0.5976)  time: 9.6383  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Train  [ 50/122]  eta: 0:11:32  lr: 0.000026  loss: 0.7140 (0.5774)  time: 9.5862  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Train  [ 60/122]  eta: 0:09:55  lr: 0.000025  loss: 0.7253 (0.5880)  time: 9.5582  data: 0.0002  max mem: 8593\n",
      "Epoch: [31] Train  [ 70/122]  eta: 0:08:19  lr: 0.000025  loss: 0.6340 (0.5804)  time: 9.5403  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Train  [ 80/122]  eta: 0:06:42  lr: 0.000025  loss: 0.9205 (0.5782)  time: 9.5354  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Train  [ 90/122]  eta: 0:05:06  lr: 0.000025  loss: 0.6374 (0.5792)  time: 9.5604  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Train  [100/122]  eta: 0:03:31  lr: 0.000024  loss: 1.0606 (0.5889)  time: 9.6052  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Train  [110/122]  eta: 0:01:55  lr: 0.000024  loss: 0.3314 (0.5941)  time: 9.5966  data: 0.0002  max mem: 8593\n",
      "Epoch: [31] Train  [120/122]  eta: 0:00:19  lr: 0.000024  loss: 0.4282 (0.5948)  time: 9.5566  data: 0.0002  max mem: 8593\n",
      "Epoch: [31] Train Total time: 0:19:29\n",
      "Epoch: [31] Test  [  0/121]  eta: 0:03:55    time: 1.9425  data: 0.5089  max mem: 8593\n",
      "Epoch: [31] Test  [ 10/121]  eta: 0:01:56    time: 1.0523  data: 0.0465  max mem: 8593\n",
      "Epoch: [31] Test  [ 20/121]  eta: 0:01:41    time: 0.9587  data: 0.0002  max mem: 8593\n",
      "Epoch: [31] Test  [ 30/121]  eta: 0:01:32    time: 1.0028  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [ 40/121]  eta: 0:01:22    time: 1.0314  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [ 50/121]  eta: 0:01:12    time: 1.0359  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [ 60/121]  eta: 0:01:02    time: 1.0243  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [ 70/121]  eta: 0:00:50    time: 0.9312  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [ 80/121]  eta: 0:00:40    time: 0.9313  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [ 90/121]  eta: 0:00:31    time: 1.1156  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [100/121]  eta: 0:00:21    time: 1.1495  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [110/121]  eta: 0:00:11    time: 1.0024  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test  [120/121]  eta: 0:00:01    time: 0.9824  data: 0.0003  max mem: 8593\n",
      "Epoch: [31] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.4', '97.3', '78.5', '95.8', '93.0', '91.2', '99.3', '91.5', '97.7', '75.5', '96.1', '75.6', '96.5', '96.2', '94.7', '96.2', '81.8', '96.3', '84.0', '97.2', '90.3']\n",
      "IoU: ['94.9', '94.7', '54.2', '90.4', '74.9', '74.7', '96.0', '82.1', '92.9', '47.8', '92.3', '64.6', '90.6', '91.4', '90.4', '90.9', '68.1', '85.0', '61.6', '89.5', '73.0']\n",
      "mean IoU: 80.9\n",
      "Epoch: [32] Train  [  0/122]  eta: 0:20:37  lr: 0.000024  loss: 0.4600 (0.4600)  time: 10.1454  data: 0.3666  max mem: 8593\n",
      "Epoch: [32] Train  [ 10/122]  eta: 0:18:01  lr: 0.000024  loss: 0.8362 (0.6418)  time: 9.6545  data: 0.0335  max mem: 8593\n",
      "Epoch: [32] Train  [ 20/122]  eta: 0:16:23  lr: 0.000024  loss: 0.8460 (0.6190)  time: 9.6178  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [ 30/122]  eta: 0:14:43  lr: 0.000023  loss: 0.7356 (0.6066)  time: 9.5747  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [ 40/122]  eta: 0:13:06  lr: 0.000023  loss: 0.2672 (0.5842)  time: 9.5265  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [ 50/122]  eta: 0:11:30  lr: 0.000023  loss: 0.3597 (0.5670)  time: 9.5810  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [ 60/122]  eta: 0:09:53  lr: 0.000023  loss: 0.5023 (0.5761)  time: 9.5619  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [ 70/122]  eta: 0:08:18  lr: 0.000022  loss: 0.7557 (0.5843)  time: 9.5931  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [ 80/122]  eta: 0:06:42  lr: 0.000022  loss: 0.6897 (0.5916)  time: 9.6350  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [ 90/122]  eta: 0:05:06  lr: 0.000022  loss: 0.6575 (0.5945)  time: 9.5669  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [100/122]  eta: 0:03:31  lr: 0.000022  loss: 0.5561 (0.5961)  time: 9.5911  data: 0.0002  max mem: 8593\n",
      "Epoch: [32] Train  [110/122]  eta: 0:01:55  lr: 0.000022  loss: 0.4790 (0.6012)  time: 9.6032  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Train  [120/122]  eta: 0:00:19  lr: 0.000021  loss: 0.6747 (0.5930)  time: 9.5462  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Train Total time: 0:19:29\n",
      "Epoch: [32] Test  [  0/121]  eta: 0:04:01    time: 1.9965  data: 0.5706  max mem: 8593\n",
      "Epoch: [32] Test  [ 10/121]  eta: 0:01:57    time: 1.0574  data: 0.0521  max mem: 8593\n",
      "Epoch: [32] Test  [ 20/121]  eta: 0:01:41    time: 0.9578  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [ 30/121]  eta: 0:01:32    time: 1.0022  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [ 40/121]  eta: 0:01:22    time: 1.0324  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [ 50/121]  eta: 0:01:12    time: 1.0356  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [ 60/121]  eta: 0:01:02    time: 1.0231  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [ 70/121]  eta: 0:00:50    time: 0.9301  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [ 80/121]  eta: 0:00:40    time: 0.9292  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [ 90/121]  eta: 0:00:31    time: 1.1125  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [100/121]  eta: 0:00:21    time: 1.1466  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [110/121]  eta: 0:00:11    time: 1.0014  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test  [120/121]  eta: 0:00:01    time: 0.9809  data: 0.0003  max mem: 8593\n",
      "Epoch: [32] Test Total time: 0:02:03\n",
      "global correct: 95.5\n",
      "average row correct: ['96.4', '97.5', '82.7', '92.6', '89.3', '91.8', '99.2', '93.1', '98.3', '72.4', '96.2', '74.7', '95.8', '96.0', '94.9', '95.8', '82.3', '96.2', '83.5', '97.2', '91.1']\n",
      "IoU: ['94.8', '93.8', '53.6', '89.0', '72.6', '72.0', '96.5', '82.3', '91.7', '50.6', '91.6', '64.7', '89.0', '91.5', '90.4', '90.8', '67.1', '83.9', '63.1', '89.7', '67.9']\n",
      "mean IoU: 80.3\n",
      "Epoch: [33] Train  [  0/122]  eta: 0:20:02  lr: 0.000021  loss: 0.5717 (0.5717)  time: 9.8544  data: 0.3606  max mem: 8593\n",
      "Epoch: [33] Train  [ 10/122]  eta: 0:17:56  lr: 0.000021  loss: 0.6638 (0.7592)  time: 9.6107  data: 0.0330  max mem: 8593\n",
      "Epoch: [33] Train  [ 20/122]  eta: 0:16:20  lr: 0.000021  loss: 1.1633 (0.7335)  time: 9.6017  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Train  [ 30/122]  eta: 0:14:42  lr: 0.000021  loss: 0.9411 (0.7382)  time: 9.5799  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Train  [ 40/122]  eta: 0:13:06  lr: 0.000020  loss: 0.5604 (0.7274)  time: 9.5689  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Train  [ 50/122]  eta: 0:11:30  lr: 0.000020  loss: 1.0310 (0.7157)  time: 9.5737  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Train  [ 60/122]  eta: 0:09:53  lr: 0.000020  loss: 0.4064 (0.6725)  time: 9.5298  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Train  [ 70/122]  eta: 0:08:18  lr: 0.000020  loss: 0.9180 (0.6564)  time: 9.5957  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Train  [ 80/122]  eta: 0:06:42  lr: 0.000019  loss: 0.2831 (0.6390)  time: 9.6070  data: 0.0002  max mem: 8593\n",
      "Epoch: [33] Train  [ 90/122]  eta: 0:05:06  lr: 0.000019  loss: 0.6024 (0.6457)  time: 9.5237  data: 0.0002  max mem: 8593\n",
      "Epoch: [33] Train  [100/122]  eta: 0:03:30  lr: 0.000019  loss: 0.7107 (0.6339)  time: 9.5605  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Train  [110/122]  eta: 0:01:54  lr: 0.000019  loss: 0.5180 (0.6287)  time: 9.5692  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Train  [120/122]  eta: 0:00:19  lr: 0.000019  loss: 0.5241 (0.6302)  time: 9.5918  data: 0.0004  max mem: 8593\n",
      "Epoch: [33] Train Total time: 0:19:28\n",
      "Epoch: [33] Test  [  0/121]  eta: 0:03:57    time: 1.9650  data: 0.5382  max mem: 8593\n",
      "Epoch: [33] Test  [ 10/121]  eta: 0:01:56    time: 1.0530  data: 0.0492  max mem: 8593\n",
      "Epoch: [33] Test  [ 20/121]  eta: 0:01:41    time: 0.9575  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [ 30/121]  eta: 0:01:32    time: 1.0011  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [ 40/121]  eta: 0:01:22    time: 1.0310  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [ 50/121]  eta: 0:01:12    time: 1.0366  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [ 60/121]  eta: 0:01:02    time: 1.0260  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [ 70/121]  eta: 0:00:50    time: 0.9327  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [ 80/121]  eta: 0:00:40    time: 0.9284  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [ 90/121]  eta: 0:00:31    time: 1.1115  data: 0.0002  max mem: 8593\n",
      "Epoch: [33] Test  [100/121]  eta: 0:00:21    time: 1.1463  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [110/121]  eta: 0:00:11    time: 0.9994  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test  [120/121]  eta: 0:00:01    time: 0.9804  data: 0.0003  max mem: 8593\n",
      "Epoch: [33] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.7', '96.2', '60.7', '93.9', '86.2', '90.9', '99.0', '92.7', '97.1', '73.2', '95.8', '73.1', '94.9', '96.1', '93.7', '96.4', '80.6', '95.6', '82.8', '97.0', '90.7']\n",
      "IoU: ['94.9', '93.0', '49.6', '90.0', '75.9', '74.6', '97.1', '82.5', '92.3', '48.4', '92.2', '63.3', '89.8', '91.7', '89.9', '90.3', '68.8', '86.6', '61.1', '88.1', '67.6']\n",
      "mean IoU: 80.4\n",
      "Epoch: [34] Train  [  0/122]  eta: 0:19:55  lr: 0.000019  loss: 1.1095 (1.1095)  time: 9.7974  data: 0.3539  max mem: 8593\n",
      "Epoch: [34] Train  [ 10/122]  eta: 0:18:00  lr: 0.000018  loss: 0.8740 (0.7729)  time: 9.6442  data: 0.0324  max mem: 8593\n",
      "Epoch: [34] Train  [ 20/122]  eta: 0:16:28  lr: 0.000018  loss: 0.5149 (0.7698)  time: 9.6810  data: 0.0002  max mem: 8593\n",
      "Epoch: [34] Train  [ 30/122]  eta: 0:14:48  lr: 0.000018  loss: 0.6795 (0.7385)  time: 9.6714  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Train  [ 40/122]  eta: 0:13:09  lr: 0.000018  loss: 0.7401 (0.7178)  time: 9.5667  data: 0.0004  max mem: 8593\n",
      "Epoch: [34] Train  [ 50/122]  eta: 0:11:33  lr: 0.000017  loss: 0.6674 (0.6803)  time: 9.5714  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Train  [ 60/122]  eta: 0:09:56  lr: 0.000017  loss: 0.5749 (0.6640)  time: 9.5931  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Train  [ 70/122]  eta: 0:08:19  lr: 0.000017  loss: 0.4523 (0.6407)  time: 9.5667  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Train  [ 80/122]  eta: 0:06:42  lr: 0.000017  loss: 0.5365 (0.6269)  time: 9.4989  data: 0.0004  max mem: 8593\n",
      "Epoch: [34] Train  [ 90/122]  eta: 0:05:06  lr: 0.000016  loss: 0.5043 (0.6249)  time: 9.4780  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Train  [100/122]  eta: 0:03:30  lr: 0.000016  loss: 0.6721 (0.6244)  time: 9.5638  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Train  [110/122]  eta: 0:01:55  lr: 0.000016  loss: 0.5939 (0.6208)  time: 9.6184  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Train  [120/122]  eta: 0:00:19  lr: 0.000016  loss: 1.1104 (0.6235)  time: 9.5976  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Train Total time: 0:19:29\n",
      "Epoch: [34] Test  [  0/121]  eta: 0:04:06    time: 2.0395  data: 0.6097  max mem: 8593\n",
      "Epoch: [34] Test  [ 10/121]  eta: 0:01:57    time: 1.0585  data: 0.0557  max mem: 8593\n",
      "Epoch: [34] Test  [ 20/121]  eta: 0:01:41    time: 0.9561  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test  [ 30/121]  eta: 0:01:33    time: 1.0026  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test  [ 40/121]  eta: 0:01:22    time: 1.0330  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test  [ 50/121]  eta: 0:01:12    time: 1.0363  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test  [ 60/121]  eta: 0:01:02    time: 1.0245  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test  [ 70/121]  eta: 0:00:51    time: 0.9307  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test  [ 80/121]  eta: 0:00:40    time: 0.9292  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test  [ 90/121]  eta: 0:00:31    time: 1.1125  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test  [100/121]  eta: 0:00:21    time: 1.1466  data: 0.0004  max mem: 8593\n",
      "Epoch: [34] Test  [110/121]  eta: 0:00:11    time: 1.0008  data: 0.0005  max mem: 8593\n",
      "Epoch: [34] Test  [120/121]  eta: 0:00:01    time: 0.9798  data: 0.0003  max mem: 8593\n",
      "Epoch: [34] Test Total time: 0:02:03\n",
      "global correct: 95.7\n",
      "average row correct: ['96.8', '97.1', '74.4', '94.2', '90.2', '91.1', '99.3', '92.8', '97.1', '69.3', '95.4', '73.9', '94.8', '96.0', '94.8', '96.5', '79.6', '96.0', '83.4', '97.0', '90.7']\n",
      "IoU: ['95.0', '93.1', '54.3', '90.1', '75.8', '73.5', '96.5', '82.4', '92.2', '51.3', '92.5', '65.5', '90.3', '92.2', '90.1', '90.1', '69.2', '84.7', '61.6', '88.2', '68.2']\n",
      "mean IoU: 80.8\n",
      "Epoch: [35] Train  [  0/122]  eta: 0:19:49  lr: 0.000016  loss: 0.5383 (0.5383)  time: 9.7498  data: 0.3728  max mem: 8593\n",
      "Epoch: [35] Train  [ 10/122]  eta: 0:18:06  lr: 0.000015  loss: 0.5498 (0.5642)  time: 9.7034  data: 0.0341  max mem: 8593\n",
      "Epoch: [35] Train  [ 20/122]  eta: 0:16:23  lr: 0.000015  loss: 0.8105 (0.6218)  time: 9.6321  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Train  [ 30/122]  eta: 0:14:44  lr: 0.000015  loss: 0.3630 (0.5885)  time: 9.5633  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Train  [ 40/122]  eta: 0:13:07  lr: 0.000015  loss: 0.7472 (0.5842)  time: 9.5618  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Train  [ 50/122]  eta: 0:11:29  lr: 0.000015  loss: 0.5050 (0.5916)  time: 9.5339  data: 0.0004  max mem: 8593\n",
      "Epoch: [35] Train  [ 60/122]  eta: 0:09:54  lr: 0.000014  loss: 0.3915 (0.5833)  time: 9.5854  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Train  [ 70/122]  eta: 0:08:19  lr: 0.000014  loss: 0.8255 (0.5913)  time: 9.6697  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Train  [ 80/122]  eta: 0:06:43  lr: 0.000014  loss: 0.4897 (0.6061)  time: 9.6379  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Train  [ 90/122]  eta: 0:05:07  lr: 0.000014  loss: 0.6641 (0.5988)  time: 9.6110  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Train  [100/122]  eta: 0:03:31  lr: 0.000013  loss: 0.5444 (0.6055)  time: 9.5902  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Train  [110/122]  eta: 0:01:55  lr: 0.000013  loss: 0.7027 (0.6046)  time: 9.5329  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Train  [120/122]  eta: 0:00:19  lr: 0.000013  loss: 0.5579 (0.6021)  time: 9.5296  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Train Total time: 0:19:29\n",
      "Epoch: [35] Test  [  0/121]  eta: 0:04:04    time: 2.0195  data: 0.5876  max mem: 8593\n",
      "Epoch: [35] Test  [ 10/121]  eta: 0:01:57    time: 1.0558  data: 0.0537  max mem: 8593\n",
      "Epoch: [35] Test  [ 20/121]  eta: 0:01:41    time: 0.9564  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Test  [ 30/121]  eta: 0:01:32    time: 1.0021  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Test  [ 40/121]  eta: 0:01:22    time: 1.0304  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Test  [ 50/121]  eta: 0:01:12    time: 1.0338  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Test  [ 60/121]  eta: 0:01:02    time: 1.0236  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Test  [ 70/121]  eta: 0:00:50    time: 0.9306  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Test  [ 80/121]  eta: 0:00:40    time: 0.9301  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Test  [ 90/121]  eta: 0:00:31    time: 1.1139  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Test  [100/121]  eta: 0:00:21    time: 1.1462  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Test  [110/121]  eta: 0:00:11    time: 0.9996  data: 0.0003  max mem: 8593\n",
      "Epoch: [35] Test  [120/121]  eta: 0:00:01    time: 0.9794  data: 0.0002  max mem: 8593\n",
      "Epoch: [35] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.6', '97.2', '78.1', '93.2', '85.6', '91.6', '98.9', '92.2', '97.4', '74.7', '96.3', '73.1', '95.8', '96.4', '95.8', '96.2', '80.9', '95.8', '83.0', '96.7', '90.4']\n",
      "IoU: ['94.9', '93.9', '54.2', '89.6', '75.4', '71.8', '96.9', '82.8', '92.6', '48.6', '91.9', '63.9', '90.0', '91.2', '90.6', '90.2', '68.9', '86.5', '62.1', '88.6', '75.1']\n",
      "mean IoU: 80.9\n",
      "Epoch: [36] Train  [  0/122]  eta: 0:19:57  lr: 0.000013  loss: 0.3162 (0.3162)  time: 9.8128  data: 0.3667  max mem: 8593\n",
      "Epoch: [36] Train  [ 10/122]  eta: 0:17:50  lr: 0.000013  loss: 0.4905 (0.6614)  time: 9.5542  data: 0.0336  max mem: 8593\n",
      "Epoch: [36] Train  [ 20/122]  eta: 0:16:15  lr: 0.000012  loss: 0.3475 (0.6290)  time: 9.5543  data: 0.0002  max mem: 8593\n",
      "Epoch: [36] Train  [ 30/122]  eta: 0:14:41  lr: 0.000012  loss: 0.4232 (0.6093)  time: 9.5994  data: 0.0002  max mem: 8593\n",
      "Epoch: [36] Train  [ 40/122]  eta: 0:13:06  lr: 0.000012  loss: 0.5698 (0.6024)  time: 9.6113  data: 0.0002  max mem: 8593\n",
      "Epoch: [36] Train  [ 50/122]  eta: 0:11:29  lr: 0.000012  loss: 0.7157 (0.5994)  time: 9.5490  data: 0.0002  max mem: 8593\n",
      "Epoch: [36] Train  [ 60/122]  eta: 0:09:53  lr: 0.000011  loss: 0.5959 (0.6007)  time: 9.5452  data: 0.0002  max mem: 8593\n",
      "Epoch: [36] Train  [ 70/122]  eta: 0:08:17  lr: 0.000011  loss: 0.6834 (0.6228)  time: 9.5878  data: 0.0004  max mem: 8593\n",
      "Epoch: [36] Train  [ 80/122]  eta: 0:06:42  lr: 0.000011  loss: 0.5606 (0.6114)  time: 9.5817  data: 0.0004  max mem: 8593\n",
      "Epoch: [36] Train  [ 90/122]  eta: 0:05:06  lr: 0.000011  loss: 0.4596 (0.6175)  time: 9.5436  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Train  [100/122]  eta: 0:03:30  lr: 0.000010  loss: 0.5908 (0.6189)  time: 9.5751  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Train  [110/122]  eta: 0:01:54  lr: 0.000010  loss: 0.4906 (0.6130)  time: 9.6236  data: 0.0002  max mem: 8593\n",
      "Epoch: [36] Train  [120/122]  eta: 0:00:19  lr: 0.000010  loss: 0.4504 (0.6099)  time: 9.6362  data: 0.0002  max mem: 8593\n",
      "Epoch: [36] Train Total time: 0:19:29\n",
      "Epoch: [36] Test  [  0/121]  eta: 0:04:03    time: 2.0116  data: 0.5887  max mem: 8593\n",
      "Epoch: [36] Test  [ 10/121]  eta: 0:01:57    time: 1.0565  data: 0.0538  max mem: 8593\n",
      "Epoch: [36] Test  [ 20/121]  eta: 0:01:41    time: 0.9577  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [ 30/121]  eta: 0:01:32    time: 1.0017  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [ 40/121]  eta: 0:01:22    time: 1.0291  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [ 50/121]  eta: 0:01:12    time: 1.0344  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [ 60/121]  eta: 0:01:02    time: 1.0240  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [ 70/121]  eta: 0:00:50    time: 0.9296  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [ 80/121]  eta: 0:00:40    time: 0.9309  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [ 90/121]  eta: 0:00:31    time: 1.1167  data: 0.0004  max mem: 8593\n",
      "Epoch: [36] Test  [100/121]  eta: 0:00:21    time: 1.1475  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [110/121]  eta: 0:00:11    time: 0.9992  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test  [120/121]  eta: 0:00:01    time: 0.9807  data: 0.0003  max mem: 8593\n",
      "Epoch: [36] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.8', '96.2', '71.3', '95.3', '93.5', '87.6', '99.1', '92.4', '94.6', '68.2', '93.8', '73.8', '96.0', '96.9', '94.2', '96.6', '76.4', '95.5', '83.9', '97.6', '89.9']\n",
      "IoU: ['95.0', '94.4', '53.9', '90.0', '74.3', '76.5', '96.8', '82.1', '92.2', '47.5', '91.4', '63.6', '90.7', '89.6', '89.8', '90.1', '68.4', '86.0', '60.4', '86.2', '75.1']\n",
      "mean IoU: 80.7\n",
      "Epoch: [37] Train  [  0/122]  eta: 0:19:28  lr: 0.000010  loss: 0.7034 (0.7034)  time: 9.5782  data: 0.3703  max mem: 8593\n",
      "Epoch: [37] Train  [ 10/122]  eta: 0:17:53  lr: 0.000010  loss: 0.6842 (0.6084)  time: 9.5819  data: 0.0338  max mem: 8593\n",
      "Epoch: [37] Train  [ 20/122]  eta: 0:16:20  lr: 0.000009  loss: 0.7023 (0.5815)  time: 9.6106  data: 0.0002  max mem: 8593\n",
      "Epoch: [37] Train  [ 30/122]  eta: 0:14:43  lr: 0.000009  loss: 0.5524 (0.5836)  time: 9.6105  data: 0.0002  max mem: 8593\n",
      "Epoch: [37] Train  [ 40/122]  eta: 0:13:07  lr: 0.000009  loss: 0.7287 (0.5928)  time: 9.5996  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Train  [ 50/122]  eta: 0:11:31  lr: 0.000009  loss: 0.6637 (0.5913)  time: 9.6220  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Train  [ 60/122]  eta: 0:09:55  lr: 0.000008  loss: 0.6208 (0.6118)  time: 9.6135  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Train  [ 70/122]  eta: 0:08:19  lr: 0.000008  loss: 0.5212 (0.6173)  time: 9.5640  data: 0.0004  max mem: 8593\n",
      "Epoch: [37] Train  [ 80/122]  eta: 0:06:43  lr: 0.000008  loss: 0.5867 (0.6173)  time: 9.5920  data: 0.0004  max mem: 8593\n",
      "Epoch: [37] Train  [ 90/122]  eta: 0:05:07  lr: 0.000008  loss: 0.6371 (0.6219)  time: 9.6342  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Train  [100/122]  eta: 0:03:31  lr: 0.000007  loss: 0.5071 (0.6130)  time: 9.6204  data: 0.0002  max mem: 8593\n",
      "Epoch: [37] Train  [110/122]  eta: 0:01:55  lr: 0.000007  loss: 1.9054 (0.6224)  time: 9.5704  data: 0.0002  max mem: 8593\n",
      "Epoch: [37] Train  [120/122]  eta: 0:00:19  lr: 0.000007  loss: 0.5344 (0.6189)  time: 9.5353  data: 0.0002  max mem: 8593\n",
      "Epoch: [37] Train Total time: 0:19:30\n",
      "Epoch: [37] Test  [  0/121]  eta: 0:03:54    time: 1.9377  data: 0.5081  max mem: 8593\n",
      "Epoch: [37] Test  [ 10/121]  eta: 0:01:56    time: 1.0459  data: 0.0464  max mem: 8593\n",
      "Epoch: [37] Test  [ 20/121]  eta: 0:01:41    time: 0.9566  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [ 30/121]  eta: 0:01:32    time: 1.0034  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [ 40/121]  eta: 0:01:22    time: 1.0323  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [ 50/121]  eta: 0:01:12    time: 1.0371  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [ 60/121]  eta: 0:01:02    time: 1.0258  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [ 70/121]  eta: 0:00:50    time: 0.9328  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [ 80/121]  eta: 0:00:40    time: 0.9314  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [ 90/121]  eta: 0:00:31    time: 1.1148  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [100/121]  eta: 0:00:21    time: 1.1469  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [110/121]  eta: 0:00:11    time: 1.0001  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test  [120/121]  eta: 0:00:01    time: 0.9800  data: 0.0003  max mem: 8593\n",
      "Epoch: [37] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.7', '97.0', '82.2', '92.0', '89.7', '91.9', '99.0', '92.2', '96.6', '71.2', '92.7', '73.1', '97.6', '96.5', '94.2', '96.4', '79.6', '96.1', '82.5', '96.9', '89.8']\n",
      "IoU: ['95.0', '93.7', '55.9', '88.4', '74.6', '71.7', '96.9', '82.5', '92.7', '49.3', '90.2', '64.0', '88.2', '89.8', '89.6', '90.1', '68.8', '83.0', '61.7', '89.2', '77.2']\n",
      "mean IoU: 80.6\n",
      "Epoch: [38] Train  [  0/122]  eta: 0:20:12  lr: 0.000007  loss: 0.3315 (0.3315)  time: 9.9390  data: 0.3922  max mem: 8593\n",
      "Epoch: [38] Train  [ 10/122]  eta: 0:18:03  lr: 0.000007  loss: 0.6535 (0.6290)  time: 9.6784  data: 0.0358  max mem: 8593\n",
      "Epoch: [38] Train  [ 20/122]  eta: 0:16:21  lr: 0.000006  loss: 0.7481 (0.6397)  time: 9.6080  data: 0.0002  max mem: 8593\n",
      "Epoch: [38] Train  [ 30/122]  eta: 0:14:45  lr: 0.000006  loss: 0.6274 (0.6066)  time: 9.5975  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Train  [ 40/122]  eta: 0:13:08  lr: 0.000006  loss: 0.7921 (0.6406)  time: 9.6037  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Train  [ 50/122]  eta: 0:11:30  lr: 0.000006  loss: 0.5192 (0.6637)  time: 9.5453  data: 0.0002  max mem: 8593\n",
      "Epoch: [38] Train  [ 60/122]  eta: 0:09:55  lr: 0.000005  loss: 0.2977 (0.6436)  time: 9.5639  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Train  [ 70/122]  eta: 0:08:18  lr: 0.000005  loss: 0.5661 (0.6338)  time: 9.5966  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Train  [ 80/122]  eta: 0:06:42  lr: 0.000005  loss: 0.5520 (0.6346)  time: 9.5438  data: 0.0002  max mem: 8593\n",
      "Epoch: [38] Train  [ 90/122]  eta: 0:05:06  lr: 0.000005  loss: 0.3427 (0.6239)  time: 9.5261  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Train  [100/122]  eta: 0:03:30  lr: 0.000004  loss: 0.3781 (0.6282)  time: 9.5860  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Train  [110/122]  eta: 0:01:54  lr: 0.000004  loss: 0.4002 (0.6211)  time: 9.5640  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Train  [120/122]  eta: 0:00:19  lr: 0.000004  loss: 0.4585 (0.6169)  time: 9.5382  data: 0.0002  max mem: 8593\n",
      "Epoch: [38] Train Total time: 0:19:28\n",
      "Epoch: [38] Test  [  0/121]  eta: 0:03:55    time: 1.9497  data: 0.5222  max mem: 8593\n",
      "Epoch: [38] Test  [ 10/121]  eta: 0:01:56    time: 1.0475  data: 0.0477  max mem: 8593\n",
      "Epoch: [38] Test  [ 20/121]  eta: 0:01:41    time: 0.9526  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [ 30/121]  eta: 0:01:32    time: 0.9993  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [ 40/121]  eta: 0:01:22    time: 1.0296  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [ 50/121]  eta: 0:01:12    time: 1.0336  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [ 60/121]  eta: 0:01:02    time: 1.0241  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [ 70/121]  eta: 0:00:50    time: 0.9309  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [ 80/121]  eta: 0:00:40    time: 0.9287  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [ 90/121]  eta: 0:00:31    time: 1.1118  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [100/121]  eta: 0:00:21    time: 1.1468  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [110/121]  eta: 0:00:11    time: 1.0001  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test  [120/121]  eta: 0:00:01    time: 0.9804  data: 0.0003  max mem: 8593\n",
      "Epoch: [38] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.6', '96.2', '81.4', '95.3', '87.8', '91.4', '99.1', '93.5', '98.5', '75.5', '95.9', '68.6', '96.9', '96.0', '94.2', '95.4', '84.0', '95.8', '82.6', '97.2', '90.7']\n",
      "IoU: ['94.9', '94.4', '53.9', '91.1', '74.0', '72.6', '96.8', '83.0', '92.4', '49.4', '91.8', '62.2', '88.6', '91.6', '89.9', '90.9', '69.0', '88.2', '62.6', '87.5', '74.1']\n",
      "mean IoU: 80.9\n",
      "Epoch: [39] Train  [  0/122]  eta: 0:20:20  lr: 0.000004  loss: 0.4375 (0.4375)  time: 10.0041  data: 0.3992  max mem: 8593\n",
      "Epoch: [39] Train  [ 10/122]  eta: 0:17:58  lr: 0.000003  loss: 0.7847 (0.7314)  time: 9.6314  data: 0.0366  max mem: 8593\n",
      "Epoch: [39] Train  [ 20/122]  eta: 0:16:16  lr: 0.000003  loss: 0.4371 (0.6744)  time: 9.5545  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Train  [ 30/122]  eta: 0:14:39  lr: 0.000003  loss: 0.7038 (0.6376)  time: 9.5189  data: 0.0002  max mem: 8593\n",
      "Epoch: [39] Train  [ 40/122]  eta: 0:13:02  lr: 0.000003  loss: 0.6191 (0.6160)  time: 9.5168  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Train  [ 50/122]  eta: 0:11:27  lr: 0.000002  loss: 0.5142 (0.5978)  time: 9.5226  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Train  [ 60/122]  eta: 0:09:52  lr: 0.000002  loss: 1.0389 (0.6117)  time: 9.5765  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Train  [ 70/122]  eta: 0:08:16  lr: 0.000002  loss: 0.5199 (0.5973)  time: 9.5638  data: 0.0004  max mem: 8593\n",
      "Epoch: [39] Train  [ 80/122]  eta: 0:06:41  lr: 0.000001  loss: 0.6686 (0.5988)  time: 9.5800  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Train  [ 90/122]  eta: 0:05:05  lr: 0.000001  loss: 0.7348 (0.5944)  time: 9.6021  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Train  [100/122]  eta: 0:03:30  lr: 0.000001  loss: 1.4035 (0.6079)  time: 9.5886  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Train  [110/122]  eta: 0:01:54  lr: 0.000000  loss: 0.2915 (0.6135)  time: 9.5685  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Train  [120/122]  eta: 0:00:19  lr: 0.000000  loss: 0.4236 (0.6068)  time: 9.5286  data: 0.0002  max mem: 8593\n",
      "Epoch: [39] Train Total time: 0:19:26\n",
      "Epoch: [39] Test  [  0/121]  eta: 0:03:55    time: 1.9484  data: 0.5241  max mem: 8593\n",
      "Epoch: [39] Test  [ 10/121]  eta: 0:01:56    time: 1.0512  data: 0.0480  max mem: 8593\n",
      "Epoch: [39] Test  [ 20/121]  eta: 0:01:41    time: 0.9573  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Test  [ 30/121]  eta: 0:01:32    time: 1.0019  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Test  [ 40/121]  eta: 0:01:22    time: 1.0300  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Test  [ 50/121]  eta: 0:01:12    time: 1.0332  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Test  [ 60/121]  eta: 0:01:02    time: 1.0232  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Test  [ 70/121]  eta: 0:00:50    time: 0.9313  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Test  [ 80/121]  eta: 0:00:40    time: 0.9300  data: 0.0002  max mem: 8593\n",
      "Epoch: [39] Test  [ 90/121]  eta: 0:00:31    time: 1.1131  data: 0.0002  max mem: 8593\n",
      "Epoch: [39] Test  [100/121]  eta: 0:00:21    time: 1.1462  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Test  [110/121]  eta: 0:00:11    time: 1.0012  data: 0.0002  max mem: 8593\n",
      "Epoch: [39] Test  [120/121]  eta: 0:00:01    time: 0.9806  data: 0.0003  max mem: 8593\n",
      "Epoch: [39] Test Total time: 0:02:03\n",
      "global correct: 95.6\n",
      "average row correct: ['96.7', '97.5', '77.6', '94.6', '88.1', '91.1', '99.3', '91.5', '98.5', '70.5', '96.2', '71.0', '97.1', '96.4', '95.1', '95.7', '82.1', '96.9', '83.5', '97.5', '90.9']\n",
      "IoU: ['95.0', '92.8', '54.4', '89.8', '73.9', '75.1', '96.1', '82.5', '92.5', '50.3', '91.8', '62.8', '89.0', '90.4', '90.5', '90.7', '68.4', '83.4', '62.9', '89.5', '70.1']\n",
      "mean IoU: 80.6\n",
      "Training time 14:26:10\n"
     ]
    }
   ],
   "source": [
    "# simsiam selfattention123\n",
    "!experiment_name=\"attention\";cd ../ ;\\\n",
    "    name_date=\"${experiment_name}/$(date +%Y-%m%d-%H%M%S)\";\\\n",
    "    dir=\"./results/${name_date}\";mkdir -p ${dir};dir_log=\"${dir}/output.log\";\\\n",
    "CUDA_VISIBLE_DEVICES=1,2 torchrun --nproc_per_node=2 --master_port=1454 train_multi_GPU.py \\\n",
    "    --wandb False --wandb_model run --sync_bn False --amp True --aux False \\\n",
    "    --model_name aspp_contrast_resnet101 --pre_trained deeplabv3_resnet101_coco.pth \\\n",
    "    --weight_only_backbone False --lr 0.0001 --wd 0.0001 --attention selfattention \\\n",
    "    --data_path pascal-voc-2012 --num_classes 21 --data_train_type train.txt \\\n",
    "    --epochs 40 --batch_size 6 --batch_size_val 6 --memory_size 0 \\\n",
    "    --contrast 0 --L1_loss 0.1 --L2_loss 0.1 --L3_loss 0.1 \\\n",
    "    --loss_name aspp_loss --sample adapt_excite_8 \\\n",
    "    --name_date $name_date \\\n",
    "    2>&1 | tee $dir_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
