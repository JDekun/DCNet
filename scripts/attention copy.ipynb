{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| distributed init (rank 0): env://\n",
      "attention/2023-0407-163253\n",
      "Namespace(data_path='pascal-voc-2012', data_train_type='train.txt', device='cuda', num_classes=21, batch_size=8, batch_size_val=6, aux=False, start_epoch=0, epochs=40, sync_bn=False, workers=1, lr=0.0001, momentum=0.9, weight_decay=0.0001, print_freq=10, checkpoint_dir='./results/attention/2023-0407-163253', resume='', test_only=False, world_size=1, dist_url='env://', amp=True, seed=304, name_date='attention/2023-0407-163253', wandb=False, wandb_model='run', run_name='', model_name='aspp_contrast_resnet101', project_dim=128, loss_name='aspp_loss', contrast=0, pre_trained='deeplabv3_resnet101_coco.pth', L3_loss=0.1, L2_loss=0.1, L1_loss=0.1, GAcc=1, memory_size=0, proj_dim=128, network_stride=8, pixel_update_freq=10, ddp=False, weight_only_backbone=False, sample='adapt_excite_8', attention=True, rank=0, gpu=0, distributed=True, dist_backend='nccl')\n",
      "Creating data loaders\n",
      "Creating model\n",
      "missing_keys:  ['contrast.convs.0.0.weight', 'contrast.convs.0.1.weight', 'contrast.convs.0.1.bias', 'contrast.convs.0.1.running_mean', 'contrast.convs.0.1.running_var', 'contrast.convs.0.3.weight', 'contrast.convs.0.4.weight', 'contrast.convs.0.4.bias', 'contrast.convs.0.4.running_mean', 'contrast.convs.0.4.running_var', 'contrast.convs.1.0.weight', 'contrast.convs.1.1.weight', 'contrast.convs.1.1.bias', 'contrast.convs.1.1.running_mean', 'contrast.convs.1.1.running_var', 'contrast.convs.1.3.weight', 'contrast.convs.1.4.weight', 'contrast.convs.1.4.bias', 'contrast.convs.1.4.running_mean', 'contrast.convs.1.4.running_var', 'contrast.convs.2.0.weight', 'contrast.convs.2.1.weight', 'contrast.convs.2.1.bias', 'contrast.convs.2.1.running_mean', 'contrast.convs.2.1.running_var', 'contrast.convs.2.3.weight', 'contrast.convs.2.4.weight', 'contrast.convs.2.4.bias', 'contrast.convs.2.4.running_mean', 'contrast.convs.2.4.running_var', 'attention.ca.se.0.weight', 'attention.ca.se.2.weight', 'attention.sa.conv.weight', 'attention.sa.conv.bias']\n",
      "unexpected_keys:  ['aux_classifier.0.weight', 'aux_classifier.1.weight', 'aux_classifier.1.bias', 'aux_classifier.1.running_mean', 'aux_classifier.1.running_var', 'aux_classifier.1.num_batches_tracked', 'aux_classifier.4.weight', 'aux_classifier.4.bias']\n",
      "DistributedDataParallel(\n",
      "  (module): DeepLabV3(\n",
      "    (backbone): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (6): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (7): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (8): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (9): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (10): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (11): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (12): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (13): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (14): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (15): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (16): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (17): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (18): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (19): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (20): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (21): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (22): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): DeepLabHead(\n",
      "      (0): ASPP(\n",
      "        (convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): ASPPPooling(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (contrast): contrast_head(\n",
      "      (convs): ModuleList(\n",
      "        (0): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attention): CBAMBlock(\n",
      "      (ca): ChannelAttention(\n",
      "        (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (se): Sequential(\n",
      "          (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Start training\n",
      "Epoch: [0] Train  [  0/183]  eta: 0:45:23  lr: 0.000001  loss: 1.6377 (1.6377)  time: 14.8828  data: 0.4573  max mem: 9117\n",
      "Epoch: [0] Train  [ 10/183]  eta: 0:36:58  lr: 0.000006  loss: 0.8885 (1.1397)  time: 12.8232  data: 0.0420  max mem: 9586\n",
      "Epoch: [0] Train  [ 20/183]  eta: 0:34:18  lr: 0.000012  loss: 1.3847 (1.2334)  time: 12.5160  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Train  [ 30/183]  eta: 0:32:11  lr: 0.000017  loss: 0.9623 (1.1872)  time: 12.5151  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [ 40/183]  eta: 0:29:59  lr: 0.000022  loss: 1.0218 (1.1882)  time: 12.5340  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Train  [ 50/183]  eta: 0:27:50  lr: 0.000028  loss: 1.5941 (1.2127)  time: 12.4595  data: 0.0007  max mem: 9586\n",
      "Epoch: [0] Train  [ 60/183]  eta: 0:25:40  lr: 0.000033  loss: 0.9272 (1.2427)  time: 12.3990  data: 0.0005  max mem: 9586\n",
      "Epoch: [0] Train  [ 70/183]  eta: 0:23:32  lr: 0.000039  loss: 0.8477 (1.2264)  time: 12.3557  data: 0.0002  max mem: 9586\n",
      "Epoch: [0] Train  [ 80/183]  eta: 0:21:24  lr: 0.000044  loss: 0.9576 (1.2053)  time: 12.3234  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [ 90/183]  eta: 0:19:19  lr: 0.000050  loss: 0.6577 (1.1823)  time: 12.3455  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Train  [100/183]  eta: 0:17:15  lr: 0.000055  loss: 1.6305 (1.1982)  time: 12.4983  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Train  [110/183]  eta: 0:15:10  lr: 0.000061  loss: 1.1563 (1.2047)  time: 12.5136  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [120/183]  eta: 0:13:05  lr: 0.000066  loss: 0.9062 (1.2120)  time: 12.4031  data: 0.0002  max mem: 9586\n",
      "Epoch: [0] Train  [130/183]  eta: 0:11:00  lr: 0.000072  loss: 0.5942 (1.2034)  time: 12.3735  data: 0.0002  max mem: 9586\n",
      "Epoch: [0] Train  [140/183]  eta: 0:08:55  lr: 0.000077  loss: 1.0309 (1.1900)  time: 12.3575  data: 0.0002  max mem: 9586\n",
      "Epoch: [0] Train  [150/183]  eta: 0:06:50  lr: 0.000083  loss: 0.5240 (1.1687)  time: 12.3137  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [160/183]  eta: 0:04:46  lr: 0.000088  loss: 1.2727 (1.1735)  time: 12.3390  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [170/183]  eta: 0:02:41  lr: 0.000093  loss: 0.9591 (1.1602)  time: 12.4061  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [180/183]  eta: 0:00:37  lr: 0.000099  loss: 0.6159 (1.1488)  time: 12.3859  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train Total time: 0:37:54\n",
      "Epoch: [0] Test  [  0/242]  eta: 0:08:12    time: 2.0353  data: 0.4145  max mem: 9586\n",
      "Epoch: [0] Test  [ 10/242]  eta: 0:04:03    time: 1.0486  data: 0.0380  max mem: 9586\n",
      "Epoch: [0] Test  [ 20/242]  eta: 0:03:40    time: 0.9406  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 30/242]  eta: 0:03:34    time: 0.9939  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 40/242]  eta: 0:03:26    time: 1.0539  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 50/242]  eta: 0:03:16    time: 1.0455  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 60/242]  eta: 0:03:09    time: 1.0768  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [ 70/242]  eta: 0:02:59    time: 1.0858  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 80/242]  eta: 0:02:48    time: 1.0301  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 90/242]  eta: 0:02:36    time: 0.9789  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [100/242]  eta: 0:02:26    time: 1.0117  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [110/242]  eta: 0:02:15    time: 1.0296  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [120/242]  eta: 0:02:06    time: 1.0418  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [130/242]  eta: 0:01:55    time: 1.0317  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [140/242]  eta: 0:01:44    time: 0.9815  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [150/242]  eta: 0:01:34    time: 0.9886  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [160/242]  eta: 0:01:23    time: 1.0047  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [170/242]  eta: 0:01:14    time: 1.0685  data: 0.0005  max mem: 9586\n",
      "Epoch: [0] Test  [180/242]  eta: 0:01:04    time: 1.1257  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [190/242]  eta: 0:00:53    time: 1.1127  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [200/242]  eta: 0:00:43    time: 1.0596  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [210/242]  eta: 0:00:33    time: 1.0331  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [220/242]  eta: 0:00:22    time: 1.0401  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [230/242]  eta: 0:00:12    time: 1.0487  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [240/242]  eta: 0:00:02    time: 1.0104  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test Total time: 0:04:10\n",
      "global correct: 95.2\n",
      "average row correct: ['97.3', '94.7', '79.0', '94.3', '81.5', '73.2', '97.6', '79.9', '96.0', '66.7', '94.4', '60.9', '89.8', '93.7', '93.5', '97.0', '70.4', '94.7', '82.9', '94.5', '84.3']\n",
      "IoU: ['94.4', '90.9', '40.5', '89.2', '72.8', '67.6', '96.2', '76.1', '91.8', '50.4', '92.4', '55.3', '86.9', '88.6', '89.1', '87.9', '62.1', '89.4', '62.9', '89.8', '81.4']\n",
      "mean IoU: 78.9\n",
      "Epoch: [1] Train  [  0/183]  eta: 0:39:37  lr: 0.000100  loss: 1.0170 (1.0170)  time: 12.9927  data: 0.3927  max mem: 9586\n",
      "Epoch: [1] Train  [ 10/183]  eta: 0:36:10  lr: 0.000100  loss: 0.6539 (0.9033)  time: 12.5445  data: 0.0361  max mem: 9586\n",
      "Epoch: [1] Train  [ 20/183]  eta: 0:33:58  lr: 0.000100  loss: 1.6438 (0.9229)  time: 12.4790  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Train  [ 30/183]  eta: 0:31:55  lr: 0.000100  loss: 2.7592 (0.9893)  time: 12.5039  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Train  [ 40/183]  eta: 0:29:48  lr: 0.000099  loss: 0.7215 (0.9761)  time: 12.5118  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 50/183]  eta: 0:27:42  lr: 0.000099  loss: 0.7908 (0.9442)  time: 12.4750  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 60/183]  eta: 0:25:36  lr: 0.000099  loss: 0.5589 (0.9865)  time: 12.4574  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 70/183]  eta: 0:23:27  lr: 0.000099  loss: 0.6175 (0.9647)  time: 12.3453  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 80/183]  eta: 0:21:23  lr: 0.000099  loss: 0.7059 (0.9607)  time: 12.3891  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 90/183]  eta: 0:19:16  lr: 0.000099  loss: 0.4569 (0.9456)  time: 12.3635  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [100/183]  eta: 0:17:12  lr: 0.000099  loss: 0.6866 (0.9346)  time: 12.3278  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Train  [110/183]  eta: 0:15:07  lr: 0.000099  loss: 0.9738 (0.9151)  time: 12.4280  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Train  [120/183]  eta: 0:13:03  lr: 0.000098  loss: 0.3467 (0.9243)  time: 12.3801  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Train  [130/183]  eta: 0:10:58  lr: 0.000098  loss: 1.3595 (0.9138)  time: 12.3703  data: 0.0002  max mem: 9586\n",
      "Epoch: [1] Train  [140/183]  eta: 0:08:54  lr: 0.000098  loss: 1.2148 (0.9034)  time: 12.3568  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Train  [150/183]  eta: 0:06:49  lr: 0.000098  loss: 0.5551 (0.8879)  time: 12.3696  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Train  [160/183]  eta: 0:04:45  lr: 0.000098  loss: 0.5474 (0.8657)  time: 12.3420  data: 0.0006  max mem: 9586\n",
      "Epoch: [1] Train  [170/183]  eta: 0:02:41  lr: 0.000098  loss: 1.2188 (0.8673)  time: 12.2778  data: 0.0007  max mem: 9586\n",
      "Epoch: [1] Train  [180/183]  eta: 0:00:37  lr: 0.000098  loss: 0.6434 (0.8577)  time: 12.3228  data: 0.0007  max mem: 9586\n",
      "Epoch: [1] Train Total time: 0:37:48\n",
      "Epoch: [1] Test  [  0/242]  eta: 0:05:49    time: 1.4432  data: 0.3795  max mem: 9586\n",
      "Epoch: [1] Test  [ 10/242]  eta: 0:03:51    time: 0.9958  data: 0.0348  max mem: 9586\n",
      "Epoch: [1] Test  [ 20/242]  eta: 0:03:34    time: 0.9405  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Test  [ 30/242]  eta: 0:03:30    time: 0.9914  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 40/242]  eta: 0:03:23    time: 1.0532  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 50/242]  eta: 0:03:14    time: 1.0481  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 60/242]  eta: 0:03:07    time: 1.0790  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 70/242]  eta: 0:02:58    time: 1.0873  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 80/242]  eta: 0:02:46    time: 1.0298  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 90/242]  eta: 0:02:35    time: 0.9796  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [100/242]  eta: 0:02:25    time: 1.0145  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [110/242]  eta: 0:02:15    time: 1.0327  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [120/242]  eta: 0:02:05    time: 1.0465  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [130/242]  eta: 0:01:54    time: 1.0341  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [140/242]  eta: 0:01:44    time: 0.9823  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [150/242]  eta: 0:01:33    time: 0.9891  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Test  [160/242]  eta: 0:01:23    time: 1.0046  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Test  [170/242]  eta: 0:01:13    time: 1.0560  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [180/242]  eta: 0:01:03    time: 1.1132  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [190/242]  eta: 0:00:53    time: 1.1146  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [200/242]  eta: 0:00:43    time: 1.0595  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [210/242]  eta: 0:00:33    time: 1.0334  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [220/242]  eta: 0:00:22    time: 1.0420  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [230/242]  eta: 0:00:12    time: 1.0486  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [240/242]  eta: 0:00:02    time: 1.0095  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['96.9', '95.1', '82.1', '95.1', '83.2', '80.2', '98.7', '85.3', '97.4', '73.3', '94.3', '63.3', '92.3', '94.1', '95.7', '96.1', '71.2', '95.5', '83.3', '97.0', '87.0']\n",
      "IoU: ['94.5', '92.0', '42.2', '88.9', '75.1', '72.4', '96.8', '78.4', '91.3', '46.3', '91.0', '57.2', '88.0', '89.1', '89.6', '89.6', '61.3', '86.7', '62.9', '90.4', '80.9']\n",
      "mean IoU: 79.3\n",
      "Epoch: [2] Train  [  0/183]  eta: 0:37:44  lr: 0.000098  loss: 0.3637 (0.3637)  time: 12.3757  data: 0.4039  max mem: 9586\n",
      "Epoch: [2] Train  [ 10/183]  eta: 0:35:36  lr: 0.000098  loss: 0.3588 (0.7715)  time: 12.3490  data: 0.0370  max mem: 9586\n",
      "Epoch: [2] Train  [ 20/183]  eta: 0:33:28  lr: 0.000097  loss: 0.4822 (0.7077)  time: 12.3165  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [ 30/183]  eta: 0:31:25  lr: 0.000097  loss: 0.9735 (0.6932)  time: 12.3142  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train  [ 40/183]  eta: 0:29:26  lr: 0.000097  loss: 1.2567 (0.6928)  time: 12.3884  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train  [ 50/183]  eta: 0:27:23  lr: 0.000097  loss: 0.8185 (0.7242)  time: 12.4001  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [ 60/183]  eta: 0:25:21  lr: 0.000097  loss: 0.9570 (0.7331)  time: 12.3927  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [ 70/183]  eta: 0:23:19  lr: 0.000097  loss: 0.6409 (0.7306)  time: 12.4449  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train  [ 80/183]  eta: 0:21:13  lr: 0.000097  loss: 0.5831 (0.7233)  time: 12.3556  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train  [ 90/183]  eta: 0:19:09  lr: 0.000097  loss: 0.6897 (0.7320)  time: 12.2966  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [100/183]  eta: 0:17:05  lr: 0.000096  loss: 0.6414 (0.7394)  time: 12.3503  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [110/183]  eta: 0:15:02  lr: 0.000096  loss: 1.5429 (0.7411)  time: 12.3418  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [120/183]  eta: 0:12:59  lr: 0.000096  loss: 0.4596 (0.7494)  time: 12.4019  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [130/183]  eta: 0:10:54  lr: 0.000096  loss: 0.6204 (0.7449)  time: 12.3464  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [140/183]  eta: 0:08:50  lr: 0.000096  loss: 0.7506 (0.7417)  time: 12.2207  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [150/183]  eta: 0:06:47  lr: 0.000096  loss: 0.5929 (0.7307)  time: 12.3059  data: 0.0002  max mem: 9586\n",
      "Epoch: [2] Train  [160/183]  eta: 0:04:44  lr: 0.000096  loss: 0.8514 (0.7378)  time: 12.4107  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [170/183]  eta: 0:02:40  lr: 0.000096  loss: 0.3746 (0.7375)  time: 12.3779  data: 0.0006  max mem: 9586\n",
      "Epoch: [2] Train  [180/183]  eta: 0:00:37  lr: 0.000095  loss: 0.1677 (0.7326)  time: 12.3865  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train Total time: 0:37:41\n",
      "Epoch: [2] Test  [  0/242]  eta: 0:06:00    time: 1.4888  data: 0.4186  max mem: 9586\n",
      "Epoch: [2] Test  [ 10/242]  eta: 0:03:51    time: 0.9983  data: 0.0383  max mem: 9586\n",
      "Epoch: [2] Test  [ 20/242]  eta: 0:03:34    time: 0.9384  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 30/242]  eta: 0:03:30    time: 0.9903  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 40/242]  eta: 0:03:23    time: 1.0535  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 50/242]  eta: 0:03:14    time: 1.0476  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 60/242]  eta: 0:03:07    time: 1.0785  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 70/242]  eta: 0:02:58    time: 1.0876  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 80/242]  eta: 0:02:46    time: 1.0295  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [ 90/242]  eta: 0:02:35    time: 0.9789  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [100/242]  eta: 0:02:25    time: 1.0156  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [110/242]  eta: 0:02:15    time: 1.0336  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [120/242]  eta: 0:02:05    time: 1.0442  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [130/242]  eta: 0:01:54    time: 1.0335  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [140/242]  eta: 0:01:44    time: 0.9836  data: 0.0010  max mem: 9586\n",
      "Epoch: [2] Test  [150/242]  eta: 0:01:33    time: 0.9902  data: 0.0010  max mem: 9586\n",
      "Epoch: [2] Test  [160/242]  eta: 0:01:23    time: 1.0037  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [170/242]  eta: 0:01:13    time: 1.0535  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [180/242]  eta: 0:01:03    time: 1.1118  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [190/242]  eta: 0:00:53    time: 1.1157  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [200/242]  eta: 0:00:43    time: 1.0633  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [210/242]  eta: 0:00:33    time: 1.0352  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [220/242]  eta: 0:00:22    time: 1.0419  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [230/242]  eta: 0:00:12    time: 1.0493  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [240/242]  eta: 0:00:02    time: 1.0129  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['96.7', '95.8', '80.7', '96.6', '86.1', '88.8', '99.1', '86.9', '97.2', '71.7', '95.8', '63.3', '93.2', '95.1', '94.2', '96.1', '76.7', '95.4', '83.2', '97.2', '88.1']\n",
      "IoU: ['94.6', '93.0', '42.2', '87.9', '71.4', '74.7', '96.3', '79.2', '92.0', '45.4', '92.3', '57.8', '88.0', '89.5', '90.5', '90.2', '63.0', '88.9', '62.4', '90.1', '80.1']\n",
      "mean IoU: 79.5\n",
      "Epoch: [3] Train  [  0/183]  eta: 0:39:42  lr: 0.000095  loss: 0.3288 (0.3288)  time: 13.0197  data: 0.3527  max mem: 9586\n",
      "Epoch: [3] Train  [ 10/183]  eta: 0:36:00  lr: 0.000095  loss: 1.1062 (0.6076)  time: 12.4856  data: 0.0325  max mem: 9586\n",
      "Epoch: [3] Train  [ 20/183]  eta: 0:33:48  lr: 0.000095  loss: 0.5259 (0.5978)  time: 12.4157  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Train  [ 30/183]  eta: 0:31:39  lr: 0.000095  loss: 0.4410 (0.5956)  time: 12.3758  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 40/183]  eta: 0:29:34  lr: 0.000095  loss: 0.7446 (0.5929)  time: 12.3769  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 50/183]  eta: 0:27:28  lr: 0.000095  loss: 0.8013 (0.6036)  time: 12.3579  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 60/183]  eta: 0:25:25  lr: 0.000095  loss: 1.5783 (0.6326)  time: 12.3863  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 70/183]  eta: 0:23:20  lr: 0.000094  loss: 1.3977 (0.6586)  time: 12.3978  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 80/183]  eta: 0:21:16  lr: 0.000094  loss: 0.3971 (0.6575)  time: 12.3717  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Train  [ 90/183]  eta: 0:19:12  lr: 0.000094  loss: 0.5483 (0.6557)  time: 12.3805  data: 0.0008  max mem: 9586\n",
      "Epoch: [3] Train  [100/183]  eta: 0:17:08  lr: 0.000094  loss: 0.1684 (0.6532)  time: 12.3624  data: 0.0009  max mem: 9586\n",
      "Epoch: [3] Train  [110/183]  eta: 0:15:04  lr: 0.000094  loss: 0.6665 (0.6555)  time: 12.3574  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Train  [120/183]  eta: 0:12:59  lr: 0.000094  loss: 0.4262 (0.6615)  time: 12.3216  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [130/183]  eta: 0:10:56  lr: 0.000094  loss: 0.8553 (0.6662)  time: 12.3563  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [140/183]  eta: 0:08:52  lr: 0.000094  loss: 0.4776 (0.6717)  time: 12.4657  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [150/183]  eta: 0:06:48  lr: 0.000093  loss: 0.1478 (0.6676)  time: 12.4024  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [160/183]  eta: 0:04:44  lr: 0.000093  loss: 0.6808 (0.6787)  time: 12.3267  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [170/183]  eta: 0:02:40  lr: 0.000093  loss: 0.3831 (0.6822)  time: 12.3684  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [180/183]  eta: 0:00:37  lr: 0.000093  loss: 0.5146 (0.6824)  time: 12.3244  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train Total time: 0:37:45\n",
      "Epoch: [3] Test  [  0/242]  eta: 0:06:08    time: 1.5224  data: 0.4460  max mem: 9586\n",
      "Epoch: [3] Test  [ 10/242]  eta: 0:03:52    time: 1.0035  data: 0.0408  max mem: 9586\n",
      "Epoch: [3] Test  [ 20/242]  eta: 0:03:35    time: 0.9427  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [ 30/242]  eta: 0:03:31    time: 0.9928  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [ 40/242]  eta: 0:03:24    time: 1.0530  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [ 50/242]  eta: 0:03:15    time: 1.0494  data: 0.0006  max mem: 9586\n",
      "Epoch: [3] Test  [ 60/242]  eta: 0:03:08    time: 1.0825  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Test  [ 70/242]  eta: 0:02:58    time: 1.0900  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [ 80/242]  eta: 0:02:47    time: 1.0307  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [ 90/242]  eta: 0:02:35    time: 0.9795  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [100/242]  eta: 0:02:26    time: 1.0133  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [110/242]  eta: 0:02:15    time: 1.0339  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [120/242]  eta: 0:02:05    time: 1.0474  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [130/242]  eta: 0:01:55    time: 1.0359  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [140/242]  eta: 0:01:44    time: 0.9853  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Test  [150/242]  eta: 0:01:34    time: 0.9914  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [160/242]  eta: 0:01:23    time: 1.0058  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [170/242]  eta: 0:01:13    time: 1.0536  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [180/242]  eta: 0:01:04    time: 1.1117  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [190/242]  eta: 0:00:53    time: 1.1162  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [200/242]  eta: 0:00:43    time: 1.0636  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [210/242]  eta: 0:00:33    time: 1.0371  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [220/242]  eta: 0:00:22    time: 1.0441  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [230/242]  eta: 0:00:12    time: 1.0511  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [240/242]  eta: 0:00:02    time: 1.0132  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test Total time: 0:04:10\n",
      "global correct: 95.4\n",
      "average row correct: ['96.9', '96.0', '75.2', '94.7', '85.8', '82.8', '98.9', '88.7', '97.8', '68.4', '95.6', '67.6', '92.9', '94.0', '94.8', '96.1', '78.4', '95.0', '86.1', '97.1', '88.2']\n",
      "IoU: ['94.7', '91.2', '41.5', '89.5', '75.8', '74.5', '96.3', '80.6', '92.9', '47.7', '91.8', '59.7', '88.2', '88.8', '90.6', '90.2', '62.8', '87.9', '62.7', '89.4', '80.0']\n",
      "mean IoU: 79.9\n",
      "Epoch: [4] Train  [  0/183]  eta: 0:38:32  lr: 0.000093  loss: 0.2677 (0.2677)  time: 12.6390  data: 0.4225  max mem: 9586\n",
      "Epoch: [4] Train  [ 10/183]  eta: 0:35:34  lr: 0.000093  loss: 0.4279 (0.5954)  time: 12.3355  data: 0.0388  max mem: 9586\n",
      "Epoch: [4] Train  [ 20/183]  eta: 0:33:28  lr: 0.000093  loss: 0.1500 (0.5714)  time: 12.3071  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [ 30/183]  eta: 0:31:26  lr: 0.000093  loss: 0.8125 (0.5848)  time: 12.3283  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [ 40/183]  eta: 0:29:21  lr: 0.000093  loss: 0.6132 (0.5883)  time: 12.3144  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [ 50/183]  eta: 0:27:17  lr: 0.000092  loss: 0.4280 (0.5819)  time: 12.2786  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [ 60/183]  eta: 0:25:17  lr: 0.000092  loss: 0.9610 (0.6157)  time: 12.3754  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [ 70/183]  eta: 0:23:11  lr: 0.000092  loss: 0.9816 (0.6215)  time: 12.3204  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [ 80/183]  eta: 0:21:09  lr: 0.000092  loss: 0.3801 (0.6205)  time: 12.2909  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Train  [ 90/183]  eta: 0:19:06  lr: 0.000092  loss: 0.4599 (0.6218)  time: 12.4045  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [100/183]  eta: 0:17:04  lr: 0.000092  loss: 0.8073 (0.6348)  time: 12.4103  data: 0.0006  max mem: 9586\n",
      "Epoch: [4] Train  [110/183]  eta: 0:15:00  lr: 0.000092  loss: 0.8747 (0.6545)  time: 12.3655  data: 0.0006  max mem: 9586\n",
      "Epoch: [4] Train  [120/183]  eta: 0:12:57  lr: 0.000092  loss: 1.0896 (0.6709)  time: 12.3112  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [130/183]  eta: 0:10:53  lr: 0.000091  loss: 0.9496 (0.6745)  time: 12.3089  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [140/183]  eta: 0:08:50  lr: 0.000091  loss: 0.7409 (0.6774)  time: 12.3803  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Train  [150/183]  eta: 0:06:47  lr: 0.000091  loss: 0.2105 (0.6728)  time: 12.4105  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [160/183]  eta: 0:04:43  lr: 0.000091  loss: 0.3757 (0.6660)  time: 12.3565  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [170/183]  eta: 0:02:40  lr: 0.000091  loss: 1.3889 (0.6667)  time: 12.2879  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [180/183]  eta: 0:00:37  lr: 0.000091  loss: 0.4911 (0.6667)  time: 12.3194  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train Total time: 0:37:38\n",
      "Epoch: [4] Test  [  0/242]  eta: 0:05:55    time: 1.4672  data: 0.3937  max mem: 9586\n",
      "Epoch: [4] Test  [ 10/242]  eta: 0:03:51    time: 0.9977  data: 0.0360  max mem: 9586\n",
      "Epoch: [4] Test  [ 20/242]  eta: 0:03:34    time: 0.9406  data: 0.0002  max mem: 9586\n",
      "Epoch: [4] Test  [ 30/242]  eta: 0:03:30    time: 0.9932  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [ 40/242]  eta: 0:03:23    time: 1.0543  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [ 50/242]  eta: 0:03:15    time: 1.0485  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [ 60/242]  eta: 0:03:08    time: 1.0824  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Test  [ 70/242]  eta: 0:02:58    time: 1.0906  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [ 80/242]  eta: 0:02:47    time: 1.0321  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [ 90/242]  eta: 0:02:35    time: 0.9827  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [100/242]  eta: 0:02:26    time: 1.0165  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Test  [110/242]  eta: 0:02:15    time: 1.0330  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Test  [120/242]  eta: 0:02:05    time: 1.0457  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [130/242]  eta: 0:01:55    time: 1.0359  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [140/242]  eta: 0:01:44    time: 0.9856  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [150/242]  eta: 0:01:34    time: 0.9931  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [160/242]  eta: 0:01:23    time: 1.0091  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [170/242]  eta: 0:01:13    time: 1.0565  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [180/242]  eta: 0:01:04    time: 1.1152  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [190/242]  eta: 0:00:53    time: 1.1190  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [200/242]  eta: 0:00:43    time: 1.0636  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [210/242]  eta: 0:00:33    time: 1.0387  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [220/242]  eta: 0:00:22    time: 1.0470  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [230/242]  eta: 0:00:12    time: 1.0512  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [240/242]  eta: 0:00:02    time: 1.0127  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['96.9', '96.6', '78.4', '95.7', '86.3', '89.6', '99.0', '89.7', '97.5', '70.1', '95.6', '66.3', '95.4', '92.4', '94.9', '96.5', '79.5', '95.3', '85.0', '96.5', '88.0']\n",
      "IoU: ['94.9', '93.0', '43.8', '89.6', '75.0', '74.4', '96.5', '81.4', '93.4', '51.1', '90.5', '59.7', '89.6', '88.9', '90.5', '90.0', '65.0', '88.6', '62.8', '91.0', '79.9']\n",
      "mean IoU: 80.4\n",
      "Epoch: [5] Train  [  0/183]  eta: 0:39:27  lr: 0.000091  loss: 0.5017 (0.5017)  time: 12.9380  data: 0.4147  max mem: 9586\n",
      "Epoch: [5] Train  [ 10/183]  eta: 0:35:56  lr: 0.000091  loss: 0.4687 (0.5452)  time: 12.4637  data: 0.0379  max mem: 9586\n",
      "Epoch: [5] Train  [ 20/183]  eta: 0:33:26  lr: 0.000090  loss: 0.8859 (0.5692)  time: 12.2786  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Train  [ 30/183]  eta: 0:31:26  lr: 0.000090  loss: 0.8072 (0.5670)  time: 12.2559  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Train  [ 40/183]  eta: 0:29:23  lr: 0.000090  loss: 0.7653 (0.5645)  time: 12.3600  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Train  [ 50/183]  eta: 0:27:19  lr: 0.000090  loss: 0.2550 (0.5452)  time: 12.3276  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Train  [ 60/183]  eta: 0:25:16  lr: 0.000090  loss: 0.3001 (0.5501)  time: 12.3241  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [ 70/183]  eta: 0:23:14  lr: 0.000090  loss: 0.1605 (0.5707)  time: 12.3561  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [ 80/183]  eta: 0:21:11  lr: 0.000090  loss: 0.5729 (0.5978)  time: 12.3746  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [ 90/183]  eta: 0:19:07  lr: 0.000090  loss: 0.6296 (0.6048)  time: 12.3577  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [100/183]  eta: 0:17:03  lr: 0.000089  loss: 0.9929 (0.6168)  time: 12.3123  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [110/183]  eta: 0:15:00  lr: 0.000089  loss: 0.9259 (0.6152)  time: 12.3219  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [120/183]  eta: 0:12:57  lr: 0.000089  loss: 0.9291 (0.6188)  time: 12.3820  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [130/183]  eta: 0:10:54  lr: 0.000089  loss: 1.0838 (0.6129)  time: 12.3608  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [140/183]  eta: 0:08:50  lr: 0.000089  loss: 0.5090 (0.6056)  time: 12.2957  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [150/183]  eta: 0:06:47  lr: 0.000089  loss: 0.1233 (0.6049)  time: 12.3607  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [160/183]  eta: 0:04:43  lr: 0.000089  loss: 0.3247 (0.6073)  time: 12.3819  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [170/183]  eta: 0:02:40  lr: 0.000089  loss: 0.7513 (0.6079)  time: 12.2503  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Train  [180/183]  eta: 0:00:37  lr: 0.000088  loss: 0.4253 (0.6082)  time: 12.2614  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Train Total time: 0:37:37\n",
      "Epoch: [5] Test  [  0/242]  eta: 0:06:08    time: 1.5233  data: 0.4533  max mem: 9586\n",
      "Epoch: [5] Test  [ 10/242]  eta: 0:03:52    time: 1.0033  data: 0.0415  max mem: 9586\n",
      "Epoch: [5] Test  [ 20/242]  eta: 0:03:35    time: 0.9436  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 30/242]  eta: 0:03:31    time: 0.9963  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 40/242]  eta: 0:03:24    time: 1.0579  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 50/242]  eta: 0:03:15    time: 1.0514  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 60/242]  eta: 0:03:08    time: 1.0815  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [ 70/242]  eta: 0:02:58    time: 1.0917  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Test  [ 80/242]  eta: 0:02:47    time: 1.0362  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 90/242]  eta: 0:02:36    time: 0.9844  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [100/242]  eta: 0:02:26    time: 1.0167  data: 0.0002  max mem: 9586\n",
      "Epoch: [5] Test  [110/242]  eta: 0:02:15    time: 1.0354  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [120/242]  eta: 0:02:06    time: 1.0486  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [130/242]  eta: 0:01:55    time: 1.0386  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [140/242]  eta: 0:01:44    time: 0.9877  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [150/242]  eta: 0:01:34    time: 0.9926  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [160/242]  eta: 0:01:24    time: 1.0074  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [170/242]  eta: 0:01:14    time: 1.0573  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [180/242]  eta: 0:01:04    time: 1.1160  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [190/242]  eta: 0:00:54    time: 1.1199  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [200/242]  eta: 0:00:43    time: 1.0644  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [210/242]  eta: 0:00:33    time: 1.0358  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [220/242]  eta: 0:00:22    time: 1.0454  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [230/242]  eta: 0:00:12    time: 1.0533  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [240/242]  eta: 0:00:02    time: 1.0132  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['97.0', '96.2', '73.8', '95.4', '84.4', '88.1', '99.0', '91.5', '97.8', '71.8', '95.6', '70.0', '90.9', '95.0', '94.0', '96.8', '80.5', '95.4', '82.4', '96.2', '88.6']\n",
      "IoU: ['94.9', '93.1', '43.9', '89.7', '75.3', '76.1', '96.8', '83.3', '90.8', '49.7', '92.3', '61.7', '86.9', '88.4', '90.6', '90.4', '67.1', '89.4', '62.7', '89.6', '78.6']\n",
      "mean IoU: 80.5\n",
      "Epoch: [6] Train  [  0/183]  eta: 0:40:52  lr: 0.000088  loss: 0.2039 (0.2039)  time: 13.4012  data: 0.4570  max mem: 9586\n",
      "Epoch: [6] Train  [ 10/183]  eta: 0:35:46  lr: 0.000088  loss: 0.8718 (0.8066)  time: 12.4064  data: 0.0418  max mem: 9586\n",
      "Epoch: [6] Train  [ 20/183]  eta: 0:33:34  lr: 0.000088  loss: 0.2042 (0.7120)  time: 12.3100  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [ 30/183]  eta: 0:31:27  lr: 0.000088  loss: 0.7804 (0.6728)  time: 12.3017  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [ 40/183]  eta: 0:29:28  lr: 0.000088  loss: 0.3918 (0.6550)  time: 12.3666  data: 0.0002  max mem: 9586\n",
      "Epoch: [6] Train  [ 50/183]  eta: 0:27:20  lr: 0.000088  loss: 0.3699 (0.6109)  time: 12.3304  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [ 60/183]  eta: 0:25:20  lr: 0.000088  loss: 0.7363 (0.6093)  time: 12.3514  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Train  [ 70/183]  eta: 0:23:16  lr: 0.000087  loss: 1.0203 (0.6195)  time: 12.4091  data: 0.0005  max mem: 9586\n",
      "Epoch: [6] Train  [ 80/183]  eta: 0:21:12  lr: 0.000087  loss: 0.2865 (0.6151)  time: 12.3421  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Train  [ 90/183]  eta: 0:19:07  lr: 0.000087  loss: 0.5454 (0.6252)  time: 12.2990  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [100/183]  eta: 0:17:03  lr: 0.000087  loss: 0.4279 (0.6230)  time: 12.2587  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [110/183]  eta: 0:15:01  lr: 0.000087  loss: 0.3814 (0.6124)  time: 12.3829  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [120/183]  eta: 0:12:57  lr: 0.000087  loss: 0.3790 (0.6039)  time: 12.3634  data: 0.0002  max mem: 9586\n",
      "Epoch: [6] Train  [130/183]  eta: 0:10:54  lr: 0.000087  loss: 0.8294 (0.6006)  time: 12.2971  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [140/183]  eta: 0:08:50  lr: 0.000087  loss: 0.4590 (0.5932)  time: 12.3868  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [150/183]  eta: 0:06:47  lr: 0.000086  loss: 0.2210 (0.5928)  time: 12.4149  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [160/183]  eta: 0:04:44  lr: 0.000086  loss: 0.3772 (0.5849)  time: 12.3629  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [170/183]  eta: 0:02:40  lr: 0.000086  loss: 0.7619 (0.5846)  time: 12.2799  data: 0.0003  max mem: 9586\n"
     ]
    }
   ],
   "source": [
    "# simsiam\n",
    "!experiment_name=\"attention\";cd ../ ;\\\n",
    "    name_date=\"${experiment_name}/$(date +%Y-%m%d-%H%M%S)\";\\\n",
    "    dir=\"./results/${name_date}\";mkdir -p ${dir};dir_log=\"${dir}/output.log\";\\\n",
    "CUDA_VISIBLE_DEVICES=3 torchrun --nproc_per_node=1 --master_port=14534 train_multi_GPU.py \\\n",
    "    --wandb False --wandb_model run --sync_bn False --amp True --aux False \\\n",
    "    --model_name aspp_contrast_resnet101 --pre_trained deeplabv3_resnet101_coco.pth \\\n",
    "    --weight_only_backbone False --lr 0.0001 --wd 0.0001 --attention cbam \\\n",
    "    --data_path pascal-voc-2012 --num_classes 21 --data_train_type train.txt \\\n",
    "    --epochs 40 --batch_size 8 --batch_size_val 6 --memory_size 0 \\\n",
    "    --contrast 0 --L1_loss 0.1 --L2_loss 0.1 --L3_loss 0.1 \\\n",
    "    --loss_name aspp_loss --sample adapt_excite_8 \\\n",
    "    --name_date $name_date \\\n",
    "    2>&1 | tee $dir_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
