{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| distributed init (rank 0): env://\n",
      "attention/2023-0407-163253\n",
      "Namespace(data_path='pascal-voc-2012', data_train_type='train.txt', device='cuda', num_classes=21, batch_size=8, batch_size_val=6, aux=False, start_epoch=0, epochs=40, sync_bn=False, workers=1, lr=0.0001, momentum=0.9, weight_decay=0.0001, print_freq=10, checkpoint_dir='./results/attention/2023-0407-163253', resume='', test_only=False, world_size=1, dist_url='env://', amp=True, seed=304, name_date='attention/2023-0407-163253', wandb=False, wandb_model='run', run_name='', model_name='aspp_contrast_resnet101', project_dim=128, loss_name='aspp_loss', contrast=0, pre_trained='deeplabv3_resnet101_coco.pth', L3_loss=0.1, L2_loss=0.1, L1_loss=0.1, GAcc=1, memory_size=0, proj_dim=128, network_stride=8, pixel_update_freq=10, ddp=False, weight_only_backbone=False, sample='adapt_excite_8', attention=True, rank=0, gpu=0, distributed=True, dist_backend='nccl')\n",
      "Creating data loaders\n",
      "Creating model\n",
      "missing_keys:  ['contrast.convs.0.0.weight', 'contrast.convs.0.1.weight', 'contrast.convs.0.1.bias', 'contrast.convs.0.1.running_mean', 'contrast.convs.0.1.running_var', 'contrast.convs.0.3.weight', 'contrast.convs.0.4.weight', 'contrast.convs.0.4.bias', 'contrast.convs.0.4.running_mean', 'contrast.convs.0.4.running_var', 'contrast.convs.1.0.weight', 'contrast.convs.1.1.weight', 'contrast.convs.1.1.bias', 'contrast.convs.1.1.running_mean', 'contrast.convs.1.1.running_var', 'contrast.convs.1.3.weight', 'contrast.convs.1.4.weight', 'contrast.convs.1.4.bias', 'contrast.convs.1.4.running_mean', 'contrast.convs.1.4.running_var', 'contrast.convs.2.0.weight', 'contrast.convs.2.1.weight', 'contrast.convs.2.1.bias', 'contrast.convs.2.1.running_mean', 'contrast.convs.2.1.running_var', 'contrast.convs.2.3.weight', 'contrast.convs.2.4.weight', 'contrast.convs.2.4.bias', 'contrast.convs.2.4.running_mean', 'contrast.convs.2.4.running_var', 'attention.ca.se.0.weight', 'attention.ca.se.2.weight', 'attention.sa.conv.weight', 'attention.sa.conv.bias']\n",
      "unexpected_keys:  ['aux_classifier.0.weight', 'aux_classifier.1.weight', 'aux_classifier.1.bias', 'aux_classifier.1.running_mean', 'aux_classifier.1.running_var', 'aux_classifier.1.num_batches_tracked', 'aux_classifier.4.weight', 'aux_classifier.4.bias']\n",
      "DistributedDataParallel(\n",
      "  (module): DeepLabV3(\n",
      "    (backbone): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (6): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (7): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (8): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (9): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (10): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (11): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (12): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (13): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (14): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (15): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (16): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (17): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (18): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (19): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (20): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (21): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (22): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): DeepLabHead(\n",
      "      (0): ASPP(\n",
      "        (convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): ASPPPooling(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (contrast): contrast_head(\n",
      "      (convs): ModuleList(\n",
      "        (0): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attention): CBAMBlock(\n",
      "      (ca): ChannelAttention(\n",
      "        (maxpool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (se): Sequential(\n",
      "          (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Start training\n",
      "Epoch: [0] Train  [  0/183]  eta: 0:45:23  lr: 0.000001  loss: 1.6377 (1.6377)  time: 14.8828  data: 0.4573  max mem: 9117\n",
      "Epoch: [0] Train  [ 10/183]  eta: 0:36:58  lr: 0.000006  loss: 0.8885 (1.1397)  time: 12.8232  data: 0.0420  max mem: 9586\n",
      "Epoch: [0] Train  [ 20/183]  eta: 0:34:18  lr: 0.000012  loss: 1.3847 (1.2334)  time: 12.5160  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Train  [ 30/183]  eta: 0:32:11  lr: 0.000017  loss: 0.9623 (1.1872)  time: 12.5151  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [ 40/183]  eta: 0:29:59  lr: 0.000022  loss: 1.0218 (1.1882)  time: 12.5340  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Train  [ 50/183]  eta: 0:27:50  lr: 0.000028  loss: 1.5941 (1.2127)  time: 12.4595  data: 0.0007  max mem: 9586\n",
      "Epoch: [0] Train  [ 60/183]  eta: 0:25:40  lr: 0.000033  loss: 0.9272 (1.2427)  time: 12.3990  data: 0.0005  max mem: 9586\n",
      "Epoch: [0] Train  [ 70/183]  eta: 0:23:32  lr: 0.000039  loss: 0.8477 (1.2264)  time: 12.3557  data: 0.0002  max mem: 9586\n",
      "Epoch: [0] Train  [ 80/183]  eta: 0:21:24  lr: 0.000044  loss: 0.9576 (1.2053)  time: 12.3234  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [ 90/183]  eta: 0:19:19  lr: 0.000050  loss: 0.6577 (1.1823)  time: 12.3455  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Train  [100/183]  eta: 0:17:15  lr: 0.000055  loss: 1.6305 (1.1982)  time: 12.4983  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Train  [110/183]  eta: 0:15:10  lr: 0.000061  loss: 1.1563 (1.2047)  time: 12.5136  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [120/183]  eta: 0:13:05  lr: 0.000066  loss: 0.9062 (1.2120)  time: 12.4031  data: 0.0002  max mem: 9586\n",
      "Epoch: [0] Train  [130/183]  eta: 0:11:00  lr: 0.000072  loss: 0.5942 (1.2034)  time: 12.3735  data: 0.0002  max mem: 9586\n",
      "Epoch: [0] Train  [140/183]  eta: 0:08:55  lr: 0.000077  loss: 1.0309 (1.1900)  time: 12.3575  data: 0.0002  max mem: 9586\n",
      "Epoch: [0] Train  [150/183]  eta: 0:06:50  lr: 0.000083  loss: 0.5240 (1.1687)  time: 12.3137  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [160/183]  eta: 0:04:46  lr: 0.000088  loss: 1.2727 (1.1735)  time: 12.3390  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [170/183]  eta: 0:02:41  lr: 0.000093  loss: 0.9591 (1.1602)  time: 12.4061  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train  [180/183]  eta: 0:00:37  lr: 0.000099  loss: 0.6159 (1.1488)  time: 12.3859  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Train Total time: 0:37:54\n",
      "Epoch: [0] Test  [  0/242]  eta: 0:08:12    time: 2.0353  data: 0.4145  max mem: 9586\n",
      "Epoch: [0] Test  [ 10/242]  eta: 0:04:03    time: 1.0486  data: 0.0380  max mem: 9586\n",
      "Epoch: [0] Test  [ 20/242]  eta: 0:03:40    time: 0.9406  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 30/242]  eta: 0:03:34    time: 0.9939  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 40/242]  eta: 0:03:26    time: 1.0539  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 50/242]  eta: 0:03:16    time: 1.0455  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 60/242]  eta: 0:03:09    time: 1.0768  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [ 70/242]  eta: 0:02:59    time: 1.0858  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 80/242]  eta: 0:02:48    time: 1.0301  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [ 90/242]  eta: 0:02:36    time: 0.9789  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [100/242]  eta: 0:02:26    time: 1.0117  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [110/242]  eta: 0:02:15    time: 1.0296  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [120/242]  eta: 0:02:06    time: 1.0418  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [130/242]  eta: 0:01:55    time: 1.0317  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [140/242]  eta: 0:01:44    time: 0.9815  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [150/242]  eta: 0:01:34    time: 0.9886  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [160/242]  eta: 0:01:23    time: 1.0047  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [170/242]  eta: 0:01:14    time: 1.0685  data: 0.0005  max mem: 9586\n",
      "Epoch: [0] Test  [180/242]  eta: 0:01:04    time: 1.1257  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [190/242]  eta: 0:00:53    time: 1.1127  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test  [200/242]  eta: 0:00:43    time: 1.0596  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [210/242]  eta: 0:00:33    time: 1.0331  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [220/242]  eta: 0:00:22    time: 1.0401  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [230/242]  eta: 0:00:12    time: 1.0487  data: 0.0004  max mem: 9586\n",
      "Epoch: [0] Test  [240/242]  eta: 0:00:02    time: 1.0104  data: 0.0003  max mem: 9586\n",
      "Epoch: [0] Test Total time: 0:04:10\n",
      "global correct: 95.2\n",
      "average row correct: ['97.3', '94.7', '79.0', '94.3', '81.5', '73.2', '97.6', '79.9', '96.0', '66.7', '94.4', '60.9', '89.8', '93.7', '93.5', '97.0', '70.4', '94.7', '82.9', '94.5', '84.3']\n",
      "IoU: ['94.4', '90.9', '40.5', '89.2', '72.8', '67.6', '96.2', '76.1', '91.8', '50.4', '92.4', '55.3', '86.9', '88.6', '89.1', '87.9', '62.1', '89.4', '62.9', '89.8', '81.4']\n",
      "mean IoU: 78.9\n",
      "Epoch: [1] Train  [  0/183]  eta: 0:39:37  lr: 0.000100  loss: 1.0170 (1.0170)  time: 12.9927  data: 0.3927  max mem: 9586\n",
      "Epoch: [1] Train  [ 10/183]  eta: 0:36:10  lr: 0.000100  loss: 0.6539 (0.9033)  time: 12.5445  data: 0.0361  max mem: 9586\n",
      "Epoch: [1] Train  [ 20/183]  eta: 0:33:58  lr: 0.000100  loss: 1.6438 (0.9229)  time: 12.4790  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Train  [ 30/183]  eta: 0:31:55  lr: 0.000100  loss: 2.7592 (0.9893)  time: 12.5039  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Train  [ 40/183]  eta: 0:29:48  lr: 0.000099  loss: 0.7215 (0.9761)  time: 12.5118  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 50/183]  eta: 0:27:42  lr: 0.000099  loss: 0.7908 (0.9442)  time: 12.4750  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 60/183]  eta: 0:25:36  lr: 0.000099  loss: 0.5589 (0.9865)  time: 12.4574  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 70/183]  eta: 0:23:27  lr: 0.000099  loss: 0.6175 (0.9647)  time: 12.3453  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 80/183]  eta: 0:21:23  lr: 0.000099  loss: 0.7059 (0.9607)  time: 12.3891  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [ 90/183]  eta: 0:19:16  lr: 0.000099  loss: 0.4569 (0.9456)  time: 12.3635  data: 0.0005  max mem: 9586\n",
      "Epoch: [1] Train  [100/183]  eta: 0:17:12  lr: 0.000099  loss: 0.6866 (0.9346)  time: 12.3278  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Train  [110/183]  eta: 0:15:07  lr: 0.000099  loss: 0.9738 (0.9151)  time: 12.4280  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Train  [120/183]  eta: 0:13:03  lr: 0.000098  loss: 0.3467 (0.9243)  time: 12.3801  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Train  [130/183]  eta: 0:10:58  lr: 0.000098  loss: 1.3595 (0.9138)  time: 12.3703  data: 0.0002  max mem: 9586\n",
      "Epoch: [1] Train  [140/183]  eta: 0:08:54  lr: 0.000098  loss: 1.2148 (0.9034)  time: 12.3568  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Train  [150/183]  eta: 0:06:49  lr: 0.000098  loss: 0.5551 (0.8879)  time: 12.3696  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Train  [160/183]  eta: 0:04:45  lr: 0.000098  loss: 0.5474 (0.8657)  time: 12.3420  data: 0.0006  max mem: 9586\n",
      "Epoch: [1] Train  [170/183]  eta: 0:02:41  lr: 0.000098  loss: 1.2188 (0.8673)  time: 12.2778  data: 0.0007  max mem: 9586\n",
      "Epoch: [1] Train  [180/183]  eta: 0:00:37  lr: 0.000098  loss: 0.6434 (0.8577)  time: 12.3228  data: 0.0007  max mem: 9586\n",
      "Epoch: [1] Train Total time: 0:37:48\n",
      "Epoch: [1] Test  [  0/242]  eta: 0:05:49    time: 1.4432  data: 0.3795  max mem: 9586\n",
      "Epoch: [1] Test  [ 10/242]  eta: 0:03:51    time: 0.9958  data: 0.0348  max mem: 9586\n",
      "Epoch: [1] Test  [ 20/242]  eta: 0:03:34    time: 0.9405  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Test  [ 30/242]  eta: 0:03:30    time: 0.9914  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 40/242]  eta: 0:03:23    time: 1.0532  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 50/242]  eta: 0:03:14    time: 1.0481  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 60/242]  eta: 0:03:07    time: 1.0790  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 70/242]  eta: 0:02:58    time: 1.0873  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 80/242]  eta: 0:02:46    time: 1.0298  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [ 90/242]  eta: 0:02:35    time: 0.9796  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [100/242]  eta: 0:02:25    time: 1.0145  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [110/242]  eta: 0:02:15    time: 1.0327  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [120/242]  eta: 0:02:05    time: 1.0465  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [130/242]  eta: 0:01:54    time: 1.0341  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [140/242]  eta: 0:01:44    time: 0.9823  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [150/242]  eta: 0:01:33    time: 0.9891  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Test  [160/242]  eta: 0:01:23    time: 1.0046  data: 0.0004  max mem: 9586\n",
      "Epoch: [1] Test  [170/242]  eta: 0:01:13    time: 1.0560  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [180/242]  eta: 0:01:03    time: 1.1132  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [190/242]  eta: 0:00:53    time: 1.1146  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [200/242]  eta: 0:00:43    time: 1.0595  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [210/242]  eta: 0:00:33    time: 1.0334  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [220/242]  eta: 0:00:22    time: 1.0420  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [230/242]  eta: 0:00:12    time: 1.0486  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test  [240/242]  eta: 0:00:02    time: 1.0095  data: 0.0003  max mem: 9586\n",
      "Epoch: [1] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['96.9', '95.1', '82.1', '95.1', '83.2', '80.2', '98.7', '85.3', '97.4', '73.3', '94.3', '63.3', '92.3', '94.1', '95.7', '96.1', '71.2', '95.5', '83.3', '97.0', '87.0']\n",
      "IoU: ['94.5', '92.0', '42.2', '88.9', '75.1', '72.4', '96.8', '78.4', '91.3', '46.3', '91.0', '57.2', '88.0', '89.1', '89.6', '89.6', '61.3', '86.7', '62.9', '90.4', '80.9']\n",
      "mean IoU: 79.3\n",
      "Epoch: [2] Train  [  0/183]  eta: 0:37:44  lr: 0.000098  loss: 0.3637 (0.3637)  time: 12.3757  data: 0.4039  max mem: 9586\n",
      "Epoch: [2] Train  [ 10/183]  eta: 0:35:36  lr: 0.000098  loss: 0.3588 (0.7715)  time: 12.3490  data: 0.0370  max mem: 9586\n",
      "Epoch: [2] Train  [ 20/183]  eta: 0:33:28  lr: 0.000097  loss: 0.4822 (0.7077)  time: 12.3165  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [ 30/183]  eta: 0:31:25  lr: 0.000097  loss: 0.9735 (0.6932)  time: 12.3142  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train  [ 40/183]  eta: 0:29:26  lr: 0.000097  loss: 1.2567 (0.6928)  time: 12.3884  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train  [ 50/183]  eta: 0:27:23  lr: 0.000097  loss: 0.8185 (0.7242)  time: 12.4001  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [ 60/183]  eta: 0:25:21  lr: 0.000097  loss: 0.9570 (0.7331)  time: 12.3927  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [ 70/183]  eta: 0:23:19  lr: 0.000097  loss: 0.6409 (0.7306)  time: 12.4449  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train  [ 80/183]  eta: 0:21:13  lr: 0.000097  loss: 0.5831 (0.7233)  time: 12.3556  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train  [ 90/183]  eta: 0:19:09  lr: 0.000097  loss: 0.6897 (0.7320)  time: 12.2966  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [100/183]  eta: 0:17:05  lr: 0.000096  loss: 0.6414 (0.7394)  time: 12.3503  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [110/183]  eta: 0:15:02  lr: 0.000096  loss: 1.5429 (0.7411)  time: 12.3418  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [120/183]  eta: 0:12:59  lr: 0.000096  loss: 0.4596 (0.7494)  time: 12.4019  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [130/183]  eta: 0:10:54  lr: 0.000096  loss: 0.6204 (0.7449)  time: 12.3464  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [140/183]  eta: 0:08:50  lr: 0.000096  loss: 0.7506 (0.7417)  time: 12.2207  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Train  [150/183]  eta: 0:06:47  lr: 0.000096  loss: 0.5929 (0.7307)  time: 12.3059  data: 0.0002  max mem: 9586\n",
      "Epoch: [2] Train  [160/183]  eta: 0:04:44  lr: 0.000096  loss: 0.8514 (0.7378)  time: 12.4107  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Train  [170/183]  eta: 0:02:40  lr: 0.000096  loss: 0.3746 (0.7375)  time: 12.3779  data: 0.0006  max mem: 9586\n",
      "Epoch: [2] Train  [180/183]  eta: 0:00:37  lr: 0.000095  loss: 0.1677 (0.7326)  time: 12.3865  data: 0.0005  max mem: 9586\n",
      "Epoch: [2] Train Total time: 0:37:41\n",
      "Epoch: [2] Test  [  0/242]  eta: 0:06:00    time: 1.4888  data: 0.4186  max mem: 9586\n",
      "Epoch: [2] Test  [ 10/242]  eta: 0:03:51    time: 0.9983  data: 0.0383  max mem: 9586\n",
      "Epoch: [2] Test  [ 20/242]  eta: 0:03:34    time: 0.9384  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 30/242]  eta: 0:03:30    time: 0.9903  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 40/242]  eta: 0:03:23    time: 1.0535  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 50/242]  eta: 0:03:14    time: 1.0476  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 60/242]  eta: 0:03:07    time: 1.0785  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 70/242]  eta: 0:02:58    time: 1.0876  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [ 80/242]  eta: 0:02:46    time: 1.0295  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [ 90/242]  eta: 0:02:35    time: 0.9789  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [100/242]  eta: 0:02:25    time: 1.0156  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [110/242]  eta: 0:02:15    time: 1.0336  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [120/242]  eta: 0:02:05    time: 1.0442  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [130/242]  eta: 0:01:54    time: 1.0335  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [140/242]  eta: 0:01:44    time: 0.9836  data: 0.0010  max mem: 9586\n",
      "Epoch: [2] Test  [150/242]  eta: 0:01:33    time: 0.9902  data: 0.0010  max mem: 9586\n",
      "Epoch: [2] Test  [160/242]  eta: 0:01:23    time: 1.0037  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [170/242]  eta: 0:01:13    time: 1.0535  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [180/242]  eta: 0:01:03    time: 1.1118  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [190/242]  eta: 0:00:53    time: 1.1157  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [200/242]  eta: 0:00:43    time: 1.0633  data: 0.0004  max mem: 9586\n",
      "Epoch: [2] Test  [210/242]  eta: 0:00:33    time: 1.0352  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [220/242]  eta: 0:00:22    time: 1.0419  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [230/242]  eta: 0:00:12    time: 1.0493  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test  [240/242]  eta: 0:00:02    time: 1.0129  data: 0.0003  max mem: 9586\n",
      "Epoch: [2] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['96.7', '95.8', '80.7', '96.6', '86.1', '88.8', '99.1', '86.9', '97.2', '71.7', '95.8', '63.3', '93.2', '95.1', '94.2', '96.1', '76.7', '95.4', '83.2', '97.2', '88.1']\n",
      "IoU: ['94.6', '93.0', '42.2', '87.9', '71.4', '74.7', '96.3', '79.2', '92.0', '45.4', '92.3', '57.8', '88.0', '89.5', '90.5', '90.2', '63.0', '88.9', '62.4', '90.1', '80.1']\n",
      "mean IoU: 79.5\n",
      "Epoch: [3] Train  [  0/183]  eta: 0:39:42  lr: 0.000095  loss: 0.3288 (0.3288)  time: 13.0197  data: 0.3527  max mem: 9586\n",
      "Epoch: [3] Train  [ 10/183]  eta: 0:36:00  lr: 0.000095  loss: 1.1062 (0.6076)  time: 12.4856  data: 0.0325  max mem: 9586\n",
      "Epoch: [3] Train  [ 20/183]  eta: 0:33:48  lr: 0.000095  loss: 0.5259 (0.5978)  time: 12.4157  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Train  [ 30/183]  eta: 0:31:39  lr: 0.000095  loss: 0.4410 (0.5956)  time: 12.3758  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 40/183]  eta: 0:29:34  lr: 0.000095  loss: 0.7446 (0.5929)  time: 12.3769  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 50/183]  eta: 0:27:28  lr: 0.000095  loss: 0.8013 (0.6036)  time: 12.3579  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 60/183]  eta: 0:25:25  lr: 0.000095  loss: 1.5783 (0.6326)  time: 12.3863  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 70/183]  eta: 0:23:20  lr: 0.000094  loss: 1.3977 (0.6586)  time: 12.3978  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Train  [ 80/183]  eta: 0:21:16  lr: 0.000094  loss: 0.3971 (0.6575)  time: 12.3717  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Train  [ 90/183]  eta: 0:19:12  lr: 0.000094  loss: 0.5483 (0.6557)  time: 12.3805  data: 0.0008  max mem: 9586\n",
      "Epoch: [3] Train  [100/183]  eta: 0:17:08  lr: 0.000094  loss: 0.1684 (0.6532)  time: 12.3624  data: 0.0009  max mem: 9586\n",
      "Epoch: [3] Train  [110/183]  eta: 0:15:04  lr: 0.000094  loss: 0.6665 (0.6555)  time: 12.3574  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Train  [120/183]  eta: 0:12:59  lr: 0.000094  loss: 0.4262 (0.6615)  time: 12.3216  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [130/183]  eta: 0:10:56  lr: 0.000094  loss: 0.8553 (0.6662)  time: 12.3563  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [140/183]  eta: 0:08:52  lr: 0.000094  loss: 0.4776 (0.6717)  time: 12.4657  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [150/183]  eta: 0:06:48  lr: 0.000093  loss: 0.1478 (0.6676)  time: 12.4024  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [160/183]  eta: 0:04:44  lr: 0.000093  loss: 0.6808 (0.6787)  time: 12.3267  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [170/183]  eta: 0:02:40  lr: 0.000093  loss: 0.3831 (0.6822)  time: 12.3684  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train  [180/183]  eta: 0:00:37  lr: 0.000093  loss: 0.5146 (0.6824)  time: 12.3244  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Train Total time: 0:37:45\n",
      "Epoch: [3] Test  [  0/242]  eta: 0:06:08    time: 1.5224  data: 0.4460  max mem: 9586\n",
      "Epoch: [3] Test  [ 10/242]  eta: 0:03:52    time: 1.0035  data: 0.0408  max mem: 9586\n",
      "Epoch: [3] Test  [ 20/242]  eta: 0:03:35    time: 0.9427  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [ 30/242]  eta: 0:03:31    time: 0.9928  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [ 40/242]  eta: 0:03:24    time: 1.0530  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [ 50/242]  eta: 0:03:15    time: 1.0494  data: 0.0006  max mem: 9586\n",
      "Epoch: [3] Test  [ 60/242]  eta: 0:03:08    time: 1.0825  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Test  [ 70/242]  eta: 0:02:58    time: 1.0900  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [ 80/242]  eta: 0:02:47    time: 1.0307  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [ 90/242]  eta: 0:02:35    time: 0.9795  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [100/242]  eta: 0:02:26    time: 1.0133  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [110/242]  eta: 0:02:15    time: 1.0339  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [120/242]  eta: 0:02:05    time: 1.0474  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [130/242]  eta: 0:01:55    time: 1.0359  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [140/242]  eta: 0:01:44    time: 0.9853  data: 0.0005  max mem: 9586\n",
      "Epoch: [3] Test  [150/242]  eta: 0:01:34    time: 0.9914  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [160/242]  eta: 0:01:23    time: 1.0058  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [170/242]  eta: 0:01:13    time: 1.0536  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [180/242]  eta: 0:01:04    time: 1.1117  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [190/242]  eta: 0:00:53    time: 1.1162  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [200/242]  eta: 0:00:43    time: 1.0636  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [210/242]  eta: 0:00:33    time: 1.0371  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [220/242]  eta: 0:00:22    time: 1.0441  data: 0.0003  max mem: 9586\n",
      "Epoch: [3] Test  [230/242]  eta: 0:00:12    time: 1.0511  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test  [240/242]  eta: 0:00:02    time: 1.0132  data: 0.0004  max mem: 9586\n",
      "Epoch: [3] Test Total time: 0:04:10\n",
      "global correct: 95.4\n",
      "average row correct: ['96.9', '96.0', '75.2', '94.7', '85.8', '82.8', '98.9', '88.7', '97.8', '68.4', '95.6', '67.6', '92.9', '94.0', '94.8', '96.1', '78.4', '95.0', '86.1', '97.1', '88.2']\n",
      "IoU: ['94.7', '91.2', '41.5', '89.5', '75.8', '74.5', '96.3', '80.6', '92.9', '47.7', '91.8', '59.7', '88.2', '88.8', '90.6', '90.2', '62.8', '87.9', '62.7', '89.4', '80.0']\n",
      "mean IoU: 79.9\n",
      "Epoch: [4] Train  [  0/183]  eta: 0:38:32  lr: 0.000093  loss: 0.2677 (0.2677)  time: 12.6390  data: 0.4225  max mem: 9586\n",
      "Epoch: [4] Train  [ 10/183]  eta: 0:35:34  lr: 0.000093  loss: 0.4279 (0.5954)  time: 12.3355  data: 0.0388  max mem: 9586\n",
      "Epoch: [4] Train  [ 20/183]  eta: 0:33:28  lr: 0.000093  loss: 0.1500 (0.5714)  time: 12.3071  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [ 30/183]  eta: 0:31:26  lr: 0.000093  loss: 0.8125 (0.5848)  time: 12.3283  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [ 40/183]  eta: 0:29:21  lr: 0.000093  loss: 0.6132 (0.5883)  time: 12.3144  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [ 50/183]  eta: 0:27:17  lr: 0.000092  loss: 0.4280 (0.5819)  time: 12.2786  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [ 60/183]  eta: 0:25:17  lr: 0.000092  loss: 0.9610 (0.6157)  time: 12.3754  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [ 70/183]  eta: 0:23:11  lr: 0.000092  loss: 0.9816 (0.6215)  time: 12.3204  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [ 80/183]  eta: 0:21:09  lr: 0.000092  loss: 0.3801 (0.6205)  time: 12.2909  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Train  [ 90/183]  eta: 0:19:06  lr: 0.000092  loss: 0.4599 (0.6218)  time: 12.4045  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [100/183]  eta: 0:17:04  lr: 0.000092  loss: 0.8073 (0.6348)  time: 12.4103  data: 0.0006  max mem: 9586\n",
      "Epoch: [4] Train  [110/183]  eta: 0:15:00  lr: 0.000092  loss: 0.8747 (0.6545)  time: 12.3655  data: 0.0006  max mem: 9586\n",
      "Epoch: [4] Train  [120/183]  eta: 0:12:57  lr: 0.000092  loss: 1.0896 (0.6709)  time: 12.3112  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Train  [130/183]  eta: 0:10:53  lr: 0.000091  loss: 0.9496 (0.6745)  time: 12.3089  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [140/183]  eta: 0:08:50  lr: 0.000091  loss: 0.7409 (0.6774)  time: 12.3803  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Train  [150/183]  eta: 0:06:47  lr: 0.000091  loss: 0.2105 (0.6728)  time: 12.4105  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [160/183]  eta: 0:04:43  lr: 0.000091  loss: 0.3757 (0.6660)  time: 12.3565  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [170/183]  eta: 0:02:40  lr: 0.000091  loss: 1.3889 (0.6667)  time: 12.2879  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train  [180/183]  eta: 0:00:37  lr: 0.000091  loss: 0.4911 (0.6667)  time: 12.3194  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Train Total time: 0:37:38\n",
      "Epoch: [4] Test  [  0/242]  eta: 0:05:55    time: 1.4672  data: 0.3937  max mem: 9586\n",
      "Epoch: [4] Test  [ 10/242]  eta: 0:03:51    time: 0.9977  data: 0.0360  max mem: 9586\n",
      "Epoch: [4] Test  [ 20/242]  eta: 0:03:34    time: 0.9406  data: 0.0002  max mem: 9586\n",
      "Epoch: [4] Test  [ 30/242]  eta: 0:03:30    time: 0.9932  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [ 40/242]  eta: 0:03:23    time: 1.0543  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [ 50/242]  eta: 0:03:15    time: 1.0485  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [ 60/242]  eta: 0:03:08    time: 1.0824  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Test  [ 70/242]  eta: 0:02:58    time: 1.0906  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [ 80/242]  eta: 0:02:47    time: 1.0321  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [ 90/242]  eta: 0:02:35    time: 0.9827  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [100/242]  eta: 0:02:26    time: 1.0165  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Test  [110/242]  eta: 0:02:15    time: 1.0330  data: 0.0005  max mem: 9586\n",
      "Epoch: [4] Test  [120/242]  eta: 0:02:05    time: 1.0457  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [130/242]  eta: 0:01:55    time: 1.0359  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [140/242]  eta: 0:01:44    time: 0.9856  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [150/242]  eta: 0:01:34    time: 0.9931  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [160/242]  eta: 0:01:23    time: 1.0091  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [170/242]  eta: 0:01:13    time: 1.0565  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [180/242]  eta: 0:01:04    time: 1.1152  data: 0.0004  max mem: 9586\n",
      "Epoch: [4] Test  [190/242]  eta: 0:00:53    time: 1.1190  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [200/242]  eta: 0:00:43    time: 1.0636  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [210/242]  eta: 0:00:33    time: 1.0387  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [220/242]  eta: 0:00:22    time: 1.0470  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [230/242]  eta: 0:00:12    time: 1.0512  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test  [240/242]  eta: 0:00:02    time: 1.0127  data: 0.0003  max mem: 9586\n",
      "Epoch: [4] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['96.9', '96.6', '78.4', '95.7', '86.3', '89.6', '99.0', '89.7', '97.5', '70.1', '95.6', '66.3', '95.4', '92.4', '94.9', '96.5', '79.5', '95.3', '85.0', '96.5', '88.0']\n",
      "IoU: ['94.9', '93.0', '43.8', '89.6', '75.0', '74.4', '96.5', '81.4', '93.4', '51.1', '90.5', '59.7', '89.6', '88.9', '90.5', '90.0', '65.0', '88.6', '62.8', '91.0', '79.9']\n",
      "mean IoU: 80.4\n",
      "Epoch: [5] Train  [  0/183]  eta: 0:39:27  lr: 0.000091  loss: 0.5017 (0.5017)  time: 12.9380  data: 0.4147  max mem: 9586\n",
      "Epoch: [5] Train  [ 10/183]  eta: 0:35:56  lr: 0.000091  loss: 0.4687 (0.5452)  time: 12.4637  data: 0.0379  max mem: 9586\n",
      "Epoch: [5] Train  [ 20/183]  eta: 0:33:26  lr: 0.000090  loss: 0.8859 (0.5692)  time: 12.2786  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Train  [ 30/183]  eta: 0:31:26  lr: 0.000090  loss: 0.8072 (0.5670)  time: 12.2559  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Train  [ 40/183]  eta: 0:29:23  lr: 0.000090  loss: 0.7653 (0.5645)  time: 12.3600  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Train  [ 50/183]  eta: 0:27:19  lr: 0.000090  loss: 0.2550 (0.5452)  time: 12.3276  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Train  [ 60/183]  eta: 0:25:16  lr: 0.000090  loss: 0.3001 (0.5501)  time: 12.3241  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [ 70/183]  eta: 0:23:14  lr: 0.000090  loss: 0.1605 (0.5707)  time: 12.3561  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [ 80/183]  eta: 0:21:11  lr: 0.000090  loss: 0.5729 (0.5978)  time: 12.3746  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [ 90/183]  eta: 0:19:07  lr: 0.000090  loss: 0.6296 (0.6048)  time: 12.3577  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [100/183]  eta: 0:17:03  lr: 0.000089  loss: 0.9929 (0.6168)  time: 12.3123  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [110/183]  eta: 0:15:00  lr: 0.000089  loss: 0.9259 (0.6152)  time: 12.3219  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [120/183]  eta: 0:12:57  lr: 0.000089  loss: 0.9291 (0.6188)  time: 12.3820  data: 0.0006  max mem: 9586\n",
      "Epoch: [5] Train  [130/183]  eta: 0:10:54  lr: 0.000089  loss: 1.0838 (0.6129)  time: 12.3608  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [140/183]  eta: 0:08:50  lr: 0.000089  loss: 0.5090 (0.6056)  time: 12.2957  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [150/183]  eta: 0:06:47  lr: 0.000089  loss: 0.1233 (0.6049)  time: 12.3607  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [160/183]  eta: 0:04:43  lr: 0.000089  loss: 0.3247 (0.6073)  time: 12.3819  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Train  [170/183]  eta: 0:02:40  lr: 0.000089  loss: 0.7513 (0.6079)  time: 12.2503  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Train  [180/183]  eta: 0:00:37  lr: 0.000088  loss: 0.4253 (0.6082)  time: 12.2614  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Train Total time: 0:37:37\n",
      "Epoch: [5] Test  [  0/242]  eta: 0:06:08    time: 1.5233  data: 0.4533  max mem: 9586\n",
      "Epoch: [5] Test  [ 10/242]  eta: 0:03:52    time: 1.0033  data: 0.0415  max mem: 9586\n",
      "Epoch: [5] Test  [ 20/242]  eta: 0:03:35    time: 0.9436  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 30/242]  eta: 0:03:31    time: 0.9963  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 40/242]  eta: 0:03:24    time: 1.0579  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 50/242]  eta: 0:03:15    time: 1.0514  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 60/242]  eta: 0:03:08    time: 1.0815  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [ 70/242]  eta: 0:02:58    time: 1.0917  data: 0.0005  max mem: 9586\n",
      "Epoch: [5] Test  [ 80/242]  eta: 0:02:47    time: 1.0362  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [ 90/242]  eta: 0:02:36    time: 0.9844  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [100/242]  eta: 0:02:26    time: 1.0167  data: 0.0002  max mem: 9586\n",
      "Epoch: [5] Test  [110/242]  eta: 0:02:15    time: 1.0354  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [120/242]  eta: 0:02:06    time: 1.0486  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [130/242]  eta: 0:01:55    time: 1.0386  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [140/242]  eta: 0:01:44    time: 0.9877  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [150/242]  eta: 0:01:34    time: 0.9926  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [160/242]  eta: 0:01:24    time: 1.0074  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [170/242]  eta: 0:01:14    time: 1.0573  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [180/242]  eta: 0:01:04    time: 1.1160  data: 0.0004  max mem: 9586\n",
      "Epoch: [5] Test  [190/242]  eta: 0:00:54    time: 1.1199  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [200/242]  eta: 0:00:43    time: 1.0644  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [210/242]  eta: 0:00:33    time: 1.0358  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [220/242]  eta: 0:00:22    time: 1.0454  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [230/242]  eta: 0:00:12    time: 1.0533  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test  [240/242]  eta: 0:00:02    time: 1.0132  data: 0.0003  max mem: 9586\n",
      "Epoch: [5] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['97.0', '96.2', '73.8', '95.4', '84.4', '88.1', '99.0', '91.5', '97.8', '71.8', '95.6', '70.0', '90.9', '95.0', '94.0', '96.8', '80.5', '95.4', '82.4', '96.2', '88.6']\n",
      "IoU: ['94.9', '93.1', '43.9', '89.7', '75.3', '76.1', '96.8', '83.3', '90.8', '49.7', '92.3', '61.7', '86.9', '88.4', '90.6', '90.4', '67.1', '89.4', '62.7', '89.6', '78.6']\n",
      "mean IoU: 80.5\n",
      "Epoch: [6] Train  [  0/183]  eta: 0:40:52  lr: 0.000088  loss: 0.2039 (0.2039)  time: 13.4012  data: 0.4570  max mem: 9586\n",
      "Epoch: [6] Train  [ 10/183]  eta: 0:35:46  lr: 0.000088  loss: 0.8718 (0.8066)  time: 12.4064  data: 0.0418  max mem: 9586\n",
      "Epoch: [6] Train  [ 20/183]  eta: 0:33:34  lr: 0.000088  loss: 0.2042 (0.7120)  time: 12.3100  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [ 30/183]  eta: 0:31:27  lr: 0.000088  loss: 0.7804 (0.6728)  time: 12.3017  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [ 40/183]  eta: 0:29:28  lr: 0.000088  loss: 0.3918 (0.6550)  time: 12.3666  data: 0.0002  max mem: 9586\n",
      "Epoch: [6] Train  [ 50/183]  eta: 0:27:20  lr: 0.000088  loss: 0.3699 (0.6109)  time: 12.3304  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [ 60/183]  eta: 0:25:20  lr: 0.000088  loss: 0.7363 (0.6093)  time: 12.3514  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Train  [ 70/183]  eta: 0:23:16  lr: 0.000087  loss: 1.0203 (0.6195)  time: 12.4091  data: 0.0005  max mem: 9586\n",
      "Epoch: [6] Train  [ 80/183]  eta: 0:21:12  lr: 0.000087  loss: 0.2865 (0.6151)  time: 12.3421  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Train  [ 90/183]  eta: 0:19:07  lr: 0.000087  loss: 0.5454 (0.6252)  time: 12.2990  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [100/183]  eta: 0:17:03  lr: 0.000087  loss: 0.4279 (0.6230)  time: 12.2587  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [110/183]  eta: 0:15:01  lr: 0.000087  loss: 0.3814 (0.6124)  time: 12.3829  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [120/183]  eta: 0:12:57  lr: 0.000087  loss: 0.3790 (0.6039)  time: 12.3634  data: 0.0002  max mem: 9586\n",
      "Epoch: [6] Train  [130/183]  eta: 0:10:54  lr: 0.000087  loss: 0.8294 (0.6006)  time: 12.2971  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [140/183]  eta: 0:08:50  lr: 0.000087  loss: 0.4590 (0.5932)  time: 12.3868  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [150/183]  eta: 0:06:47  lr: 0.000086  loss: 0.2210 (0.5928)  time: 12.4149  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [160/183]  eta: 0:04:44  lr: 0.000086  loss: 0.3772 (0.5849)  time: 12.3629  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [170/183]  eta: 0:02:40  lr: 0.000086  loss: 0.7619 (0.5846)  time: 12.2799  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Train  [180/183]  eta: 0:00:37  lr: 0.000086  loss: 0.8581 (0.5868)  time: 12.2756  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Train Total time: 0:37:38\n",
      "Epoch: [6] Test  [  0/242]  eta: 0:05:54    time: 1.4638  data: 0.3805  max mem: 9586\n",
      "Epoch: [6] Test  [ 10/242]  eta: 0:03:52    time: 1.0012  data: 0.0349  max mem: 9586\n",
      "Epoch: [6] Test  [ 20/242]  eta: 0:03:35    time: 0.9448  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Test  [ 30/242]  eta: 0:03:31    time: 0.9960  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Test  [ 40/242]  eta: 0:03:24    time: 1.0562  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Test  [ 50/242]  eta: 0:03:15    time: 1.0499  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Test  [ 60/242]  eta: 0:03:08    time: 1.0824  data: 0.0002  max mem: 9586\n",
      "Epoch: [6] Test  [ 70/242]  eta: 0:02:58    time: 1.0917  data: 0.0006  max mem: 9586\n",
      "Epoch: [6] Test  [ 80/242]  eta: 0:02:47    time: 1.0343  data: 0.0006  max mem: 9586\n",
      "Epoch: [6] Test  [ 90/242]  eta: 0:02:36    time: 0.9846  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Test  [100/242]  eta: 0:02:26    time: 1.0172  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Test  [110/242]  eta: 0:02:15    time: 1.0341  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Test  [120/242]  eta: 0:02:06    time: 1.0494  data: 0.0006  max mem: 9586\n",
      "Epoch: [6] Test  [130/242]  eta: 0:01:55    time: 1.0387  data: 0.0006  max mem: 9586\n",
      "Epoch: [6] Test  [140/242]  eta: 0:01:44    time: 0.9881  data: 0.0006  max mem: 9586\n",
      "Epoch: [6] Test  [150/242]  eta: 0:01:34    time: 0.9944  data: 0.0005  max mem: 9586\n",
      "Epoch: [6] Test  [160/242]  eta: 0:01:24    time: 1.0067  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Test  [170/242]  eta: 0:01:14    time: 1.0564  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Test  [180/242]  eta: 0:01:04    time: 1.1149  data: 0.0005  max mem: 9586\n",
      "Epoch: [6] Test  [190/242]  eta: 0:00:53    time: 1.1170  data: 0.0006  max mem: 9586\n",
      "Epoch: [6] Test  [200/242]  eta: 0:00:43    time: 1.0634  data: 0.0005  max mem: 9586\n",
      "Epoch: [6] Test  [210/242]  eta: 0:00:33    time: 1.0360  data: 0.0003  max mem: 9586\n",
      "Epoch: [6] Test  [220/242]  eta: 0:00:22    time: 1.0454  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Test  [230/242]  eta: 0:00:12    time: 1.0534  data: 0.0004  max mem: 9586\n",
      "Epoch: [6] Test  [240/242]  eta: 0:00:02    time: 1.0155  data: 0.0006  max mem: 9586\n",
      "Epoch: [6] Test Total time: 0:04:10\n",
      "global correct: 95.5\n",
      "average row correct: ['96.6', '96.7', '79.7', '96.2', '81.4', '90.9', '99.2', '91.8', '98.6', '74.0', '95.3', '69.5', '92.9', '95.0', '94.2', '96.2', '81.9', '96.0', '81.9', '95.7', '89.1']\n",
      "IoU: ['94.7', '94.7', '46.5', '89.7', '74.9', '72.9', '95.5', '83.4', '90.0', '47.9', '91.5', '61.0', '87.9', '90.3', '90.5', '90.7', '64.8', '87.8', '62.5', '90.9', '75.1']\n",
      "mean IoU: 80.2\n",
      "Epoch: [7] Train  [  0/183]  eta: 0:39:58  lr: 0.000086  loss: 0.8636 (0.8636)  time: 13.1050  data: 0.4015  max mem: 9586\n",
      "Epoch: [7] Train  [ 10/183]  eta: 0:36:02  lr: 0.000086  loss: 0.5841 (0.5642)  time: 12.5007  data: 0.0368  max mem: 9586\n",
      "Epoch: [7] Train  [ 20/183]  eta: 0:33:42  lr: 0.000086  loss: 0.6658 (0.5706)  time: 12.3754  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Train  [ 30/183]  eta: 0:31:40  lr: 0.000086  loss: 0.5989 (0.5624)  time: 12.3815  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Train  [ 40/183]  eta: 0:29:35  lr: 0.000086  loss: 0.5882 (0.5604)  time: 12.4285  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Train  [ 50/183]  eta: 0:27:28  lr: 0.000085  loss: 0.7742 (0.5563)  time: 12.3561  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Train  [ 60/183]  eta: 0:25:22  lr: 0.000085  loss: 0.8236 (0.5542)  time: 12.2863  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Train  [ 70/183]  eta: 0:23:18  lr: 0.000085  loss: 0.3517 (0.5601)  time: 12.3100  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [ 80/183]  eta: 0:21:13  lr: 0.000085  loss: 0.1953 (0.5789)  time: 12.3338  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [ 90/183]  eta: 0:19:09  lr: 0.000085  loss: 0.8329 (0.5870)  time: 12.3144  data: 0.0005  max mem: 9586\n",
      "Epoch: [7] Train  [100/183]  eta: 0:17:06  lr: 0.000085  loss: 0.2878 (0.5948)  time: 12.3784  data: 0.0005  max mem: 9586\n",
      "Epoch: [7] Train  [110/183]  eta: 0:15:02  lr: 0.000085  loss: 0.3207 (0.5859)  time: 12.3655  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [120/183]  eta: 0:12:58  lr: 0.000084  loss: 0.5645 (0.5840)  time: 12.3219  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [130/183]  eta: 0:10:55  lr: 0.000084  loss: 1.2499 (0.5842)  time: 12.3914  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [140/183]  eta: 0:08:51  lr: 0.000084  loss: 0.5082 (0.5817)  time: 12.3974  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [150/183]  eta: 0:06:48  lr: 0.000084  loss: 0.7570 (0.5895)  time: 12.3594  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [160/183]  eta: 0:04:44  lr: 0.000084  loss: 0.7115 (0.5952)  time: 12.3330  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [170/183]  eta: 0:02:40  lr: 0.000084  loss: 0.4414 (0.5919)  time: 12.3043  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train  [180/183]  eta: 0:00:37  lr: 0.000084  loss: 0.9541 (0.6026)  time: 12.3423  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Train Total time: 0:37:41\n",
      "Epoch: [7] Test  [  0/242]  eta: 0:06:01    time: 1.4937  data: 0.4077  max mem: 9586\n",
      "Epoch: [7] Test  [ 10/242]  eta: 0:03:52    time: 1.0027  data: 0.0374  max mem: 9586\n",
      "Epoch: [7] Test  [ 20/242]  eta: 0:03:35    time: 0.9438  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [ 30/242]  eta: 0:03:31    time: 0.9967  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Test  [ 40/242]  eta: 0:03:24    time: 1.0580  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [ 50/242]  eta: 0:03:15    time: 1.0511  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [ 60/242]  eta: 0:03:08    time: 1.0842  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [ 70/242]  eta: 0:02:58    time: 1.0949  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [ 80/242]  eta: 0:02:47    time: 1.0378  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [ 90/242]  eta: 0:02:36    time: 0.9858  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [100/242]  eta: 0:02:26    time: 1.0174  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [110/242]  eta: 0:02:15    time: 1.0345  data: 0.0002  max mem: 9586\n",
      "Epoch: [7] Test  [120/242]  eta: 0:02:06    time: 1.0481  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [130/242]  eta: 0:01:55    time: 1.0397  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [140/242]  eta: 0:01:44    time: 0.9918  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [150/242]  eta: 0:01:34    time: 0.9967  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [160/242]  eta: 0:01:24    time: 1.0082  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [170/242]  eta: 0:01:14    time: 1.0590  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [180/242]  eta: 0:01:04    time: 1.1200  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [190/242]  eta: 0:00:54    time: 1.1215  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Test  [200/242]  eta: 0:00:43    time: 1.0667  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Test  [210/242]  eta: 0:00:33    time: 1.0408  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [220/242]  eta: 0:00:22    time: 1.0477  data: 0.0003  max mem: 9586\n",
      "Epoch: [7] Test  [230/242]  eta: 0:00:12    time: 1.0541  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Test  [240/242]  eta: 0:00:02    time: 1.0155  data: 0.0004  max mem: 9586\n",
      "Epoch: [7] Test Total time: 0:04:10\n",
      "global correct: 95.8\n",
      "average row correct: ['97.4', '96.6', '71.2', '94.7', '86.4', '89.7', '98.9', '91.3', '95.5', '68.3', '94.9', '69.0', '93.2', '95.6', '92.6', '96.5', '77.9', '95.3', '82.1', '95.1', '88.5']\n",
      "IoU: ['95.2', '92.3', '48.1', '88.8', '76.3', '75.0', '96.5', '84.4', '92.8', '51.0', '92.3', '62.0', '88.5', '87.8', '89.5', '90.2', '67.3', '89.4', '62.8', '89.7', '78.4']\n",
      "mean IoU: 80.9\n",
      "Epoch: [8] Train  [  0/183]  eta: 0:37:59  lr: 0.000084  loss: 0.7502 (0.7502)  time: 12.4581  data: 0.4827  max mem: 9586\n",
      "Epoch: [8] Train  [ 10/183]  eta: 0:35:31  lr: 0.000084  loss: 1.1429 (0.7015)  time: 12.3222  data: 0.0442  max mem: 9586\n",
      "Epoch: [8] Train  [ 20/183]  eta: 0:33:28  lr: 0.000083  loss: 0.4536 (0.5880)  time: 12.3166  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Train  [ 30/183]  eta: 0:31:25  lr: 0.000083  loss: 0.7178 (0.5807)  time: 12.3278  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Train  [ 40/183]  eta: 0:29:26  lr: 0.000083  loss: 0.9664 (0.6078)  time: 12.3776  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Train  [ 50/183]  eta: 0:27:25  lr: 0.000083  loss: 0.5660 (0.5689)  time: 12.4422  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Train  [ 60/183]  eta: 0:25:18  lr: 0.000083  loss: 0.3609 (0.5825)  time: 12.3245  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Train  [ 70/183]  eta: 0:23:13  lr: 0.000083  loss: 0.3443 (0.5691)  time: 12.2233  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Train  [ 80/183]  eta: 0:21:10  lr: 0.000083  loss: 0.7515 (0.5680)  time: 12.3003  data: 0.0005  max mem: 9586\n",
      "Epoch: [8] Train  [ 90/183]  eta: 0:19:06  lr: 0.000083  loss: 0.6348 (0.5636)  time: 12.3241  data: 0.0006  max mem: 9586\n",
      "Epoch: [8] Train  [100/183]  eta: 0:17:04  lr: 0.000082  loss: 0.6928 (0.5711)  time: 12.3667  data: 0.0007  max mem: 9586\n",
      "Epoch: [8] Train  [110/183]  eta: 0:15:00  lr: 0.000082  loss: 0.6743 (0.5595)  time: 12.4009  data: 0.0008  max mem: 9586\n",
      "Epoch: [8] Train  [120/183]  eta: 0:12:57  lr: 0.000082  loss: 0.8477 (0.5646)  time: 12.3618  data: 0.0009  max mem: 9586\n",
      "Epoch: [8] Train  [130/183]  eta: 0:10:54  lr: 0.000082  loss: 0.3937 (0.5683)  time: 12.4045  data: 0.0006  max mem: 9586\n",
      "Epoch: [8] Train  [140/183]  eta: 0:08:51  lr: 0.000082  loss: 0.2332 (0.5747)  time: 12.4402  data: 0.0006  max mem: 9586\n",
      "Epoch: [8] Train  [150/183]  eta: 0:06:47  lr: 0.000082  loss: 0.7159 (0.5786)  time: 12.3765  data: 0.0006  max mem: 9586\n",
      "Epoch: [8] Train  [160/183]  eta: 0:04:44  lr: 0.000082  loss: 0.2303 (0.5819)  time: 12.3617  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Train  [170/183]  eta: 0:02:40  lr: 0.000081  loss: 0.5704 (0.5812)  time: 12.3257  data: 0.0006  max mem: 9586\n",
      "Epoch: [8] Train  [180/183]  eta: 0:00:37  lr: 0.000081  loss: 1.7618 (0.5864)  time: 12.3127  data: 0.0006  max mem: 9586\n",
      "Epoch: [8] Train Total time: 0:37:40\n",
      "Epoch: [8] Test  [  0/242]  eta: 0:05:50    time: 1.4502  data: 0.3778  max mem: 9586\n",
      "Epoch: [8] Test  [ 10/242]  eta: 0:03:52    time: 1.0003  data: 0.0347  max mem: 9586\n",
      "Epoch: [8] Test  [ 20/242]  eta: 0:03:35    time: 0.9462  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [ 30/242]  eta: 0:03:31    time: 0.9957  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [ 40/242]  eta: 0:03:24    time: 1.0555  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Test  [ 50/242]  eta: 0:03:15    time: 1.0504  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Test  [ 60/242]  eta: 0:03:08    time: 1.0823  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Test  [ 70/242]  eta: 0:02:58    time: 1.0940  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [ 80/242]  eta: 0:02:47    time: 1.0380  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [ 90/242]  eta: 0:02:36    time: 0.9857  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [100/242]  eta: 0:02:26    time: 1.0180  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [110/242]  eta: 0:02:15    time: 1.0370  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [120/242]  eta: 0:02:06    time: 1.0495  data: 0.0005  max mem: 9586\n",
      "Epoch: [8] Test  [130/242]  eta: 0:01:55    time: 1.0386  data: 0.0005  max mem: 9586\n",
      "Epoch: [8] Test  [140/242]  eta: 0:01:44    time: 0.9896  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [150/242]  eta: 0:01:34    time: 0.9960  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [160/242]  eta: 0:01:24    time: 1.0106  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Test  [170/242]  eta: 0:01:14    time: 1.0583  data: 0.0005  max mem: 9586\n",
      "Epoch: [8] Test  [180/242]  eta: 0:01:04    time: 1.1165  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Test  [190/242]  eta: 0:00:54    time: 1.1209  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [200/242]  eta: 0:00:43    time: 1.0674  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [210/242]  eta: 0:00:33    time: 1.0402  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [220/242]  eta: 0:00:22    time: 1.0479  data: 0.0004  max mem: 9586\n",
      "Epoch: [8] Test  [230/242]  eta: 0:00:12    time: 1.0553  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test  [240/242]  eta: 0:00:02    time: 1.0174  data: 0.0003  max mem: 9586\n",
      "Epoch: [8] Test Total time: 0:04:10\n",
      "global correct: 95.7\n",
      "average row correct: ['96.8', '96.8', '78.5', '93.9', '85.8', '89.6', '99.2', '91.8', '97.9', '74.7', '95.8', '70.9', '95.2', '96.0', '93.1', '96.0', '77.8', '96.8', '84.4', '96.7', '89.8']\n",
      "IoU: ['95.0', '94.2', '50.5', '89.3', '74.3', '75.8', '96.5', '84.3', '92.8', '49.1', '91.8', '62.4', '88.8', '89.6', '89.7', '90.8', '67.2', '83.0', '62.8', '90.1', '78.6']\n",
      "mean IoU: 80.8\n",
      "Epoch: [9] Train  [  0/183]  eta: 0:38:48  lr: 0.000081  loss: 0.5620 (0.5620)  time: 12.7244  data: 0.6210  max mem: 9586\n",
      "Epoch: [9] Train  [ 10/183]  eta: 0:36:16  lr: 0.000081  loss: 0.7533 (0.5695)  time: 12.5789  data: 0.0568  max mem: 9586\n",
      "Epoch: [9] Train  [ 20/183]  eta: 0:33:44  lr: 0.000081  loss: 0.6001 (0.6582)  time: 12.4070  data: 0.0004  max mem: 9586\n",
      "Epoch: [9] Train  [ 30/183]  eta: 0:31:30  lr: 0.000081  loss: 0.4753 (0.6012)  time: 12.2356  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [ 40/183]  eta: 0:29:22  lr: 0.000081  loss: 0.5199 (0.6463)  time: 12.2215  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [ 50/183]  eta: 0:27:21  lr: 0.000081  loss: 0.8959 (0.6640)  time: 12.3128  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [ 60/183]  eta: 0:25:19  lr: 0.000081  loss: 0.3680 (0.6434)  time: 12.4036  data: 0.0002  max mem: 9586\n",
      "Epoch: [9] Train  [ 70/183]  eta: 0:23:15  lr: 0.000080  loss: 0.7531 (0.6334)  time: 12.3649  data: 0.0002  max mem: 9586\n",
      "Epoch: [9] Train  [ 80/183]  eta: 0:21:10  lr: 0.000080  loss: 0.3896 (0.6115)  time: 12.2693  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [ 90/183]  eta: 0:19:06  lr: 0.000080  loss: 0.2423 (0.5988)  time: 12.2706  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [100/183]  eta: 0:17:04  lr: 0.000080  loss: 0.3975 (0.5909)  time: 12.3745  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [110/183]  eta: 0:15:00  lr: 0.000080  loss: 0.5218 (0.5954)  time: 12.3396  data: 0.0002  max mem: 9586\n",
      "Epoch: [9] Train  [120/183]  eta: 0:12:57  lr: 0.000080  loss: 0.5692 (0.6127)  time: 12.3548  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [130/183]  eta: 0:10:53  lr: 0.000080  loss: 0.5764 (0.6105)  time: 12.3755  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [140/183]  eta: 0:08:50  lr: 0.000080  loss: 0.3952 (0.6048)  time: 12.3581  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [150/183]  eta: 0:06:47  lr: 0.000079  loss: 1.0899 (0.6123)  time: 12.3653  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Train  [160/183]  eta: 0:04:43  lr: 0.000079  loss: 0.8188 (0.6105)  time: 12.3235  data: 0.0002  max mem: 9586\n",
      "Epoch: [9] Train  [170/183]  eta: 0:02:40  lr: 0.000079  loss: 0.7620 (0.6152)  time: 12.3052  data: 0.0006  max mem: 9586\n",
      "Epoch: [9] Train  [180/183]  eta: 0:00:37  lr: 0.000079  loss: 0.6648 (0.6247)  time: 12.3590  data: 0.0008  max mem: 9586\n",
      "Epoch: [9] Train Total time: 0:37:39\n",
      "Epoch: [9] Test  [  0/242]  eta: 0:05:58    time: 1.4834  data: 0.4105  max mem: 9586\n",
      "Epoch: [9] Test  [ 10/242]  eta: 0:03:53    time: 1.0047  data: 0.0376  max mem: 9586\n",
      "Epoch: [9] Test  [ 20/242]  eta: 0:03:35    time: 0.9453  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [ 30/242]  eta: 0:03:31    time: 0.9949  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [ 40/242]  eta: 0:03:24    time: 1.0568  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [ 50/242]  eta: 0:03:15    time: 1.0519  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [ 60/242]  eta: 0:03:08    time: 1.0855  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [ 70/242]  eta: 0:02:59    time: 1.0957  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [ 80/242]  eta: 0:02:47    time: 1.0374  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [ 90/242]  eta: 0:02:36    time: 0.9874  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [100/242]  eta: 0:02:26    time: 1.0200  data: 0.0004  max mem: 9586\n",
      "Epoch: [9] Test  [110/242]  eta: 0:02:16    time: 1.0371  data: 0.0005  max mem: 9586\n",
      "Epoch: [9] Test  [120/242]  eta: 0:02:06    time: 1.0501  data: 0.0004  max mem: 9586\n",
      "Epoch: [9] Test  [130/242]  eta: 0:01:55    time: 1.0377  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [140/242]  eta: 0:01:45    time: 0.9886  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [150/242]  eta: 0:01:34    time: 0.9969  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [160/242]  eta: 0:01:24    time: 1.0101  data: 0.0002  max mem: 9586\n",
      "Epoch: [9] Test  [170/242]  eta: 0:01:14    time: 1.0579  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [180/242]  eta: 0:01:04    time: 1.1169  data: 0.0004  max mem: 9586\n",
      "Epoch: [9] Test  [190/242]  eta: 0:00:54    time: 1.1209  data: 0.0004  max mem: 9586\n",
      "Epoch: [9] Test  [200/242]  eta: 0:00:43    time: 1.0678  data: 0.0004  max mem: 9586\n",
      "Epoch: [9] Test  [210/242]  eta: 0:00:33    time: 1.0406  data: 0.0005  max mem: 9586\n",
      "Epoch: [9] Test  [220/242]  eta: 0:00:22    time: 1.0473  data: 0.0004  max mem: 9586\n",
      "Epoch: [9] Test  [230/242]  eta: 0:00:12    time: 1.0545  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test  [240/242]  eta: 0:00:02    time: 1.0171  data: 0.0003  max mem: 9586\n",
      "Epoch: [9] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['96.8', '97.0', '71.3', '94.4', '85.8', '89.2', '99.2', '93.2', '97.6', '73.1', '96.6', '73.9', '93.6', '92.4', '93.6', '96.1', '77.1', '96.0', '85.0', '96.4', '90.2']\n",
      "IoU: ['94.9', '94.0', '50.4', '90.1', '75.7', '76.8', '96.4', '83.6', '92.9', '47.4', '90.2', '63.1', '89.3', '86.9', '90.0', '90.7', '67.0', '88.8', '61.2', '89.4', '74.8']\n",
      "mean IoU: 80.7\n",
      "Epoch: [10] Train  [  0/183]  eta: 0:39:05  lr: 0.000079  loss: 0.5386 (0.5386)  time: 12.8189  data: 0.3666  max mem: 9586\n",
      "Epoch: [10] Train  [ 10/183]  eta: 0:35:33  lr: 0.000079  loss: 0.5713 (0.5941)  time: 12.3319  data: 0.0336  max mem: 9586\n",
      "Epoch: [10] Train  [ 20/183]  eta: 0:33:38  lr: 0.000079  loss: 0.5388 (0.5648)  time: 12.3591  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [ 30/183]  eta: 0:31:32  lr: 0.000079  loss: 0.9633 (0.5510)  time: 12.3871  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [ 40/183]  eta: 0:29:26  lr: 0.000078  loss: 0.5061 (0.5860)  time: 12.3188  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [ 50/183]  eta: 0:27:24  lr: 0.000078  loss: 0.5347 (0.5869)  time: 12.3616  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [ 60/183]  eta: 0:25:19  lr: 0.000078  loss: 0.3713 (0.5849)  time: 12.3610  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [ 70/183]  eta: 0:23:14  lr: 0.000078  loss: 0.0973 (0.5802)  time: 12.2701  data: 0.0002  max mem: 9586\n",
      "Epoch: [10] Train  [ 80/183]  eta: 0:21:11  lr: 0.000078  loss: 0.6226 (0.5770)  time: 12.3268  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [ 90/183]  eta: 0:19:07  lr: 0.000078  loss: 0.5350 (0.5723)  time: 12.3357  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [100/183]  eta: 0:17:03  lr: 0.000078  loss: 0.3210 (0.5789)  time: 12.2883  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [110/183]  eta: 0:15:00  lr: 0.000078  loss: 0.3475 (0.5841)  time: 12.3279  data: 0.0002  max mem: 9586\n",
      "Epoch: [10] Train  [120/183]  eta: 0:12:57  lr: 0.000077  loss: 1.1715 (0.5860)  time: 12.3371  data: 0.0002  max mem: 9586\n",
      "Epoch: [10] Train  [130/183]  eta: 0:10:54  lr: 0.000077  loss: 0.4630 (0.5828)  time: 12.3714  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [140/183]  eta: 0:08:50  lr: 0.000077  loss: 0.3596 (0.5893)  time: 12.3966  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [150/183]  eta: 0:06:47  lr: 0.000077  loss: 0.4900 (0.5832)  time: 12.3846  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train  [160/183]  eta: 0:04:43  lr: 0.000077  loss: 0.9330 (0.5796)  time: 12.3583  data: 0.0004  max mem: 9586\n",
      "Epoch: [10] Train  [170/183]  eta: 0:02:40  lr: 0.000077  loss: 1.0216 (0.5836)  time: 12.3578  data: 0.0004  max mem: 9586\n",
      "Epoch: [10] Train  [180/183]  eta: 0:00:37  lr: 0.000077  loss: 0.7037 (0.5894)  time: 12.3491  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Train Total time: 0:37:39\n",
      "Epoch: [10] Test  [  0/242]  eta: 0:06:08    time: 1.5217  data: 0.4378  max mem: 9586\n",
      "Epoch: [10] Test  [ 10/242]  eta: 0:03:53    time: 1.0068  data: 0.0401  max mem: 9586\n",
      "Epoch: [10] Test  [ 20/242]  eta: 0:03:36    time: 0.9456  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [ 30/242]  eta: 0:03:32    time: 0.9973  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [ 40/242]  eta: 0:03:24    time: 1.0579  data: 0.0004  max mem: 9586\n",
      "Epoch: [10] Test  [ 50/242]  eta: 0:03:15    time: 1.0514  data: 0.0004  max mem: 9586\n",
      "Epoch: [10] Test  [ 60/242]  eta: 0:03:08    time: 1.0855  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [ 70/242]  eta: 0:02:59    time: 1.0958  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [ 80/242]  eta: 0:02:48    time: 1.0374  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [ 90/242]  eta: 0:02:36    time: 0.9891  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [100/242]  eta: 0:02:26    time: 1.0228  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [110/242]  eta: 0:02:16    time: 1.0383  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [120/242]  eta: 0:02:06    time: 1.0513  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [130/242]  eta: 0:01:55    time: 1.0393  data: 0.0005  max mem: 9586\n",
      "Epoch: [10] Test  [140/242]  eta: 0:01:45    time: 0.9885  data: 0.0004  max mem: 9586\n",
      "Epoch: [10] Test  [150/242]  eta: 0:01:34    time: 0.9944  data: 0.0005  max mem: 9586\n",
      "Epoch: [10] Test  [160/242]  eta: 0:01:24    time: 1.0085  data: 0.0006  max mem: 9586\n",
      "Epoch: [10] Test  [170/242]  eta: 0:01:14    time: 1.0602  data: 0.0004  max mem: 9586\n",
      "Epoch: [10] Test  [180/242]  eta: 0:01:04    time: 1.1196  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [190/242]  eta: 0:00:54    time: 1.1211  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [200/242]  eta: 0:00:43    time: 1.0664  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [210/242]  eta: 0:00:33    time: 1.0408  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [220/242]  eta: 0:00:22    time: 1.0482  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [230/242]  eta: 0:00:12    time: 1.0550  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test  [240/242]  eta: 0:00:02    time: 1.0178  data: 0.0003  max mem: 9586\n",
      "Epoch: [10] Test Total time: 0:04:11\n",
      "global correct: 95.7\n",
      "average row correct: ['96.9', '97.1', '75.7', '94.5', '86.4', '92.0', '99.2', '92.5', '98.2', '70.6', '96.6', '71.7', '92.4', '96.0', '94.8', '96.6', '78.6', '95.4', '83.7', '95.9', '90.5']\n",
      "IoU: ['95.1', '93.7', '53.0', '89.3', '76.6', '74.0', '96.2', '83.1', '91.7', '51.2', '93.0', '63.4', '87.7', '88.6', '90.2', '90.3', '67.7', '89.8', '63.3', '90.1', '74.4']\n",
      "mean IoU: 81.1\n",
      "Epoch: [11] Train  [  0/183]  eta: 0:38:32  lr: 0.000077  loss: 0.2290 (0.2290)  time: 12.6341  data: 0.3957  max mem: 9586\n",
      "Epoch: [11] Train  [ 10/183]  eta: 0:35:44  lr: 0.000076  loss: 0.2912 (0.5267)  time: 12.3979  data: 0.0363  max mem: 9586\n",
      "Epoch: [11] Train  [ 20/183]  eta: 0:33:36  lr: 0.000076  loss: 0.5909 (0.6171)  time: 12.3555  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [ 30/183]  eta: 0:31:39  lr: 0.000076  loss: 0.7373 (0.5919)  time: 12.4201  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [ 40/183]  eta: 0:29:34  lr: 0.000076  loss: 0.5084 (0.6117)  time: 12.4505  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [ 50/183]  eta: 0:27:27  lr: 0.000076  loss: 0.5480 (0.6014)  time: 12.3571  data: 0.0002  max mem: 9586\n",
      "Epoch: [11] Train  [ 60/183]  eta: 0:25:24  lr: 0.000076  loss: 0.3610 (0.5829)  time: 12.3586  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [ 70/183]  eta: 0:23:22  lr: 0.000076  loss: 0.4573 (0.5831)  time: 12.4742  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [ 80/183]  eta: 0:21:17  lr: 0.000076  loss: 0.3910 (0.5650)  time: 12.4486  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [ 90/183]  eta: 0:19:13  lr: 0.000075  loss: 0.8916 (0.5604)  time: 12.3464  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [100/183]  eta: 0:17:09  lr: 0.000075  loss: 0.6678 (0.5746)  time: 12.3826  data: 0.0004  max mem: 9586\n",
      "Epoch: [11] Train  [110/183]  eta: 0:15:05  lr: 0.000075  loss: 0.4395 (0.5637)  time: 12.4206  data: 0.0004  max mem: 9586\n",
      "Epoch: [11] Train  [120/183]  eta: 0:13:01  lr: 0.000075  loss: 0.1519 (0.5556)  time: 12.3783  data: 0.0002  max mem: 9586\n",
      "Epoch: [11] Train  [130/183]  eta: 0:10:57  lr: 0.000075  loss: 0.3506 (0.5490)  time: 12.3985  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [140/183]  eta: 0:08:52  lr: 0.000075  loss: 0.1554 (0.5460)  time: 12.3584  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [150/183]  eta: 0:06:48  lr: 0.000075  loss: 0.5286 (0.5385)  time: 12.2764  data: 0.0002  max mem: 9586\n",
      "Epoch: [11] Train  [160/183]  eta: 0:04:44  lr: 0.000075  loss: 0.2606 (0.5403)  time: 12.3781  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [170/183]  eta: 0:02:41  lr: 0.000074  loss: 0.7571 (0.5410)  time: 12.3864  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Train  [180/183]  eta: 0:00:37  lr: 0.000074  loss: 0.5521 (0.5474)  time: 12.3533  data: 0.0002  max mem: 9586\n",
      "Epoch: [11] Train Total time: 0:37:46\n",
      "Epoch: [11] Test  [  0/242]  eta: 0:06:01    time: 1.4943  data: 0.4166  max mem: 9586\n",
      "Epoch: [11] Test  [ 10/242]  eta: 0:03:53    time: 1.0046  data: 0.0381  max mem: 9586\n",
      "Epoch: [11] Test  [ 20/242]  eta: 0:03:35    time: 0.9466  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [ 30/242]  eta: 0:03:32    time: 0.9979  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [ 40/242]  eta: 0:03:24    time: 1.0578  data: 0.0002  max mem: 9586\n",
      "Epoch: [11] Test  [ 50/242]  eta: 0:03:15    time: 1.0523  data: 0.0002  max mem: 9586\n",
      "Epoch: [11] Test  [ 60/242]  eta: 0:03:08    time: 1.0849  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [ 70/242]  eta: 0:02:59    time: 1.0947  data: 0.0004  max mem: 9586\n",
      "Epoch: [11] Test  [ 80/242]  eta: 0:02:48    time: 1.0372  data: 0.0004  max mem: 9586\n",
      "Epoch: [11] Test  [ 90/242]  eta: 0:02:36    time: 0.9861  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [100/242]  eta: 0:02:26    time: 1.0188  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [110/242]  eta: 0:02:16    time: 1.0364  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [120/242]  eta: 0:02:06    time: 1.0519  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [130/242]  eta: 0:01:55    time: 1.0421  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [140/242]  eta: 0:01:45    time: 0.9911  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [150/242]  eta: 0:01:34    time: 0.9973  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [160/242]  eta: 0:01:24    time: 1.0108  data: 0.0004  max mem: 9586\n",
      "Epoch: [11] Test  [170/242]  eta: 0:01:14    time: 1.0611  data: 0.0005  max mem: 9586\n",
      "Epoch: [11] Test  [180/242]  eta: 0:01:04    time: 1.1215  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [190/242]  eta: 0:00:54    time: 1.1256  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [200/242]  eta: 0:00:43    time: 1.0705  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [210/242]  eta: 0:00:33    time: 1.0405  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [220/242]  eta: 0:00:22    time: 1.0472  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [230/242]  eta: 0:00:12    time: 1.0557  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test  [240/242]  eta: 0:00:02    time: 1.0180  data: 0.0003  max mem: 9586\n",
      "Epoch: [11] Test Total time: 0:04:11\n",
      "global correct: 95.8\n",
      "average row correct: ['97.1', '97.0', '78.8', '94.5', '83.9', '89.7', '99.1', '92.7', '97.7', '70.7', '96.3', '73.4', '95.3', '93.5', '93.9', '95.7', '79.6', '96.2', '81.7', '96.3', '89.8']\n",
      "IoU: ['95.2', '94.8', '57.2', '90.5', '74.9', '75.5', '96.4', '84.9', '93.7', '50.0', '90.4', '63.8', '88.4', '87.1', '89.7', '90.6', '68.5', '87.6', '61.6', '90.7', '77.9']\n",
      "mean IoU: 81.4\n",
      "Epoch: [12] Train  [  0/183]  eta: 0:38:14  lr: 0.000074  loss: 0.2895 (0.2895)  time: 12.5386  data: 0.3753  max mem: 9586\n",
      "Epoch: [12] Train  [ 10/183]  eta: 0:36:05  lr: 0.000074  loss: 0.5229 (0.3775)  time: 12.5150  data: 0.0343  max mem: 9586\n",
      "Epoch: [12] Train  [ 20/183]  eta: 0:33:51  lr: 0.000074  loss: 0.4878 (0.4557)  time: 12.4608  data: 0.0002  max mem: 9586\n",
      "Epoch: [12] Train  [ 30/183]  eta: 0:31:40  lr: 0.000074  loss: 0.6930 (0.4556)  time: 12.3748  data: 0.0002  max mem: 9586\n",
      "Epoch: [12] Train  [ 40/183]  eta: 0:29:32  lr: 0.000074  loss: 0.0603 (0.4373)  time: 12.3173  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [ 50/183]  eta: 0:27:26  lr: 0.000074  loss: 0.4767 (0.4462)  time: 12.3151  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [ 60/183]  eta: 0:25:22  lr: 0.000073  loss: 0.9947 (0.4703)  time: 12.3602  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [ 70/183]  eta: 0:23:19  lr: 0.000073  loss: 0.3606 (0.4740)  time: 12.3915  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [ 80/183]  eta: 0:21:14  lr: 0.000073  loss: 0.6721 (0.4846)  time: 12.3299  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [ 90/183]  eta: 0:19:10  lr: 0.000073  loss: 0.3458 (0.4837)  time: 12.3120  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [100/183]  eta: 0:17:07  lr: 0.000073  loss: 0.8425 (0.5043)  time: 12.4281  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [110/183]  eta: 0:15:04  lr: 0.000073  loss: 0.4462 (0.5136)  time: 12.4529  data: 0.0002  max mem: 9586\n",
      "Epoch: [12] Train  [120/183]  eta: 0:13:00  lr: 0.000073  loss: 1.0456 (0.5234)  time: 12.4438  data: 0.0002  max mem: 9586\n",
      "Epoch: [12] Train  [130/183]  eta: 0:10:55  lr: 0.000073  loss: 0.5409 (0.5287)  time: 12.3308  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [140/183]  eta: 0:08:52  lr: 0.000072  loss: 0.5748 (0.5252)  time: 12.3265  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [150/183]  eta: 0:06:48  lr: 0.000072  loss: 0.3675 (0.5179)  time: 12.3967  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [160/183]  eta: 0:04:44  lr: 0.000072  loss: 0.5545 (0.5222)  time: 12.3859  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [170/183]  eta: 0:02:40  lr: 0.000072  loss: 0.4642 (0.5236)  time: 12.3674  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Train  [180/183]  eta: 0:00:37  lr: 0.000072  loss: 0.6885 (0.5218)  time: 12.3472  data: 0.0002  max mem: 9586\n",
      "Epoch: [12] Train Total time: 0:37:45\n",
      "Epoch: [12] Test  [  0/242]  eta: 0:06:07    time: 1.5202  data: 0.4450  max mem: 9586\n",
      "Epoch: [12] Test  [ 10/242]  eta: 0:03:53    time: 1.0066  data: 0.0407  max mem: 9586\n",
      "Epoch: [12] Test  [ 20/242]  eta: 0:03:36    time: 0.9463  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [ 30/242]  eta: 0:03:32    time: 0.9993  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [ 40/242]  eta: 0:03:25    time: 1.0590  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [ 50/242]  eta: 0:03:16    time: 1.0523  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [ 60/242]  eta: 0:03:08    time: 1.0833  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [ 70/242]  eta: 0:02:59    time: 1.0921  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [ 80/242]  eta: 0:02:48    time: 1.0366  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [ 90/242]  eta: 0:02:36    time: 0.9864  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [100/242]  eta: 0:02:26    time: 1.0194  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [110/242]  eta: 0:02:16    time: 1.0361  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [120/242]  eta: 0:02:06    time: 1.0495  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [130/242]  eta: 0:01:55    time: 1.0389  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [140/242]  eta: 0:01:45    time: 0.9886  data: 0.0002  max mem: 9586\n",
      "Epoch: [12] Test  [150/242]  eta: 0:01:34    time: 0.9960  data: 0.0002  max mem: 9586\n",
      "Epoch: [12] Test  [160/242]  eta: 0:01:24    time: 1.0102  data: 0.0002  max mem: 9586\n",
      "Epoch: [12] Test  [170/242]  eta: 0:01:14    time: 1.0597  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [180/242]  eta: 0:01:04    time: 1.1176  data: 0.0004  max mem: 9586\n",
      "Epoch: [12] Test  [190/242]  eta: 0:00:54    time: 1.1207  data: 0.0005  max mem: 9586\n",
      "Epoch: [12] Test  [200/242]  eta: 0:00:43    time: 1.0667  data: 0.0004  max mem: 9586\n",
      "Epoch: [12] Test  [210/242]  eta: 0:00:33    time: 1.0386  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [220/242]  eta: 0:00:22    time: 1.0464  data: 0.0004  max mem: 9586\n",
      "Epoch: [12] Test  [230/242]  eta: 0:00:12    time: 1.0550  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test  [240/242]  eta: 0:00:02    time: 1.0187  data: 0.0003  max mem: 9586\n",
      "Epoch: [12] Test Total time: 0:04:10\n",
      "global correct: 95.8\n",
      "average row correct: ['97.2', '96.4', '73.2', '94.2', '85.7', '90.5', '99.1', '90.6', '98.0', '74.9', '95.7', '69.3', '94.3', '96.0', '93.1', '95.7', '78.2', '96.3', '79.6', '95.8', '90.6']\n",
      "IoU: ['95.2', '94.4', '56.6', '90.3', '74.2', '75.6', '96.0', '84.6', '92.9', '47.6', '92.1', '62.5', '88.6', '89.2', '89.5', '90.7', '67.9', '87.8', '60.8', '90.7', '77.0']\n",
      "mean IoU: 81.2\n",
      "Epoch: [13] Train  [  0/183]  eta: 0:39:17  lr: 0.000072  loss: 0.6076 (0.6076)  time: 12.8833  data: 0.3976  max mem: 9586\n",
      "Epoch: [13] Train  [ 10/183]  eta: 0:36:10  lr: 0.000072  loss: 0.8003 (0.5498)  time: 12.5491  data: 0.0365  max mem: 9586\n",
      "Epoch: [13] Train  [ 20/183]  eta: 0:33:45  lr: 0.000072  loss: 0.4097 (0.5159)  time: 12.4045  data: 0.0005  max mem: 9586\n",
      "Epoch: [13] Train  [ 30/183]  eta: 0:31:40  lr: 0.000071  loss: 0.5254 (0.5388)  time: 12.3548  data: 0.0005  max mem: 9586\n",
      "Epoch: [13] Train  [ 40/183]  eta: 0:29:35  lr: 0.000071  loss: 0.5295 (0.5535)  time: 12.4095  data: 0.0002  max mem: 9586\n",
      "Epoch: [13] Train  [ 50/183]  eta: 0:27:33  lr: 0.000071  loss: 0.8356 (0.5577)  time: 12.4428  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [ 60/183]  eta: 0:25:30  lr: 0.000071  loss: 0.5621 (0.5415)  time: 12.4955  data: 0.0004  max mem: 9586\n",
      "Epoch: [13] Train  [ 70/183]  eta: 0:23:26  lr: 0.000071  loss: 0.5945 (0.5315)  time: 12.4997  data: 0.0004  max mem: 9586\n",
      "Epoch: [13] Train  [ 80/183]  eta: 0:21:21  lr: 0.000071  loss: 0.3979 (0.5276)  time: 12.4535  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [ 90/183]  eta: 0:19:16  lr: 0.000071  loss: 0.8735 (0.5427)  time: 12.3916  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [100/183]  eta: 0:17:12  lr: 0.000071  loss: 0.6144 (0.5401)  time: 12.4290  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [110/183]  eta: 0:15:07  lr: 0.000070  loss: 0.7586 (0.5417)  time: 12.4349  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [120/183]  eta: 0:13:03  lr: 0.000070  loss: 0.5443 (0.5334)  time: 12.3901  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [130/183]  eta: 0:10:58  lr: 0.000070  loss: 1.0213 (0.5450)  time: 12.4144  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [140/183]  eta: 0:08:54  lr: 0.000070  loss: 0.6529 (0.5440)  time: 12.4006  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [150/183]  eta: 0:06:50  lr: 0.000070  loss: 0.6569 (0.5418)  time: 12.4724  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [160/183]  eta: 0:04:45  lr: 0.000070  loss: 1.1616 (0.5409)  time: 12.4349  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [170/183]  eta: 0:02:41  lr: 0.000070  loss: 0.5030 (0.5332)  time: 12.3219  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train  [180/183]  eta: 0:00:37  lr: 0.000069  loss: 0.1510 (0.5316)  time: 12.3312  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Train Total time: 0:37:52\n",
      "Epoch: [13] Test  [  0/242]  eta: 0:05:54    time: 1.4657  data: 0.3880  max mem: 9586\n",
      "Epoch: [13] Test  [ 10/242]  eta: 0:03:52    time: 1.0023  data: 0.0356  max mem: 9586\n",
      "Epoch: [13] Test  [ 20/242]  eta: 0:03:35    time: 0.9475  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [ 30/242]  eta: 0:03:32    time: 0.9988  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [ 40/242]  eta: 0:03:24    time: 1.0582  data: 0.0002  max mem: 9586\n",
      "Epoch: [13] Test  [ 50/242]  eta: 0:03:15    time: 1.0520  data: 0.0002  max mem: 9586\n",
      "Epoch: [13] Test  [ 60/242]  eta: 0:03:08    time: 1.0872  data: 0.0002  max mem: 9586\n",
      "Epoch: [13] Test  [ 70/242]  eta: 0:02:59    time: 1.0972  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [ 80/242]  eta: 0:02:48    time: 1.0384  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [ 90/242]  eta: 0:02:36    time: 0.9870  data: 0.0002  max mem: 9586\n",
      "Epoch: [13] Test  [100/242]  eta: 0:02:26    time: 1.0191  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [110/242]  eta: 0:02:16    time: 1.0381  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [120/242]  eta: 0:02:06    time: 1.0528  data: 0.0002  max mem: 9586\n",
      "Epoch: [13] Test  [130/242]  eta: 0:01:55    time: 1.0432  data: 0.0002  max mem: 9586\n",
      "Epoch: [13] Test  [140/242]  eta: 0:01:45    time: 0.9923  data: 0.0002  max mem: 9586\n",
      "Epoch: [13] Test  [150/242]  eta: 0:01:34    time: 0.9977  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [160/242]  eta: 0:01:24    time: 1.0121  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [170/242]  eta: 0:01:14    time: 1.0603  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [180/242]  eta: 0:01:04    time: 1.1210  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [190/242]  eta: 0:00:54    time: 1.1266  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [200/242]  eta: 0:00:43    time: 1.0701  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [210/242]  eta: 0:00:33    time: 1.0429  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [220/242]  eta: 0:00:22    time: 1.0496  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [230/242]  eta: 0:00:12    time: 1.0557  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test  [240/242]  eta: 0:00:02    time: 1.0182  data: 0.0003  max mem: 9586\n",
      "Epoch: [13] Test Total time: 0:04:11\n",
      "global correct: 95.8\n",
      "average row correct: ['97.1', '96.9', '81.3', '96.0', '87.3', '90.7', '99.1', '93.9', '98.0', '73.7', '93.6', '72.9', '92.1', '96.3', '94.5', '96.1', '76.4', '96.1', '78.3', '96.0', '87.4']\n",
      "IoU: ['95.2', '94.3', '57.7', '90.5', '75.1', '75.4', '95.7', '84.4', '91.3', '48.6', '90.8', '64.3', '87.5', '87.9', '90.2', '90.6', '66.0', '87.1', '60.6', '90.0', '82.2']\n",
      "mean IoU: 81.2\n",
      "Epoch: [14] Train  [  0/183]  eta: 0:39:54  lr: 0.000069  loss: 0.5164 (0.5164)  time: 13.0822  data: 0.3935  max mem: 9586\n",
      "Epoch: [14] Train  [ 10/183]  eta: 0:35:49  lr: 0.000069  loss: 0.5165 (0.4954)  time: 12.4264  data: 0.0362  max mem: 9586\n",
      "Epoch: [14] Train  [ 20/183]  eta: 0:33:49  lr: 0.000069  loss: 0.7826 (0.5401)  time: 12.4167  data: 0.0004  max mem: 9586\n",
      "Epoch: [14] Train  [ 30/183]  eta: 0:31:36  lr: 0.000069  loss: 0.4273 (0.5343)  time: 12.3796  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Train  [ 40/183]  eta: 0:29:27  lr: 0.000069  loss: 0.3813 (0.5327)  time: 12.2696  data: 0.0004  max mem: 9586\n",
      "Epoch: [14] Train  [ 50/183]  eta: 0:27:21  lr: 0.000069  loss: 0.4882 (0.5228)  time: 12.2568  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Train  [ 60/183]  eta: 0:25:18  lr: 0.000069  loss: 0.6338 (0.5185)  time: 12.3156  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [ 70/183]  eta: 0:23:15  lr: 0.000068  loss: 0.3869 (0.5084)  time: 12.3801  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [ 80/183]  eta: 0:21:10  lr: 0.000068  loss: 0.3439 (0.5004)  time: 12.3096  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Train  [ 90/183]  eta: 0:19:08  lr: 0.000068  loss: 1.2674 (0.5081)  time: 12.3448  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Train  [100/183]  eta: 0:17:06  lr: 0.000068  loss: 0.2326 (0.5030)  time: 12.4667  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [110/183]  eta: 0:15:01  lr: 0.000068  loss: 0.4337 (0.5102)  time: 12.3654  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [120/183]  eta: 0:12:57  lr: 0.000068  loss: 0.7101 (0.5172)  time: 12.2587  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [130/183]  eta: 0:10:54  lr: 0.000068  loss: 0.2787 (0.5197)  time: 12.3868  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [140/183]  eta: 0:08:51  lr: 0.000068  loss: 0.9378 (0.5202)  time: 12.4645  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [150/183]  eta: 0:06:47  lr: 0.000067  loss: 0.3321 (0.5205)  time: 12.3688  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [160/183]  eta: 0:04:44  lr: 0.000067  loss: 0.2026 (0.5273)  time: 12.3877  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [170/183]  eta: 0:02:40  lr: 0.000067  loss: 0.6368 (0.5297)  time: 12.4074  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train  [180/183]  eta: 0:00:37  lr: 0.000067  loss: 0.3340 (0.5237)  time: 12.4375  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Train Total time: 0:37:44\n",
      "Epoch: [14] Test  [  0/242]  eta: 0:06:09    time: 1.5274  data: 0.4462  max mem: 9586\n",
      "Epoch: [14] Test  [ 10/242]  eta: 0:03:53    time: 1.0073  data: 0.0409  max mem: 9586\n",
      "Epoch: [14] Test  [ 20/242]  eta: 0:03:36    time: 0.9464  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [ 30/242]  eta: 0:03:32    time: 0.9980  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [ 40/242]  eta: 0:03:25    time: 1.0588  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [ 50/242]  eta: 0:03:16    time: 1.0548  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Test  [ 60/242]  eta: 0:03:09    time: 1.0884  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [ 70/242]  eta: 0:02:59    time: 1.0966  data: 0.0005  max mem: 9586\n",
      "Epoch: [14] Test  [ 80/242]  eta: 0:02:48    time: 1.0382  data: 0.0005  max mem: 9586\n",
      "Epoch: [14] Test  [ 90/242]  eta: 0:02:36    time: 0.9874  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [100/242]  eta: 0:02:27    time: 1.0218  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [110/242]  eta: 0:02:16    time: 1.0407  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [120/242]  eta: 0:02:06    time: 1.0535  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [130/242]  eta: 0:01:55    time: 1.0427  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [140/242]  eta: 0:01:45    time: 0.9906  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [150/242]  eta: 0:01:34    time: 0.9963  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [160/242]  eta: 0:01:24    time: 1.0123  data: 0.0002  max mem: 9586\n",
      "Epoch: [14] Test  [170/242]  eta: 0:01:14    time: 1.0628  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [180/242]  eta: 0:01:04    time: 1.1220  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [190/242]  eta: 0:00:54    time: 1.1250  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [200/242]  eta: 0:00:43    time: 1.0676  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [210/242]  eta: 0:00:33    time: 1.0384  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [220/242]  eta: 0:00:22    time: 1.0481  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [230/242]  eta: 0:00:12    time: 1.0560  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test  [240/242]  eta: 0:00:02    time: 1.0209  data: 0.0003  max mem: 9586\n",
      "Epoch: [14] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.0', '97.1', '76.4', '92.9', '86.1', '89.5', '99.1', '93.2', '97.9', '74.0', '95.9', '75.8', '95.1', '95.7', '95.0', '96.2', '77.7', '96.3', '81.2', '96.1', '89.4']\n",
      "IoU: ['95.2', '94.7', '60.0', '89.3', '74.8', '77.7', '96.3', '83.8', '93.2', '49.6', '91.7', '65.1', '88.4', '88.3', '90.5', '90.6', '69.2', '86.3', '62.0', '91.3', '77.2']\n",
      "mean IoU: 81.7\n",
      "Epoch: [15] Train  [  0/183]  eta: 0:38:10  lr: 0.000067  loss: 0.5775 (0.5775)  time: 12.5170  data: 0.4173  max mem: 9586\n",
      "Epoch: [15] Train  [ 10/183]  eta: 0:35:48  lr: 0.000067  loss: 0.2479 (0.4329)  time: 12.4166  data: 0.0382  max mem: 9586\n",
      "Epoch: [15] Train  [ 20/183]  eta: 0:33:38  lr: 0.000067  loss: 0.9467 (0.4665)  time: 12.3751  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Train  [ 30/183]  eta: 0:31:35  lr: 0.000067  loss: 0.1368 (0.4912)  time: 12.3738  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Train  [ 40/183]  eta: 0:29:31  lr: 0.000066  loss: 1.0770 (0.5197)  time: 12.3929  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Train  [ 50/183]  eta: 0:27:27  lr: 0.000066  loss: 0.3469 (0.5220)  time: 12.3789  data: 0.0005  max mem: 9586\n",
      "Epoch: [15] Train  [ 60/183]  eta: 0:25:22  lr: 0.000066  loss: 0.7164 (0.5327)  time: 12.3473  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Train  [ 70/183]  eta: 0:23:16  lr: 0.000066  loss: 0.6636 (0.5241)  time: 12.2854  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Train  [ 80/183]  eta: 0:21:14  lr: 0.000066  loss: 0.2376 (0.5244)  time: 12.3538  data: 0.0005  max mem: 9586\n",
      "Epoch: [15] Train  [ 90/183]  eta: 0:19:09  lr: 0.000066  loss: 0.6514 (0.5107)  time: 12.3504  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Train  [100/183]  eta: 0:17:07  lr: 0.000066  loss: 1.2193 (0.5209)  time: 12.3934  data: 0.0005  max mem: 9586\n",
      "Epoch: [15] Train  [110/183]  eta: 0:15:03  lr: 0.000066  loss: 1.2255 (0.5355)  time: 12.4431  data: 0.0006  max mem: 9586\n",
      "Epoch: [15] Train  [120/183]  eta: 0:13:00  lr: 0.000065  loss: 0.1448 (0.5200)  time: 12.4199  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Train  [130/183]  eta: 0:10:56  lr: 0.000065  loss: 0.4229 (0.5262)  time: 12.4168  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Train  [140/183]  eta: 0:08:52  lr: 0.000065  loss: 0.5122 (0.5226)  time: 12.3811  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Train  [150/183]  eta: 0:06:48  lr: 0.000065  loss: 0.0903 (0.5193)  time: 12.4848  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Train  [160/183]  eta: 0:04:45  lr: 0.000065  loss: 0.4835 (0.5201)  time: 12.4710  data: 0.0005  max mem: 9586\n",
      "Epoch: [15] Train  [170/183]  eta: 0:02:41  lr: 0.000065  loss: 0.7832 (0.5163)  time: 12.3469  data: 0.0006  max mem: 9586\n",
      "Epoch: [15] Train  [180/183]  eta: 0:00:37  lr: 0.000065  loss: 0.8761 (0.5231)  time: 12.2615  data: 0.0006  max mem: 9586\n",
      "Epoch: [15] Train Total time: 0:37:46\n",
      "Epoch: [15] Test  [  0/242]  eta: 0:06:04    time: 1.5060  data: 0.4310  max mem: 9586\n",
      "Epoch: [15] Test  [ 10/242]  eta: 0:03:53    time: 1.0074  data: 0.0394  max mem: 9586\n",
      "Epoch: [15] Test  [ 20/242]  eta: 0:03:36    time: 0.9476  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [ 30/242]  eta: 0:03:32    time: 0.9993  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [ 40/242]  eta: 0:03:25    time: 1.0614  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [ 50/242]  eta: 0:03:16    time: 1.0552  data: 0.0005  max mem: 9586\n",
      "Epoch: [15] Test  [ 60/242]  eta: 0:03:09    time: 1.0876  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [ 70/242]  eta: 0:02:59    time: 1.0977  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [ 80/242]  eta: 0:02:48    time: 1.0400  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [ 90/242]  eta: 0:02:36    time: 0.9879  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [100/242]  eta: 0:02:27    time: 1.0197  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [110/242]  eta: 0:02:16    time: 1.0392  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [120/242]  eta: 0:02:06    time: 1.0532  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [130/242]  eta: 0:01:55    time: 1.0406  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [140/242]  eta: 0:01:45    time: 0.9906  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [150/242]  eta: 0:01:34    time: 0.9982  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [160/242]  eta: 0:01:24    time: 1.0119  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [170/242]  eta: 0:01:14    time: 1.0621  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [180/242]  eta: 0:01:04    time: 1.1222  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [190/242]  eta: 0:00:54    time: 1.1258  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [200/242]  eta: 0:00:43    time: 1.0712  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [210/242]  eta: 0:00:33    time: 1.0433  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [220/242]  eta: 0:00:22    time: 1.0501  data: 0.0004  max mem: 9586\n",
      "Epoch: [15] Test  [230/242]  eta: 0:00:12    time: 1.0577  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test  [240/242]  eta: 0:00:02    time: 1.0193  data: 0.0003  max mem: 9586\n",
      "Epoch: [15] Test Total time: 0:04:11\n",
      "global correct: 95.8\n",
      "average row correct: ['97.0', '97.8', '79.2', '95.2', '87.4', '89.1', '99.2', '91.8', '98.5', '71.4', '96.1', '72.7', '94.2', '96.6', '94.4', '96.1', '77.2', '96.9', '81.6', '97.0', '91.0']\n",
      "IoU: ['95.2', '92.3', '59.5', '90.3', '74.8', '77.2', '96.1', '83.7', '91.8', '52.0', '91.9', '64.5', '88.2', '88.6', '90.1', '90.8', '68.3', '86.4', '63.3', '87.2', '76.0']\n",
      "mean IoU: 81.3\n",
      "Epoch: [16] Train  [  0/183]  eta: 0:39:24  lr: 0.000065  loss: 0.2141 (0.2141)  time: 12.9192  data: 0.4027  max mem: 9586\n",
      "Epoch: [16] Train  [ 10/183]  eta: 0:35:58  lr: 0.000064  loss: 0.2746 (0.4097)  time: 12.4788  data: 0.0369  max mem: 9586\n",
      "Epoch: [16] Train  [ 20/183]  eta: 0:33:47  lr: 0.000064  loss: 0.3191 (0.4615)  time: 12.4168  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Train  [ 30/183]  eta: 0:31:38  lr: 0.000064  loss: 0.2928 (0.4673)  time: 12.3668  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Train  [ 40/183]  eta: 0:29:34  lr: 0.000064  loss: 0.5557 (0.4770)  time: 12.3698  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Train  [ 50/183]  eta: 0:27:28  lr: 0.000064  loss: 0.4657 (0.5106)  time: 12.3695  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Train  [ 60/183]  eta: 0:25:21  lr: 0.000064  loss: 0.5889 (0.5112)  time: 12.3067  data: 0.0005  max mem: 9586\n",
      "Epoch: [16] Train  [ 70/183]  eta: 0:23:15  lr: 0.000064  loss: 0.2937 (0.5146)  time: 12.2480  data: 0.0005  max mem: 9586\n",
      "Epoch: [16] Train  [ 80/183]  eta: 0:21:11  lr: 0.000064  loss: 0.1638 (0.5139)  time: 12.2627  data: 0.0005  max mem: 9586\n",
      "Epoch: [16] Train  [ 90/183]  eta: 0:19:07  lr: 0.000063  loss: 0.3980 (0.5009)  time: 12.2982  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Train  [100/183]  eta: 0:17:03  lr: 0.000063  loss: 1.0279 (0.5001)  time: 12.2892  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Train  [110/183]  eta: 0:15:00  lr: 0.000063  loss: 0.3599 (0.5003)  time: 12.2830  data: 0.0005  max mem: 9586\n",
      "Epoch: [16] Train  [120/183]  eta: 0:12:56  lr: 0.000063  loss: 0.4056 (0.4987)  time: 12.3130  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Train  [130/183]  eta: 0:10:53  lr: 0.000063  loss: 0.6027 (0.5060)  time: 12.3293  data: 0.0005  max mem: 9586\n",
      "Epoch: [16] Train  [140/183]  eta: 0:08:50  lr: 0.000063  loss: 0.7795 (0.5137)  time: 12.3722  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Train  [150/183]  eta: 0:06:47  lr: 0.000063  loss: 0.8792 (0.5134)  time: 12.3771  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Train  [160/183]  eta: 0:04:43  lr: 0.000062  loss: 0.3802 (0.5099)  time: 12.3645  data: 0.0005  max mem: 9586\n",
      "Epoch: [16] Train  [170/183]  eta: 0:02:40  lr: 0.000062  loss: 0.3355 (0.5120)  time: 12.3698  data: 0.0005  max mem: 9586\n",
      "Epoch: [16] Train  [180/183]  eta: 0:00:37  lr: 0.000062  loss: 0.4682 (0.5199)  time: 12.3171  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Train Total time: 0:37:38\n",
      "Epoch: [16] Test  [  0/242]  eta: 0:06:02    time: 1.4964  data: 0.4187  max mem: 9586\n",
      "Epoch: [16] Test  [ 10/242]  eta: 0:03:53    time: 1.0054  data: 0.0385  max mem: 9586\n",
      "Epoch: [16] Test  [ 20/242]  eta: 0:03:36    time: 0.9478  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test  [ 30/242]  eta: 0:03:32    time: 0.9997  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [ 40/242]  eta: 0:03:25    time: 1.0599  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [ 50/242]  eta: 0:03:16    time: 1.0549  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [ 60/242]  eta: 0:03:09    time: 1.0901  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [ 70/242]  eta: 0:02:59    time: 1.1001  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test  [ 80/242]  eta: 0:02:48    time: 1.0413  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test  [ 90/242]  eta: 0:02:36    time: 0.9896  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [100/242]  eta: 0:02:27    time: 1.0217  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [110/242]  eta: 0:02:16    time: 1.0382  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [120/242]  eta: 0:02:06    time: 1.0523  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [130/242]  eta: 0:01:55    time: 1.0452  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test  [140/242]  eta: 0:01:45    time: 0.9933  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test  [150/242]  eta: 0:01:34    time: 0.9964  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [160/242]  eta: 0:01:24    time: 1.0136  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [170/242]  eta: 0:01:14    time: 1.0640  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [180/242]  eta: 0:01:04    time: 1.1216  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test  [190/242]  eta: 0:00:54    time: 1.1245  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test  [200/242]  eta: 0:00:43    time: 1.0687  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [210/242]  eta: 0:00:33    time: 1.0421  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [220/242]  eta: 0:00:22    time: 1.0501  data: 0.0003  max mem: 9586\n",
      "Epoch: [16] Test  [230/242]  eta: 0:00:12    time: 1.0570  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test  [240/242]  eta: 0:00:02    time: 1.0195  data: 0.0004  max mem: 9586\n",
      "Epoch: [16] Test Total time: 0:04:11\n",
      "global correct: 95.8\n",
      "average row correct: ['97.2', '97.8', '80.8', '92.5', '86.2', '90.2', '99.3', '93.0', '97.8', '73.7', '94.2', '73.5', '94.7', '96.6', '94.3', '96.2', '74.8', '95.9', '77.0', '95.4', '89.5']\n",
      "IoU: ['95.3', '93.5', '62.7', '89.0', '74.8', '74.6', '95.8', '84.0', '93.5', '50.3', '91.4', '65.0', '88.6', '88.3', '90.2', '90.4', '66.7', '88.5', '61.0', '89.7', '77.2']\n",
      "mean IoU: 81.5\n",
      "Epoch: [17] Train  [  0/183]  eta: 0:39:32  lr: 0.000062  loss: 0.3362 (0.3362)  time: 12.9635  data: 0.4399  max mem: 9586\n",
      "Epoch: [17] Train  [ 10/183]  eta: 0:35:50  lr: 0.000062  loss: 0.5712 (0.5100)  time: 12.4299  data: 0.0404  max mem: 9586\n",
      "Epoch: [17] Train  [ 20/183]  eta: 0:33:41  lr: 0.000062  loss: 0.3540 (0.5036)  time: 12.3760  data: 0.0005  max mem: 9586\n",
      "Epoch: [17] Train  [ 30/183]  eta: 0:31:30  lr: 0.000062  loss: 0.7922 (0.4775)  time: 12.3143  data: 0.0005  max mem: 9586\n",
      "Epoch: [17] Train  [ 40/183]  eta: 0:29:29  lr: 0.000062  loss: 0.4938 (0.4626)  time: 12.3383  data: 0.0005  max mem: 9586\n",
      "Epoch: [17] Train  [ 50/183]  eta: 0:27:25  lr: 0.000061  loss: 0.6177 (0.4669)  time: 12.3930  data: 0.0004  max mem: 9586\n",
      "Epoch: [17] Train  [ 60/183]  eta: 0:25:23  lr: 0.000061  loss: 0.2372 (0.4763)  time: 12.4188  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Train  [ 70/183]  eta: 0:23:17  lr: 0.000061  loss: 0.3162 (0.4857)  time: 12.3736  data: 0.0004  max mem: 9586\n",
      "Epoch: [17] Train  [ 80/183]  eta: 0:21:14  lr: 0.000061  loss: 0.4224 (0.4977)  time: 12.3214  data: 0.0005  max mem: 9586\n",
      "Epoch: [17] Train  [ 90/183]  eta: 0:19:09  lr: 0.000061  loss: 0.4478 (0.5009)  time: 12.3235  data: 0.0005  max mem: 9586\n",
      "Epoch: [17] Train  [100/183]  eta: 0:17:05  lr: 0.000061  loss: 0.6902 (0.5071)  time: 12.2819  data: 0.0005  max mem: 9586\n",
      "Epoch: [17] Train  [110/183]  eta: 0:15:00  lr: 0.000061  loss: 0.5335 (0.5102)  time: 12.2429  data: 0.0004  max mem: 9586\n",
      "Epoch: [17] Train  [120/183]  eta: 0:12:57  lr: 0.000061  loss: 0.6527 (0.5181)  time: 12.3143  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Train  [130/183]  eta: 0:10:54  lr: 0.000060  loss: 0.4112 (0.5228)  time: 12.3659  data: 0.0002  max mem: 9586\n",
      "Epoch: [17] Train  [140/183]  eta: 0:08:50  lr: 0.000060  loss: 0.4599 (0.5263)  time: 12.2410  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Train  [150/183]  eta: 0:06:46  lr: 0.000060  loss: 0.5794 (0.5452)  time: 12.1703  data: 0.0006  max mem: 9586\n",
      "Epoch: [17] Train  [160/183]  eta: 0:04:43  lr: 0.000060  loss: 0.6067 (0.5364)  time: 12.2947  data: 0.0006  max mem: 9586\n",
      "Epoch: [17] Train  [170/183]  eta: 0:02:40  lr: 0.000060  loss: 0.5558 (0.5343)  time: 12.3578  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Train  [180/183]  eta: 0:00:36  lr: 0.000060  loss: 0.3728 (0.5362)  time: 12.3276  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Train Total time: 0:37:36\n",
      "Epoch: [17] Test  [  0/242]  eta: 0:06:03    time: 1.5010  data: 0.4193  max mem: 9586\n",
      "Epoch: [17] Test  [ 10/242]  eta: 0:03:52    time: 1.0043  data: 0.0384  max mem: 9586\n",
      "Epoch: [17] Test  [ 20/242]  eta: 0:03:36    time: 0.9472  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [ 30/242]  eta: 0:03:32    time: 1.0019  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [ 40/242]  eta: 0:03:25    time: 1.0618  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [ 50/242]  eta: 0:03:16    time: 1.0543  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [ 60/242]  eta: 0:03:09    time: 1.0876  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [ 70/242]  eta: 0:02:59    time: 1.0953  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [ 80/242]  eta: 0:02:48    time: 1.0367  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [ 90/242]  eta: 0:02:36    time: 0.9874  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [100/242]  eta: 0:02:27    time: 1.0196  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [110/242]  eta: 0:02:16    time: 1.0368  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [120/242]  eta: 0:02:06    time: 1.0505  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [130/242]  eta: 0:01:55    time: 1.0398  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [140/242]  eta: 0:01:45    time: 0.9900  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [150/242]  eta: 0:01:34    time: 0.9957  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [160/242]  eta: 0:01:24    time: 1.0104  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [170/242]  eta: 0:01:14    time: 1.0601  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [180/242]  eta: 0:01:04    time: 1.1200  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [190/242]  eta: 0:00:54    time: 1.1241  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [200/242]  eta: 0:00:43    time: 1.0681  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [210/242]  eta: 0:00:33    time: 1.0388  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [220/242]  eta: 0:00:22    time: 1.0465  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [230/242]  eta: 0:00:12    time: 1.0568  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test  [240/242]  eta: 0:00:02    time: 1.0206  data: 0.0003  max mem: 9586\n",
      "Epoch: [17] Test Total time: 0:04:11\n",
      "global correct: 95.7\n",
      "average row correct: ['96.8', '97.8', '80.0', '96.2', '88.0', '91.5', '99.3', '94.1', '98.0', '73.8', '96.1', '72.2', '94.6', '95.2', '95.3', '96.2', '75.6', '96.2', '80.6', '96.8', '88.9']\n",
      "IoU: ['95.1', '93.4', '61.4', '90.3', '74.9', '73.2', '95.5', '83.2', '92.8', '48.3', '91.5', '64.5', '89.1', '88.7', '90.4', '90.6', '67.7', '88.9', '61.6', '88.2', '77.1']\n",
      "mean IoU: 81.3\n",
      "Epoch: [18] Train  [  0/183]  eta: 0:39:43  lr: 0.000060  loss: 0.2527 (0.2527)  time: 13.0249  data: 0.4269  max mem: 9586\n",
      "Epoch: [18] Train  [ 10/183]  eta: 0:35:19  lr: 0.000060  loss: 0.2790 (0.4229)  time: 12.2505  data: 0.0391  max mem: 9586\n",
      "Epoch: [18] Train  [ 20/183]  eta: 0:33:22  lr: 0.000059  loss: 0.2073 (0.4496)  time: 12.2493  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Train  [ 30/183]  eta: 0:31:22  lr: 0.000059  loss: 0.4887 (0.4216)  time: 12.3352  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Train  [ 40/183]  eta: 0:29:19  lr: 0.000059  loss: 0.3540 (0.4456)  time: 12.3280  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Train  [ 50/183]  eta: 0:27:19  lr: 0.000059  loss: 0.3163 (0.4510)  time: 12.3515  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Train  [ 60/183]  eta: 0:25:16  lr: 0.000059  loss: 0.5401 (0.5069)  time: 12.3738  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Train  [ 70/183]  eta: 0:23:10  lr: 0.000059  loss: 1.6975 (0.5487)  time: 12.2724  data: 0.0005  max mem: 9586\n",
      "Epoch: [18] Train  [ 80/183]  eta: 0:21:07  lr: 0.000059  loss: 0.6777 (0.5534)  time: 12.2336  data: 0.0005  max mem: 9586\n",
      "Epoch: [18] Train  [ 90/183]  eta: 0:19:05  lr: 0.000059  loss: 0.3199 (0.5396)  time: 12.3315  data: 0.0002  max mem: 9586\n",
      "Epoch: [18] Train  [100/183]  eta: 0:17:02  lr: 0.000058  loss: 0.8703 (0.5429)  time: 12.3691  data: 0.0002  max mem: 9586\n",
      "Epoch: [18] Train  [110/183]  eta: 0:14:59  lr: 0.000058  loss: 0.2246 (0.5454)  time: 12.3235  data: 0.0002  max mem: 9586\n",
      "Epoch: [18] Train  [120/183]  eta: 0:12:55  lr: 0.000058  loss: 0.3970 (0.5513)  time: 12.2440  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Train  [130/183]  eta: 0:10:51  lr: 0.000058  loss: 0.4672 (0.5535)  time: 12.2162  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Train  [140/183]  eta: 0:08:48  lr: 0.000058  loss: 0.6723 (0.5509)  time: 12.2603  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Train  [150/183]  eta: 0:06:46  lr: 0.000058  loss: 0.5279 (0.5515)  time: 12.3284  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Train  [160/183]  eta: 0:04:43  lr: 0.000058  loss: 0.4957 (0.5504)  time: 12.3850  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Train  [170/183]  eta: 0:02:40  lr: 0.000057  loss: 0.5674 (0.5488)  time: 12.3853  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Train  [180/183]  eta: 0:00:36  lr: 0.000057  loss: 0.3183 (0.5406)  time: 12.3100  data: 0.0005  max mem: 9586\n",
      "Epoch: [18] Train Total time: 0:37:32\n",
      "Epoch: [18] Test  [  0/242]  eta: 0:06:07    time: 1.5184  data: 0.4412  max mem: 9586\n",
      "Epoch: [18] Test  [ 10/242]  eta: 0:03:53    time: 1.0083  data: 0.0403  max mem: 9586\n",
      "Epoch: [18] Test  [ 20/242]  eta: 0:03:36    time: 0.9480  data: 0.0002  max mem: 9586\n",
      "Epoch: [18] Test  [ 30/242]  eta: 0:03:32    time: 0.9986  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [ 40/242]  eta: 0:03:25    time: 1.0598  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [ 50/242]  eta: 0:03:16    time: 1.0551  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [ 60/242]  eta: 0:03:09    time: 1.0867  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [ 70/242]  eta: 0:02:59    time: 1.0968  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [ 80/242]  eta: 0:02:48    time: 1.0390  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [ 90/242]  eta: 0:02:36    time: 0.9859  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [100/242]  eta: 0:02:27    time: 1.0198  data: 0.0002  max mem: 9586\n",
      "Epoch: [18] Test  [110/242]  eta: 0:02:16    time: 1.0385  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [120/242]  eta: 0:02:06    time: 1.0516  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [130/242]  eta: 0:01:55    time: 1.0395  data: 0.0005  max mem: 9586\n",
      "Epoch: [18] Test  [140/242]  eta: 0:01:45    time: 0.9881  data: 0.0005  max mem: 9586\n",
      "Epoch: [18] Test  [150/242]  eta: 0:01:34    time: 0.9976  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [160/242]  eta: 0:01:24    time: 1.0131  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Test  [170/242]  eta: 0:01:14    time: 1.0602  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Test  [180/242]  eta: 0:01:04    time: 1.1203  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Test  [190/242]  eta: 0:00:54    time: 1.1249  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Test  [200/242]  eta: 0:00:43    time: 1.0697  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [210/242]  eta: 0:00:33    time: 1.0415  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [220/242]  eta: 0:00:22    time: 1.0483  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [230/242]  eta: 0:00:12    time: 1.0562  data: 0.0003  max mem: 9586\n",
      "Epoch: [18] Test  [240/242]  eta: 0:00:02    time: 1.0178  data: 0.0004  max mem: 9586\n",
      "Epoch: [18] Test Total time: 0:04:11\n",
      "global correct: 95.8\n",
      "average row correct: ['97.0', '97.6', '80.0', '95.6', '87.0', '89.9', '99.2', '92.5', '97.5', '68.5', '95.0', '73.0', '95.8', '96.0', '95.1', '96.1', '76.9', '96.3', '84.8', '96.7', '89.6']\n",
      "IoU: ['95.2', '93.1', '62.5', '89.7', '75.3', '74.6', '96.2', '83.3', '93.9', '51.3', '91.6', '64.2', '88.1', '88.8', '90.1', '90.3', '68.1', '87.2', '63.6', '89.1', '78.4']\n",
      "mean IoU: 81.6\n",
      "Epoch: [19] Train  [  0/183]  eta: 0:37:47  lr: 0.000057  loss: 0.7422 (0.7422)  time: 12.3885  data: 0.3790  max mem: 9586\n",
      "Epoch: [19] Train  [ 10/183]  eta: 0:35:34  lr: 0.000057  loss: 0.6491 (0.4751)  time: 12.3410  data: 0.0349  max mem: 9586\n",
      "Epoch: [19] Train  [ 20/183]  eta: 0:33:27  lr: 0.000057  loss: 0.4774 (0.4946)  time: 12.3119  data: 0.0010  max mem: 9586\n",
      "Epoch: [19] Train  [ 30/183]  eta: 0:31:27  lr: 0.000057  loss: 0.5531 (0.5138)  time: 12.3329  data: 0.0010  max mem: 9586\n",
      "Epoch: [19] Train  [ 40/183]  eta: 0:29:23  lr: 0.000057  loss: 0.7592 (0.5663)  time: 12.3488  data: 0.0005  max mem: 9586\n",
      "Epoch: [19] Train  [ 50/183]  eta: 0:27:18  lr: 0.000057  loss: 0.6234 (0.5573)  time: 12.2894  data: 0.0005  max mem: 9586\n",
      "Epoch: [19] Train  [ 60/183]  eta: 0:25:15  lr: 0.000056  loss: 0.2029 (0.5345)  time: 12.2979  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Train  [ 70/183]  eta: 0:23:12  lr: 0.000056  loss: 0.4541 (0.5470)  time: 12.3464  data: 0.0006  max mem: 9586\n",
      "Epoch: [19] Train  [ 80/183]  eta: 0:21:09  lr: 0.000056  loss: 0.4658 (0.5339)  time: 12.3515  data: 0.0006  max mem: 9586\n",
      "Epoch: [19] Train  [ 90/183]  eta: 0:19:04  lr: 0.000056  loss: 0.7002 (0.5360)  time: 12.2513  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Train  [100/183]  eta: 0:17:01  lr: 0.000056  loss: 0.8723 (0.5399)  time: 12.2152  data: 0.0005  max mem: 9586\n",
      "Epoch: [19] Train  [110/183]  eta: 0:14:58  lr: 0.000056  loss: 0.4107 (0.5252)  time: 12.3049  data: 0.0005  max mem: 9586\n",
      "Epoch: [19] Train  [120/183]  eta: 0:12:55  lr: 0.000056  loss: 0.6029 (0.5140)  time: 12.3131  data: 0.0005  max mem: 9586\n",
      "Epoch: [19] Train  [130/183]  eta: 0:10:52  lr: 0.000056  loss: 0.1420 (0.5098)  time: 12.2921  data: 0.0005  max mem: 9586\n",
      "Epoch: [19] Train  [140/183]  eta: 0:08:48  lr: 0.000055  loss: 0.4802 (0.5078)  time: 12.2251  data: 0.0005  max mem: 9586\n",
      "Epoch: [19] Train  [150/183]  eta: 0:06:45  lr: 0.000055  loss: 0.4901 (0.5027)  time: 12.2381  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Train  [160/183]  eta: 0:04:42  lr: 0.000055  loss: 0.4568 (0.5054)  time: 12.3556  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Train  [170/183]  eta: 0:02:39  lr: 0.000055  loss: 0.5169 (0.5062)  time: 12.3397  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Train  [180/183]  eta: 0:00:36  lr: 0.000055  loss: 0.3345 (0.5080)  time: 12.3185  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Train Total time: 0:37:32\n",
      "Epoch: [19] Test  [  0/242]  eta: 0:06:09    time: 1.5265  data: 0.4545  max mem: 9586\n",
      "Epoch: [19] Test  [ 10/242]  eta: 0:03:54    time: 1.0102  data: 0.0416  max mem: 9586\n",
      "Epoch: [19] Test  [ 20/242]  eta: 0:03:36    time: 0.9485  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Test  [ 30/242]  eta: 0:03:32    time: 1.0000  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Test  [ 40/242]  eta: 0:03:25    time: 1.0602  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [ 50/242]  eta: 0:03:16    time: 1.0534  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [ 60/242]  eta: 0:03:09    time: 1.0868  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Test  [ 70/242]  eta: 0:02:59    time: 1.0968  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Test  [ 80/242]  eta: 0:02:48    time: 1.0392  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [ 90/242]  eta: 0:02:36    time: 0.9880  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [100/242]  eta: 0:02:27    time: 1.0212  data: 0.0005  max mem: 9586\n",
      "Epoch: [19] Test  [110/242]  eta: 0:02:16    time: 1.0404  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Test  [120/242]  eta: 0:02:06    time: 1.0547  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Test  [130/242]  eta: 0:01:55    time: 1.0426  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [140/242]  eta: 0:01:45    time: 0.9920  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [150/242]  eta: 0:01:34    time: 0.9989  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [160/242]  eta: 0:01:24    time: 1.0111  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [170/242]  eta: 0:01:14    time: 1.0605  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [180/242]  eta: 0:01:04    time: 1.1203  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Test  [190/242]  eta: 0:00:54    time: 1.1246  data: 0.0004  max mem: 9586\n",
      "Epoch: [19] Test  [200/242]  eta: 0:00:43    time: 1.0700  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [210/242]  eta: 0:00:33    time: 1.0406  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [220/242]  eta: 0:00:22    time: 1.0483  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [230/242]  eta: 0:00:12    time: 1.0575  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test  [240/242]  eta: 0:00:02    time: 1.0191  data: 0.0003  max mem: 9586\n",
      "Epoch: [19] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.2', '97.4', '75.7', '94.2', '88.4', '89.4', '99.2', '93.3', '98.2', '71.1', '95.5', '75.9', '93.6', '96.5', '94.9', '96.2', '76.0', '96.1', '80.6', '96.3', '89.1']\n",
      "IoU: ['95.4', '93.4', '62.8', '90.3', '75.8', '76.9', '96.0', '83.7', '92.3', '52.0', '91.9', '65.4', '87.6', '88.1', '90.4', '90.3', '68.9', '87.5', '62.8', '90.2', '79.5']\n",
      "mean IoU: 82.0\n",
      "Epoch: [20] Train  [  0/183]  eta: 0:39:10  lr: 0.000055  loss: 0.5517 (0.5517)  time: 12.8453  data: 0.4606  max mem: 9586\n",
      "Epoch: [20] Train  [ 10/183]  eta: 0:35:22  lr: 0.000055  loss: 0.1900 (0.4206)  time: 12.2685  data: 0.0421  max mem: 9586\n",
      "Epoch: [20] Train  [ 20/183]  eta: 0:33:13  lr: 0.000055  loss: 0.5503 (0.5145)  time: 12.1981  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Train  [ 30/183]  eta: 0:31:14  lr: 0.000054  loss: 0.6414 (0.5448)  time: 12.2468  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Train  [ 40/183]  eta: 0:29:12  lr: 0.000054  loss: 0.4367 (0.5194)  time: 12.2803  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Train  [ 50/183]  eta: 0:27:11  lr: 0.000054  loss: 0.3423 (0.5162)  time: 12.2823  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Train  [ 60/183]  eta: 0:25:12  lr: 0.000054  loss: 0.3043 (0.4950)  time: 12.3753  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Train  [ 70/183]  eta: 0:23:10  lr: 0.000054  loss: 0.2481 (0.4936)  time: 12.3937  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Train  [ 80/183]  eta: 0:21:06  lr: 0.000054  loss: 0.7569 (0.4997)  time: 12.2937  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Train  [ 90/183]  eta: 0:19:05  lr: 0.000054  loss: 0.4766 (0.4896)  time: 12.3542  data: 0.0005  max mem: 9586\n",
      "Epoch: [20] Train  [100/183]  eta: 0:17:01  lr: 0.000053  loss: 0.4286 (0.4834)  time: 12.3629  data: 0.0005  max mem: 9586\n",
      "Epoch: [20] Train  [110/183]  eta: 0:14:58  lr: 0.000053  loss: 0.6863 (0.4826)  time: 12.2963  data: 0.0005  max mem: 9586\n",
      "Epoch: [20] Train  [120/183]  eta: 0:12:55  lr: 0.000053  loss: 0.1591 (0.4817)  time: 12.3518  data: 0.0005  max mem: 9586\n",
      "Epoch: [20] Train  [130/183]  eta: 0:10:52  lr: 0.000053  loss: 0.2829 (0.4791)  time: 12.3219  data: 0.0006  max mem: 9586\n",
      "Epoch: [20] Train  [140/183]  eta: 0:08:49  lr: 0.000053  loss: 0.6524 (0.4840)  time: 12.3457  data: 0.0005  max mem: 9586\n",
      "Epoch: [20] Train  [150/183]  eta: 0:06:46  lr: 0.000053  loss: 0.8056 (0.4865)  time: 12.3330  data: 0.0005  max mem: 9586\n",
      "Epoch: [20] Train  [160/183]  eta: 0:04:43  lr: 0.000053  loss: 0.7981 (0.4961)  time: 12.3246  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Train  [170/183]  eta: 0:02:40  lr: 0.000053  loss: 0.5154 (0.4932)  time: 12.3165  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Train  [180/183]  eta: 0:00:36  lr: 0.000052  loss: 0.1794 (0.4901)  time: 12.2446  data: 0.0005  max mem: 9586\n",
      "Epoch: [20] Train Total time: 0:37:32\n",
      "Epoch: [20] Test  [  0/242]  eta: 0:06:09    time: 1.5274  data: 0.4421  max mem: 9586\n",
      "Epoch: [20] Test  [ 10/242]  eta: 0:03:53    time: 1.0060  data: 0.0406  max mem: 9586\n",
      "Epoch: [20] Test  [ 20/242]  eta: 0:03:35    time: 0.9448  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Test  [ 30/242]  eta: 0:03:32    time: 0.9977  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Test  [ 40/242]  eta: 0:03:24    time: 1.0593  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Test  [ 50/242]  eta: 0:03:16    time: 1.0539  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [ 60/242]  eta: 0:03:09    time: 1.0870  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [ 70/242]  eta: 0:02:59    time: 1.0944  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [ 80/242]  eta: 0:02:48    time: 1.0372  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [ 90/242]  eta: 0:02:36    time: 0.9867  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [100/242]  eta: 0:02:26    time: 1.0191  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [110/242]  eta: 0:02:16    time: 1.0372  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [120/242]  eta: 0:02:06    time: 1.0504  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [130/242]  eta: 0:01:55    time: 1.0393  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [140/242]  eta: 0:01:45    time: 0.9898  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [150/242]  eta: 0:01:34    time: 0.9970  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Test  [160/242]  eta: 0:01:24    time: 1.0100  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Test  [170/242]  eta: 0:01:14    time: 1.0592  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [180/242]  eta: 0:01:04    time: 1.1181  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [190/242]  eta: 0:00:54    time: 1.1220  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [200/242]  eta: 0:00:43    time: 1.0681  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [210/242]  eta: 0:00:33    time: 1.0393  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test  [220/242]  eta: 0:00:22    time: 1.0471  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Test  [230/242]  eta: 0:00:12    time: 1.0555  data: 0.0004  max mem: 9586\n",
      "Epoch: [20] Test  [240/242]  eta: 0:00:02    time: 1.0174  data: 0.0003  max mem: 9586\n",
      "Epoch: [20] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.0', '98.1', '77.2', '96.1', '86.5', '91.4', '98.9', '94.7', '97.9', '69.4', '96.0', '72.7', '95.9', '95.6', '96.0', '96.0', '76.9', '96.5', '82.3', '96.5', '90.2']\n",
      "IoU: ['95.3', '93.0', '62.1', '90.3', '75.8', '75.9', '96.0', '84.3', '93.8', '51.1', '91.2', '65.5', '88.6', '88.4', '90.6', '90.7', '68.8', '88.0', '62.1', '89.0', '75.5']\n",
      "mean IoU: 81.7\n",
      "Epoch: [21] Train  [  0/183]  eta: 0:39:52  lr: 0.000052  loss: 0.2970 (0.2970)  time: 13.0725  data: 0.4424  max mem: 9586\n",
      "Epoch: [21] Train  [ 10/183]  eta: 0:35:23  lr: 0.000052  loss: 0.1091 (0.4170)  time: 12.2743  data: 0.0406  max mem: 9586\n",
      "Epoch: [21] Train  [ 20/183]  eta: 0:33:23  lr: 0.000052  loss: 0.5953 (0.4336)  time: 12.2504  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Train  [ 30/183]  eta: 0:31:15  lr: 0.000052  loss: 0.2782 (0.4342)  time: 12.2506  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Train  [ 40/183]  eta: 0:29:16  lr: 0.000052  loss: 0.4531 (0.4668)  time: 12.2817  data: 0.0007  max mem: 9586\n",
      "Epoch: [21] Train  [ 50/183]  eta: 0:27:12  lr: 0.000052  loss: 0.2067 (0.4749)  time: 12.3037  data: 0.0006  max mem: 9586\n",
      "Epoch: [21] Train  [ 60/183]  eta: 0:25:10  lr: 0.000052  loss: 0.4078 (0.4669)  time: 12.2705  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Train  [ 70/183]  eta: 0:23:06  lr: 0.000051  loss: 0.7009 (0.4799)  time: 12.2580  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Train  [ 80/183]  eta: 0:21:04  lr: 0.000051  loss: 0.5418 (0.4840)  time: 12.2520  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Train  [ 90/183]  eta: 0:19:02  lr: 0.000051  loss: 0.2088 (0.4741)  time: 12.3441  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Train  [100/183]  eta: 0:16:59  lr: 0.000051  loss: 0.6790 (0.4762)  time: 12.3141  data: 0.0005  max mem: 9586\n",
      "Epoch: [21] Train  [110/183]  eta: 0:14:56  lr: 0.000051  loss: 0.2827 (0.4735)  time: 12.2222  data: 0.0005  max mem: 9586\n",
      "Epoch: [21] Train  [120/183]  eta: 0:12:53  lr: 0.000051  loss: 0.7374 (0.4840)  time: 12.2842  data: 0.0005  max mem: 9586\n",
      "Epoch: [21] Train  [130/183]  eta: 0:10:50  lr: 0.000051  loss: 0.0340 (0.4785)  time: 12.2587  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Train  [140/183]  eta: 0:08:47  lr: 0.000050  loss: 0.2614 (0.4734)  time: 12.2473  data: 0.0005  max mem: 9586\n",
      "Epoch: [21] Train  [150/183]  eta: 0:06:45  lr: 0.000050  loss: 0.5099 (0.4759)  time: 12.3616  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Train  [160/183]  eta: 0:04:42  lr: 0.000050  loss: 0.6299 (0.4772)  time: 12.2996  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Train  [170/183]  eta: 0:02:39  lr: 0.000050  loss: 0.7115 (0.4828)  time: 12.2216  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Train  [180/183]  eta: 0:00:36  lr: 0.000050  loss: 0.2412 (0.4845)  time: 12.2556  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Train Total time: 0:37:26\n",
      "Epoch: [21] Test  [  0/242]  eta: 0:05:53    time: 1.4597  data: 0.3883  max mem: 9586\n",
      "Epoch: [21] Test  [ 10/242]  eta: 0:03:51    time: 0.9995  data: 0.0356  max mem: 9586\n",
      "Epoch: [21] Test  [ 20/242]  eta: 0:03:35    time: 0.9463  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [ 30/242]  eta: 0:03:31    time: 0.9980  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [ 40/242]  eta: 0:03:24    time: 1.0580  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [ 50/242]  eta: 0:03:15    time: 1.0526  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [ 60/242]  eta: 0:03:08    time: 1.0852  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [ 70/242]  eta: 0:02:59    time: 1.0944  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [ 80/242]  eta: 0:02:47    time: 1.0369  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [ 90/242]  eta: 0:02:36    time: 0.9863  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [100/242]  eta: 0:02:26    time: 1.0200  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [110/242]  eta: 0:02:15    time: 1.0367  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [120/242]  eta: 0:02:06    time: 1.0487  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [130/242]  eta: 0:01:55    time: 1.0410  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [140/242]  eta: 0:01:45    time: 0.9917  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [150/242]  eta: 0:01:34    time: 0.9971  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [160/242]  eta: 0:01:24    time: 1.0094  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [170/242]  eta: 0:01:14    time: 1.0580  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [180/242]  eta: 0:01:04    time: 1.1188  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [190/242]  eta: 0:00:54    time: 1.1223  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [200/242]  eta: 0:00:43    time: 1.0674  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [210/242]  eta: 0:00:33    time: 1.0400  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [220/242]  eta: 0:00:22    time: 1.0489  data: 0.0003  max mem: 9586\n",
      "Epoch: [21] Test  [230/242]  eta: 0:00:12    time: 1.0552  data: 0.0004  max mem: 9586\n",
      "Epoch: [21] Test  [240/242]  eta: 0:00:02    time: 1.0157  data: 0.0005  max mem: 9586\n",
      "Epoch: [21] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.2', '97.2', '79.7', '94.1', '86.6', '92.5', '99.2', '89.6', '98.1', '76.5', '94.7', '74.7', '96.1', '95.9', '95.2', '95.7', '77.3', '96.3', '76.3', '96.4', '90.2']\n",
      "IoU: ['95.3', '94.5', '62.6', '90.1', '75.3', '75.5', '96.2', '86.6', '93.5', '46.4', '91.1', '65.8', '89.1', '89.9', '90.4', '90.9', '68.9', '87.5', '59.8', '90.5', '77.1']\n",
      "mean IoU: 81.7\n",
      "Epoch: [22] Train  [  0/183]  eta: 0:39:14  lr: 0.000050  loss: 0.4350 (0.4350)  time: 12.8641  data: 0.3854  max mem: 9586\n",
      "Epoch: [22] Train  [ 10/183]  eta: 0:35:54  lr: 0.000050  loss: 0.2616 (0.4787)  time: 12.4526  data: 0.0355  max mem: 9586\n",
      "Epoch: [22] Train  [ 20/183]  eta: 0:33:35  lr: 0.000050  loss: 0.3934 (0.4757)  time: 12.3397  data: 0.0005  max mem: 9586\n",
      "Epoch: [22] Train  [ 30/183]  eta: 0:31:33  lr: 0.000049  loss: 0.6131 (0.4569)  time: 12.3312  data: 0.0005  max mem: 9586\n",
      "Epoch: [22] Train  [ 40/183]  eta: 0:29:24  lr: 0.000049  loss: 0.4990 (0.4640)  time: 12.3137  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train  [ 50/183]  eta: 0:27:22  lr: 0.000049  loss: 0.5496 (0.4707)  time: 12.3087  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train  [ 60/183]  eta: 0:25:15  lr: 0.000049  loss: 0.2801 (0.4931)  time: 12.2933  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train  [ 70/183]  eta: 0:23:12  lr: 0.000049  loss: 0.6155 (0.4862)  time: 12.2652  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train  [ 80/183]  eta: 0:21:09  lr: 0.000049  loss: 0.6931 (0.5040)  time: 12.3190  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train  [ 90/183]  eta: 0:19:05  lr: 0.000049  loss: 0.1649 (0.4930)  time: 12.2713  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train  [100/183]  eta: 0:17:02  lr: 0.000048  loss: 0.3077 (0.4826)  time: 12.3155  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Train  [110/183]  eta: 0:14:59  lr: 0.000048  loss: 0.4246 (0.4774)  time: 12.3790  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Train  [120/183]  eta: 0:12:56  lr: 0.000048  loss: 0.8158 (0.4787)  time: 12.3421  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train  [130/183]  eta: 0:10:53  lr: 0.000048  loss: 0.6195 (0.4781)  time: 12.3432  data: 0.0005  max mem: 9586\n",
      "Epoch: [22] Train  [140/183]  eta: 0:08:49  lr: 0.000048  loss: 0.5553 (0.4696)  time: 12.3197  data: 0.0006  max mem: 9586\n",
      "Epoch: [22] Train  [150/183]  eta: 0:06:46  lr: 0.000048  loss: 0.6531 (0.4617)  time: 12.3355  data: 0.0006  max mem: 9586\n",
      "Epoch: [22] Train  [160/183]  eta: 0:04:43  lr: 0.000048  loss: 0.5004 (0.4641)  time: 12.3191  data: 0.0005  max mem: 9586\n",
      "Epoch: [22] Train  [170/183]  eta: 0:02:40  lr: 0.000048  loss: 0.3319 (0.4641)  time: 12.2354  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train  [180/183]  eta: 0:00:36  lr: 0.000047  loss: 0.9733 (0.4687)  time: 12.2805  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Train Total time: 0:37:34\n",
      "Epoch: [22] Test  [  0/242]  eta: 0:05:53    time: 1.4621  data: 0.3836  max mem: 9586\n",
      "Epoch: [22] Test  [ 10/242]  eta: 0:03:52    time: 1.0024  data: 0.0352  max mem: 9586\n",
      "Epoch: [22] Test  [ 20/242]  eta: 0:03:35    time: 0.9475  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [ 30/242]  eta: 0:03:32    time: 0.9987  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [ 40/242]  eta: 0:03:24    time: 1.0578  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [ 50/242]  eta: 0:03:15    time: 1.0523  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [ 60/242]  eta: 0:03:08    time: 1.0861  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [ 70/242]  eta: 0:02:59    time: 1.0963  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [ 80/242]  eta: 0:02:48    time: 1.0399  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [ 90/242]  eta: 0:02:36    time: 0.9884  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [100/242]  eta: 0:02:26    time: 1.0200  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Test  [110/242]  eta: 0:02:16    time: 1.0371  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [120/242]  eta: 0:02:06    time: 1.0534  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [130/242]  eta: 0:01:55    time: 1.0421  data: 0.0005  max mem: 9586\n",
      "Epoch: [22] Test  [140/242]  eta: 0:01:45    time: 0.9889  data: 0.0005  max mem: 9586\n",
      "Epoch: [22] Test  [150/242]  eta: 0:01:34    time: 0.9969  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [160/242]  eta: 0:01:24    time: 1.0122  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [170/242]  eta: 0:01:14    time: 1.0602  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Test  [180/242]  eta: 0:01:04    time: 1.1182  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Test  [190/242]  eta: 0:00:54    time: 1.1216  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Test  [200/242]  eta: 0:00:43    time: 1.0667  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [210/242]  eta: 0:00:33    time: 1.0406  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [220/242]  eta: 0:00:22    time: 1.0498  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test  [230/242]  eta: 0:00:12    time: 1.0562  data: 0.0004  max mem: 9586\n",
      "Epoch: [22] Test  [240/242]  eta: 0:00:02    time: 1.0168  data: 0.0003  max mem: 9586\n",
      "Epoch: [22] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.2', '97.6', '79.8', '93.5', '89.0', '91.9', '99.0', '93.6', '97.5', '70.3', '95.4', '74.3', '95.4', '95.8', '94.9', '95.9', '80.2', '95.9', '80.7', '93.9', '89.1']\n",
      "IoU: ['95.3', '93.5', '63.0', '89.6', '76.0', '75.1', '95.9', '84.0', '94.1', '49.4', '91.8', '65.5', '89.0', '89.1', '90.1', '90.6', '69.9', '89.2', '60.8', '90.4', '81.1']\n",
      "mean IoU: 82.1\n",
      "Epoch: [23] Train  [  0/183]  eta: 0:39:04  lr: 0.000047  loss: 0.4063 (0.4063)  time: 12.8118  data: 0.4265  max mem: 9586\n",
      "Epoch: [23] Train  [ 10/183]  eta: 0:35:29  lr: 0.000047  loss: 0.4989 (0.4611)  time: 12.3106  data: 0.0391  max mem: 9586\n",
      "Epoch: [23] Train  [ 20/183]  eta: 0:33:24  lr: 0.000047  loss: 0.3690 (0.4694)  time: 12.2731  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Train  [ 30/183]  eta: 0:31:20  lr: 0.000047  loss: 0.2698 (0.4793)  time: 12.2753  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Train  [ 40/183]  eta: 0:29:19  lr: 0.000047  loss: 0.1894 (0.4953)  time: 12.3088  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Train  [ 50/183]  eta: 0:27:15  lr: 0.000047  loss: 0.2494 (0.4938)  time: 12.3120  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Train  [ 60/183]  eta: 0:25:14  lr: 0.000047  loss: 0.5195 (0.4965)  time: 12.3304  data: 0.0005  max mem: 9586\n",
      "Epoch: [23] Train  [ 70/183]  eta: 0:23:12  lr: 0.000046  loss: 0.8136 (0.4973)  time: 12.3978  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Train  [ 80/183]  eta: 0:21:09  lr: 0.000046  loss: 0.4454 (0.4872)  time: 12.3806  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Train  [ 90/183]  eta: 0:19:08  lr: 0.000046  loss: 0.2984 (0.4804)  time: 12.4122  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Train  [100/183]  eta: 0:17:03  lr: 0.000046  loss: 0.4618 (0.4925)  time: 12.3515  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Train  [110/183]  eta: 0:14:59  lr: 0.000046  loss: 0.3826 (0.4872)  time: 12.2470  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Train  [120/183]  eta: 0:12:56  lr: 0.000046  loss: 0.3802 (0.4841)  time: 12.3233  data: 0.0006  max mem: 9586\n",
      "Epoch: [23] Train  [130/183]  eta: 0:10:53  lr: 0.000046  loss: 0.3713 (0.4774)  time: 12.3370  data: 0.0005  max mem: 9586\n",
      "Epoch: [23] Train  [140/183]  eta: 0:08:49  lr: 0.000045  loss: 0.4924 (0.4850)  time: 12.2679  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Train  [150/183]  eta: 0:06:46  lr: 0.000045  loss: 0.5316 (0.4822)  time: 12.3124  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Train  [160/183]  eta: 0:04:43  lr: 0.000045  loss: 0.5020 (0.4815)  time: 12.3035  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Train  [170/183]  eta: 0:02:40  lr: 0.000045  loss: 0.9146 (0.4788)  time: 12.3139  data: 0.0006  max mem: 9586\n",
      "Epoch: [23] Train  [180/183]  eta: 0:00:36  lr: 0.000045  loss: 0.3323 (0.4749)  time: 12.3257  data: 0.0005  max mem: 9586\n",
      "Epoch: [23] Train Total time: 0:37:34\n",
      "Epoch: [23] Test  [  0/242]  eta: 0:06:00    time: 1.4894  data: 0.4078  max mem: 9586\n",
      "Epoch: [23] Test  [ 10/242]  eta: 0:03:53    time: 1.0060  data: 0.0374  max mem: 9586\n",
      "Epoch: [23] Test  [ 20/242]  eta: 0:03:35    time: 0.9471  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Test  [ 30/242]  eta: 0:03:32    time: 0.9987  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [ 40/242]  eta: 0:03:25    time: 1.0615  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [ 50/242]  eta: 0:03:16    time: 1.0548  data: 0.0005  max mem: 9586\n",
      "Epoch: [23] Test  [ 60/242]  eta: 0:03:09    time: 1.0865  data: 0.0005  max mem: 9586\n",
      "Epoch: [23] Test  [ 70/242]  eta: 0:02:59    time: 1.0978  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [ 80/242]  eta: 0:02:48    time: 1.0396  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [ 90/242]  eta: 0:02:36    time: 0.9874  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [100/242]  eta: 0:02:27    time: 1.0206  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [110/242]  eta: 0:02:16    time: 1.0400  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [120/242]  eta: 0:02:06    time: 1.0543  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Test  [130/242]  eta: 0:01:55    time: 1.0444  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Test  [140/242]  eta: 0:01:45    time: 0.9930  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Test  [150/242]  eta: 0:01:34    time: 0.9973  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [160/242]  eta: 0:01:24    time: 1.0121  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [170/242]  eta: 0:01:14    time: 1.0605  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [180/242]  eta: 0:01:04    time: 1.1200  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [190/242]  eta: 0:00:54    time: 1.1238  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Test  [200/242]  eta: 0:00:43    time: 1.0686  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [210/242]  eta: 0:00:33    time: 1.0415  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Test  [220/242]  eta: 0:00:22    time: 1.0479  data: 0.0003  max mem: 9586\n",
      "Epoch: [23] Test  [230/242]  eta: 0:00:12    time: 1.0542  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test  [240/242]  eta: 0:00:02    time: 1.0171  data: 0.0004  max mem: 9586\n",
      "Epoch: [23] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.3', '97.1', '76.3', '94.4', '84.8', '92.1', '99.0', '91.6', '98.3', '72.8', '96.1', '73.1', '92.2', '95.9', '94.4', '96.3', '79.5', '95.5', '76.2', '95.8', '90.3']\n",
      "IoU: ['95.4', '94.4', '61.8', '90.5', '76.0', '73.8', '96.4', '85.4', '91.6', '49.3', '92.6', '65.0', '88.1', '89.0', '90.0', '90.6', '69.5', '91.4', '60.9', '90.8', '74.2']\n",
      "mean IoU: 81.8\n",
      "Epoch: [24] Train  [  0/183]  eta: 0:39:17  lr: 0.000045  loss: 0.6572 (0.6572)  time: 12.8798  data: 0.3999  max mem: 9586\n",
      "Epoch: [24] Train  [ 10/183]  eta: 0:36:03  lr: 0.000045  loss: 0.2139 (0.4280)  time: 12.5067  data: 0.0369  max mem: 9586\n",
      "Epoch: [24] Train  [ 20/183]  eta: 0:33:35  lr: 0.000045  loss: 0.3832 (0.4061)  time: 12.3379  data: 0.0006  max mem: 9586\n",
      "Epoch: [24] Train  [ 30/183]  eta: 0:31:26  lr: 0.000044  loss: 0.4924 (0.4285)  time: 12.2340  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Train  [ 40/183]  eta: 0:29:25  lr: 0.000044  loss: 0.3704 (0.4029)  time: 12.3208  data: 0.0006  max mem: 9586\n",
      "Epoch: [24] Train  [ 50/183]  eta: 0:27:21  lr: 0.000044  loss: 0.6802 (0.4108)  time: 12.3671  data: 0.0007  max mem: 9586\n",
      "Epoch: [24] Train  [ 60/183]  eta: 0:25:19  lr: 0.000044  loss: 0.5186 (0.4267)  time: 12.3827  data: 0.0006  max mem: 9586\n",
      "Epoch: [24] Train  [ 70/183]  eta: 0:23:13  lr: 0.000044  loss: 0.6039 (0.4485)  time: 12.2830  data: 0.0007  max mem: 9586\n",
      "Epoch: [24] Train  [ 80/183]  eta: 0:21:08  lr: 0.000044  loss: 0.8009 (0.4495)  time: 12.1905  data: 0.0008  max mem: 9586\n",
      "Epoch: [24] Train  [ 90/183]  eta: 0:19:04  lr: 0.000044  loss: 0.4067 (0.4538)  time: 12.2356  data: 0.0006  max mem: 9586\n",
      "Epoch: [24] Train  [100/183]  eta: 0:17:02  lr: 0.000043  loss: 0.5448 (0.4817)  time: 12.3646  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Train  [110/183]  eta: 0:14:59  lr: 0.000043  loss: 0.0814 (0.4775)  time: 12.4154  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Train  [120/183]  eta: 0:12:56  lr: 0.000043  loss: 0.3165 (0.4773)  time: 12.3555  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Train  [130/183]  eta: 0:10:53  lr: 0.000043  loss: 1.0484 (0.4790)  time: 12.3270  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Train  [140/183]  eta: 0:08:50  lr: 0.000043  loss: 0.3495 (0.4768)  time: 12.3420  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Train  [150/183]  eta: 0:06:46  lr: 0.000043  loss: 0.3112 (0.4828)  time: 12.2637  data: 0.0006  max mem: 9586\n",
      "Epoch: [24] Train  [160/183]  eta: 0:04:43  lr: 0.000043  loss: 0.2644 (0.4768)  time: 12.2509  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Train  [170/183]  eta: 0:02:40  lr: 0.000042  loss: 0.3788 (0.4801)  time: 12.3213  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Train  [180/183]  eta: 0:00:36  lr: 0.000042  loss: 0.4095 (0.4802)  time: 12.3138  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Train Total time: 0:37:34\n",
      "Epoch: [24] Test  [  0/242]  eta: 0:06:06    time: 1.5141  data: 0.4221  max mem: 9586\n",
      "Epoch: [24] Test  [ 10/242]  eta: 0:03:54    time: 1.0103  data: 0.0391  max mem: 9586\n",
      "Epoch: [24] Test  [ 20/242]  eta: 0:03:36    time: 0.9499  data: 0.0007  max mem: 9586\n",
      "Epoch: [24] Test  [ 30/242]  eta: 0:03:33    time: 1.0026  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Test  [ 40/242]  eta: 0:03:25    time: 1.0642  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [ 50/242]  eta: 0:03:16    time: 1.0567  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [ 60/242]  eta: 0:03:09    time: 1.0893  data: 0.0003  max mem: 9586\n",
      "Epoch: [24] Test  [ 70/242]  eta: 0:02:59    time: 1.0986  data: 0.0003  max mem: 9586\n",
      "Epoch: [24] Test  [ 80/242]  eta: 0:02:48    time: 1.0403  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [ 90/242]  eta: 0:02:37    time: 0.9903  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [100/242]  eta: 0:02:27    time: 1.0243  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Test  [110/242]  eta: 0:02:16    time: 1.0401  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Test  [120/242]  eta: 0:02:06    time: 1.0523  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Test  [130/242]  eta: 0:01:56    time: 1.0438  data: 0.0005  max mem: 9586\n",
      "Epoch: [24] Test  [140/242]  eta: 0:01:45    time: 0.9930  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [150/242]  eta: 0:01:34    time: 0.9981  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [160/242]  eta: 0:01:24    time: 1.0115  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [170/242]  eta: 0:01:14    time: 1.0619  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [180/242]  eta: 0:01:04    time: 1.1243  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [190/242]  eta: 0:00:54    time: 1.1270  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test  [200/242]  eta: 0:00:43    time: 1.0729  data: 0.0003  max mem: 9586\n",
      "Epoch: [24] Test  [210/242]  eta: 0:00:33    time: 1.0446  data: 0.0003  max mem: 9586\n",
      "Epoch: [24] Test  [220/242]  eta: 0:00:22    time: 1.0489  data: 0.0003  max mem: 9586\n",
      "Epoch: [24] Test  [230/242]  eta: 0:00:12    time: 1.0571  data: 0.0003  max mem: 9586\n",
      "Epoch: [24] Test  [240/242]  eta: 0:00:02    time: 1.0198  data: 0.0004  max mem: 9586\n",
      "Epoch: [24] Test Total time: 0:04:11\n",
      "global correct: 95.8\n",
      "average row correct: ['97.1', '97.5', '80.3', '95.8', '86.8', '90.5', '99.2', '93.9', '98.6', '73.2', '95.5', '74.0', '95.1', '96.4', '92.7', '95.8', '75.5', '96.4', '78.1', '96.3', '89.7']\n",
      "IoU: ['95.3', '94.4', '62.0', '90.9', '74.8', '77.7', '95.7', '83.9', '91.8', '49.1', '91.8', '64.9', '87.9', '89.7', '89.3', '90.6', '67.8', '88.7', '60.7', '90.4', '76.4']\n",
      "mean IoU: 81.6\n",
      "Epoch: [25] Train  [  0/183]  eta: 0:37:26  lr: 0.000042  loss: 0.4141 (0.4141)  time: 12.2738  data: 0.4382  max mem: 9586\n",
      "Epoch: [25] Train  [ 10/183]  eta: 0:35:28  lr: 0.000042  loss: 0.5052 (0.5568)  time: 12.3006  data: 0.0401  max mem: 9586\n",
      "Epoch: [25] Train  [ 20/183]  eta: 0:33:33  lr: 0.000042  loss: 0.4071 (0.5234)  time: 12.3541  data: 0.0004  max mem: 9586\n",
      "Epoch: [25] Train  [ 30/183]  eta: 0:31:35  lr: 0.000042  loss: 0.4024 (0.4939)  time: 12.4423  data: 0.0005  max mem: 9586\n",
      "Epoch: [25] Train  [ 40/183]  eta: 0:29:29  lr: 0.000042  loss: 0.3884 (0.4807)  time: 12.3969  data: 0.0004  max mem: 9586\n",
      "Epoch: [25] Train  [ 50/183]  eta: 0:27:27  lr: 0.000042  loss: 0.6688 (0.5210)  time: 12.3755  data: 0.0004  max mem: 9586\n",
      "Epoch: [25] Train  [ 60/183]  eta: 0:25:20  lr: 0.000041  loss: 0.2594 (0.4992)  time: 12.3406  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Train  [ 70/183]  eta: 0:23:13  lr: 0.000041  loss: 0.2631 (0.4890)  time: 12.1885  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Train  [ 80/183]  eta: 0:21:06  lr: 0.000041  loss: 0.3021 (0.4833)  time: 12.0751  data: 0.0002  max mem: 9586\n",
      "Epoch: [25] Train  [ 90/183]  eta: 0:19:02  lr: 0.000041  loss: 1.3217 (0.5030)  time: 12.1491  data: 0.0002  max mem: 9586\n",
      "Epoch: [25] Train  [100/183]  eta: 0:17:00  lr: 0.000041  loss: 0.4563 (0.4949)  time: 12.3241  data: 0.0006  max mem: 9586\n",
      "Epoch: [25] Train  [110/183]  eta: 0:14:58  lr: 0.000041  loss: 0.6355 (0.4935)  time: 12.3542  data: 0.0005  max mem: 9586\n",
      "Epoch: [25] Train  [120/183]  eta: 0:12:55  lr: 0.000041  loss: 0.3232 (0.4850)  time: 12.3534  data: 0.0002  max mem: 9586\n",
      "Epoch: [25] Train  [130/183]  eta: 0:10:52  lr: 0.000040  loss: 0.3622 (0.4839)  time: 12.3126  data: 0.0005  max mem: 9586\n",
      "Epoch: [25] Train  [140/183]  eta: 0:08:49  lr: 0.000040  loss: 0.3289 (0.4788)  time: 12.2951  data: 0.0005  max mem: 9586\n",
      "Epoch: [25] Train  [150/183]  eta: 0:06:46  lr: 0.000040  loss: 0.4738 (0.4750)  time: 12.3206  data: 0.0005  max mem: 9586\n",
      "Epoch: [25] Train  [160/183]  eta: 0:04:42  lr: 0.000040  loss: 0.6097 (0.4778)  time: 12.2865  data: 0.0006  max mem: 9586\n",
      "Epoch: [25] Train  [170/183]  eta: 0:02:39  lr: 0.000040  loss: 0.7047 (0.4854)  time: 12.2577  data: 0.0004  max mem: 9586\n",
      "Epoch: [25] Train  [180/183]  eta: 0:00:36  lr: 0.000040  loss: 0.3090 (0.4915)  time: 12.2495  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Train Total time: 0:37:31\n",
      "Epoch: [25] Test  [  0/242]  eta: 0:05:58    time: 1.4812  data: 0.4030  max mem: 9586\n",
      "Epoch: [25] Test  [ 10/242]  eta: 0:03:53    time: 1.0081  data: 0.0369  max mem: 9586\n",
      "Epoch: [25] Test  [ 20/242]  eta: 0:03:36    time: 0.9519  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [ 30/242]  eta: 0:03:33    time: 1.0033  data: 0.0002  max mem: 9586\n",
      "Epoch: [25] Test  [ 40/242]  eta: 0:03:25    time: 1.0625  data: 0.0002  max mem: 9586\n",
      "Epoch: [25] Test  [ 50/242]  eta: 0:03:17    time: 1.0589  data: 0.0002  max mem: 9586\n",
      "Epoch: [25] Test  [ 60/242]  eta: 0:03:09    time: 1.0930  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [ 70/242]  eta: 0:03:00    time: 1.1011  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [ 80/242]  eta: 0:02:48    time: 1.0419  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [ 90/242]  eta: 0:02:37    time: 0.9902  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [100/242]  eta: 0:02:27    time: 1.0251  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [110/242]  eta: 0:02:16    time: 1.0420  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [120/242]  eta: 0:02:07    time: 1.0560  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [130/242]  eta: 0:01:56    time: 1.0458  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [140/242]  eta: 0:01:45    time: 0.9930  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [150/242]  eta: 0:01:34    time: 0.9992  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [160/242]  eta: 0:01:24    time: 1.0149  data: 0.0002  max mem: 9586\n",
      "Epoch: [25] Test  [170/242]  eta: 0:01:14    time: 1.0658  data: 0.0002  max mem: 9586\n",
      "Epoch: [25] Test  [180/242]  eta: 0:01:04    time: 1.1243  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [190/242]  eta: 0:00:54    time: 1.1275  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [200/242]  eta: 0:00:43    time: 1.0757  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [210/242]  eta: 0:00:33    time: 1.0460  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [220/242]  eta: 0:00:23    time: 1.0493  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [230/242]  eta: 0:00:12    time: 1.0583  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test  [240/242]  eta: 0:00:02    time: 1.0223  data: 0.0003  max mem: 9586\n",
      "Epoch: [25] Test Total time: 0:04:12\n",
      "global correct: 95.9\n",
      "average row correct: ['97.1', '97.8', '80.6', '95.3', '88.6', '90.4', '99.2', '93.2', '97.9', '71.1', '96.1', '72.8', '96.4', '92.3', '94.6', '96.3', '77.3', '96.6', '82.4', '95.8', '89.6']\n",
      "IoU: ['95.3', '94.2', '64.4', '90.2', '75.8', '76.9', '95.7', '84.6', '93.5', '50.1', '89.2', '64.9', '90.3', '88.5', '90.3', '90.6', '68.4', '84.6', '61.6', '90.6', '77.2']\n",
      "mean IoU: 81.8\n",
      "Epoch: [26] Train  [  0/183]  eta: 0:39:12  lr: 0.000040  loss: 0.4853 (0.4853)  time: 12.8530  data: 0.4114  max mem: 9586\n",
      "Epoch: [26] Train  [ 10/183]  eta: 0:35:25  lr: 0.000040  loss: 0.4944 (0.4547)  time: 12.2841  data: 0.0376  max mem: 9586\n",
      "Epoch: [26] Train  [ 20/183]  eta: 0:33:24  lr: 0.000039  loss: 0.2741 (0.4644)  time: 12.2703  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Train  [ 30/183]  eta: 0:31:18  lr: 0.000039  loss: 0.8669 (0.4976)  time: 12.2755  data: 0.0004  max mem: 9586\n",
      "Epoch: [26] Train  [ 40/183]  eta: 0:29:15  lr: 0.000039  loss: 0.4598 (0.4954)  time: 12.2469  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Train  [ 50/183]  eta: 0:27:16  lr: 0.000039  loss: 0.7143 (0.5018)  time: 12.3477  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Train  [ 60/183]  eta: 0:25:15  lr: 0.000039  loss: 0.4273 (0.4804)  time: 12.4172  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Train  [ 70/183]  eta: 0:23:12  lr: 0.000039  loss: 0.0528 (0.4675)  time: 12.3564  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Train  [ 80/183]  eta: 0:21:09  lr: 0.000039  loss: 0.3448 (0.4748)  time: 12.3495  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Train  [ 90/183]  eta: 0:19:07  lr: 0.000038  loss: 1.0099 (0.4862)  time: 12.4116  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Train  [100/183]  eta: 0:17:03  lr: 0.000038  loss: 0.4192 (0.4732)  time: 12.3484  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Train  [110/183]  eta: 0:14:59  lr: 0.000038  loss: 0.4588 (0.4746)  time: 12.2389  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Train  [120/183]  eta: 0:12:55  lr: 0.000038  loss: 0.2839 (0.4737)  time: 12.2344  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Train  [130/183]  eta: 0:10:52  lr: 0.000038  loss: 0.2189 (0.4706)  time: 12.2579  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Train  [140/183]  eta: 0:08:48  lr: 0.000038  loss: 0.2885 (0.4715)  time: 12.2107  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Train  [150/183]  eta: 0:06:45  lr: 0.000038  loss: 0.2896 (0.4768)  time: 12.1702  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Train  [160/183]  eta: 0:04:42  lr: 0.000038  loss: 0.4806 (0.4747)  time: 12.2916  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Train  [170/183]  eta: 0:02:39  lr: 0.000037  loss: 0.8888 (0.4755)  time: 12.3072  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Train  [180/183]  eta: 0:00:36  lr: 0.000037  loss: 0.5867 (0.4803)  time: 12.2384  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Train Total time: 0:37:29\n",
      "Epoch: [26] Test  [  0/242]  eta: 0:06:08    time: 1.5220  data: 0.4328  max mem: 9586\n",
      "Epoch: [26] Test  [ 10/242]  eta: 0:03:54    time: 1.0109  data: 0.0396  max mem: 9586\n",
      "Epoch: [26] Test  [ 20/242]  eta: 0:03:36    time: 0.9494  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [ 30/242]  eta: 0:03:32    time: 0.9992  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [ 40/242]  eta: 0:03:25    time: 1.0607  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [ 50/242]  eta: 0:03:16    time: 1.0538  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [ 60/242]  eta: 0:03:09    time: 1.0863  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [ 70/242]  eta: 0:02:59    time: 1.0972  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [ 80/242]  eta: 0:02:48    time: 1.0394  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [ 90/242]  eta: 0:02:36    time: 0.9888  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [100/242]  eta: 0:02:27    time: 1.0215  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [110/242]  eta: 0:02:16    time: 1.0404  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [120/242]  eta: 0:02:06    time: 1.0554  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [130/242]  eta: 0:01:55    time: 1.0461  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [140/242]  eta: 0:01:45    time: 0.9938  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [150/242]  eta: 0:01:34    time: 0.9978  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [160/242]  eta: 0:01:24    time: 1.0119  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [170/242]  eta: 0:01:14    time: 1.0627  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [180/242]  eta: 0:01:04    time: 1.1229  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [190/242]  eta: 0:00:54    time: 1.1256  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test  [200/242]  eta: 0:00:43    time: 1.0704  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [210/242]  eta: 0:00:33    time: 1.0428  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [220/242]  eta: 0:00:22    time: 1.0503  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [230/242]  eta: 0:00:12    time: 1.0572  data: 0.0002  max mem: 9586\n",
      "Epoch: [26] Test  [240/242]  eta: 0:00:02    time: 1.0188  data: 0.0003  max mem: 9586\n",
      "Epoch: [26] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.1', '97.5', '80.9', '95.3', '87.1', '92.5', '98.9', '93.0', '98.2', '69.6', '95.2', '74.4', '95.0', '95.5', '94.6', '95.7', '80.7', '96.2', '82.2', '96.0', '90.3']\n",
      "IoU: ['95.3', '95.0', '63.8', '90.7', '74.3', '76.7', '95.7', '85.5', '92.6', '50.4', '90.7', '64.9', '89.3', '89.6', '90.2', '90.7', '69.4', '88.1', '61.7', '89.7', '74.9']\n",
      "mean IoU: 81.9\n",
      "Epoch: [27] Train  [  0/183]  eta: 0:38:14  lr: 0.000037  loss: 0.4173 (0.4173)  time: 12.5381  data: 0.3745  max mem: 9586\n",
      "Epoch: [27] Train  [ 10/183]  eta: 0:35:21  lr: 0.000037  loss: 0.5168 (0.4652)  time: 12.2626  data: 0.0343  max mem: 9586\n",
      "Epoch: [27] Train  [ 20/183]  eta: 0:33:13  lr: 0.000037  loss: 0.4883 (0.4650)  time: 12.2144  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [ 30/183]  eta: 0:31:06  lr: 0.000037  loss: 0.2940 (0.4784)  time: 12.1658  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [ 40/183]  eta: 0:29:04  lr: 0.000037  loss: 0.3080 (0.4524)  time: 12.1625  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [ 50/183]  eta: 0:27:04  lr: 0.000036  loss: 0.7639 (0.4511)  time: 12.2414  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [ 60/183]  eta: 0:25:02  lr: 0.000036  loss: 0.3405 (0.4538)  time: 12.2584  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [ 70/183]  eta: 0:23:00  lr: 0.000036  loss: 0.4533 (0.4488)  time: 12.2039  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [ 80/183]  eta: 0:20:58  lr: 0.000036  loss: 0.8848 (0.4419)  time: 12.2032  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [ 90/183]  eta: 0:18:57  lr: 0.000036  loss: 0.3193 (0.4409)  time: 12.2787  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [100/183]  eta: 0:16:55  lr: 0.000036  loss: 0.7813 (0.4479)  time: 12.3207  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [110/183]  eta: 0:14:52  lr: 0.000036  loss: 0.0922 (0.4591)  time: 12.2508  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [120/183]  eta: 0:12:50  lr: 0.000035  loss: 0.8724 (0.4653)  time: 12.2096  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Train  [130/183]  eta: 0:10:48  lr: 0.000035  loss: 0.6231 (0.4601)  time: 12.3089  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Train  [140/183]  eta: 0:08:46  lr: 0.000035  loss: 0.5931 (0.4661)  time: 12.3429  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Train  [150/183]  eta: 0:06:43  lr: 0.000035  loss: 0.4461 (0.4658)  time: 12.2323  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Train  [160/183]  eta: 0:04:41  lr: 0.000035  loss: 0.4663 (0.4695)  time: 12.2153  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [170/183]  eta: 0:02:39  lr: 0.000035  loss: 0.5835 (0.4709)  time: 12.2743  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train  [180/183]  eta: 0:00:36  lr: 0.000035  loss: 0.8791 (0.4697)  time: 12.3070  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Train Total time: 0:37:21\n",
      "Epoch: [27] Test  [  0/242]  eta: 0:05:46    time: 1.4321  data: 0.3558  max mem: 9586\n",
      "Epoch: [27] Test  [ 10/242]  eta: 0:03:51    time: 0.9992  data: 0.0326  max mem: 9586\n",
      "Epoch: [27] Test  [ 20/242]  eta: 0:03:35    time: 0.9484  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [ 30/242]  eta: 0:03:31    time: 1.0003  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Test  [ 40/242]  eta: 0:03:25    time: 1.0615  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Test  [ 50/242]  eta: 0:03:16    time: 1.0563  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [ 60/242]  eta: 0:03:09    time: 1.0882  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [ 70/242]  eta: 0:02:59    time: 1.0972  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Test  [ 80/242]  eta: 0:02:48    time: 1.0391  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Test  [ 90/242]  eta: 0:02:36    time: 0.9886  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [100/242]  eta: 0:02:27    time: 1.0210  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [110/242]  eta: 0:02:16    time: 1.0403  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [120/242]  eta: 0:02:06    time: 1.0546  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [130/242]  eta: 0:01:55    time: 1.0419  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [140/242]  eta: 0:01:45    time: 0.9918  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [150/242]  eta: 0:01:34    time: 1.0002  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Test  [160/242]  eta: 0:01:24    time: 1.0140  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Test  [170/242]  eta: 0:01:14    time: 1.0639  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [180/242]  eta: 0:01:04    time: 1.1242  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Test  [190/242]  eta: 0:00:54    time: 1.1259  data: 0.0002  max mem: 9586\n",
      "Epoch: [27] Test  [200/242]  eta: 0:00:43    time: 1.0709  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [210/242]  eta: 0:00:33    time: 1.0437  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [220/242]  eta: 0:00:22    time: 1.0509  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [230/242]  eta: 0:00:12    time: 1.0580  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test  [240/242]  eta: 0:00:02    time: 1.0187  data: 0.0003  max mem: 9586\n",
      "Epoch: [27] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.1', '97.9', '77.8', '96.0', '85.8', '92.2', '99.0', '92.2', '98.3', '73.5', '94.8', '73.8', '93.9', '96.3', '95.4', '95.8', '76.1', '96.5', '81.0', '96.5', '90.1']\n",
      "IoU: ['95.3', '93.2', '63.7', '90.9', '75.8', '74.5', '96.2', '86.1', '91.8', '48.5', '91.8', '66.2', '89.1', '90.7', '90.8', '91.0', '68.7', '86.0', '60.9', '88.9', '78.4']\n",
      "mean IoU: 81.8\n",
      "Epoch: [28] Train  [  0/183]  eta: 0:38:37  lr: 0.000035  loss: 0.6284 (0.6284)  time: 12.6622  data: 0.3972  max mem: 9586\n",
      "Epoch: [28] Train  [ 10/183]  eta: 0:35:36  lr: 0.000034  loss: 0.5048 (0.4729)  time: 12.3477  data: 0.0363  max mem: 9586\n",
      "Epoch: [28] Train  [ 20/183]  eta: 0:33:19  lr: 0.000034  loss: 0.4556 (0.4544)  time: 12.2495  data: 0.0002  max mem: 9586\n",
      "Epoch: [28] Train  [ 30/183]  eta: 0:31:13  lr: 0.000034  loss: 0.4039 (0.4518)  time: 12.1902  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [ 40/183]  eta: 0:29:04  lr: 0.000034  loss: 0.3099 (0.4430)  time: 12.1306  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [ 50/183]  eta: 0:27:03  lr: 0.000034  loss: 0.5520 (0.4692)  time: 12.1476  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [ 60/183]  eta: 0:25:02  lr: 0.000034  loss: 0.6502 (0.4483)  time: 12.2523  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [ 70/183]  eta: 0:22:59  lr: 0.000034  loss: 0.3901 (0.4556)  time: 12.2247  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [ 80/183]  eta: 0:21:00  lr: 0.000033  loss: 0.6141 (0.4689)  time: 12.2867  data: 0.0002  max mem: 9586\n",
      "Epoch: [28] Train  [ 90/183]  eta: 0:18:57  lr: 0.000033  loss: 0.3318 (0.4594)  time: 12.3062  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [100/183]  eta: 0:16:54  lr: 0.000033  loss: 0.5705 (0.4745)  time: 12.1939  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [110/183]  eta: 0:14:51  lr: 0.000033  loss: 0.5169 (0.4753)  time: 12.1552  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [120/183]  eta: 0:12:49  lr: 0.000033  loss: 0.3769 (0.4735)  time: 12.1860  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [130/183]  eta: 0:10:47  lr: 0.000033  loss: 0.8530 (0.4734)  time: 12.2285  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [140/183]  eta: 0:08:45  lr: 0.000033  loss: 0.2876 (0.4743)  time: 12.2641  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [150/183]  eta: 0:06:43  lr: 0.000032  loss: 0.5276 (0.4688)  time: 12.2791  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [160/183]  eta: 0:04:41  lr: 0.000032  loss: 0.3142 (0.4646)  time: 12.2381  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train  [170/183]  eta: 0:02:38  lr: 0.000032  loss: 0.5217 (0.4765)  time: 12.1744  data: 0.0002  max mem: 9586\n",
      "Epoch: [28] Train  [180/183]  eta: 0:00:36  lr: 0.000032  loss: 0.3941 (0.4699)  time: 12.1931  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Train Total time: 0:37:17\n",
      "Epoch: [28] Test  [  0/242]  eta: 0:05:59    time: 1.4875  data: 0.3956  max mem: 9586\n",
      "Epoch: [28] Test  [ 10/242]  eta: 0:03:53    time: 1.0084  data: 0.0362  max mem: 9586\n",
      "Epoch: [28] Test  [ 20/242]  eta: 0:03:36    time: 0.9501  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [ 30/242]  eta: 0:03:32    time: 1.0011  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [ 40/242]  eta: 0:03:25    time: 1.0625  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [ 50/242]  eta: 0:03:16    time: 1.0573  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [ 60/242]  eta: 0:03:09    time: 1.0909  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [ 70/242]  eta: 0:02:59    time: 1.0998  data: 0.0004  max mem: 9586\n",
      "Epoch: [28] Test  [ 80/242]  eta: 0:02:48    time: 1.0406  data: 0.0004  max mem: 9586\n",
      "Epoch: [28] Test  [ 90/242]  eta: 0:02:37    time: 0.9907  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [100/242]  eta: 0:02:27    time: 1.0243  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [110/242]  eta: 0:02:16    time: 1.0416  data: 0.0002  max mem: 9586\n",
      "Epoch: [28] Test  [120/242]  eta: 0:02:07    time: 1.0560  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [130/242]  eta: 0:01:56    time: 1.0455  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [140/242]  eta: 0:01:45    time: 0.9947  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [150/242]  eta: 0:01:34    time: 1.0005  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [160/242]  eta: 0:01:24    time: 1.0135  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [170/242]  eta: 0:01:14    time: 1.0633  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [180/242]  eta: 0:01:04    time: 1.1240  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [190/242]  eta: 0:00:54    time: 1.1270  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [200/242]  eta: 0:00:43    time: 1.0713  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [210/242]  eta: 0:00:33    time: 1.0438  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [220/242]  eta: 0:00:23    time: 1.0509  data: 0.0003  max mem: 9586\n",
      "Epoch: [28] Test  [230/242]  eta: 0:00:12    time: 1.0586  data: 0.0005  max mem: 9586\n",
      "Epoch: [28] Test  [240/242]  eta: 0:00:02    time: 1.0205  data: 0.0005  max mem: 9586\n",
      "Epoch: [28] Test Total time: 0:04:12\n",
      "global correct: 95.8\n",
      "average row correct: ['97.1', '97.6', '82.0', '94.9', '88.7', '92.5', '99.2', '91.8', '98.5', '72.7', '95.3', '71.9', '92.3', '96.0', '93.6', '96.1', '78.4', '96.2', '77.8', '96.2', '90.7']\n",
      "IoU: ['95.3', '94.3', '62.8', '90.9', '75.4', '74.2', '96.7', '85.0', '89.8', '48.9', '91.4', '64.8', '87.0', '90.0', '89.4', '90.5', '69.1', '88.0', '60.2', '90.3', '73.1']\n",
      "mean IoU: 81.3\n",
      "Epoch: [29] Train  [  0/183]  eta: 0:39:13  lr: 0.000032  loss: 0.6728 (0.6728)  time: 12.8611  data: 0.4178  max mem: 9586\n",
      "Epoch: [29] Train  [ 10/183]  eta: 0:35:25  lr: 0.000032  loss: 0.5775 (0.5366)  time: 12.2840  data: 0.0383  max mem: 9586\n",
      "Epoch: [29] Train  [ 20/183]  eta: 0:33:25  lr: 0.000032  loss: 0.3582 (0.5476)  time: 12.2734  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [ 30/183]  eta: 0:31:25  lr: 0.000032  loss: 0.5023 (0.5333)  time: 12.3463  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [ 40/183]  eta: 0:29:23  lr: 0.000031  loss: 0.2361 (0.4947)  time: 12.3594  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [ 50/183]  eta: 0:27:16  lr: 0.000031  loss: 0.1478 (0.4937)  time: 12.2648  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [ 60/183]  eta: 0:25:12  lr: 0.000031  loss: 0.1776 (0.4964)  time: 12.2277  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [ 70/183]  eta: 0:23:07  lr: 0.000031  loss: 0.4199 (0.4880)  time: 12.2319  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [ 80/183]  eta: 0:21:06  lr: 0.000031  loss: 0.4811 (0.4911)  time: 12.3002  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Train  [ 90/183]  eta: 0:19:03  lr: 0.000031  loss: 0.5811 (0.4853)  time: 12.3522  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Train  [100/183]  eta: 0:17:00  lr: 0.000031  loss: 0.3543 (0.4845)  time: 12.2727  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Train  [110/183]  eta: 0:14:57  lr: 0.000030  loss: 0.3992 (0.4977)  time: 12.2808  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [120/183]  eta: 0:12:54  lr: 0.000030  loss: 0.3439 (0.5016)  time: 12.2775  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Train  [130/183]  eta: 0:10:51  lr: 0.000030  loss: 0.3057 (0.5009)  time: 12.2464  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Train  [140/183]  eta: 0:08:48  lr: 0.000030  loss: 0.3338 (0.4896)  time: 12.3019  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Train  [150/183]  eta: 0:06:45  lr: 0.000030  loss: 0.4145 (0.4869)  time: 12.3406  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [160/183]  eta: 0:04:42  lr: 0.000030  loss: 0.4817 (0.4830)  time: 12.2831  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [170/183]  eta: 0:02:39  lr: 0.000030  loss: 0.2586 (0.4807)  time: 12.2219  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train  [180/183]  eta: 0:00:36  lr: 0.000029  loss: 0.4323 (0.4841)  time: 12.2621  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Train Total time: 0:37:28\n",
      "Epoch: [29] Test  [  0/242]  eta: 0:05:54    time: 1.4662  data: 0.3876  max mem: 9586\n",
      "Epoch: [29] Test  [ 10/242]  eta: 0:03:52    time: 1.0033  data: 0.0354  max mem: 9586\n",
      "Epoch: [29] Test  [ 20/242]  eta: 0:03:36    time: 0.9487  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [ 30/242]  eta: 0:03:32    time: 1.0007  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [ 40/242]  eta: 0:03:25    time: 1.0619  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [ 50/242]  eta: 0:03:16    time: 1.0564  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [ 60/242]  eta: 0:03:09    time: 1.0888  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [ 70/242]  eta: 0:02:59    time: 1.0997  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [ 80/242]  eta: 0:02:48    time: 1.0417  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [ 90/242]  eta: 0:02:36    time: 0.9890  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [100/242]  eta: 0:02:27    time: 1.0211  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [110/242]  eta: 0:02:16    time: 1.0403  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [120/242]  eta: 0:02:06    time: 1.0534  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [130/242]  eta: 0:01:55    time: 1.0411  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [140/242]  eta: 0:01:45    time: 0.9907  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [150/242]  eta: 0:01:34    time: 0.9997  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [160/242]  eta: 0:01:24    time: 1.0150  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [170/242]  eta: 0:01:14    time: 1.0625  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [180/242]  eta: 0:01:04    time: 1.1221  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [190/242]  eta: 0:00:54    time: 1.1252  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [200/242]  eta: 0:00:43    time: 1.0687  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [210/242]  eta: 0:00:33    time: 1.0399  data: 0.0003  max mem: 9586\n",
      "Epoch: [29] Test  [220/242]  eta: 0:00:22    time: 1.0503  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [230/242]  eta: 0:00:12    time: 1.0598  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test  [240/242]  eta: 0:00:02    time: 1.0204  data: 0.0002  max mem: 9586\n",
      "Epoch: [29] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.4', '97.5', '80.7', '93.2', '84.6', '92.1', '99.0', '91.7', '98.2', '70.9', '95.6', '68.9', '95.7', '96.6', '93.8', '95.7', '76.8', '96.2', '78.4', '95.3', '89.4']\n",
      "IoU: ['95.4', '94.8', '65.2', '89.5', '75.3', '74.8', '96.1', '86.3', '93.2', '50.6', '91.5', '63.9', '88.2', '90.0', '89.7', '90.5', '68.4', '88.7', '60.0', '90.4', '78.6']\n",
      "mean IoU: 81.9\n",
      "Epoch: [30] Train  [  0/183]  eta: 0:39:05  lr: 0.000029  loss: 0.4942 (0.4942)  time: 12.8149  data: 0.4169  max mem: 9586\n",
      "Epoch: [30] Train  [ 10/183]  eta: 0:35:40  lr: 0.000029  loss: 0.2712 (0.4193)  time: 12.3702  data: 0.0381  max mem: 9586\n",
      "Epoch: [30] Train  [ 20/183]  eta: 0:33:23  lr: 0.000029  loss: 0.0680 (0.3732)  time: 12.2638  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [ 30/183]  eta: 0:31:24  lr: 0.000029  loss: 0.2817 (0.3810)  time: 12.2914  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [ 40/183]  eta: 0:29:22  lr: 0.000029  loss: 0.7189 (0.4352)  time: 12.3665  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [ 50/183]  eta: 0:27:20  lr: 0.000029  loss: 0.5562 (0.4587)  time: 12.3537  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [ 60/183]  eta: 0:25:14  lr: 0.000028  loss: 0.8875 (0.4573)  time: 12.2749  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [ 70/183]  eta: 0:23:11  lr: 0.000028  loss: 0.5289 (0.4618)  time: 12.2648  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Train  [ 80/183]  eta: 0:21:07  lr: 0.000028  loss: 0.3882 (0.4550)  time: 12.2807  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Train  [ 90/183]  eta: 0:19:04  lr: 0.000028  loss: 0.1781 (0.4535)  time: 12.2648  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Train  [100/183]  eta: 0:17:01  lr: 0.000028  loss: 0.4098 (0.4529)  time: 12.3258  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [110/183]  eta: 0:14:58  lr: 0.000028  loss: 0.2516 (0.4499)  time: 12.3250  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [120/183]  eta: 0:12:54  lr: 0.000028  loss: 0.3698 (0.4569)  time: 12.2695  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Train  [130/183]  eta: 0:10:51  lr: 0.000027  loss: 0.4774 (0.4559)  time: 12.2413  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Train  [140/183]  eta: 0:08:48  lr: 0.000027  loss: 0.5892 (0.4587)  time: 12.2185  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Train  [150/183]  eta: 0:06:45  lr: 0.000027  loss: 0.6337 (0.4537)  time: 12.2657  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Train  [160/183]  eta: 0:04:42  lr: 0.000027  loss: 0.3292 (0.4551)  time: 12.2983  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [170/183]  eta: 0:02:39  lr: 0.000027  loss: 0.5435 (0.4551)  time: 12.2755  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Train  [180/183]  eta: 0:00:36  lr: 0.000027  loss: 0.6274 (0.4556)  time: 12.2633  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Train Total time: 0:37:28\n",
      "Epoch: [30] Test  [  0/242]  eta: 0:06:00    time: 1.4876  data: 0.4042  max mem: 9586\n",
      "Epoch: [30] Test  [ 10/242]  eta: 0:03:53    time: 1.0059  data: 0.0370  max mem: 9586\n",
      "Epoch: [30] Test  [ 20/242]  eta: 0:03:36    time: 0.9473  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Test  [ 30/242]  eta: 0:03:32    time: 0.9984  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [ 40/242]  eta: 0:03:25    time: 1.0598  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [ 50/242]  eta: 0:03:16    time: 1.0552  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Test  [ 60/242]  eta: 0:03:09    time: 1.0879  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Test  [ 70/242]  eta: 0:02:59    time: 1.0973  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [ 80/242]  eta: 0:02:48    time: 1.0403  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [ 90/242]  eta: 0:02:36    time: 0.9898  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [100/242]  eta: 0:02:27    time: 1.0246  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [110/242]  eta: 0:02:16    time: 1.0425  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [120/242]  eta: 0:02:06    time: 1.0547  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [130/242]  eta: 0:01:55    time: 1.0427  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Test  [140/242]  eta: 0:01:45    time: 0.9925  data: 0.0002  max mem: 9586\n",
      "Epoch: [30] Test  [150/242]  eta: 0:01:34    time: 0.9993  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [160/242]  eta: 0:01:24    time: 1.0141  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [170/242]  eta: 0:01:14    time: 1.0641  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [180/242]  eta: 0:01:04    time: 1.1216  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [190/242]  eta: 0:00:54    time: 1.1243  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [200/242]  eta: 0:00:43    time: 1.0694  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [210/242]  eta: 0:00:33    time: 1.0408  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [220/242]  eta: 0:00:22    time: 1.0497  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [230/242]  eta: 0:00:12    time: 1.0591  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test  [240/242]  eta: 0:00:02    time: 1.0195  data: 0.0003  max mem: 9586\n",
      "Epoch: [30] Test Total time: 0:04:11\n",
      "global correct: 95.8\n",
      "average row correct: ['97.0', '97.7', '80.9', '96.1', '89.8', '91.1', '99.2', '92.7', '98.2', '72.5', '96.6', '73.0', '93.4', '94.7', '94.6', '96.1', '80.1', '96.4', '80.1', '97.2', '90.4']\n",
      "IoU: ['95.2', '93.7', '64.3', '90.3', '76.5', '76.2', '96.0', '85.4', '92.2', '49.3', '90.5', '64.8', '88.4', '87.9', '90.2', '90.8', '70.0', '88.1', '60.7', '87.6', '74.2']\n",
      "mean IoU: 81.5\n",
      "Epoch: [31] Train  [  0/183]  eta: 0:38:27  lr: 0.000027  loss: 0.1282 (0.1282)  time: 12.6087  data: 0.4396  max mem: 9586\n",
      "Epoch: [31] Train  [ 10/183]  eta: 0:35:37  lr: 0.000027  loss: 0.2494 (0.5169)  time: 12.3563  data: 0.0401  max mem: 9586\n",
      "Epoch: [31] Train  [ 20/183]  eta: 0:33:24  lr: 0.000026  loss: 0.4366 (0.4984)  time: 12.2796  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [ 30/183]  eta: 0:31:14  lr: 0.000026  loss: 0.2968 (0.5062)  time: 12.1926  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Train  [ 40/183]  eta: 0:29:14  lr: 0.000026  loss: 0.8992 (0.4965)  time: 12.2454  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Train  [ 50/183]  eta: 0:27:16  lr: 0.000026  loss: 0.8243 (0.5086)  time: 12.3805  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Train  [ 60/183]  eta: 0:25:09  lr: 0.000026  loss: 0.1137 (0.5017)  time: 12.2781  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Train  [ 70/183]  eta: 0:23:05  lr: 0.000026  loss: 0.5767 (0.4833)  time: 12.1726  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Train  [ 80/183]  eta: 0:21:02  lr: 0.000026  loss: 0.5070 (0.4856)  time: 12.1936  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [ 90/183]  eta: 0:19:00  lr: 0.000025  loss: 0.6386 (0.4849)  time: 12.2637  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Train  [100/183]  eta: 0:16:58  lr: 0.000025  loss: 0.5949 (0.4794)  time: 12.3347  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [110/183]  eta: 0:14:54  lr: 0.000025  loss: 0.6278 (0.4843)  time: 12.2081  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [120/183]  eta: 0:12:52  lr: 0.000025  loss: 0.1824 (0.4759)  time: 12.2297  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [130/183]  eta: 0:10:49  lr: 0.000025  loss: 0.7402 (0.4780)  time: 12.2919  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [140/183]  eta: 0:08:47  lr: 0.000025  loss: 0.5259 (0.4812)  time: 12.3433  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [150/183]  eta: 0:06:44  lr: 0.000025  loss: 0.7908 (0.4806)  time: 12.2881  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [160/183]  eta: 0:04:42  lr: 0.000024  loss: 0.3519 (0.4818)  time: 12.2283  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Train  [170/183]  eta: 0:02:39  lr: 0.000024  loss: 0.1673 (0.4830)  time: 12.3859  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Train  [180/183]  eta: 0:00:36  lr: 0.000024  loss: 0.5222 (0.4881)  time: 12.3043  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Train Total time: 0:37:26\n",
      "Epoch: [31] Test  [  0/242]  eta: 0:05:54    time: 1.4630  data: 0.3899  max mem: 9586\n",
      "Epoch: [31] Test  [ 10/242]  eta: 0:03:52    time: 1.0030  data: 0.0356  max mem: 9586\n",
      "Epoch: [31] Test  [ 20/242]  eta: 0:03:35    time: 0.9475  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Test  [ 30/242]  eta: 0:03:32    time: 1.0000  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [ 40/242]  eta: 0:03:25    time: 1.0613  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [ 50/242]  eta: 0:03:16    time: 1.0556  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Test  [ 60/242]  eta: 0:03:09    time: 1.0867  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [ 70/242]  eta: 0:02:59    time: 1.0955  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [ 80/242]  eta: 0:02:48    time: 1.0381  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [ 90/242]  eta: 0:02:36    time: 0.9874  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [100/242]  eta: 0:02:27    time: 1.0231  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [110/242]  eta: 0:02:16    time: 1.0426  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [120/242]  eta: 0:02:06    time: 1.0547  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [130/242]  eta: 0:01:55    time: 1.0436  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [140/242]  eta: 0:01:45    time: 0.9953  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [150/242]  eta: 0:01:34    time: 1.0021  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [160/242]  eta: 0:01:24    time: 1.0143  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [170/242]  eta: 0:01:14    time: 1.0623  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [180/242]  eta: 0:01:04    time: 1.1211  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [190/242]  eta: 0:00:54    time: 1.1237  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Test  [200/242]  eta: 0:00:43    time: 1.0702  data: 0.0002  max mem: 9586\n",
      "Epoch: [31] Test  [210/242]  eta: 0:00:33    time: 1.0442  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [220/242]  eta: 0:00:22    time: 1.0508  data: 0.0003  max mem: 9586\n",
      "Epoch: [31] Test  [230/242]  eta: 0:00:12    time: 1.0586  data: 0.0004  max mem: 9586\n",
      "Epoch: [31] Test  [240/242]  eta: 0:00:02    time: 1.0203  data: 0.0004  max mem: 9586\n",
      "Epoch: [31] Test Total time: 0:04:11\n",
      "global correct: 95.9\n",
      "average row correct: ['97.1', '97.9', '82.5', '95.9', '90.3', '90.8', '99.2', '91.8', '98.0', '74.5', '95.8', '74.5', '95.7', '96.1', '93.9', '96.2', '77.2', '96.4', '79.0', '95.9', '90.2']\n",
      "IoU: ['95.4', '94.3', '66.0', '90.5', '75.0', '77.8', '95.9', '85.0', '92.7', '48.2', '91.8', '66.0', '89.8', '90.8', '89.8', '90.8', '68.3', '88.3', '60.4', '91.2', '75.3']\n",
      "mean IoU: 82.1\n",
      "Epoch: [32] Train  [  0/183]  eta: 0:39:04  lr: 0.000024  loss: 0.3449 (0.3449)  time: 12.8109  data: 0.3710  max mem: 9586\n",
      "Epoch: [32] Train  [ 10/183]  eta: 0:35:35  lr: 0.000024  loss: 0.7470 (0.4287)  time: 12.3413  data: 0.0340  max mem: 9586\n",
      "Epoch: [32] Train  [ 20/183]  eta: 0:33:18  lr: 0.000024  loss: 0.1825 (0.4366)  time: 12.2328  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Train  [ 30/183]  eta: 0:31:16  lr: 0.000024  loss: 0.2524 (0.4387)  time: 12.2220  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [ 40/183]  eta: 0:29:16  lr: 0.000023  loss: 0.8843 (0.4240)  time: 12.3079  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [ 50/183]  eta: 0:27:10  lr: 0.000023  loss: 0.2933 (0.4135)  time: 12.2498  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [ 60/183]  eta: 0:25:09  lr: 0.000023  loss: 0.5716 (0.4303)  time: 12.2419  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [ 70/183]  eta: 0:23:06  lr: 0.000023  loss: 0.1627 (0.4307)  time: 12.3059  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [ 80/183]  eta: 0:21:06  lr: 0.000023  loss: 0.2527 (0.4298)  time: 12.3733  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [ 90/183]  eta: 0:19:02  lr: 0.000023  loss: 0.8462 (0.4271)  time: 12.3292  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [100/183]  eta: 0:16:59  lr: 0.000023  loss: 0.1495 (0.4250)  time: 12.2337  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Train  [110/183]  eta: 0:14:56  lr: 0.000022  loss: 0.7357 (0.4379)  time: 12.2434  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Train  [120/183]  eta: 0:12:53  lr: 0.000022  loss: 0.4164 (0.4346)  time: 12.2680  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [130/183]  eta: 0:10:51  lr: 0.000022  loss: 0.2113 (0.4351)  time: 12.3208  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [140/183]  eta: 0:08:48  lr: 0.000022  loss: 0.6073 (0.4495)  time: 12.2887  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [150/183]  eta: 0:06:45  lr: 0.000022  loss: 0.3788 (0.4451)  time: 12.2693  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [160/183]  eta: 0:04:42  lr: 0.000022  loss: 0.5621 (0.4435)  time: 12.3130  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Train  [170/183]  eta: 0:02:39  lr: 0.000021  loss: 0.5318 (0.4403)  time: 12.2614  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Train  [180/183]  eta: 0:00:36  lr: 0.000021  loss: 0.3770 (0.4416)  time: 12.2425  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Train Total time: 0:37:27\n",
      "Epoch: [32] Test  [  0/242]  eta: 0:05:56    time: 1.4715  data: 0.3832  max mem: 9586\n",
      "Epoch: [32] Test  [ 10/242]  eta: 0:03:52    time: 1.0037  data: 0.0351  max mem: 9586\n",
      "Epoch: [32] Test  [ 20/242]  eta: 0:03:35    time: 0.9476  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [ 30/242]  eta: 0:03:32    time: 0.9993  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [ 40/242]  eta: 0:03:25    time: 1.0627  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [ 50/242]  eta: 0:03:16    time: 1.0576  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [ 60/242]  eta: 0:03:09    time: 1.0886  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [ 70/242]  eta: 0:02:59    time: 1.0992  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [ 80/242]  eta: 0:02:48    time: 1.0405  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [ 90/242]  eta: 0:02:36    time: 0.9876  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [100/242]  eta: 0:02:27    time: 1.0220  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [110/242]  eta: 0:02:16    time: 1.0390  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Test  [120/242]  eta: 0:02:06    time: 1.0536  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [130/242]  eta: 0:01:55    time: 1.0453  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [140/242]  eta: 0:01:45    time: 0.9940  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Test  [150/242]  eta: 0:01:34    time: 0.9991  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [160/242]  eta: 0:01:24    time: 1.0115  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [170/242]  eta: 0:01:14    time: 1.0625  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [180/242]  eta: 0:01:04    time: 1.1213  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [190/242]  eta: 0:00:54    time: 1.1240  data: 0.0004  max mem: 9586\n",
      "Epoch: [32] Test  [200/242]  eta: 0:00:43    time: 1.0711  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [210/242]  eta: 0:00:33    time: 1.0426  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Test  [220/242]  eta: 0:00:22    time: 1.0490  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [230/242]  eta: 0:00:12    time: 1.0578  data: 0.0003  max mem: 9586\n",
      "Epoch: [32] Test  [240/242]  eta: 0:00:02    time: 1.0186  data: 0.0002  max mem: 9586\n",
      "Epoch: [32] Test Total time: 0:04:11\n",
      "global correct: 95.7\n",
      "average row correct: ['96.8', '98.0', '83.4', '95.3', '88.0', '92.7', '99.1', '94.1', '98.6', '74.1', '95.2', '75.8', '93.7', '95.1', '93.8', '95.8', '82.2', '96.4', '78.4', '96.7', '90.6']\n",
      "IoU: ['95.2', '93.8', '64.7', '90.7', '75.3', '76.0', '95.6', '84.4', '90.9', '48.3', '90.7', '66.3', '87.8', '89.2', '89.9', '90.5', '69.1', '88.1', '60.3', '89.5', '74.6']\n",
      "mean IoU: 81.5\n",
      "Epoch: [33] Train  [  0/183]  eta: 0:37:30  lr: 0.000021  loss: 0.4217 (0.4217)  time: 12.3004  data: 0.4199  max mem: 9586\n",
      "Epoch: [33] Train  [ 10/183]  eta: 0:35:41  lr: 0.000021  loss: 0.1815 (0.4706)  time: 12.3780  data: 0.0384  max mem: 9586\n",
      "Epoch: [33] Train  [ 20/183]  eta: 0:33:27  lr: 0.000021  loss: 0.5882 (0.5019)  time: 12.3168  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Train  [ 30/183]  eta: 0:31:17  lr: 0.000021  loss: 0.3706 (0.4618)  time: 12.2077  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [ 40/183]  eta: 0:29:06  lr: 0.000021  loss: 0.3211 (0.4490)  time: 12.1113  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [ 50/183]  eta: 0:27:06  lr: 0.000021  loss: 0.3644 (0.4756)  time: 12.1784  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [ 60/183]  eta: 0:25:01  lr: 0.000020  loss: 0.3025 (0.4688)  time: 12.1838  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [ 70/183]  eta: 0:23:00  lr: 0.000020  loss: 0.4432 (0.4617)  time: 12.1804  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [ 80/183]  eta: 0:20:56  lr: 0.000020  loss: 0.4310 (0.4537)  time: 12.1844  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [ 90/183]  eta: 0:18:56  lr: 0.000020  loss: 0.4811 (0.4554)  time: 12.2328  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [100/183]  eta: 0:16:55  lr: 0.000020  loss: 0.2656 (0.4490)  time: 12.3572  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [110/183]  eta: 0:14:54  lr: 0.000020  loss: 0.2264 (0.4530)  time: 12.3689  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Train  [120/183]  eta: 0:12:51  lr: 0.000019  loss: 0.5517 (0.4461)  time: 12.3042  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Train  [130/183]  eta: 0:10:48  lr: 0.000019  loss: 0.3368 (0.4440)  time: 12.1886  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [140/183]  eta: 0:08:45  lr: 0.000019  loss: 0.1566 (0.4355)  time: 12.1639  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [150/183]  eta: 0:06:43  lr: 0.000019  loss: 0.3036 (0.4373)  time: 12.1518  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [160/183]  eta: 0:04:41  lr: 0.000019  loss: 0.4657 (0.4398)  time: 12.2058  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [170/183]  eta: 0:02:39  lr: 0.000019  loss: 0.6395 (0.4406)  time: 12.2758  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train  [180/183]  eta: 0:00:36  lr: 0.000019  loss: 0.3627 (0.4444)  time: 12.3384  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Train Total time: 0:37:19\n",
      "Epoch: [33] Test  [  0/242]  eta: 0:05:54    time: 1.4630  data: 0.3810  max mem: 9586\n",
      "Epoch: [33] Test  [ 10/242]  eta: 0:03:52    time: 1.0041  data: 0.0349  max mem: 9586\n",
      "Epoch: [33] Test  [ 20/242]  eta: 0:03:36    time: 0.9487  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Test  [ 30/242]  eta: 0:03:32    time: 1.0016  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Test  [ 40/242]  eta: 0:03:25    time: 1.0629  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [ 50/242]  eta: 0:03:16    time: 1.0560  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [ 60/242]  eta: 0:03:09    time: 1.0886  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [ 70/242]  eta: 0:02:59    time: 1.0978  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [ 80/242]  eta: 0:02:48    time: 1.0386  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [ 90/242]  eta: 0:02:36    time: 0.9877  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [100/242]  eta: 0:02:27    time: 1.0212  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [110/242]  eta: 0:02:16    time: 1.0391  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [120/242]  eta: 0:02:06    time: 1.0533  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [130/242]  eta: 0:01:55    time: 1.0425  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [140/242]  eta: 0:01:45    time: 0.9934  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [150/242]  eta: 0:01:34    time: 0.9999  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [160/242]  eta: 0:01:24    time: 1.0134  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [170/242]  eta: 0:01:14    time: 1.0617  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [180/242]  eta: 0:01:04    time: 1.1210  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [190/242]  eta: 0:00:54    time: 1.1260  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [200/242]  eta: 0:00:43    time: 1.0704  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [210/242]  eta: 0:00:33    time: 1.0430  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Test  [220/242]  eta: 0:00:22    time: 1.0499  data: 0.0002  max mem: 9586\n",
      "Epoch: [33] Test  [230/242]  eta: 0:00:12    time: 1.0575  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test  [240/242]  eta: 0:00:02    time: 1.0206  data: 0.0003  max mem: 9586\n",
      "Epoch: [33] Test Total time: 0:04:11\n",
      "global correct: 95.7\n",
      "average row correct: ['96.8', '97.6', '80.2', '93.8', '88.9', '93.9', '98.9', '94.7', '98.6', '74.2', '96.4', '74.8', '92.6', '94.5', '93.9', '96.1', '80.2', '95.8', '77.7', '96.5', '90.3']\n",
      "IoU: ['95.1', '93.7', '64.4', '90.1', '75.6', '74.4', '96.4', '83.3', '90.5', '46.3', '91.0', '65.7', '87.9', '88.9', '90.0', '90.6', '70.1', '89.8', '58.8', '88.4', '74.9']\n",
      "mean IoU: 81.2\n",
      "Epoch: [34] Train  [  0/183]  eta: 0:39:04  lr: 0.000019  loss: 0.5362 (0.5362)  time: 12.8111  data: 0.4077  max mem: 9586\n",
      "Epoch: [34] Train  [ 10/183]  eta: 0:35:44  lr: 0.000018  loss: 1.0279 (0.4306)  time: 12.3980  data: 0.0373  max mem: 9586\n",
      "Epoch: [34] Train  [ 20/183]  eta: 0:33:36  lr: 0.000018  loss: 0.1697 (0.4126)  time: 12.3507  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Train  [ 30/183]  eta: 0:31:31  lr: 0.000018  loss: 0.5116 (0.4394)  time: 12.3452  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [ 40/183]  eta: 0:29:31  lr: 0.000018  loss: 0.5634 (0.4287)  time: 12.4037  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [ 50/183]  eta: 0:27:23  lr: 0.000018  loss: 0.1378 (0.4327)  time: 12.3537  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [ 60/183]  eta: 0:25:17  lr: 0.000018  loss: 0.4888 (0.4291)  time: 12.2354  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [ 70/183]  eta: 0:23:13  lr: 0.000017  loss: 0.1237 (0.4284)  time: 12.2717  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Train  [ 80/183]  eta: 0:21:11  lr: 0.000017  loss: 0.7911 (0.4400)  time: 12.3681  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Train  [ 90/183]  eta: 0:19:07  lr: 0.000017  loss: 0.0468 (0.4387)  time: 12.3384  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [100/183]  eta: 0:17:04  lr: 0.000017  loss: 0.2155 (0.4467)  time: 12.3064  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [110/183]  eta: 0:15:00  lr: 0.000017  loss: 0.3701 (0.4426)  time: 12.3329  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Train  [120/183]  eta: 0:12:56  lr: 0.000017  loss: 0.3119 (0.4281)  time: 12.2756  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Train  [130/183]  eta: 0:10:52  lr: 0.000017  loss: 0.6929 (0.4347)  time: 12.2020  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [140/183]  eta: 0:08:49  lr: 0.000016  loss: 0.4007 (0.4380)  time: 12.2285  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [150/183]  eta: 0:06:46  lr: 0.000016  loss: 0.3877 (0.4347)  time: 12.3582  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Train  [160/183]  eta: 0:04:43  lr: 0.000016  loss: 0.0779 (0.4251)  time: 12.3682  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Train  [170/183]  eta: 0:02:40  lr: 0.000016  loss: 0.6792 (0.4293)  time: 12.2967  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Train  [180/183]  eta: 0:00:36  lr: 0.000016  loss: 0.5524 (0.4328)  time: 12.2266  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Train Total time: 0:37:32\n",
      "Epoch: [34] Test  [  0/242]  eta: 0:06:04    time: 1.5075  data: 0.4331  max mem: 9586\n",
      "Epoch: [34] Test  [ 10/242]  eta: 0:03:53    time: 1.0060  data: 0.0396  max mem: 9586\n",
      "Epoch: [34] Test  [ 20/242]  eta: 0:03:36    time: 0.9475  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [ 30/242]  eta: 0:03:32    time: 0.9987  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [ 40/242]  eta: 0:03:25    time: 1.0580  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [ 50/242]  eta: 0:03:16    time: 1.0535  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [ 60/242]  eta: 0:03:09    time: 1.0875  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [ 70/242]  eta: 0:02:59    time: 1.0991  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [ 80/242]  eta: 0:02:48    time: 1.0423  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [ 90/242]  eta: 0:02:36    time: 0.9898  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [100/242]  eta: 0:02:27    time: 1.0232  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [110/242]  eta: 0:02:16    time: 1.0400  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [120/242]  eta: 0:02:06    time: 1.0550  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [130/242]  eta: 0:01:55    time: 1.0467  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [140/242]  eta: 0:01:45    time: 0.9935  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [150/242]  eta: 0:01:34    time: 0.9978  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [160/242]  eta: 0:01:24    time: 1.0135  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [170/242]  eta: 0:01:14    time: 1.0654  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [180/242]  eta: 0:01:04    time: 1.1238  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [190/242]  eta: 0:00:54    time: 1.1263  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [200/242]  eta: 0:00:43    time: 1.0712  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [210/242]  eta: 0:00:33    time: 1.0430  data: 0.0003  max mem: 9586\n",
      "Epoch: [34] Test  [220/242]  eta: 0:00:22    time: 1.0521  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [230/242]  eta: 0:00:12    time: 1.0603  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test  [240/242]  eta: 0:00:02    time: 1.0215  data: 0.0002  max mem: 9586\n",
      "Epoch: [34] Test Total time: 0:04:11\n",
      "global correct: 96.0\n",
      "average row correct: ['97.2', '98.0', '83.3', '95.0', '90.2', '91.2', '99.1', '93.7', '98.0', '69.9', '95.4', '73.5', '95.6', '96.3', '94.6', '96.2', '79.1', '96.5', '78.8', '96.5', '90.5']\n",
      "IoU: ['95.4', '92.5', '64.8', '90.1', '76.7', '76.7', '95.8', '85.3', '93.7', '52.0', '92.0', '66.1', '89.8', '89.9', '90.0', '90.1', '69.7', '86.6', '61.1', '90.4', '74.4']\n",
      "mean IoU: 82.1\n",
      "Epoch: [35] Train  [  0/183]  eta: 0:40:16  lr: 0.000016  loss: 0.2030 (0.2030)  time: 13.2069  data: 0.3805  max mem: 9586\n",
      "Epoch: [35] Train  [ 10/183]  eta: 0:35:36  lr: 0.000016  loss: 0.3768 (0.3375)  time: 12.3468  data: 0.0348  max mem: 9586\n",
      "Epoch: [35] Train  [ 20/183]  eta: 0:33:22  lr: 0.000015  loss: 0.4677 (0.4215)  time: 12.2409  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Train  [ 30/183]  eta: 0:31:18  lr: 0.000015  loss: 0.1564 (0.4038)  time: 12.2445  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Train  [ 40/183]  eta: 0:29:12  lr: 0.000015  loss: 0.3255 (0.4212)  time: 12.2182  data: 0.0004  max mem: 9586\n",
      "Epoch: [35] Train  [ 50/183]  eta: 0:27:09  lr: 0.000015  loss: 0.2771 (0.4304)  time: 12.2135  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Train  [ 60/183]  eta: 0:25:07  lr: 0.000015  loss: 0.4280 (0.4294)  time: 12.2703  data: 0.0004  max mem: 9586\n",
      "Epoch: [35] Train  [ 70/183]  eta: 0:23:05  lr: 0.000015  loss: 0.4299 (0.4343)  time: 12.2802  data: 0.0004  max mem: 9586\n",
      "Epoch: [35] Train  [ 80/183]  eta: 0:21:01  lr: 0.000014  loss: 0.3077 (0.4369)  time: 12.2059  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Train  [ 90/183]  eta: 0:18:59  lr: 0.000014  loss: 0.4397 (0.4399)  time: 12.2023  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Train  [100/183]  eta: 0:16:57  lr: 0.000014  loss: 0.2788 (0.4417)  time: 12.2949  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Train  [110/183]  eta: 0:14:55  lr: 0.000014  loss: 0.4913 (0.4539)  time: 12.3211  data: 0.0004  max mem: 9586\n",
      "Epoch: [35] Train  [120/183]  eta: 0:12:51  lr: 0.000014  loss: 0.2593 (0.4566)  time: 12.2403  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Train  [130/183]  eta: 0:10:48  lr: 0.000014  loss: 0.1071 (0.4612)  time: 12.1349  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Train  [140/183]  eta: 0:08:46  lr: 0.000014  loss: 0.7465 (0.4638)  time: 12.1747  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Train  [150/183]  eta: 0:06:44  lr: 0.000013  loss: 0.5484 (0.4642)  time: 12.2489  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Train  [160/183]  eta: 0:04:41  lr: 0.000013  loss: 0.7454 (0.4606)  time: 12.2764  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Train  [170/183]  eta: 0:02:39  lr: 0.000013  loss: 0.4695 (0.4628)  time: 12.2351  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Train  [180/183]  eta: 0:00:36  lr: 0.000013  loss: 0.5092 (0.4632)  time: 12.2116  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Train Total time: 0:37:20\n",
      "Epoch: [35] Test  [  0/242]  eta: 0:06:11    time: 1.5359  data: 0.4485  max mem: 9586\n",
      "Epoch: [35] Test  [ 10/242]  eta: 0:03:54    time: 1.0127  data: 0.0413  max mem: 9586\n",
      "Epoch: [35] Test  [ 20/242]  eta: 0:03:36    time: 0.9495  data: 0.0004  max mem: 9586\n",
      "Epoch: [35] Test  [ 30/242]  eta: 0:03:32    time: 0.9999  data: 0.0004  max mem: 9586\n",
      "Epoch: [35] Test  [ 40/242]  eta: 0:03:25    time: 1.0618  data: 0.0005  max mem: 9586\n",
      "Epoch: [35] Test  [ 50/242]  eta: 0:03:16    time: 1.0562  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [ 60/242]  eta: 0:03:09    time: 1.0890  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [ 70/242]  eta: 0:02:59    time: 1.1000  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [ 80/242]  eta: 0:02:48    time: 1.0409  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [ 90/242]  eta: 0:02:37    time: 0.9878  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [100/242]  eta: 0:02:27    time: 1.0219  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [110/242]  eta: 0:02:16    time: 1.0389  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [120/242]  eta: 0:02:06    time: 1.0515  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [130/242]  eta: 0:01:55    time: 1.0441  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [140/242]  eta: 0:01:45    time: 0.9943  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [150/242]  eta: 0:01:34    time: 0.9992  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [160/242]  eta: 0:01:24    time: 1.0118  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [170/242]  eta: 0:01:14    time: 1.0621  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [180/242]  eta: 0:01:04    time: 1.1225  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [190/242]  eta: 0:00:54    time: 1.1267  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [200/242]  eta: 0:00:43    time: 1.0728  data: 0.0003  max mem: 9586\n",
      "Epoch: [35] Test  [210/242]  eta: 0:00:33    time: 1.0455  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Test  [220/242]  eta: 0:00:22    time: 1.0522  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Test  [230/242]  eta: 0:00:12    time: 1.0601  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Test  [240/242]  eta: 0:00:02    time: 1.0223  data: 0.0002  max mem: 9586\n",
      "Epoch: [35] Test Total time: 0:04:12\n",
      "global correct: 95.8\n",
      "average row correct: ['96.9', '97.7', '84.5', '93.9', '86.2', '92.7', '99.1', '93.1', '98.1', '73.1', '96.3', '73.5', '96.0', '94.5', '94.5', '95.8', '78.9', '96.4', '82.0', '96.2', '90.0']\n",
      "IoU: ['95.2', '94.4', '63.7', '90.1', '75.3', '74.7', '96.0', '85.0', '92.6', '47.9', '90.5', '65.5', '89.3', '89.0', '89.7', '90.7', '68.9', '87.9', '60.8', '90.9', '76.5']\n",
      "mean IoU: 81.6\n",
      "Epoch: [36] Train  [  0/183]  eta: 0:39:49  lr: 0.000013  loss: 0.2203 (0.2203)  time: 13.0595  data: 0.4568  max mem: 9586\n",
      "Epoch: [36] Train  [ 10/183]  eta: 0:35:31  lr: 0.000013  loss: 0.5126 (0.4479)  time: 12.3220  data: 0.0418  max mem: 9586\n",
      "Epoch: [36] Train  [ 20/183]  eta: 0:33:17  lr: 0.000013  loss: 0.2786 (0.4378)  time: 12.2158  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Train  [ 30/183]  eta: 0:31:15  lr: 0.000012  loss: 0.3610 (0.4249)  time: 12.2235  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Train  [ 40/183]  eta: 0:29:15  lr: 0.000012  loss: 0.3484 (0.4024)  time: 12.2983  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Train  [ 50/183]  eta: 0:27:10  lr: 0.000012  loss: 0.1872 (0.4132)  time: 12.2517  data: 0.0004  max mem: 9586\n",
      "Epoch: [36] Train  [ 60/183]  eta: 0:25:05  lr: 0.000012  loss: 0.5799 (0.4244)  time: 12.1755  data: 0.0005  max mem: 9586\n",
      "Epoch: [36] Train  [ 70/183]  eta: 0:23:05  lr: 0.000012  loss: 0.3623 (0.4112)  time: 12.2609  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Train  [ 80/183]  eta: 0:21:03  lr: 0.000012  loss: 0.4419 (0.4120)  time: 12.3486  data: 0.0004  max mem: 9586\n",
      "Epoch: [36] Train  [ 90/183]  eta: 0:19:00  lr: 0.000011  loss: 0.2041 (0.4086)  time: 12.2878  data: 0.0004  max mem: 9586\n",
      "Epoch: [36] Train  [100/183]  eta: 0:16:58  lr: 0.000011  loss: 0.6979 (0.4140)  time: 12.2854  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Train  [110/183]  eta: 0:14:55  lr: 0.000011  loss: 0.9759 (0.4160)  time: 12.2661  data: 0.0004  max mem: 9586\n",
      "Epoch: [36] Train  [120/183]  eta: 0:12:53  lr: 0.000011  loss: 0.6106 (0.4220)  time: 12.2593  data: 0.0005  max mem: 9586\n",
      "Epoch: [36] Train  [130/183]  eta: 0:10:50  lr: 0.000011  loss: 0.6313 (0.4336)  time: 12.3191  data: 0.0005  max mem: 9586\n",
      "Epoch: [36] Train  [140/183]  eta: 0:08:47  lr: 0.000011  loss: 0.9755 (0.4430)  time: 12.2429  data: 0.0004  max mem: 9586\n",
      "Epoch: [36] Train  [150/183]  eta: 0:06:44  lr: 0.000010  loss: 0.4682 (0.4407)  time: 12.1551  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Train  [160/183]  eta: 0:04:41  lr: 0.000010  loss: 0.6225 (0.4441)  time: 12.0861  data: 0.0002  max mem: 9586\n",
      "Epoch: [36] Train  [170/183]  eta: 0:02:39  lr: 0.000010  loss: 0.3185 (0.4425)  time: 12.1542  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Train  [180/183]  eta: 0:00:36  lr: 0.000010  loss: 0.3826 (0.4426)  time: 12.2533  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Train Total time: 0:37:20\n",
      "Epoch: [36] Test  [  0/242]  eta: 0:06:13    time: 1.5452  data: 0.4573  max mem: 9586\n",
      "Epoch: [36] Test  [ 10/242]  eta: 0:03:55    time: 1.0140  data: 0.0418  max mem: 9586\n",
      "Epoch: [36] Test  [ 20/242]  eta: 0:03:37    time: 0.9503  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [ 30/242]  eta: 0:03:33    time: 1.0008  data: 0.0002  max mem: 9586\n",
      "Epoch: [36] Test  [ 40/242]  eta: 0:03:26    time: 1.0631  data: 0.0002  max mem: 9586\n",
      "Epoch: [36] Test  [ 50/242]  eta: 0:03:17    time: 1.0594  data: 0.0002  max mem: 9586\n",
      "Epoch: [36] Test  [ 60/242]  eta: 0:03:09    time: 1.0907  data: 0.0002  max mem: 9586\n",
      "Epoch: [36] Test  [ 70/242]  eta: 0:03:00    time: 1.1006  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [ 80/242]  eta: 0:02:48    time: 1.0433  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [ 90/242]  eta: 0:02:37    time: 0.9910  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [100/242]  eta: 0:02:27    time: 1.0241  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [110/242]  eta: 0:02:16    time: 1.0429  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [120/242]  eta: 0:02:07    time: 1.0578  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [130/242]  eta: 0:01:56    time: 1.0452  data: 0.0005  max mem: 9586\n",
      "Epoch: [36] Test  [140/242]  eta: 0:01:45    time: 0.9948  data: 0.0005  max mem: 9586\n",
      "Epoch: [36] Test  [150/242]  eta: 0:01:35    time: 1.0008  data: 0.0002  max mem: 9586\n",
      "Epoch: [36] Test  [160/242]  eta: 0:01:24    time: 1.0132  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [170/242]  eta: 0:01:14    time: 1.0638  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [180/242]  eta: 0:01:04    time: 1.1241  data: 0.0005  max mem: 9586\n",
      "Epoch: [36] Test  [190/242]  eta: 0:00:54    time: 1.1267  data: 0.0005  max mem: 9586\n",
      "Epoch: [36] Test  [200/242]  eta: 0:00:43    time: 1.0721  data: 0.0002  max mem: 9586\n",
      "Epoch: [36] Test  [210/242]  eta: 0:00:33    time: 1.0455  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [220/242]  eta: 0:00:23    time: 1.0527  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [230/242]  eta: 0:00:12    time: 1.0591  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test  [240/242]  eta: 0:00:02    time: 1.0202  data: 0.0003  max mem: 9586\n",
      "Epoch: [36] Test Total time: 0:04:12\n",
      "global correct: 96.0\n",
      "average row correct: ['97.3', '96.9', '79.5', '93.9', '87.4', '90.1', '99.0', '91.1', '98.0', '72.7', '95.4', '73.4', '96.5', '95.4', '95.0', '96.0', '76.5', '96.0', '81.0', '96.2', '90.0']\n",
      "IoU: ['95.4', '94.7', '66.4', '89.9', '76.6', '77.6', '96.3', '85.8', '93.7', '49.9', '91.4', '64.8', '89.9', '90.7', '90.2', '90.4', '68.6', '89.4', '61.2', '89.3', '75.0']\n",
      "mean IoU: 82.3\n",
      "Epoch: [37] Train  [  0/183]  eta: 0:37:21  lr: 0.000010  loss: 0.3005 (0.3005)  time: 12.2510  data: 0.4152  max mem: 9586\n",
      "Epoch: [37] Train  [ 10/183]  eta: 0:35:14  lr: 0.000010  loss: 0.5598 (0.4882)  time: 12.2209  data: 0.0380  max mem: 9586\n",
      "Epoch: [37] Train  [ 20/183]  eta: 0:33:18  lr: 0.000010  loss: 0.3970 (0.4633)  time: 12.2626  data: 0.0002  max mem: 9586\n",
      "Epoch: [37] Train  [ 30/183]  eta: 0:31:09  lr: 0.000009  loss: 0.2042 (0.4771)  time: 12.2181  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [ 40/183]  eta: 0:29:11  lr: 0.000009  loss: 0.6522 (0.4479)  time: 12.2325  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [ 50/183]  eta: 0:27:05  lr: 0.000009  loss: 0.6692 (0.4495)  time: 12.2279  data: 0.0002  max mem: 9586\n",
      "Epoch: [37] Train  [ 60/183]  eta: 0:25:03  lr: 0.000009  loss: 0.1775 (0.4455)  time: 12.1793  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [ 70/183]  eta: 0:23:04  lr: 0.000009  loss: 1.2533 (0.4517)  time: 12.3165  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [ 80/183]  eta: 0:21:00  lr: 0.000009  loss: 0.2912 (0.4464)  time: 12.2714  data: 0.0002  max mem: 9586\n",
      "Epoch: [37] Train  [ 90/183]  eta: 0:18:58  lr: 0.000008  loss: 0.4389 (0.4577)  time: 12.2264  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [100/183]  eta: 0:16:54  lr: 0.000008  loss: 0.3197 (0.4553)  time: 12.1929  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [110/183]  eta: 0:14:51  lr: 0.000008  loss: 0.3834 (0.4537)  time: 12.0745  data: 0.0002  max mem: 9586\n",
      "Epoch: [37] Train  [120/183]  eta: 0:12:49  lr: 0.000008  loss: 0.0538 (0.4443)  time: 12.1312  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [130/183]  eta: 0:10:46  lr: 0.000008  loss: 0.6939 (0.4502)  time: 12.1611  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [140/183]  eta: 0:08:45  lr: 0.000008  loss: 0.5257 (0.4534)  time: 12.1948  data: 0.0002  max mem: 9586\n",
      "Epoch: [37] Train  [150/183]  eta: 0:06:43  lr: 0.000007  loss: 0.0932 (0.4444)  time: 12.2621  data: 0.0002  max mem: 9586\n",
      "Epoch: [37] Train  [160/183]  eta: 0:04:40  lr: 0.000007  loss: 0.2650 (0.4493)  time: 12.2326  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [170/183]  eta: 0:02:38  lr: 0.000007  loss: 0.2865 (0.4528)  time: 12.2694  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train  [180/183]  eta: 0:00:36  lr: 0.000007  loss: 0.1338 (0.4489)  time: 12.2856  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Train Total time: 0:37:16\n",
      "Epoch: [37] Test  [  0/242]  eta: 0:06:03    time: 1.5011  data: 0.4231  max mem: 9586\n",
      "Epoch: [37] Test  [ 10/242]  eta: 0:03:54    time: 1.0089  data: 0.0387  max mem: 9586\n",
      "Epoch: [37] Test  [ 20/242]  eta: 0:03:36    time: 0.9500  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [ 30/242]  eta: 0:03:32    time: 1.0009  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [ 40/242]  eta: 0:03:25    time: 1.0625  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [ 50/242]  eta: 0:03:16    time: 1.0561  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [ 60/242]  eta: 0:03:09    time: 1.0895  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [ 70/242]  eta: 0:02:59    time: 1.0994  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [ 80/242]  eta: 0:02:48    time: 1.0407  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [ 90/242]  eta: 0:02:37    time: 0.9899  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [100/242]  eta: 0:02:27    time: 1.0215  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [110/242]  eta: 0:02:16    time: 1.0385  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [120/242]  eta: 0:02:06    time: 1.0553  data: 0.0004  max mem: 9586\n",
      "Epoch: [37] Test  [130/242]  eta: 0:01:56    time: 1.0472  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [140/242]  eta: 0:01:45    time: 0.9943  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [150/242]  eta: 0:01:34    time: 0.9993  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [160/242]  eta: 0:01:24    time: 1.0128  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [170/242]  eta: 0:01:14    time: 1.0646  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [180/242]  eta: 0:01:04    time: 1.1231  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [190/242]  eta: 0:00:54    time: 1.1226  data: 0.0002  max mem: 9586\n",
      "Epoch: [37] Test  [200/242]  eta: 0:00:43    time: 1.0719  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [210/242]  eta: 0:00:33    time: 1.0458  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [220/242]  eta: 0:00:22    time: 1.0526  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [230/242]  eta: 0:00:12    time: 1.0616  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test  [240/242]  eta: 0:00:02    time: 1.0224  data: 0.0003  max mem: 9586\n",
      "Epoch: [37] Test Total time: 0:04:12\n",
      "global correct: 95.9\n",
      "average row correct: ['97.2', '97.5', '84.6', '93.7', '88.9', '92.1', '98.9', '93.7', '98.2', '70.5', '95.9', '71.0', '95.9', '95.0', '93.9', '95.9', '79.3', '96.3', '77.9', '96.4', '90.3']\n",
      "IoU: ['95.3', '94.6', '66.1', '89.9', '76.2', '75.0', '96.5', '85.1', '92.7', '51.1', '91.3', '64.7', '89.1', '90.2', '89.3', '90.5', '68.9', '87.6', '60.7', '89.4', '73.4']\n",
      "mean IoU: 81.8\n",
      "Epoch: [38] Train  [  0/183]  eta: 0:39:25  lr: 0.000007  loss: 0.4463 (0.4463)  time: 12.9282  data: 0.3840  max mem: 9586\n",
      "Epoch: [38] Train  [ 10/183]  eta: 0:35:46  lr: 0.000007  loss: 0.3316 (0.4536)  time: 12.4062  data: 0.0352  max mem: 9586\n",
      "Epoch: [38] Train  [ 20/183]  eta: 0:33:34  lr: 0.000007  loss: 0.5085 (0.4622)  time: 12.3287  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Train  [ 30/183]  eta: 0:31:26  lr: 0.000006  loss: 0.4567 (0.4543)  time: 12.2852  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Train  [ 40/183]  eta: 0:29:21  lr: 0.000006  loss: 0.3428 (0.4472)  time: 12.2792  data: 0.0006  max mem: 9586\n",
      "Epoch: [38] Train  [ 50/183]  eta: 0:27:20  lr: 0.000006  loss: 0.2595 (0.4519)  time: 12.3435  data: 0.0006  max mem: 9586\n",
      "Epoch: [38] Train  [ 60/183]  eta: 0:25:15  lr: 0.000006  loss: 0.9246 (0.4759)  time: 12.3290  data: 0.0004  max mem: 9586\n",
      "Epoch: [38] Train  [ 70/183]  eta: 0:23:10  lr: 0.000006  loss: 0.3607 (0.4667)  time: 12.2431  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Train  [ 80/183]  eta: 0:21:07  lr: 0.000006  loss: 0.5761 (0.4651)  time: 12.2536  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Train  [ 90/183]  eta: 0:19:04  lr: 0.000005  loss: 0.3718 (0.4673)  time: 12.2985  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Train  [100/183]  eta: 0:17:00  lr: 0.000005  loss: 0.4633 (0.4649)  time: 12.2581  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Train  [110/183]  eta: 0:14:57  lr: 0.000005  loss: 0.8264 (0.4737)  time: 12.2250  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Train  [120/183]  eta: 0:12:53  lr: 0.000005  loss: 0.4684 (0.4785)  time: 12.2075  data: 0.0004  max mem: 9586\n",
      "Epoch: [38] Train  [130/183]  eta: 0:10:50  lr: 0.000005  loss: 0.3432 (0.4690)  time: 12.2176  data: 0.0004  max mem: 9586\n",
      "Epoch: [38] Train  [140/183]  eta: 0:08:48  lr: 0.000004  loss: 0.3082 (0.4656)  time: 12.2691  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Train  [150/183]  eta: 0:06:44  lr: 0.000004  loss: 0.5696 (0.4645)  time: 12.2069  data: 0.0005  max mem: 9586\n",
      "Epoch: [38] Train  [160/183]  eta: 0:04:42  lr: 0.000004  loss: 0.2691 (0.4555)  time: 12.2075  data: 0.0006  max mem: 9586\n",
      "Epoch: [38] Train  [170/183]  eta: 0:02:39  lr: 0.000004  loss: 0.4551 (0.4536)  time: 12.2327  data: 0.0005  max mem: 9586\n",
      "Epoch: [38] Train  [180/183]  eta: 0:00:36  lr: 0.000004  loss: 0.1304 (0.4507)  time: 12.2979  data: 0.0004  max mem: 9586\n",
      "Epoch: [38] Train Total time: 0:37:26\n",
      "Epoch: [38] Test  [  0/242]  eta: 0:06:07    time: 1.5185  data: 0.4332  max mem: 9586\n",
      "Epoch: [38] Test  [ 10/242]  eta: 0:03:54    time: 1.0112  data: 0.0397  max mem: 9586\n",
      "Epoch: [38] Test  [ 20/242]  eta: 0:03:36    time: 0.9499  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [ 30/242]  eta: 0:03:32    time: 1.0010  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [ 40/242]  eta: 0:03:25    time: 1.0620  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [ 50/242]  eta: 0:03:16    time: 1.0546  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [ 60/242]  eta: 0:03:09    time: 1.0863  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [ 70/242]  eta: 0:02:59    time: 1.0984  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [ 80/242]  eta: 0:02:48    time: 1.0425  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [ 90/242]  eta: 0:02:36    time: 0.9894  data: 0.0002  max mem: 9586\n",
      "Epoch: [38] Test  [100/242]  eta: 0:02:27    time: 1.0219  data: 0.0002  max mem: 9586\n",
      "Epoch: [38] Test  [110/242]  eta: 0:02:16    time: 1.0399  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [120/242]  eta: 0:02:06    time: 1.0537  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [130/242]  eta: 0:01:56    time: 1.0445  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [140/242]  eta: 0:01:45    time: 0.9931  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [150/242]  eta: 0:01:34    time: 0.9980  data: 0.0002  max mem: 9586\n",
      "Epoch: [38] Test  [160/242]  eta: 0:01:24    time: 1.0129  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [170/242]  eta: 0:01:14    time: 1.0636  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [180/242]  eta: 0:01:04    time: 1.1232  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [190/242]  eta: 0:00:54    time: 1.1262  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [200/242]  eta: 0:00:43    time: 1.0729  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [210/242]  eta: 0:00:33    time: 1.0435  data: 0.0002  max mem: 9586\n",
      "Epoch: [38] Test  [220/242]  eta: 0:00:22    time: 1.0487  data: 0.0002  max mem: 9586\n",
      "Epoch: [38] Test  [230/242]  eta: 0:00:12    time: 1.0579  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test  [240/242]  eta: 0:00:02    time: 1.0198  data: 0.0003  max mem: 9586\n",
      "Epoch: [38] Test Total time: 0:04:11\n",
      "global correct: 96.0\n",
      "average row correct: ['97.4', '97.5', '81.0', '95.2', '86.6', '91.9', '99.1', '91.5', '98.4', '70.1', '95.4', '69.0', '94.1', '95.7', '95.0', '95.9', '80.8', '96.0', '79.1', '96.2', '90.4']\n",
      "IoU: ['95.5', '94.5', '65.3', '90.5', '76.3', '75.6', '96.6', '85.5', '91.5', '51.3', '91.7', '63.8', '88.8', '91.5', '90.3', '90.9', '69.8', '88.9', '62.6', '88.2', '75.8']\n",
      "mean IoU: 82.1\n",
      "Epoch: [39] Train  [  0/183]  eta: 0:38:40  lr: 0.000004  loss: 0.2625 (0.2625)  time: 12.6803  data: 0.4150  max mem: 9586\n",
      "Epoch: [39] Train  [ 10/183]  eta: 0:35:39  lr: 0.000003  loss: 0.4425 (0.5615)  time: 12.3666  data: 0.0380  max mem: 9586\n",
      "Epoch: [39] Train  [ 20/183]  eta: 0:33:36  lr: 0.000003  loss: 0.2388 (0.5435)  time: 12.3575  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Train  [ 30/183]  eta: 0:31:26  lr: 0.000003  loss: 1.1242 (0.5295)  time: 12.3120  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Train  [ 40/183]  eta: 0:29:17  lr: 0.000003  loss: 0.9005 (0.5302)  time: 12.2022  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Train  [ 50/183]  eta: 0:27:11  lr: 0.000003  loss: 0.2862 (0.5123)  time: 12.1701  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Train  [ 60/183]  eta: 0:25:09  lr: 0.000003  loss: 0.6596 (0.5079)  time: 12.2318  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Train  [ 70/183]  eta: 0:23:06  lr: 0.000002  loss: 0.6251 (0.4969)  time: 12.2884  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Train  [ 80/183]  eta: 0:21:02  lr: 0.000002  loss: 0.3447 (0.4955)  time: 12.2281  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Train  [ 90/183]  eta: 0:18:58  lr: 0.000002  loss: 1.0055 (0.4925)  time: 12.1116  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Train  [100/183]  eta: 0:16:55  lr: 0.000002  loss: 0.2606 (0.4714)  time: 12.1166  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Train  [110/183]  eta: 0:14:52  lr: 0.000002  loss: 0.4266 (0.4726)  time: 12.2069  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Train  [120/183]  eta: 0:12:50  lr: 0.000001  loss: 0.3738 (0.4707)  time: 12.2274  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Train  [130/183]  eta: 0:10:48  lr: 0.000001  loss: 0.9874 (0.4646)  time: 12.2740  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Train  [140/183]  eta: 0:08:46  lr: 0.000001  loss: 0.2123 (0.4563)  time: 12.3238  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Train  [150/183]  eta: 0:06:43  lr: 0.000001  loss: 0.4779 (0.4537)  time: 12.2557  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Train  [160/183]  eta: 0:04:41  lr: 0.000001  loss: 0.1346 (0.4521)  time: 12.2500  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Train  [170/183]  eta: 0:02:39  lr: 0.000000  loss: 0.1745 (0.4539)  time: 12.2542  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Train  [180/183]  eta: 0:00:36  lr: 0.000000  loss: 0.5903 (0.4587)  time: 12.2088  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Train Total time: 0:37:19\n",
      "Epoch: [39] Test  [  0/242]  eta: 0:06:09    time: 1.5259  data: 0.4345  max mem: 9586\n",
      "Epoch: [39] Test  [ 10/242]  eta: 0:03:54    time: 1.0105  data: 0.0398  max mem: 9586\n",
      "Epoch: [39] Test  [ 20/242]  eta: 0:03:36    time: 0.9494  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [ 30/242]  eta: 0:03:32    time: 1.0005  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [ 40/242]  eta: 0:03:25    time: 1.0636  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [ 50/242]  eta: 0:03:16    time: 1.0583  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Test  [ 60/242]  eta: 0:03:09    time: 1.0893  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Test  [ 70/242]  eta: 0:02:59    time: 1.1000  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [ 80/242]  eta: 0:02:48    time: 1.0422  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [ 90/242]  eta: 0:02:37    time: 0.9899  data: 0.0002  max mem: 9586\n",
      "Epoch: [39] Test  [100/242]  eta: 0:02:27    time: 1.0231  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [110/242]  eta: 0:02:16    time: 1.0411  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [120/242]  eta: 0:02:07    time: 1.0559  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Test  [130/242]  eta: 0:01:56    time: 1.0460  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Test  [140/242]  eta: 0:01:45    time: 0.9941  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [150/242]  eta: 0:01:34    time: 1.0005  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Test  [160/242]  eta: 0:01:24    time: 1.0151  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Test  [170/242]  eta: 0:01:14    time: 1.0651  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [180/242]  eta: 0:01:04    time: 1.1243  data: 0.0004  max mem: 9586\n",
      "Epoch: [39] Test  [190/242]  eta: 0:00:54    time: 1.1276  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [200/242]  eta: 0:00:43    time: 1.0735  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [210/242]  eta: 0:00:33    time: 1.0458  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [220/242]  eta: 0:00:23    time: 1.0533  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [230/242]  eta: 0:00:12    time: 1.0613  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test  [240/242]  eta: 0:00:02    time: 1.0219  data: 0.0003  max mem: 9586\n",
      "Epoch: [39] Test Total time: 0:04:12\n",
      "global correct: 95.9\n",
      "average row correct: ['97.1', '98.0', '82.2', '95.9', '87.8', '91.6', '99.0', '93.7', '98.3', '72.9', '94.7', '73.3', '97.0', '96.8', '93.9', '96.0', '77.9', '96.7', '76.7', '96.0', '90.3']\n",
      "IoU: ['95.3', '94.5', '65.4', '90.4', '75.5', '77.7', '95.9', '85.2', '93.5', '49.2', '91.3', '65.5', '89.1', '90.1', '89.7', '90.3', '69.4', '86.2', '60.6', '90.1', '73.8']\n",
      "mean IoU: 81.8\n",
      "Training time 1 day, 3:52:51\n"
     ]
    }
   ],
   "source": [
    "# simsiam\n",
    "!experiment_name=\"attention\";cd ../ ;\\\n",
    "    name_date=\"${experiment_name}/$(date +%Y-%m%d-%H%M%S)\";\\\n",
    "    dir=\"./results/${name_date}\";mkdir -p ${dir};dir_log=\"${dir}/output.log\";\\\n",
    "CUDA_VISIBLE_DEVICES=3 torchrun --nproc_per_node=1 --master_port=14534 train_multi_GPU.py \\\n",
    "    --wandb False --wandb_model run --sync_bn False --amp True --aux False \\\n",
    "    --model_name aspp_contrast_resnet101 --pre_trained deeplabv3_resnet101_coco.pth \\\n",
    "    --weight_only_backbone False --lr 0.0001 --wd 0.0001 --attention cbam \\\n",
    "    --data_path pascal-voc-2012 --num_classes 21 --data_train_type train.txt \\\n",
    "    --epochs 40 --batch_size 8 --batch_size_val 6 --memory_size 0 \\\n",
    "    --contrast 0 --L1_loss 0.1 --L2_loss 0.1 --L3_loss 0.1 \\\n",
    "    --loss_name aspp_loss --sample adapt_excite_8 \\\n",
    "    --name_date $name_date \\\n",
    "    2>&1 | tee $dir_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
