{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| distributed init (rank 0): env://\n",
      "temp/2023-0405-224856\n",
      "Namespace(data_path='pascal-voc-2012', data_train_type='train.txt', device='cuda', num_classes=21, batch_size=8, batch_size_val=6, aux=False, start_epoch=0, epochs=40, sync_bn=False, workers=1, lr=0.001, momentum=0.9, weight_decay=0.0001, print_freq=10, checkpoint_dir='./results/temp/2023-0405-224856', resume='', test_only=False, world_size=1, dist_url='env://', amp=True, seed=304, name_date='temp/2023-0405-224856', wandb=False, wandb_model='dryrun', run_name='', model_name='aspp_contrast_resnet101', project_dim=128, loss_name='aspp_loss', contrast=0, pre_trained='deeplabv3_resnet101_coco.pth', L3_loss=0.1, L2_loss=0.1, L1_loss=0.1, GAcc=1, memory_size=32768, proj_dim=128, network_stride=8, pixel_update_freq=10, ddp=False, weight_only_backbone=False, sample='self_pace_ploy', rank=0, gpu=0, distributed=True, dist_backend='nccl')\n",
      "Creating data loaders\n",
      "Creating model\n",
      "missing_keys:  ['encode3_queue', 'encode3_queue_ptr', 'code3_queue_label', 'encode2_queue', 'encode2_queue_ptr', 'code2_queue_label', 'encode1_queue', 'encode1_queue_ptr', 'code1_queue_label', 'contrast.convs.0.0.weight', 'contrast.convs.0.1.weight', 'contrast.convs.0.1.bias', 'contrast.convs.0.1.running_mean', 'contrast.convs.0.1.running_var', 'contrast.convs.0.3.weight', 'contrast.convs.0.4.weight', 'contrast.convs.0.4.bias', 'contrast.convs.0.4.running_mean', 'contrast.convs.0.4.running_var', 'contrast.convs.1.0.weight', 'contrast.convs.1.1.weight', 'contrast.convs.1.1.bias', 'contrast.convs.1.1.running_mean', 'contrast.convs.1.1.running_var', 'contrast.convs.1.3.weight', 'contrast.convs.1.4.weight', 'contrast.convs.1.4.bias', 'contrast.convs.1.4.running_mean', 'contrast.convs.1.4.running_var', 'contrast.convs.2.0.weight', 'contrast.convs.2.1.weight', 'contrast.convs.2.1.bias', 'contrast.convs.2.1.running_mean', 'contrast.convs.2.1.running_var', 'contrast.convs.2.3.weight', 'contrast.convs.2.4.weight', 'contrast.convs.2.4.bias', 'contrast.convs.2.4.running_mean', 'contrast.convs.2.4.running_var']\n",
      "unexpected_keys:  ['aux_classifier.0.weight', 'aux_classifier.1.weight', 'aux_classifier.1.bias', 'aux_classifier.1.running_mean', 'aux_classifier.1.running_var', 'aux_classifier.1.num_batches_tracked', 'aux_classifier.4.weight', 'aux_classifier.4.bias']\n",
      "DistributedDataParallel(\n",
      "  (module): DeepLabV3(\n",
      "    (backbone): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (6): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (7): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (8): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (9): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (10): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (11): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (12): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (13): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (14): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (15): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (16): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (17): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (18): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (19): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (20): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (21): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (22): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): DeepLabHead(\n",
      "      (0): ASPP(\n",
      "        (convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): ASPPConv(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): ASPPPooling(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (contrast): contrast_head(\n",
      "      (convs): ModuleList(\n",
      "        (0): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ASPPContrast(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Start training\n",
      "Epoch: [0] Train  [  0/183]  eta: 0:45:04  lr: 0.000006  loss: 2.3454 (2.3454)  time: 14.7777  data: 0.4604  max mem: 9064\n",
      "Epoch: [0] Train  [ 10/183]  eta: 0:36:48  lr: 0.000061  loss: 2.7851 (2.6839)  time: 12.7685  data: 0.0423  max mem: 9536\n",
      "Epoch: [0] Train  [ 20/183]  eta: 0:34:21  lr: 0.000116  loss: 3.3880 (2.7651)  time: 12.5430  data: 0.0004  max mem: 9536\n",
      "Epoch: [0] Train  [ 30/183]  eta: 0:32:10  lr: 0.000170  loss: 2.6293 (2.7943)  time: 12.5378  data: 0.0004  max mem: 9536\n",
      "Epoch: [0] Train  [ 40/183]  eta: 0:29:55  lr: 0.000225  loss: 2.9957 (2.8520)  time: 12.4592  data: 0.0004  max mem: 9536\n",
      "Epoch: [0] Train  [ 50/183]  eta: 0:27:45  lr: 0.000279  loss: 3.0984 (2.8644)  time: 12.3694  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Train  [ 60/183]  eta: 0:25:37  lr: 0.000334  loss: 2.9895 (2.9043)  time: 12.3862  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Train  [ 70/183]  eta: 0:23:31  lr: 0.000389  loss: 3.0233 (2.9290)  time: 12.4130  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [ 80/183]  eta: 0:21:25  lr: 0.000443  loss: 2.9062 (2.9219)  time: 12.4111  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [ 90/183]  eta: 0:19:19  lr: 0.000498  loss: 2.6174 (2.9032)  time: 12.3886  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [100/183]  eta: 0:17:13  lr: 0.000552  loss: 3.1396 (2.9121)  time: 12.3510  data: 0.0005  max mem: 9536\n",
      "Epoch: [0] Train  [110/183]  eta: 0:15:09  lr: 0.000607  loss: 3.0118 (2.9295)  time: 12.3901  data: 0.0005  max mem: 9536\n",
      "Epoch: [0] Train  [120/183]  eta: 0:13:04  lr: 0.000662  loss: 2.5869 (2.9400)  time: 12.4106  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [130/183]  eta: 0:10:59  lr: 0.000716  loss: 2.7400 (2.9441)  time: 12.3949  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [140/183]  eta: 0:08:55  lr: 0.000771  loss: 2.6998 (2.9429)  time: 12.4463  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [150/183]  eta: 0:06:50  lr: 0.000825  loss: 2.4901 (2.9324)  time: 12.4019  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [160/183]  eta: 0:04:46  lr: 0.000880  loss: 3.3397 (2.9409)  time: 12.3588  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [170/183]  eta: 0:02:41  lr: 0.000934  loss: 2.8024 (2.9327)  time: 12.3441  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train  [180/183]  eta: 0:00:37  lr: 0.000989  loss: 2.5024 (2.9329)  time: 12.3457  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Train Total time: 0:37:53\n",
      "Epoch: [0] Test  [  0/242]  eta: 0:09:07    time: 2.2628  data: 0.4160  max mem: 9536\n",
      "Epoch: [0] Test  [ 10/242]  eta: 0:04:06    time: 1.0643  data: 0.0380  max mem: 9536\n",
      "Epoch: [0] Test  [ 20/242]  eta: 0:03:41    time: 0.9361  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Test  [ 30/242]  eta: 0:03:35    time: 0.9911  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [ 40/242]  eta: 0:03:27    time: 1.0518  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [ 50/242]  eta: 0:03:17    time: 1.0423  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Test  [ 60/242]  eta: 0:03:09    time: 1.0727  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Test  [ 70/242]  eta: 0:02:59    time: 1.0822  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Test  [ 80/242]  eta: 0:02:47    time: 1.0256  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [ 90/242]  eta: 0:02:36    time: 0.9745  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [100/242]  eta: 0:02:26    time: 1.0079  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [110/242]  eta: 0:02:15    time: 1.0244  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [120/242]  eta: 0:02:05    time: 1.0396  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [130/242]  eta: 0:01:55    time: 1.0282  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Test  [140/242]  eta: 0:01:44    time: 0.9763  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [150/242]  eta: 0:01:34    time: 0.9870  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [160/242]  eta: 0:01:23    time: 0.9994  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [170/242]  eta: 0:01:13    time: 1.0591  data: 0.0002  max mem: 9536\n",
      "Epoch: [0] Test  [180/242]  eta: 0:01:03    time: 1.1183  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [190/242]  eta: 0:00:53    time: 1.1091  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [200/242]  eta: 0:00:43    time: 1.0547  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [210/242]  eta: 0:00:33    time: 1.0283  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [220/242]  eta: 0:00:22    time: 1.0369  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [230/242]  eta: 0:00:12    time: 1.0443  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test  [240/242]  eta: 0:00:02    time: 1.0052  data: 0.0003  max mem: 9536\n",
      "Epoch: [0] Test Total time: 0:04:09\n",
      "global correct: 94.8\n",
      "average row correct: ['96.2', '95.7', '82.4', '94.9', '85.0', '86.6', '97.4', '87.5', '96.2', '62.1', '96.6', '60.3', '91.2', '96.8', '94.6', '97.0', '75.8', '90.3', '83.1', '96.0', '94.2']\n",
      "IoU: ['94.1', '91.5', '41.3', '83.0', '73.7', '71.6', '95.2', '82.8', '90.7', '46.9', '89.1', '54.9', '87.3', '86.4', '88.9', '88.8', '63.7', '80.5', '60.4', '89.6', '58.1']\n",
      "mean IoU: 77.1\n",
      "Epoch: [1] Train  [  0/183]  eta: 0:40:09  lr: 0.001000  loss: 2.6048 (2.6048)  time: 13.1655  data: 0.4341  max mem: 9536\n",
      "Epoch: [1] Train  [ 10/183]  eta: 0:36:09  lr: 0.000999  loss: 2.5617 (2.7785)  time: 12.5421  data: 0.0398  max mem: 9536\n",
      "Epoch: [1] Train  [ 20/183]  eta: 0:34:00  lr: 0.000997  loss: 3.2479 (2.8312)  time: 12.4857  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [ 30/183]  eta: 0:31:44  lr: 0.000996  loss: 3.0775 (2.8482)  time: 12.3958  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [ 40/183]  eta: 0:29:38  lr: 0.000995  loss: 2.6121 (2.8482)  time: 12.3490  data: 0.0005  max mem: 9536\n",
      "Epoch: [1] Train  [ 50/183]  eta: 0:27:36  lr: 0.000994  loss: 2.7022 (2.8502)  time: 12.4700  data: 0.0005  max mem: 9536\n",
      "Epoch: [1] Train  [ 60/183]  eta: 0:25:32  lr: 0.000992  loss: 2.6597 (2.8714)  time: 12.5103  data: 0.0004  max mem: 9536\n",
      "Epoch: [1] Train  [ 70/183]  eta: 0:23:25  lr: 0.000991  loss: 2.7151 (2.8636)  time: 12.3877  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [ 80/183]  eta: 0:21:22  lr: 0.000990  loss: 2.9011 (2.8602)  time: 12.4315  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [ 90/183]  eta: 0:19:16  lr: 0.000989  loss: 2.5085 (2.8492)  time: 12.4426  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [100/183]  eta: 0:17:12  lr: 0.000987  loss: 2.6734 (2.8584)  time: 12.3968  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [110/183]  eta: 0:15:08  lr: 0.000986  loss: 3.0310 (2.8523)  time: 12.4465  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [120/183]  eta: 0:13:03  lr: 0.000985  loss: 2.5418 (2.8597)  time: 12.4489  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [130/183]  eta: 0:10:59  lr: 0.000983  loss: 3.6449 (2.8773)  time: 12.4620  data: 0.0002  max mem: 9536\n",
      "Epoch: [1] Train  [140/183]  eta: 0:08:55  lr: 0.000982  loss: 2.7406 (2.8745)  time: 12.4523  data: 0.0004  max mem: 9536\n",
      "Epoch: [1] Train  [150/183]  eta: 0:06:50  lr: 0.000981  loss: 3.1298 (2.8784)  time: 12.4141  data: 0.0004  max mem: 9536\n",
      "Epoch: [1] Train  [160/183]  eta: 0:04:46  lr: 0.000980  loss: 2.6924 (2.8691)  time: 12.4150  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [170/183]  eta: 0:02:41  lr: 0.000978  loss: 3.0001 (2.8650)  time: 12.3897  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train  [180/183]  eta: 0:00:37  lr: 0.000977  loss: 2.7683 (2.8693)  time: 12.3151  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Train Total time: 0:37:54\n",
      "Epoch: [1] Test  [  0/242]  eta: 0:06:05    time: 1.5102  data: 0.4516  max mem: 9536\n",
      "Epoch: [1] Test  [ 10/242]  eta: 0:03:51    time: 0.9981  data: 0.0413  max mem: 9536\n",
      "Epoch: [1] Test  [ 20/242]  eta: 0:03:33    time: 0.9363  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [ 30/242]  eta: 0:03:30    time: 0.9884  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [ 40/242]  eta: 0:03:23    time: 1.0486  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [ 50/242]  eta: 0:03:14    time: 1.0419  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [ 60/242]  eta: 0:03:07    time: 1.0735  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [ 70/242]  eta: 0:02:57    time: 1.0833  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [ 80/242]  eta: 0:02:46    time: 1.0274  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [ 90/242]  eta: 0:02:34    time: 0.9753  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [100/242]  eta: 0:02:25    time: 1.0104  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [110/242]  eta: 0:02:14    time: 1.0287  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [120/242]  eta: 0:02:05    time: 1.0382  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [130/242]  eta: 0:01:54    time: 1.0283  data: 0.0002  max mem: 9536\n",
      "Epoch: [1] Test  [140/242]  eta: 0:01:44    time: 0.9800  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [150/242]  eta: 0:01:33    time: 0.9867  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [160/242]  eta: 0:01:23    time: 0.9997  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [170/242]  eta: 0:01:13    time: 1.0489  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [180/242]  eta: 0:01:03    time: 1.1103  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [190/242]  eta: 0:00:53    time: 1.1128  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [200/242]  eta: 0:00:43    time: 1.0568  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [210/242]  eta: 0:00:32    time: 1.0299  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [220/242]  eta: 0:00:22    time: 1.0362  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [230/242]  eta: 0:00:12    time: 1.0429  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test  [240/242]  eta: 0:00:02    time: 1.0058  data: 0.0003  max mem: 9536\n",
      "Epoch: [1] Test Total time: 0:04:08\n",
      "global correct: 94.9\n",
      "average row correct: ['96.4', '96.7', '81.3', '92.8', '90.6', '85.4', '99.0', '92.6', '98.3', '66.9', '87.1', '73.6', '84.0', '95.6', '93.7', '95.9', '69.1', '96.4', '84.8', '94.2', '91.4']\n",
      "IoU: ['94.5', '94.3', '51.2', '87.7', '74.9', '72.6', '92.8', '82.3', '83.4', '48.7', '84.8', '63.6', '76.1', '86.0', '89.0', '89.2', '61.8', '71.2', '61.2', '87.9', '75.5']\n",
      "mean IoU: 77.6\n",
      "Epoch: [2] Train  [  0/183]  eta: 0:38:36  lr: 0.000977  loss: 2.7044 (2.7044)  time: 12.6560  data: 0.3698  max mem: 9536\n",
      "Epoch: [2] Train  [ 10/183]  eta: 0:36:10  lr: 0.000976  loss: 2.7836 (2.8724)  time: 12.5482  data: 0.0338  max mem: 9536\n",
      "Epoch: [2] Train  [ 20/183]  eta: 0:33:59  lr: 0.000974  loss: 2.6131 (2.8200)  time: 12.5019  data: 0.0002  max mem: 9536\n",
      "Epoch: [2] Train  [ 30/183]  eta: 0:31:48  lr: 0.000973  loss: 2.7178 (2.8429)  time: 12.4356  data: 0.0002  max mem: 9536\n",
      "Epoch: [2] Train  [ 40/183]  eta: 0:29:43  lr: 0.000972  loss: 3.3813 (2.8430)  time: 12.4293  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [ 50/183]  eta: 0:27:39  lr: 0.000970  loss: 2.5408 (2.8575)  time: 12.4833  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [ 60/183]  eta: 0:25:34  lr: 0.000969  loss: 2.7998 (2.8517)  time: 12.4868  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [ 70/183]  eta: 0:23:28  lr: 0.000968  loss: 2.8240 (2.8520)  time: 12.4432  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [ 80/183]  eta: 0:21:21  lr: 0.000967  loss: 2.9915 (2.8483)  time: 12.3424  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [ 90/183]  eta: 0:19:16  lr: 0.000965  loss: 2.7276 (2.8574)  time: 12.3143  data: 0.0004  max mem: 9536\n",
      "Epoch: [2] Train  [100/183]  eta: 0:17:11  lr: 0.000964  loss: 2.9840 (2.8736)  time: 12.3947  data: 0.0005  max mem: 9536\n",
      "Epoch: [2] Train  [110/183]  eta: 0:15:08  lr: 0.000963  loss: 2.7079 (2.8692)  time: 12.4748  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [120/183]  eta: 0:13:03  lr: 0.000962  loss: 3.1125 (2.8786)  time: 12.4794  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [130/183]  eta: 0:10:59  lr: 0.000960  loss: 2.9975 (2.8717)  time: 12.4167  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [140/183]  eta: 0:08:54  lr: 0.000959  loss: 2.7325 (2.8676)  time: 12.4371  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [150/183]  eta: 0:06:50  lr: 0.000958  loss: 3.0952 (2.8666)  time: 12.3919  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [160/183]  eta: 0:04:45  lr: 0.000957  loss: 3.1729 (2.8793)  time: 12.3433  data: 0.0004  max mem: 9536\n",
      "Epoch: [2] Train  [170/183]  eta: 0:02:41  lr: 0.000955  loss: 3.7224 (2.8813)  time: 12.4579  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Train  [180/183]  eta: 0:00:37  lr: 0.000954  loss: 2.6002 (2.8760)  time: 12.4420  data: 0.0004  max mem: 9536\n",
      "Epoch: [2] Train Total time: 0:37:54\n",
      "Epoch: [2] Test  [  0/242]  eta: 0:05:57    time: 1.4769  data: 0.4196  max mem: 9536\n",
      "Epoch: [2] Test  [ 10/242]  eta: 0:03:51    time: 0.9967  data: 0.0385  max mem: 9536\n",
      "Epoch: [2] Test  [ 20/242]  eta: 0:03:33    time: 0.9358  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [ 30/242]  eta: 0:03:29    time: 0.9853  data: 0.0004  max mem: 9536\n",
      "Epoch: [2] Test  [ 40/242]  eta: 0:03:22    time: 1.0459  data: 0.0005  max mem: 9536\n",
      "Epoch: [2] Test  [ 50/242]  eta: 0:03:13    time: 1.0412  data: 0.0005  max mem: 9536\n",
      "Epoch: [2] Test  [ 60/242]  eta: 0:03:06    time: 1.0727  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [ 70/242]  eta: 0:02:57    time: 1.0840  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [ 80/242]  eta: 0:02:46    time: 1.0291  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [ 90/242]  eta: 0:02:34    time: 0.9753  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [100/242]  eta: 0:02:25    time: 1.0101  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [110/242]  eta: 0:02:14    time: 1.0287  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [120/242]  eta: 0:02:05    time: 1.0402  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [130/242]  eta: 0:01:54    time: 1.0284  data: 0.0002  max mem: 9536\n",
      "Epoch: [2] Test  [140/242]  eta: 0:01:43    time: 0.9787  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [150/242]  eta: 0:01:33    time: 0.9877  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [160/242]  eta: 0:01:23    time: 1.0024  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [170/242]  eta: 0:01:13    time: 1.0524  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [180/242]  eta: 0:01:03    time: 1.1101  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [190/242]  eta: 0:00:53    time: 1.1117  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [200/242]  eta: 0:00:43    time: 1.0583  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [210/242]  eta: 0:00:32    time: 1.0305  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [220/242]  eta: 0:00:22    time: 1.0382  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [230/242]  eta: 0:00:12    time: 1.0458  data: 0.0003  max mem: 9536\n",
      "Epoch: [2] Test  [240/242]  eta: 0:00:02    time: 1.0089  data: 0.0004  max mem: 9536\n",
      "Epoch: [2] Test Total time: 0:04:08\n",
      "global correct: 95.0\n",
      "average row correct: ['96.0', '97.8', '89.6', '93.2', '92.6', '91.3', '98.8', '91.7', '98.2', '69.4', '95.2', '74.6', '91.5', '95.6', '95.5', '93.7', '77.3', '97.2', '84.8', '97.8', '92.1']\n",
      "IoU: ['94.5', '92.5', '48.5', '87.2', '70.3', '75.2', '92.7', '83.5', '85.6', '43.4', '92.0', '67.0', '82.2', '91.4', '89.1', '89.8', '67.6', '78.2', '61.6', '88.2', '67.3']\n",
      "mean IoU: 78.5\n",
      "Epoch: [3] Train  [  0/183]  eta: 0:40:17  lr: 0.000954  loss: 2.4562 (2.4562)  time: 13.2100  data: 0.3809  max mem: 9536\n",
      "Epoch: [3] Train  [ 10/183]  eta: 0:35:58  lr: 0.000952  loss: 2.8610 (2.7235)  time: 12.4757  data: 0.0350  max mem: 9536\n",
      "Epoch: [3] Train  [ 20/183]  eta: 0:33:47  lr: 0.000951  loss: 2.8422 (2.7262)  time: 12.4014  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [ 30/183]  eta: 0:31:45  lr: 0.000950  loss: 2.8835 (2.7525)  time: 12.4402  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [ 40/183]  eta: 0:29:38  lr: 0.000949  loss: 3.0000 (2.7679)  time: 12.4269  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [ 50/183]  eta: 0:27:33  lr: 0.000947  loss: 3.1705 (2.7906)  time: 12.4067  data: 0.0004  max mem: 9536\n",
      "Epoch: [3] Train  [ 60/183]  eta: 0:25:29  lr: 0.000946  loss: 3.7004 (2.8212)  time: 12.4312  data: 0.0004  max mem: 9536\n",
      "Epoch: [3] Train  [ 70/183]  eta: 0:23:23  lr: 0.000945  loss: 2.7901 (2.8169)  time: 12.3929  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [ 80/183]  eta: 0:21:20  lr: 0.000943  loss: 3.0375 (2.8283)  time: 12.4200  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [ 90/183]  eta: 0:19:14  lr: 0.000942  loss: 2.8117 (2.8269)  time: 12.3911  data: 0.0005  max mem: 9536\n",
      "Epoch: [3] Train  [100/183]  eta: 0:17:11  lr: 0.000941  loss: 2.7440 (2.8383)  time: 12.4192  data: 0.0006  max mem: 9536\n",
      "Epoch: [3] Train  [110/183]  eta: 0:15:07  lr: 0.000940  loss: 2.8634 (2.8363)  time: 12.5141  data: 0.0005  max mem: 9536\n",
      "Epoch: [3] Train  [120/183]  eta: 0:13:02  lr: 0.000938  loss: 2.9085 (2.8472)  time: 12.4268  data: 0.0005  max mem: 9536\n",
      "Epoch: [3] Train  [130/183]  eta: 0:10:58  lr: 0.000937  loss: 2.9285 (2.8507)  time: 12.3559  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [140/183]  eta: 0:08:53  lr: 0.000936  loss: 2.8346 (2.8503)  time: 12.3529  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [150/183]  eta: 0:06:49  lr: 0.000935  loss: 2.7833 (2.8512)  time: 12.3821  data: 0.0002  max mem: 9536\n",
      "Epoch: [3] Train  [160/183]  eta: 0:04:45  lr: 0.000933  loss: 2.7883 (2.8495)  time: 12.3743  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [170/183]  eta: 0:02:41  lr: 0.000932  loss: 2.5886 (2.8528)  time: 12.4106  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train  [180/183]  eta: 0:00:37  lr: 0.000931  loss: 2.7730 (2.8584)  time: 12.4421  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Train Total time: 0:37:51\n",
      "Epoch: [3] Test  [  0/242]  eta: 0:05:57    time: 1.4760  data: 0.4013  max mem: 9536\n",
      "Epoch: [3] Test  [ 10/242]  eta: 0:03:50    time: 0.9936  data: 0.0367  max mem: 9536\n",
      "Epoch: [3] Test  [ 20/242]  eta: 0:03:33    time: 0.9337  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [ 30/242]  eta: 0:03:29    time: 0.9851  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [ 40/242]  eta: 0:03:22    time: 1.0457  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [ 50/242]  eta: 0:03:13    time: 1.0392  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [ 60/242]  eta: 0:03:06    time: 1.0721  data: 0.0004  max mem: 9536\n",
      "Epoch: [3] Test  [ 70/242]  eta: 0:02:57    time: 1.0826  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [ 80/242]  eta: 0:02:46    time: 1.0266  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [ 90/242]  eta: 0:02:34    time: 0.9747  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [100/242]  eta: 0:02:25    time: 1.0088  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [110/242]  eta: 0:02:14    time: 1.0283  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [120/242]  eta: 0:02:05    time: 1.0409  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [130/242]  eta: 0:01:54    time: 1.0279  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [140/242]  eta: 0:01:43    time: 0.9777  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [150/242]  eta: 0:01:33    time: 0.9851  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [160/242]  eta: 0:01:23    time: 0.9989  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [170/242]  eta: 0:01:13    time: 1.0506  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [180/242]  eta: 0:01:03    time: 1.1087  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [190/242]  eta: 0:00:53    time: 1.1091  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [200/242]  eta: 0:00:43    time: 1.0562  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [210/242]  eta: 0:00:32    time: 1.0300  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [220/242]  eta: 0:00:22    time: 1.0389  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [230/242]  eta: 0:00:12    time: 1.0468  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test  [240/242]  eta: 0:00:02    time: 1.0091  data: 0.0003  max mem: 9536\n",
      "Epoch: [3] Test Total time: 0:04:08\n",
      "global correct: 95.4\n",
      "average row correct: ['96.2', '97.6', '87.3', '93.1', '93.0', '94.0', '98.5', '95.8', '97.7', '76.0', '95.8', '77.2', '92.7', '96.6', '97.9', '95.9', '76.8', '96.3', '75.8', '97.4', '91.4']\n",
      "IoU: ['94.8', '93.0', '56.9', '87.7', '67.3', '77.3', '95.1', '83.1', '88.4', '45.9', '93.2', '70.4', '85.5', '90.0', '89.5', '89.9', '68.7', '91.2', '59.9', '84.1', '71.6']\n",
      "mean IoU: 80.2\n",
      "Epoch: [4] Train  [  0/183]  eta: 0:40:33  lr: 0.000930  loss: 2.9312 (2.9312)  time: 13.2982  data: 0.4502  max mem: 9536\n",
      "Epoch: [4] Train  [ 10/183]  eta: 0:36:13  lr: 0.000929  loss: 2.7292 (2.8000)  time: 12.5665  data: 0.0411  max mem: 9536\n",
      "Epoch: [4] Train  [ 20/183]  eta: 0:33:55  lr: 0.000928  loss: 2.4931 (2.7582)  time: 12.4464  data: 0.0002  max mem: 9536\n",
      "Epoch: [4] Train  [ 30/183]  eta: 0:31:43  lr: 0.000927  loss: 2.5821 (2.7484)  time: 12.3675  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Train  [ 40/183]  eta: 0:29:34  lr: 0.000925  loss: 3.0173 (2.7575)  time: 12.3239  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Train  [ 50/183]  eta: 0:27:27  lr: 0.000924  loss: 2.7440 (2.7762)  time: 12.3050  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Train  [ 60/183]  eta: 0:25:27  lr: 0.000923  loss: 3.1895 (2.7856)  time: 12.4335  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Train  [ 70/183]  eta: 0:23:19  lr: 0.000921  loss: 2.8075 (2.7764)  time: 12.3722  data: 0.0005  max mem: 9536\n",
      "Epoch: [4] Train  [ 80/183]  eta: 0:21:15  lr: 0.000920  loss: 2.5935 (2.7859)  time: 12.2777  data: 0.0005  max mem: 9536\n",
      "Epoch: [4] Train  [ 90/183]  eta: 0:19:11  lr: 0.000919  loss: 2.6608 (2.7927)  time: 12.4033  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Train  [100/183]  eta: 0:17:07  lr: 0.000918  loss: 2.8678 (2.8123)  time: 12.3509  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Train  [110/183]  eta: 0:15:02  lr: 0.000916  loss: 2.7252 (2.8421)  time: 12.2898  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Train  [120/183]  eta: 0:12:59  lr: 0.000915  loss: 3.6955 (2.8585)  time: 12.3572  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Train  [130/183]  eta: 0:10:55  lr: 0.000914  loss: 2.7456 (2.8627)  time: 12.3435  data: 0.0012  max mem: 9536\n",
      "Epoch: [4] Train  [140/183]  eta: 0:08:51  lr: 0.000913  loss: 3.4356 (2.8762)  time: 12.3342  data: 0.0012  max mem: 9536\n",
      "Epoch: [4] Train  [150/183]  eta: 0:06:48  lr: 0.000911  loss: 2.8576 (2.8777)  time: 12.3783  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Train  [160/183]  eta: 0:04:44  lr: 0.000910  loss: 3.1720 (2.8769)  time: 12.3563  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Train  [170/183]  eta: 0:02:40  lr: 0.000909  loss: 3.1829 (2.8822)  time: 12.3606  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Train  [180/183]  eta: 0:00:37  lr: 0.000907  loss: 2.9705 (2.8813)  time: 12.3190  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Train Total time: 0:37:41\n",
      "Epoch: [4] Test  [  0/242]  eta: 0:05:56    time: 1.4734  data: 0.4100  max mem: 9536\n",
      "Epoch: [4] Test  [ 10/242]  eta: 0:03:51    time: 0.9960  data: 0.0375  max mem: 9536\n",
      "Epoch: [4] Test  [ 20/242]  eta: 0:03:33    time: 0.9375  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [ 30/242]  eta: 0:03:29    time: 0.9870  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [ 40/242]  eta: 0:03:22    time: 1.0472  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [ 50/242]  eta: 0:03:13    time: 1.0418  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [ 60/242]  eta: 0:03:06    time: 1.0739  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [ 70/242]  eta: 0:02:57    time: 1.0854  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [ 80/242]  eta: 0:02:46    time: 1.0282  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [ 90/242]  eta: 0:02:34    time: 0.9778  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [100/242]  eta: 0:02:25    time: 1.0116  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [110/242]  eta: 0:02:14    time: 1.0281  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [120/242]  eta: 0:02:05    time: 1.0416  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [130/242]  eta: 0:01:54    time: 1.0296  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [140/242]  eta: 0:01:44    time: 0.9803  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [150/242]  eta: 0:01:33    time: 0.9889  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [160/242]  eta: 0:01:23    time: 0.9994  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [170/242]  eta: 0:01:13    time: 1.0475  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [180/242]  eta: 0:01:03    time: 1.1075  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [190/242]  eta: 0:00:53    time: 1.1097  data: 0.0004  max mem: 9536\n",
      "Epoch: [4] Test  [200/242]  eta: 0:00:43    time: 1.0548  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [210/242]  eta: 0:00:32    time: 1.0294  data: 0.0003  max mem: 9536\n",
      "Epoch: [4] Test  [220/242]  eta: 0:00:22    time: 1.0397  data: 0.0002  max mem: 9536\n",
      "Epoch: [4] Test  [230/242]  eta: 0:00:12    time: 1.0460  data: 0.0002  max mem: 9536\n",
      "Epoch: [4] Test  [240/242]  eta: 0:00:02    time: 1.0085  data: 0.0002  max mem: 9536\n",
      "Epoch: [4] Test Total time: 0:04:08\n",
      "global correct: 94.6\n",
      "average row correct: ['96.0', '97.8', '89.2', '92.8', '92.8', '94.3', '95.9', '87.9', '97.9', '67.3', '93.5', '74.0', '82.0', '95.2', '97.3', '93.4', '88.8', '97.3', '80.1', '98.0', '89.9']\n",
      "IoU: ['94.3', '91.3', '57.9', '85.9', '66.0', '74.0', '93.2', '84.2', '80.4', '50.1', '87.6', '68.2', '75.6', '90.0', '84.6', '90.4', '68.5', '69.1', '64.4', '73.0', '63.0']\n",
      "mean IoU: 76.7\n",
      "Epoch: [5] Train  [  0/183]  eta: 0:39:21  lr: 0.000907  loss: 2.5820 (2.5820)  time: 12.9065  data: 0.4030  max mem: 9536\n",
      "Epoch: [5] Train  [ 10/183]  eta: 0:35:46  lr: 0.000906  loss: 2.6582 (2.8124)  time: 12.4103  data: 0.0369  max mem: 9536\n",
      "Epoch: [5] Train  [ 20/183]  eta: 0:33:20  lr: 0.000905  loss: 2.9932 (2.7906)  time: 12.2437  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Train  [ 30/183]  eta: 0:31:23  lr: 0.000903  loss: 2.6732 (2.7922)  time: 12.2553  data: 0.0004  max mem: 9536\n",
      "Epoch: [5] Train  [ 40/183]  eta: 0:29:22  lr: 0.000902  loss: 3.1738 (2.7909)  time: 12.3716  data: 0.0004  max mem: 9536\n",
      "Epoch: [5] Train  [ 50/183]  eta: 0:27:22  lr: 0.000901  loss: 2.5753 (2.8033)  time: 12.4138  data: 0.0004  max mem: 9536\n",
      "Epoch: [5] Train  [ 60/183]  eta: 0:25:18  lr: 0.000899  loss: 2.6245 (2.7973)  time: 12.3822  data: 0.0005  max mem: 9536\n",
      "Epoch: [5] Train  [ 70/183]  eta: 0:23:14  lr: 0.000898  loss: 2.6156 (2.8083)  time: 12.3106  data: 0.0004  max mem: 9536\n",
      "Epoch: [5] Train  [ 80/183]  eta: 0:21:10  lr: 0.000897  loss: 2.7844 (2.8335)  time: 12.3088  data: 0.0005  max mem: 9536\n",
      "Epoch: [5] Train  [ 90/183]  eta: 0:19:05  lr: 0.000896  loss: 2.7573 (2.8331)  time: 12.2293  data: 0.0006  max mem: 9536\n",
      "Epoch: [5] Train  [100/183]  eta: 0:17:01  lr: 0.000894  loss: 2.8755 (2.8254)  time: 12.2220  data: 0.0005  max mem: 9536\n",
      "Epoch: [5] Train  [110/183]  eta: 0:14:59  lr: 0.000893  loss: 2.7561 (2.8229)  time: 12.3286  data: 0.0004  max mem: 9536\n",
      "Epoch: [5] Train  [120/183]  eta: 0:12:55  lr: 0.000892  loss: 2.9755 (2.8220)  time: 12.3326  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Train  [130/183]  eta: 0:10:52  lr: 0.000890  loss: 3.1387 (2.8174)  time: 12.3232  data: 0.0004  max mem: 9536\n",
      "Epoch: [5] Train  [140/183]  eta: 0:08:49  lr: 0.000889  loss: 2.7186 (2.8106)  time: 12.3154  data: 0.0004  max mem: 9536\n",
      "Epoch: [5] Train  [150/183]  eta: 0:06:46  lr: 0.000888  loss: 2.7424 (2.8140)  time: 12.3359  data: 0.0004  max mem: 9536\n",
      "Epoch: [5] Train  [160/183]  eta: 0:04:43  lr: 0.000887  loss: 2.7739 (2.8132)  time: 12.3727  data: 0.0005  max mem: 9536\n",
      "Epoch: [5] Train  [170/183]  eta: 0:02:40  lr: 0.000885  loss: 2.9627 (2.8150)  time: 12.3258  data: 0.0005  max mem: 9536\n",
      "Epoch: [5] Train  [180/183]  eta: 0:00:36  lr: 0.000884  loss: 2.5521 (2.8136)  time: 12.2972  data: 0.0005  max mem: 9536\n",
      "Epoch: [5] Train Total time: 0:37:34\n",
      "Epoch: [5] Test  [  0/242]  eta: 0:05:53    time: 1.4599  data: 0.3997  max mem: 9536\n",
      "Epoch: [5] Test  [ 10/242]  eta: 0:03:50    time: 0.9923  data: 0.0366  max mem: 9536\n",
      "Epoch: [5] Test  [ 20/242]  eta: 0:03:33    time: 0.9355  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [ 30/242]  eta: 0:03:29    time: 0.9874  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [ 40/242]  eta: 0:03:22    time: 1.0474  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [ 50/242]  eta: 0:03:13    time: 1.0421  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [ 60/242]  eta: 0:03:06    time: 1.0742  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [ 70/242]  eta: 0:02:57    time: 1.0828  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [ 80/242]  eta: 0:02:46    time: 1.0260  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [ 90/242]  eta: 0:02:34    time: 0.9776  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [100/242]  eta: 0:02:25    time: 1.0113  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [110/242]  eta: 0:02:14    time: 1.0280  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [120/242]  eta: 0:02:05    time: 1.0426  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [130/242]  eta: 0:01:54    time: 1.0298  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [140/242]  eta: 0:01:44    time: 0.9793  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [150/242]  eta: 0:01:33    time: 0.9872  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [160/242]  eta: 0:01:23    time: 0.9991  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [170/242]  eta: 0:01:13    time: 1.0488  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [180/242]  eta: 0:01:03    time: 1.1104  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [190/242]  eta: 0:00:53    time: 1.1141  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [200/242]  eta: 0:00:43    time: 1.0583  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [210/242]  eta: 0:00:32    time: 1.0310  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [220/242]  eta: 0:00:22    time: 1.0393  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [230/242]  eta: 0:00:12    time: 1.0438  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test  [240/242]  eta: 0:00:02    time: 1.0067  data: 0.0003  max mem: 9536\n",
      "Epoch: [5] Test Total time: 0:04:08\n",
      "global correct: 95.8\n",
      "average row correct: ['97.2', '97.7', '87.4', '94.9', '90.4', '91.3', '98.6', '93.8', '98.3', '64.9', '95.7', '80.9', '87.2', '96.1', '94.8', '96.6', '83.3', '96.6', '74.1', '95.2', '91.3']\n",
      "IoU: ['95.5', '94.2', '57.7', '86.8', '73.6', '80.4', '95.9', '89.5', '87.3', '46.5', '91.9', '71.1', '83.1', '87.8', '88.5', '89.5', '66.5', '89.9', '63.5', '87.5', '77.3']\n",
      "mean IoU: 81.1\n",
      "Epoch: [6] Train  [  0/183]  eta: 0:39:23  lr: 0.000884  loss: 2.4888 (2.4888)  time: 12.9145  data: 0.4145  max mem: 9536\n",
      "Epoch: [6] Train  [ 10/183]  eta: 0:35:50  lr: 0.000882  loss: 2.8767 (3.0410)  time: 12.4317  data: 0.0380  max mem: 9536\n",
      "Epoch: [6] Train  [ 20/183]  eta: 0:33:36  lr: 0.000881  loss: 2.4884 (2.9569)  time: 12.3462  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Train  [ 30/183]  eta: 0:31:34  lr: 0.000880  loss: 2.6364 (2.9154)  time: 12.3504  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Train  [ 40/183]  eta: 0:29:30  lr: 0.000879  loss: 2.6034 (2.9368)  time: 12.3852  data: 0.0005  max mem: 9536\n",
      "Epoch: [6] Train  [ 50/183]  eta: 0:27:23  lr: 0.000877  loss: 2.9264 (2.8927)  time: 12.3263  data: 0.0005  max mem: 9536\n",
      "Epoch: [6] Train  [ 60/183]  eta: 0:25:20  lr: 0.000876  loss: 2.8380 (2.8936)  time: 12.3317  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Train  [ 70/183]  eta: 0:23:18  lr: 0.000875  loss: 2.8399 (2.8875)  time: 12.4062  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Train  [ 80/183]  eta: 0:21:11  lr: 0.000873  loss: 2.4870 (2.8681)  time: 12.2927  data: 0.0005  max mem: 9536\n",
      "Epoch: [6] Train  [ 90/183]  eta: 0:19:06  lr: 0.000872  loss: 3.0365 (2.8614)  time: 12.1744  data: 0.0005  max mem: 9536\n",
      "Epoch: [6] Train  [100/183]  eta: 0:17:03  lr: 0.000871  loss: 2.7252 (2.8560)  time: 12.2662  data: 0.0005  max mem: 9536\n",
      "Epoch: [6] Train  [110/183]  eta: 0:14:59  lr: 0.000870  loss: 2.7873 (2.8475)  time: 12.3111  data: 0.0006  max mem: 9536\n",
      "Epoch: [6] Train  [120/183]  eta: 0:12:56  lr: 0.000868  loss: 3.0197 (2.8434)  time: 12.2676  data: 0.0005  max mem: 9536\n",
      "Epoch: [6] Train  [130/183]  eta: 0:10:52  lr: 0.000867  loss: 2.7068 (2.8448)  time: 12.2595  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Train  [140/183]  eta: 0:08:49  lr: 0.000866  loss: 2.7220 (2.8442)  time: 12.2904  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Train  [150/183]  eta: 0:06:46  lr: 0.000865  loss: 2.7359 (2.8489)  time: 12.3770  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Train  [160/183]  eta: 0:04:43  lr: 0.000863  loss: 2.6777 (2.8439)  time: 12.4186  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Train  [170/183]  eta: 0:02:40  lr: 0.000862  loss: 3.1082 (2.8459)  time: 12.3331  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Train  [180/183]  eta: 0:00:37  lr: 0.000861  loss: 2.6219 (2.8431)  time: 12.3763  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Train Total time: 0:37:37\n",
      "Epoch: [6] Test  [  0/242]  eta: 0:06:00    time: 1.4908  data: 0.4280  max mem: 9536\n",
      "Epoch: [6] Test  [ 10/242]  eta: 0:03:51    time: 0.9991  data: 0.0392  max mem: 9536\n",
      "Epoch: [6] Test  [ 20/242]  eta: 0:03:33    time: 0.9365  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [ 30/242]  eta: 0:03:30    time: 0.9866  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [ 40/242]  eta: 0:03:22    time: 1.0481  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [ 50/242]  eta: 0:03:14    time: 1.0406  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Test  [ 60/242]  eta: 0:03:06    time: 1.0734  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Test  [ 70/242]  eta: 0:02:57    time: 1.0845  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [ 80/242]  eta: 0:02:46    time: 1.0274  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [ 90/242]  eta: 0:02:34    time: 0.9761  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [100/242]  eta: 0:02:25    time: 1.0106  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [110/242]  eta: 0:02:14    time: 1.0274  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [120/242]  eta: 0:02:05    time: 1.0388  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [130/242]  eta: 0:01:54    time: 1.0263  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Test  [140/242]  eta: 0:01:43    time: 0.9770  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Test  [150/242]  eta: 0:01:33    time: 0.9868  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [160/242]  eta: 0:01:23    time: 1.0005  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [170/242]  eta: 0:01:13    time: 1.0504  data: 0.0005  max mem: 9536\n",
      "Epoch: [6] Test  [180/242]  eta: 0:01:03    time: 1.1089  data: 0.0005  max mem: 9536\n",
      "Epoch: [6] Test  [190/242]  eta: 0:00:53    time: 1.1109  data: 0.0004  max mem: 9536\n",
      "Epoch: [6] Test  [200/242]  eta: 0:00:43    time: 1.0586  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [210/242]  eta: 0:00:32    time: 1.0314  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [220/242]  eta: 0:00:22    time: 1.0361  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [230/242]  eta: 0:00:12    time: 1.0416  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test  [240/242]  eta: 0:00:02    time: 1.0064  data: 0.0003  max mem: 9536\n",
      "Epoch: [6] Test Total time: 0:04:08\n",
      "global correct: 94.5\n",
      "average row correct: ['95.8', '98.3', '84.9', '95.0', '86.2', '94.1', '98.3', '94.3', '98.6', '66.5', '83.4', '83.5', '82.0', '92.6', '96.6', '94.1', '73.5', '97.6', '78.5', '97.7', '90.1']\n",
      "IoU: ['94.3', '84.8', '57.9', '85.4', '69.6', '70.1', '95.4', '86.7', '77.6', '43.2', '81.3', '66.4', '72.5', '86.8', '89.6', '89.2', '62.9', '75.3', '56.4', '87.0', '72.2']\n",
      "mean IoU: 76.4\n",
      "Epoch: [7] Train  [  0/183]  eta: 0:38:43  lr: 0.000860  loss: 2.7852 (2.7852)  time: 12.6980  data: 0.4877  max mem: 9536\n",
      "Epoch: [7] Train  [ 10/183]  eta: 0:35:45  lr: 0.000859  loss: 2.8259 (2.7696)  time: 12.4011  data: 0.0446  max mem: 9536\n",
      "Epoch: [7] Train  [ 20/183]  eta: 0:33:43  lr: 0.000858  loss: 2.5423 (2.7612)  time: 12.4008  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Train  [ 30/183]  eta: 0:31:33  lr: 0.000856  loss: 2.8208 (2.7705)  time: 12.3568  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Train  [ 40/183]  eta: 0:29:30  lr: 0.000855  loss: 2.6401 (2.7781)  time: 12.3415  data: 0.0006  max mem: 9536\n",
      "Epoch: [7] Train  [ 50/183]  eta: 0:27:24  lr: 0.000854  loss: 2.7839 (2.7928)  time: 12.3615  data: 0.0006  max mem: 9536\n",
      "Epoch: [7] Train  [ 60/183]  eta: 0:25:19  lr: 0.000853  loss: 2.8490 (2.7737)  time: 12.3052  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Train  [ 70/183]  eta: 0:23:15  lr: 0.000851  loss: 2.7682 (2.7852)  time: 12.3042  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Train  [ 80/183]  eta: 0:21:09  lr: 0.000850  loss: 2.6701 (2.7924)  time: 12.2535  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Train  [ 90/183]  eta: 0:19:08  lr: 0.000849  loss: 3.0003 (2.7980)  time: 12.3396  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Train  [100/183]  eta: 0:17:03  lr: 0.000847  loss: 2.6978 (2.8019)  time: 12.3604  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Train  [110/183]  eta: 0:14:59  lr: 0.000846  loss: 2.9837 (2.8001)  time: 12.2411  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Train  [120/183]  eta: 0:12:55  lr: 0.000845  loss: 2.7039 (2.7970)  time: 12.2088  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Train  [130/183]  eta: 0:10:52  lr: 0.000844  loss: 2.9533 (2.7899)  time: 12.1960  data: 0.0005  max mem: 9536\n",
      "Epoch: [7] Train  [140/183]  eta: 0:08:49  lr: 0.000842  loss: 2.5703 (2.7881)  time: 12.3412  data: 0.0005  max mem: 9536\n",
      "Epoch: [7] Train  [150/183]  eta: 0:06:46  lr: 0.000841  loss: 2.9086 (2.7915)  time: 12.3286  data: 0.0005  max mem: 9536\n",
      "Epoch: [7] Train  [160/183]  eta: 0:04:43  lr: 0.000840  loss: 3.1034 (2.7939)  time: 12.2662  data: 0.0007  max mem: 9536\n",
      "Epoch: [7] Train  [170/183]  eta: 0:02:40  lr: 0.000838  loss: 3.1027 (2.7950)  time: 12.2972  data: 0.0006  max mem: 9536\n",
      "Epoch: [7] Train  [180/183]  eta: 0:00:36  lr: 0.000837  loss: 2.7165 (2.7944)  time: 12.2802  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Train Total time: 0:37:32\n",
      "Epoch: [7] Test  [  0/242]  eta: 0:06:10    time: 1.5315  data: 0.4636  max mem: 9536\n",
      "Epoch: [7] Test  [ 10/242]  eta: 0:03:51    time: 0.9998  data: 0.0424  max mem: 9536\n",
      "Epoch: [7] Test  [ 20/242]  eta: 0:03:33    time: 0.9352  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [ 30/242]  eta: 0:03:30    time: 0.9860  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Test  [ 40/242]  eta: 0:03:23    time: 1.0493  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [ 50/242]  eta: 0:03:14    time: 1.0451  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [ 60/242]  eta: 0:03:07    time: 1.0776  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Test  [ 70/242]  eta: 0:02:57    time: 1.0890  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [ 80/242]  eta: 0:02:46    time: 1.0324  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Test  [ 90/242]  eta: 0:02:35    time: 0.9797  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Test  [100/242]  eta: 0:02:25    time: 1.0110  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [110/242]  eta: 0:02:15    time: 1.0306  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [120/242]  eta: 0:02:05    time: 1.0441  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Test  [130/242]  eta: 0:01:54    time: 1.0295  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Test  [140/242]  eta: 0:01:44    time: 0.9802  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [150/242]  eta: 0:01:33    time: 0.9901  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Test  [160/242]  eta: 0:01:23    time: 1.0032  data: 0.0004  max mem: 9536\n",
      "Epoch: [7] Test  [170/242]  eta: 0:01:13    time: 1.0513  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [180/242]  eta: 0:01:03    time: 1.1102  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [190/242]  eta: 0:00:53    time: 1.1120  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [200/242]  eta: 0:00:43    time: 1.0568  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [210/242]  eta: 0:00:33    time: 1.0316  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [220/242]  eta: 0:00:22    time: 1.0408  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [230/242]  eta: 0:00:12    time: 1.0465  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test  [240/242]  eta: 0:00:02    time: 1.0102  data: 0.0003  max mem: 9536\n",
      "Epoch: [7] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['96.7', '96.9', '83.0', '92.3', '95.3', '92.5', '98.4', '94.9', '97.1', '61.7', '96.5', '69.8', '93.7', '90.8', '95.7', '95.2', '80.1', '97.0', '70.6', '97.7', '90.4']\n",
      "IoU: ['94.8', '93.7', '60.5', '87.0', '69.8', '73.3', '95.7', '88.8', '89.3', '41.8', '90.6', '63.1', '84.9', '86.6', '90.8', '89.7', '63.9', '88.7', '56.9', '82.3', '74.4']\n",
      "mean IoU: 79.4\n",
      "Epoch: [8] Train  [  0/183]  eta: 0:39:46  lr: 0.000837  loss: 3.0013 (3.0013)  time: 13.0391  data: 0.4933  max mem: 9536\n",
      "Epoch: [8] Train  [ 10/183]  eta: 0:35:54  lr: 0.000835  loss: 2.6916 (2.7945)  time: 12.4549  data: 0.0451  max mem: 9536\n",
      "Epoch: [8] Train  [ 20/183]  eta: 0:33:44  lr: 0.000834  loss: 2.6243 (2.7439)  time: 12.3868  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Train  [ 30/183]  eta: 0:31:33  lr: 0.000833  loss: 2.8911 (2.7250)  time: 12.3361  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Train  [ 40/183]  eta: 0:29:29  lr: 0.000832  loss: 3.2835 (2.7545)  time: 12.3247  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Train  [ 50/183]  eta: 0:27:25  lr: 0.000830  loss: 2.5752 (2.7503)  time: 12.3613  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [ 60/183]  eta: 0:25:22  lr: 0.000829  loss: 2.5017 (2.7833)  time: 12.3963  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [ 70/183]  eta: 0:23:18  lr: 0.000828  loss: 2.6779 (2.7839)  time: 12.3851  data: 0.0005  max mem: 9536\n",
      "Epoch: [8] Train  [ 80/183]  eta: 0:21:13  lr: 0.000826  loss: 2.7445 (2.7762)  time: 12.3189  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [ 90/183]  eta: 0:19:08  lr: 0.000825  loss: 2.9700 (2.7801)  time: 12.2700  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [100/183]  eta: 0:17:04  lr: 0.000824  loss: 2.8380 (2.7786)  time: 12.2492  data: 0.0005  max mem: 9536\n",
      "Epoch: [8] Train  [110/183]  eta: 0:15:01  lr: 0.000823  loss: 2.8104 (2.7759)  time: 12.3128  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [120/183]  eta: 0:12:57  lr: 0.000821  loss: 2.7939 (2.7876)  time: 12.3717  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Train  [130/183]  eta: 0:10:54  lr: 0.000820  loss: 2.8524 (2.7909)  time: 12.3136  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [140/183]  eta: 0:08:50  lr: 0.000819  loss: 2.7161 (2.7963)  time: 12.2901  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [150/183]  eta: 0:06:46  lr: 0.000817  loss: 3.0675 (2.7963)  time: 12.2749  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Train  [160/183]  eta: 0:04:43  lr: 0.000816  loss: 2.5401 (2.7955)  time: 12.2457  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [170/183]  eta: 0:02:40  lr: 0.000815  loss: 2.9795 (2.7965)  time: 12.1864  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Train  [180/183]  eta: 0:00:36  lr: 0.000814  loss: 3.1777 (2.7963)  time: 12.1011  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Train Total time: 0:37:31\n",
      "Epoch: [8] Test  [  0/242]  eta: 0:05:49    time: 1.4441  data: 0.3810  max mem: 9536\n",
      "Epoch: [8] Test  [ 10/242]  eta: 0:03:50    time: 0.9927  data: 0.0350  max mem: 9536\n",
      "Epoch: [8] Test  [ 20/242]  eta: 0:03:33    time: 0.9370  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [ 30/242]  eta: 0:03:29    time: 0.9881  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [ 40/242]  eta: 0:03:22    time: 1.0483  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [ 50/242]  eta: 0:03:14    time: 1.0436  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [ 60/242]  eta: 0:03:07    time: 1.0779  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [ 70/242]  eta: 0:02:57    time: 1.0867  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [ 80/242]  eta: 0:02:46    time: 1.0296  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [ 90/242]  eta: 0:02:35    time: 0.9773  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [100/242]  eta: 0:02:25    time: 1.0127  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [110/242]  eta: 0:02:14    time: 1.0312  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [120/242]  eta: 0:02:05    time: 1.0407  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [130/242]  eta: 0:01:54    time: 1.0305  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [140/242]  eta: 0:01:44    time: 0.9818  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [150/242]  eta: 0:01:33    time: 0.9897  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [160/242]  eta: 0:01:23    time: 0.9999  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [170/242]  eta: 0:01:13    time: 1.0489  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [180/242]  eta: 0:01:03    time: 1.1091  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [190/242]  eta: 0:00:53    time: 1.1101  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Test  [200/242]  eta: 0:00:43    time: 1.0563  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [210/242]  eta: 0:00:33    time: 1.0299  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [220/242]  eta: 0:00:22    time: 1.0381  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [230/242]  eta: 0:00:12    time: 1.0442  data: 0.0003  max mem: 9536\n",
      "Epoch: [8] Test  [240/242]  eta: 0:00:02    time: 1.0069  data: 0.0004  max mem: 9536\n",
      "Epoch: [8] Test Total time: 0:04:08\n",
      "global correct: 95.1\n",
      "average row correct: ['96.7', '97.2', '84.9', '92.8', '87.0', '93.9', '98.6', '93.1', '97.7', '63.8', '94.0', '74.6', '87.6', '91.7', '95.0', '93.7', '83.2', '97.7', '76.9', '94.6', '91.0']\n",
      "IoU: ['94.9', '90.3', '60.5', '84.5', '72.7', '75.1', '94.9', '90.5', '83.7', '43.7', '90.2', '68.3', '77.4', '87.4', '89.2', '89.9', '66.1', '75.4', '54.0', '89.8', '71.6']\n",
      "mean IoU: 78.6\n",
      "Epoch: [9] Train  [  0/183]  eta: 0:38:00  lr: 0.000813  loss: 2.8572 (2.8572)  time: 12.4635  data: 0.3934  max mem: 9536\n",
      "Epoch: [9] Train  [ 10/183]  eta: 0:35:50  lr: 0.000812  loss: 2.6471 (2.7030)  time: 12.4311  data: 0.0360  max mem: 9536\n",
      "Epoch: [9] Train  [ 20/183]  eta: 0:33:25  lr: 0.000811  loss: 2.7881 (2.7362)  time: 12.2987  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Train  [ 30/183]  eta: 0:31:22  lr: 0.000809  loss: 2.5368 (2.7192)  time: 12.2328  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Train  [ 40/183]  eta: 0:29:21  lr: 0.000808  loss: 3.0564 (2.7453)  time: 12.3264  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Train  [ 50/183]  eta: 0:27:20  lr: 0.000807  loss: 2.6682 (2.7518)  time: 12.3753  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Train  [ 60/183]  eta: 0:25:16  lr: 0.000805  loss: 3.1503 (2.7580)  time: 12.3562  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Train  [ 70/183]  eta: 0:23:13  lr: 0.000804  loss: 2.7109 (2.7527)  time: 12.3182  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Train  [ 80/183]  eta: 0:21:08  lr: 0.000803  loss: 2.7029 (2.7602)  time: 12.2677  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Train  [ 90/183]  eta: 0:19:06  lr: 0.000802  loss: 2.5670 (2.7664)  time: 12.3118  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Train  [100/183]  eta: 0:17:03  lr: 0.000800  loss: 2.6930 (2.7615)  time: 12.3731  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Train  [110/183]  eta: 0:14:58  lr: 0.000799  loss: 2.7756 (2.7689)  time: 12.2194  data: 0.0002  max mem: 9536\n",
      "Epoch: [9] Train  [120/183]  eta: 0:12:54  lr: 0.000798  loss: 2.6879 (2.7709)  time: 12.1528  data: 0.0002  max mem: 9536\n",
      "Epoch: [9] Train  [130/183]  eta: 0:10:52  lr: 0.000796  loss: 3.0148 (2.7720)  time: 12.3443  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Train  [140/183]  eta: 0:08:49  lr: 0.000795  loss: 2.6884 (2.7711)  time: 12.4351  data: 0.0005  max mem: 9536\n",
      "Epoch: [9] Train  [150/183]  eta: 0:06:46  lr: 0.000794  loss: 3.1546 (2.7795)  time: 12.3493  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Train  [160/183]  eta: 0:04:43  lr: 0.000793  loss: 2.9640 (2.7723)  time: 12.3461  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Train  [170/183]  eta: 0:02:40  lr: 0.000791  loss: 2.6795 (2.7713)  time: 12.3005  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Train  [180/183]  eta: 0:00:36  lr: 0.000790  loss: 2.6250 (2.7721)  time: 12.2880  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Train Total time: 0:37:33\n",
      "Epoch: [9] Test  [  0/242]  eta: 0:05:48    time: 1.4417  data: 0.3851  max mem: 9536\n",
      "Epoch: [9] Test  [ 10/242]  eta: 0:03:49    time: 0.9904  data: 0.0352  max mem: 9536\n",
      "Epoch: [9] Test  [ 20/242]  eta: 0:03:33    time: 0.9357  data: 0.0002  max mem: 9536\n",
      "Epoch: [9] Test  [ 30/242]  eta: 0:03:29    time: 0.9886  data: 0.0002  max mem: 9536\n",
      "Epoch: [9] Test  [ 40/242]  eta: 0:03:22    time: 1.0490  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [ 50/242]  eta: 0:03:14    time: 1.0435  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [ 60/242]  eta: 0:03:06    time: 1.0759  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [ 70/242]  eta: 0:02:57    time: 1.0846  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [ 80/242]  eta: 0:02:46    time: 1.0282  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [ 90/242]  eta: 0:02:35    time: 0.9786  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [100/242]  eta: 0:02:25    time: 1.0143  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [110/242]  eta: 0:02:14    time: 1.0309  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Test  [120/242]  eta: 0:02:05    time: 1.0408  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [130/242]  eta: 0:01:54    time: 1.0282  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [140/242]  eta: 0:01:44    time: 0.9798  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Test  [150/242]  eta: 0:01:33    time: 0.9894  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Test  [160/242]  eta: 0:01:23    time: 1.0009  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [170/242]  eta: 0:01:13    time: 1.0509  data: 0.0002  max mem: 9536\n",
      "Epoch: [9] Test  [180/242]  eta: 0:01:03    time: 1.1107  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [190/242]  eta: 0:00:53    time: 1.1115  data: 0.0003  max mem: 9536\n",
      "Epoch: [9] Test  [200/242]  eta: 0:00:43    time: 1.0579  data: 0.0002  max mem: 9536\n",
      "Epoch: [9] Test  [210/242]  eta: 0:00:33    time: 1.0320  data: 0.0005  max mem: 9536\n",
      "Epoch: [9] Test  [220/242]  eta: 0:00:22    time: 1.0398  data: 0.0005  max mem: 9536\n",
      "Epoch: [9] Test  [230/242]  eta: 0:00:12    time: 1.0443  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Test  [240/242]  eta: 0:00:02    time: 1.0080  data: 0.0004  max mem: 9536\n",
      "Epoch: [9] Test Total time: 0:04:08\n",
      "global correct: 94.8\n",
      "average row correct: ['96.1', '95.3', '79.3', '95.7', '94.1', '92.9', '99.2', '94.3', '97.5', '58.8', '96.9', '75.2', '83.3', '94.7', '94.4', '94.7', '86.5', '96.0', '82.0', '95.0', '90.9']\n",
      "IoU: ['94.5', '91.1', '66.4', '85.1', '61.3', '76.3', '92.4', '86.2', '84.4', '39.4', '88.9', '67.1', '79.0', '84.8', '89.0', '90.0', '65.2', '86.9', '51.8', '82.7', '79.8']\n",
      "mean IoU: 78.2\n",
      "Epoch: [10] Train  [  0/183]  eta: 0:38:45  lr: 0.000790  loss: 2.4399 (2.4399)  time: 12.7094  data: 0.3757  max mem: 9536\n",
      "Epoch: [10] Train  [ 10/183]  eta: 0:35:47  lr: 0.000788  loss: 2.4253 (2.6474)  time: 12.4142  data: 0.0347  max mem: 9536\n",
      "Epoch: [10] Train  [ 20/183]  eta: 0:33:50  lr: 0.000787  loss: 2.7564 (2.6846)  time: 12.4451  data: 0.0006  max mem: 9536\n",
      "Epoch: [10] Train  [ 30/183]  eta: 0:31:35  lr: 0.000786  loss: 2.8987 (2.6722)  time: 12.3791  data: 0.0005  max mem: 9536\n",
      "Epoch: [10] Train  [ 40/183]  eta: 0:29:27  lr: 0.000784  loss: 3.2070 (2.7128)  time: 12.2557  data: 0.0005  max mem: 9536\n",
      "Epoch: [10] Train  [ 50/183]  eta: 0:27:25  lr: 0.000783  loss: 2.4817 (2.7155)  time: 12.3383  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Train  [ 60/183]  eta: 0:25:21  lr: 0.000782  loss: 2.5902 (2.7124)  time: 12.3864  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Train  [ 70/183]  eta: 0:23:14  lr: 0.000780  loss: 2.6118 (2.6899)  time: 12.2732  data: 0.0005  max mem: 9536\n",
      "Epoch: [10] Train  [ 80/183]  eta: 0:21:09  lr: 0.000779  loss: 2.4286 (2.6857)  time: 12.1987  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Train  [ 90/183]  eta: 0:19:04  lr: 0.000778  loss: 2.4267 (2.6754)  time: 12.1889  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Train  [100/183]  eta: 0:17:00  lr: 0.000777  loss: 2.6744 (2.6827)  time: 12.1987  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Train  [110/183]  eta: 0:14:57  lr: 0.000775  loss: 2.4902 (2.6892)  time: 12.2593  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Train  [120/183]  eta: 0:12:54  lr: 0.000774  loss: 3.0954 (2.6965)  time: 12.2292  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Train  [130/183]  eta: 0:10:51  lr: 0.000773  loss: 2.3172 (2.6929)  time: 12.1917  data: 0.0006  max mem: 9536\n",
      "Epoch: [10] Train  [140/183]  eta: 0:08:48  lr: 0.000771  loss: 2.5587 (2.6900)  time: 12.2405  data: 0.0005  max mem: 9536\n",
      "Epoch: [10] Train  [150/183]  eta: 0:06:45  lr: 0.000770  loss: 2.5124 (2.6894)  time: 12.2713  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Train  [160/183]  eta: 0:04:42  lr: 0.000769  loss: 2.6484 (2.6844)  time: 12.2423  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Train  [170/183]  eta: 0:02:39  lr: 0.000768  loss: 2.5952 (2.6834)  time: 12.2458  data: 0.0005  max mem: 9536\n",
      "Epoch: [10] Train  [180/183]  eta: 0:00:36  lr: 0.000766  loss: 2.9016 (2.6833)  time: 12.2746  data: 0.0005  max mem: 9536\n",
      "Epoch: [10] Train Total time: 0:37:26\n",
      "Epoch: [10] Test  [  0/242]  eta: 0:05:52    time: 1.4548  data: 0.3967  max mem: 9536\n",
      "Epoch: [10] Test  [ 10/242]  eta: 0:03:50    time: 0.9931  data: 0.0363  max mem: 9536\n",
      "Epoch: [10] Test  [ 20/242]  eta: 0:03:33    time: 0.9369  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [ 30/242]  eta: 0:03:29    time: 0.9880  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [ 40/242]  eta: 0:03:22    time: 1.0498  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [ 50/242]  eta: 0:03:14    time: 1.0441  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [ 60/242]  eta: 0:03:07    time: 1.0764  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [ 70/242]  eta: 0:02:57    time: 1.0870  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [ 80/242]  eta: 0:02:46    time: 1.0284  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Test  [ 90/242]  eta: 0:02:35    time: 0.9778  data: 0.0004  max mem: 9536\n",
      "Epoch: [10] Test  [100/242]  eta: 0:02:25    time: 1.0129  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [110/242]  eta: 0:02:14    time: 1.0308  data: 0.0002  max mem: 9536\n",
      "Epoch: [10] Test  [120/242]  eta: 0:02:05    time: 1.0440  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [130/242]  eta: 0:01:54    time: 1.0317  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [140/242]  eta: 0:01:44    time: 0.9807  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [150/242]  eta: 0:01:33    time: 0.9876  data: 0.0002  max mem: 9536\n",
      "Epoch: [10] Test  [160/242]  eta: 0:01:23    time: 0.9986  data: 0.0002  max mem: 9536\n",
      "Epoch: [10] Test  [170/242]  eta: 0:01:13    time: 1.0496  data: 0.0002  max mem: 9536\n",
      "Epoch: [10] Test  [180/242]  eta: 0:01:03    time: 1.1105  data: 0.0002  max mem: 9536\n",
      "Epoch: [10] Test  [190/242]  eta: 0:00:53    time: 1.1127  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [200/242]  eta: 0:00:43    time: 1.0573  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test  [210/242]  eta: 0:00:33    time: 1.0305  data: 0.0002  max mem: 9536\n",
      "Epoch: [10] Test  [220/242]  eta: 0:00:22    time: 1.0399  data: 0.0002  max mem: 9536\n",
      "Epoch: [10] Test  [230/242]  eta: 0:00:12    time: 1.0456  data: 0.0002  max mem: 9536\n",
      "Epoch: [10] Test  [240/242]  eta: 0:00:02    time: 1.0087  data: 0.0003  max mem: 9536\n",
      "Epoch: [10] Test Total time: 0:04:08\n",
      "global correct: 95.5\n",
      "average row correct: ['97.0', '96.5', '83.4', '92.4', '92.4', '91.4', '99.2', '94.2', '98.6', '68.6', '92.8', '76.5', '86.3', '95.4', '94.7', '95.1', '86.7', '95.3', '71.1', '94.9', '90.1']\n",
      "IoU: ['95.2', '93.8', '63.9', '85.5', '71.2', '76.8', '90.9', '86.4', '83.9', '43.6', '89.2', '68.7', '81.3', '89.0', '88.6', '90.5', '73.2', '87.1', '58.4', '87.0', '76.4']\n",
      "mean IoU: 80.0\n",
      "Epoch: [11] Train  [  0/183]  eta: 0:38:13  lr: 0.000766  loss: 2.3355 (2.3355)  time: 12.5317  data: 0.3782  max mem: 9536\n",
      "Epoch: [11] Train  [ 10/183]  eta: 0:35:33  lr: 0.000765  loss: 2.3676 (2.5977)  time: 12.3321  data: 0.0347  max mem: 9536\n",
      "Epoch: [11] Train  [ 20/183]  eta: 0:33:19  lr: 0.000763  loss: 2.4568 (2.6808)  time: 12.2518  data: 0.0004  max mem: 9536\n",
      "Epoch: [11] Train  [ 30/183]  eta: 0:31:19  lr: 0.000762  loss: 2.6064 (2.6529)  time: 12.2541  data: 0.0004  max mem: 9536\n",
      "Epoch: [11] Train  [ 40/183]  eta: 0:29:11  lr: 0.000761  loss: 2.8454 (2.6815)  time: 12.2305  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Train  [ 50/183]  eta: 0:27:11  lr: 0.000759  loss: 2.4723 (2.6642)  time: 12.2375  data: 0.0004  max mem: 9536\n",
      "Epoch: [11] Train  [ 60/183]  eta: 0:25:05  lr: 0.000758  loss: 2.3277 (2.6502)  time: 12.2128  data: 0.0006  max mem: 9536\n",
      "Epoch: [11] Train  [ 70/183]  eta: 0:23:05  lr: 0.000757  loss: 2.7536 (2.6509)  time: 12.2482  data: 0.0007  max mem: 9536\n",
      "Epoch: [11] Train  [ 80/183]  eta: 0:21:02  lr: 0.000755  loss: 2.4026 (2.6286)  time: 12.3265  data: 0.0005  max mem: 9536\n",
      "Epoch: [11] Train  [ 90/183]  eta: 0:19:00  lr: 0.000754  loss: 2.6654 (2.6272)  time: 12.2918  data: 0.0005  max mem: 9536\n",
      "Epoch: [11] Train  [100/183]  eta: 0:16:57  lr: 0.000753  loss: 2.6757 (2.6408)  time: 12.2302  data: 0.0004  max mem: 9536\n",
      "Epoch: [11] Train  [110/183]  eta: 0:14:54  lr: 0.000752  loss: 2.4873 (2.6368)  time: 12.2100  data: 0.0004  max mem: 9536\n",
      "Epoch: [11] Train  [120/183]  eta: 0:12:52  lr: 0.000750  loss: 2.6663 (2.6299)  time: 12.2958  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Train  [130/183]  eta: 0:10:50  lr: 0.000749  loss: 2.2991 (2.6213)  time: 12.3165  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Train  [140/183]  eta: 0:08:47  lr: 0.000748  loss: 2.3641 (2.6165)  time: 12.3187  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Train  [150/183]  eta: 0:06:44  lr: 0.000746  loss: 2.6213 (2.6119)  time: 12.2231  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Train  [160/183]  eta: 0:04:42  lr: 0.000745  loss: 2.4480 (2.6024)  time: 12.2970  data: 0.0005  max mem: 9536\n",
      "Epoch: [11] Train  [170/183]  eta: 0:02:39  lr: 0.000744  loss: 2.6223 (2.6004)  time: 12.3146  data: 0.0004  max mem: 9536\n",
      "Epoch: [11] Train  [180/183]  eta: 0:00:36  lr: 0.000742  loss: 2.8155 (2.5992)  time: 12.2537  data: 0.0004  max mem: 9536\n",
      "Epoch: [11] Train Total time: 0:37:25\n",
      "Epoch: [11] Test  [  0/242]  eta: 0:05:45    time: 1.4273  data: 0.3671  max mem: 9536\n",
      "Epoch: [11] Test  [ 10/242]  eta: 0:03:49    time: 0.9909  data: 0.0336  max mem: 9536\n",
      "Epoch: [11] Test  [ 20/242]  eta: 0:03:32    time: 0.9360  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [ 30/242]  eta: 0:03:29    time: 0.9878  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [ 40/242]  eta: 0:03:22    time: 1.0512  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [ 50/242]  eta: 0:03:14    time: 1.0438  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [ 60/242]  eta: 0:03:06    time: 1.0738  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [ 70/242]  eta: 0:02:57    time: 1.0853  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [ 80/242]  eta: 0:02:46    time: 1.0285  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [ 90/242]  eta: 0:02:35    time: 0.9796  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [100/242]  eta: 0:02:25    time: 1.0147  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [110/242]  eta: 0:02:14    time: 1.0297  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [120/242]  eta: 0:02:05    time: 1.0431  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [130/242]  eta: 0:01:54    time: 1.0309  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [140/242]  eta: 0:01:44    time: 0.9781  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [150/242]  eta: 0:01:33    time: 0.9875  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [160/242]  eta: 0:01:23    time: 1.0029  data: 0.0002  max mem: 9536\n",
      "Epoch: [11] Test  [170/242]  eta: 0:01:13    time: 1.0526  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [180/242]  eta: 0:01:03    time: 1.1110  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [190/242]  eta: 0:00:53    time: 1.1109  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [200/242]  eta: 0:00:43    time: 1.0570  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [210/242]  eta: 0:00:33    time: 1.0318  data: 0.0002  max mem: 9536\n",
      "Epoch: [11] Test  [220/242]  eta: 0:00:22    time: 1.0396  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [230/242]  eta: 0:00:12    time: 1.0462  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test  [240/242]  eta: 0:00:02    time: 1.0092  data: 0.0003  max mem: 9536\n",
      "Epoch: [11] Test Total time: 0:04:08\n",
      "global correct: 95.4\n",
      "average row correct: ['97.7', '95.8', '82.6', '95.0', '85.5', '89.3', '96.7', '91.7', '97.1', '68.0', '96.0', '75.7', '87.4', '94.7', '86.8', '93.4', '77.2', '96.1', '60.8', '89.4', '89.5']\n",
      "IoU: ['95.1', '93.6', '61.7', '85.1', '76.0', '75.0', '94.6', '83.5', '85.2', '42.8', '92.3', '67.6', '81.4', '91.0', '83.9', '89.9', '64.3', '89.9', '51.2', '85.9', '77.4']\n",
      "mean IoU: 79.4\n",
      "Epoch: [12] Train  [  0/183]  eta: 0:40:01  lr: 0.000742  loss: 2.5454 (2.5454)  time: 13.1228  data: 0.3871  max mem: 9536\n",
      "Epoch: [12] Train  [ 10/183]  eta: 0:35:39  lr: 0.000741  loss: 2.6350 (2.5183)  time: 12.3680  data: 0.0356  max mem: 9536\n",
      "Epoch: [12] Train  [ 20/183]  eta: 0:33:35  lr: 0.000739  loss: 2.9990 (2.5380)  time: 12.3287  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [ 30/183]  eta: 0:31:33  lr: 0.000738  loss: 2.5094 (2.5234)  time: 12.3838  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Train  [ 40/183]  eta: 0:29:27  lr: 0.000737  loss: 2.4481 (2.5211)  time: 12.3558  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Train  [ 50/183]  eta: 0:27:25  lr: 0.000735  loss: 2.3332 (2.5160)  time: 12.3602  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Train  [ 60/183]  eta: 0:25:20  lr: 0.000734  loss: 2.6142 (2.5312)  time: 12.3706  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [ 70/183]  eta: 0:23:17  lr: 0.000733  loss: 2.4922 (2.5291)  time: 12.3729  data: 0.0005  max mem: 9536\n",
      "Epoch: [12] Train  [ 80/183]  eta: 0:21:11  lr: 0.000732  loss: 2.8353 (2.5258)  time: 12.3006  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [ 90/183]  eta: 0:19:08  lr: 0.000730  loss: 2.4140 (2.5244)  time: 12.2658  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Train  [100/183]  eta: 0:17:04  lr: 0.000729  loss: 2.4755 (2.5333)  time: 12.3251  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [110/183]  eta: 0:15:00  lr: 0.000728  loss: 2.4613 (2.5268)  time: 12.3082  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [120/183]  eta: 0:12:56  lr: 0.000726  loss: 2.8552 (2.5415)  time: 12.1909  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [130/183]  eta: 0:10:52  lr: 0.000725  loss: 2.2096 (2.5382)  time: 12.1714  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [140/183]  eta: 0:08:48  lr: 0.000724  loss: 2.4506 (2.5297)  time: 12.1375  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [150/183]  eta: 0:06:45  lr: 0.000722  loss: 2.2892 (2.5198)  time: 12.1071  data: 0.0004  max mem: 9536\n",
      "Epoch: [12] Train  [160/183]  eta: 0:04:42  lr: 0.000721  loss: 2.4516 (2.5246)  time: 12.2749  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Train  [170/183]  eta: 0:02:39  lr: 0.000720  loss: 2.3960 (2.5321)  time: 12.2651  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Train  [180/183]  eta: 0:00:36  lr: 0.000719  loss: 2.6155 (2.5332)  time: 12.2761  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Train Total time: 0:37:28\n",
      "Epoch: [12] Test  [  0/242]  eta: 0:05:49    time: 1.4452  data: 0.3779  max mem: 9536\n",
      "Epoch: [12] Test  [ 10/242]  eta: 0:03:50    time: 0.9929  data: 0.0346  max mem: 9536\n",
      "Epoch: [12] Test  [ 20/242]  eta: 0:03:33    time: 0.9372  data: 0.0002  max mem: 9536\n",
      "Epoch: [12] Test  [ 30/242]  eta: 0:03:29    time: 0.9877  data: 0.0002  max mem: 9536\n",
      "Epoch: [12] Test  [ 40/242]  eta: 0:03:22    time: 1.0494  data: 0.0002  max mem: 9536\n",
      "Epoch: [12] Test  [ 50/242]  eta: 0:03:14    time: 1.0434  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [ 60/242]  eta: 0:03:07    time: 1.0752  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [ 70/242]  eta: 0:02:57    time: 1.0866  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [ 80/242]  eta: 0:02:46    time: 1.0303  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [ 90/242]  eta: 0:02:35    time: 0.9787  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [100/242]  eta: 0:02:25    time: 1.0124  data: 0.0002  max mem: 9536\n",
      "Epoch: [12] Test  [110/242]  eta: 0:02:14    time: 1.0298  data: 0.0005  max mem: 9536\n",
      "Epoch: [12] Test  [120/242]  eta: 0:02:05    time: 1.0419  data: 0.0005  max mem: 9536\n",
      "Epoch: [12] Test  [130/242]  eta: 0:01:54    time: 1.0297  data: 0.0002  max mem: 9536\n",
      "Epoch: [12] Test  [140/242]  eta: 0:01:44    time: 0.9791  data: 0.0002  max mem: 9536\n",
      "Epoch: [12] Test  [150/242]  eta: 0:01:33    time: 0.9894  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [160/242]  eta: 0:01:23    time: 1.0023  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [170/242]  eta: 0:01:13    time: 1.0510  data: 0.0002  max mem: 9536\n",
      "Epoch: [12] Test  [180/242]  eta: 0:01:03    time: 1.1115  data: 0.0002  max mem: 9536\n",
      "Epoch: [12] Test  [190/242]  eta: 0:00:53    time: 1.1123  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [200/242]  eta: 0:00:43    time: 1.0580  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [210/242]  eta: 0:00:33    time: 1.0334  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [220/242]  eta: 0:00:22    time: 1.0413  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [230/242]  eta: 0:00:12    time: 1.0461  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test  [240/242]  eta: 0:00:02    time: 1.0086  data: 0.0003  max mem: 9536\n",
      "Epoch: [12] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['97.3', '97.6', '79.0', '91.9', '90.3', '90.1', '98.1', '88.5', '98.1', '67.7', '95.3', '73.6', '89.6', '94.6', '90.6', '92.9', '69.4', '96.9', '68.9', '95.1', '89.8']\n",
      "IoU: ['95.1', '91.0', '63.0', '87.7', '67.2', '72.1', '95.4', '86.0', '84.5', '39.2', '90.8', '68.1', '82.6', '89.9', '86.7', '89.7', '63.4', '86.4', '56.6', '90.1', '78.3']\n",
      "mean IoU: 79.2\n",
      "Epoch: [13] Train  [  0/183]  eta: 0:39:31  lr: 0.000718  loss: 2.6069 (2.6069)  time: 12.9598  data: 0.3919  max mem: 9536\n",
      "Epoch: [13] Train  [ 10/183]  eta: 0:35:33  lr: 0.000717  loss: 3.4203 (2.5171)  time: 12.3342  data: 0.0358  max mem: 9536\n",
      "Epoch: [13] Train  [ 20/183]  eta: 0:33:20  lr: 0.000715  loss: 2.4645 (2.5129)  time: 12.2357  data: 0.0002  max mem: 9536\n",
      "Epoch: [13] Train  [ 30/183]  eta: 0:31:15  lr: 0.000714  loss: 2.7072 (2.5097)  time: 12.2123  data: 0.0004  max mem: 9536\n",
      "Epoch: [13] Train  [ 40/183]  eta: 0:29:07  lr: 0.000713  loss: 2.3070 (2.4991)  time: 12.1623  data: 0.0005  max mem: 9536\n",
      "Epoch: [13] Train  [ 50/183]  eta: 0:27:03  lr: 0.000712  loss: 2.2599 (2.4880)  time: 12.1290  data: 0.0005  max mem: 9536\n",
      "Epoch: [13] Train  [ 60/183]  eta: 0:25:01  lr: 0.000710  loss: 2.5415 (2.4764)  time: 12.1858  data: 0.0005  max mem: 9536\n",
      "Epoch: [13] Train  [ 70/183]  eta: 0:23:01  lr: 0.000709  loss: 2.2976 (2.4718)  time: 12.2892  data: 0.0005  max mem: 9536\n",
      "Epoch: [13] Train  [ 80/183]  eta: 0:20:59  lr: 0.000708  loss: 2.2564 (2.4637)  time: 12.3042  data: 0.0004  max mem: 9536\n",
      "Epoch: [13] Train  [ 90/183]  eta: 0:18:57  lr: 0.000706  loss: 2.8890 (2.4703)  time: 12.2291  data: 0.0004  max mem: 9536\n",
      "Epoch: [13] Train  [100/183]  eta: 0:16:55  lr: 0.000705  loss: 2.3532 (2.4718)  time: 12.2371  data: 0.0004  max mem: 9536\n",
      "Epoch: [13] Train  [110/183]  eta: 0:14:53  lr: 0.000704  loss: 2.2611 (2.4659)  time: 12.3086  data: 0.0004  max mem: 9536\n",
      "Epoch: [13] Train  [120/183]  eta: 0:12:51  lr: 0.000702  loss: 2.4663 (2.4601)  time: 12.2766  data: 0.0004  max mem: 9536\n",
      "Epoch: [13] Train  [130/183]  eta: 0:10:49  lr: 0.000701  loss: 2.9555 (2.4673)  time: 12.2579  data: 0.0005  max mem: 9536\n",
      "Epoch: [13] Train  [140/183]  eta: 0:08:46  lr: 0.000700  loss: 2.3561 (2.4709)  time: 12.3503  data: 0.0004  max mem: 9536\n",
      "Epoch: [13] Train  [150/183]  eta: 0:06:44  lr: 0.000698  loss: 2.6197 (2.4689)  time: 12.4244  data: 0.0006  max mem: 9536\n",
      "Epoch: [13] Train  [160/183]  eta: 0:04:42  lr: 0.000697  loss: 2.4265 (2.4706)  time: 12.3326  data: 0.0006  max mem: 9536\n",
      "Epoch: [13] Train  [170/183]  eta: 0:02:39  lr: 0.000696  loss: 2.5155 (2.4708)  time: 12.3049  data: 0.0005  max mem: 9536\n",
      "Epoch: [13] Train  [180/183]  eta: 0:00:36  lr: 0.000695  loss: 2.2951 (2.4824)  time: 12.3755  data: 0.0004  max mem: 9536\n",
      "Epoch: [13] Train Total time: 0:37:27\n",
      "Epoch: [13] Test  [  0/242]  eta: 0:05:47    time: 1.4371  data: 0.3756  max mem: 9536\n",
      "Epoch: [13] Test  [ 10/242]  eta: 0:03:50    time: 0.9920  data: 0.0344  max mem: 9536\n",
      "Epoch: [13] Test  [ 20/242]  eta: 0:03:33    time: 0.9367  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [ 30/242]  eta: 0:03:29    time: 0.9858  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [ 40/242]  eta: 0:03:22    time: 1.0466  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [ 50/242]  eta: 0:03:13    time: 1.0430  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [ 60/242]  eta: 0:03:06    time: 1.0762  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [ 70/242]  eta: 0:02:57    time: 1.0869  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [ 80/242]  eta: 0:02:46    time: 1.0295  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [ 90/242]  eta: 0:02:34    time: 0.9772  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [100/242]  eta: 0:02:25    time: 1.0099  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [110/242]  eta: 0:02:14    time: 1.0291  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [120/242]  eta: 0:02:05    time: 1.0451  data: 0.0002  max mem: 9536\n",
      "Epoch: [13] Test  [130/242]  eta: 0:01:54    time: 1.0324  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [140/242]  eta: 0:01:44    time: 0.9819  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [150/242]  eta: 0:01:33    time: 0.9910  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [160/242]  eta: 0:01:23    time: 1.0029  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [170/242]  eta: 0:01:13    time: 1.0510  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [180/242]  eta: 0:01:03    time: 1.1099  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [190/242]  eta: 0:00:53    time: 1.1137  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [200/242]  eta: 0:00:43    time: 1.0601  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [210/242]  eta: 0:00:33    time: 1.0335  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [220/242]  eta: 0:00:22    time: 1.0393  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [230/242]  eta: 0:00:12    time: 1.0451  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test  [240/242]  eta: 0:00:02    time: 1.0101  data: 0.0003  max mem: 9536\n",
      "Epoch: [13] Test Total time: 0:04:09\n",
      "global correct: 95.4\n",
      "average row correct: ['97.2', '96.7', '87.1', '95.4', '85.7', '90.3', '98.0', '93.1', '95.3', '71.4', '94.0', '70.3', '94.8', '94.7', '91.4', '94.0', '58.3', '95.7', '68.3', '98.2', '90.4']\n",
      "IoU: ['95.0', '92.4', '60.1', '83.4', '75.1', '70.1', '93.1', '87.0', '90.4', '46.9', '89.7', '64.1', '84.3', '85.8', '86.3', '89.5', '54.8', '89.5', '58.7', '85.7', '76.8']\n",
      "mean IoU: 79.0\n",
      "Epoch: [14] Train  [  0/183]  eta: 0:40:22  lr: 0.000694  loss: 2.3937 (2.3937)  time: 13.2359  data: 0.3729  max mem: 9536\n",
      "Epoch: [14] Train  [ 10/183]  eta: 0:35:45  lr: 0.000693  loss: 2.4860 (2.4866)  time: 12.4010  data: 0.0341  max mem: 9536\n",
      "Epoch: [14] Train  [ 20/183]  eta: 0:33:35  lr: 0.000691  loss: 2.4887 (2.4335)  time: 12.3235  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Train  [ 30/183]  eta: 0:31:23  lr: 0.000690  loss: 2.4626 (2.4748)  time: 12.2621  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Train  [ 40/183]  eta: 0:29:17  lr: 0.000689  loss: 2.1915 (2.4605)  time: 12.2116  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Train  [ 50/183]  eta: 0:27:15  lr: 0.000688  loss: 2.2278 (2.4363)  time: 12.2684  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Train  [ 60/183]  eta: 0:25:09  lr: 0.000686  loss: 2.2650 (2.4239)  time: 12.2359  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Train  [ 70/183]  eta: 0:23:05  lr: 0.000685  loss: 2.1065 (2.4152)  time: 12.1775  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Train  [ 80/183]  eta: 0:21:04  lr: 0.000684  loss: 2.7648 (2.4192)  time: 12.2779  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Train  [ 90/183]  eta: 0:19:01  lr: 0.000682  loss: 2.4507 (2.4131)  time: 12.3064  data: 0.0006  max mem: 9536\n",
      "Epoch: [14] Train  [100/183]  eta: 0:16:57  lr: 0.000681  loss: 2.1381 (2.4097)  time: 12.2139  data: 0.0006  max mem: 9536\n",
      "Epoch: [14] Train  [110/183]  eta: 0:14:54  lr: 0.000680  loss: 2.1510 (2.4062)  time: 12.1718  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Train  [120/183]  eta: 0:12:51  lr: 0.000678  loss: 2.1411 (2.4157)  time: 12.1979  data: 0.0005  max mem: 9536\n",
      "Epoch: [14] Train  [130/183]  eta: 0:10:49  lr: 0.000677  loss: 2.5986 (2.4214)  time: 12.2342  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Train  [140/183]  eta: 0:08:46  lr: 0.000676  loss: 2.5001 (2.4261)  time: 12.2604  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Train  [150/183]  eta: 0:06:44  lr: 0.000674  loss: 2.2297 (2.4192)  time: 12.3117  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Train  [160/183]  eta: 0:04:42  lr: 0.000673  loss: 2.6112 (2.4255)  time: 12.4005  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Train  [170/183]  eta: 0:02:39  lr: 0.000672  loss: 2.4600 (2.4243)  time: 12.3996  data: 0.0005  max mem: 9536\n",
      "Epoch: [14] Train  [180/183]  eta: 0:00:36  lr: 0.000670  loss: 2.8707 (2.4244)  time: 12.2733  data: 0.0005  max mem: 9536\n",
      "Epoch: [14] Train Total time: 0:37:25\n",
      "Epoch: [14] Test  [  0/242]  eta: 0:05:54    time: 1.4631  data: 0.3993  max mem: 9536\n",
      "Epoch: [14] Test  [ 10/242]  eta: 0:03:51    time: 0.9957  data: 0.0366  max mem: 9536\n",
      "Epoch: [14] Test  [ 20/242]  eta: 0:03:33    time: 0.9389  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Test  [ 30/242]  eta: 0:03:30    time: 0.9900  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Test  [ 40/242]  eta: 0:03:23    time: 1.0522  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [ 50/242]  eta: 0:03:14    time: 1.0458  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [ 60/242]  eta: 0:03:07    time: 1.0766  data: 0.0011  max mem: 9536\n",
      "Epoch: [14] Test  [ 70/242]  eta: 0:02:57    time: 1.0887  data: 0.0010  max mem: 9536\n",
      "Epoch: [14] Test  [ 80/242]  eta: 0:02:46    time: 1.0315  data: 0.0009  max mem: 9536\n",
      "Epoch: [14] Test  [ 90/242]  eta: 0:02:35    time: 0.9796  data: 0.0010  max mem: 9536\n",
      "Epoch: [14] Test  [100/242]  eta: 0:02:25    time: 1.0153  data: 0.0005  max mem: 9536\n",
      "Epoch: [14] Test  [110/242]  eta: 0:02:15    time: 1.0320  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [120/242]  eta: 0:02:05    time: 1.0441  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [130/242]  eta: 0:01:54    time: 1.0328  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [140/242]  eta: 0:01:44    time: 0.9814  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [150/242]  eta: 0:01:33    time: 0.9892  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [160/242]  eta: 0:01:23    time: 1.0020  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Test  [170/242]  eta: 0:01:13    time: 1.0527  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [180/242]  eta: 0:01:03    time: 1.1114  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [190/242]  eta: 0:00:53    time: 1.1128  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [200/242]  eta: 0:00:43    time: 1.0603  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [210/242]  eta: 0:00:33    time: 1.0335  data: 0.0003  max mem: 9536\n",
      "Epoch: [14] Test  [220/242]  eta: 0:00:22    time: 1.0397  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test  [230/242]  eta: 0:00:12    time: 1.0456  data: 0.0005  max mem: 9536\n",
      "Epoch: [14] Test  [240/242]  eta: 0:00:02    time: 1.0090  data: 0.0004  max mem: 9536\n",
      "Epoch: [14] Test Total time: 0:04:09\n",
      "global correct: 95.1\n",
      "average row correct: ['97.0', '97.3', '85.0', '92.9', '87.4', '88.8', '98.4', '92.4', '96.0', '67.6', '94.9', '74.6', '89.9', '95.6', '91.9', '94.6', '69.5', '96.8', '60.7', '94.9', '89.5']\n",
      "IoU: ['94.8', '90.2', '65.1', '83.7', '71.2', '77.0', '93.3', '86.8', '88.9', '33.6', '91.7', '66.2', '83.0', '88.1', '86.2', '89.7', '63.0', '87.1', '50.2', '87.6', '77.3']\n",
      "mean IoU: 78.8\n",
      "Epoch: [15] Train  [  0/183]  eta: 0:38:49  lr: 0.000670  loss: 2.4110 (2.4110)  time: 12.7321  data: 0.4291  max mem: 9536\n",
      "Epoch: [15] Train  [ 10/183]  eta: 0:36:01  lr: 0.000669  loss: 2.0103 (2.4070)  time: 12.4956  data: 0.0395  max mem: 9536\n",
      "Epoch: [15] Train  [ 20/183]  eta: 0:33:43  lr: 0.000667  loss: 2.4825 (2.3818)  time: 12.4001  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Train  [ 30/183]  eta: 0:31:29  lr: 0.000666  loss: 2.2548 (2.3892)  time: 12.2667  data: 0.0008  max mem: 9536\n",
      "Epoch: [15] Train  [ 40/183]  eta: 0:29:23  lr: 0.000665  loss: 2.4787 (2.3925)  time: 12.2457  data: 0.0008  max mem: 9536\n",
      "Epoch: [15] Train  [ 50/183]  eta: 0:27:17  lr: 0.000663  loss: 2.3293 (2.3868)  time: 12.2492  data: 0.0004  max mem: 9536\n",
      "Epoch: [15] Train  [ 60/183]  eta: 0:25:12  lr: 0.000662  loss: 2.2368 (2.3917)  time: 12.2261  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Train  [ 70/183]  eta: 0:23:12  lr: 0.000661  loss: 2.2018 (2.3986)  time: 12.3521  data: 0.0006  max mem: 9536\n",
      "Epoch: [15] Train  [ 80/183]  eta: 0:21:11  lr: 0.000659  loss: 2.3737 (2.3927)  time: 12.4836  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Train  [ 90/183]  eta: 0:19:07  lr: 0.000658  loss: 2.6006 (2.3924)  time: 12.3908  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Train  [100/183]  eta: 0:17:03  lr: 0.000657  loss: 2.4413 (2.3992)  time: 12.3049  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Train  [110/183]  eta: 0:15:01  lr: 0.000656  loss: 2.6590 (2.4084)  time: 12.3714  data: 0.0006  max mem: 9536\n",
      "Epoch: [15] Train  [120/183]  eta: 0:12:57  lr: 0.000654  loss: 2.1300 (2.4017)  time: 12.3762  data: 0.0007  max mem: 9536\n",
      "Epoch: [15] Train  [130/183]  eta: 0:10:54  lr: 0.000653  loss: 2.5915 (2.4085)  time: 12.3497  data: 0.0006  max mem: 9536\n",
      "Epoch: [15] Train  [140/183]  eta: 0:08:50  lr: 0.000652  loss: 2.3780 (2.4069)  time: 12.2818  data: 0.0007  max mem: 9536\n",
      "Epoch: [15] Train  [150/183]  eta: 0:06:47  lr: 0.000650  loss: 2.3339 (2.4113)  time: 12.3083  data: 0.0008  max mem: 9536\n",
      "Epoch: [15] Train  [160/183]  eta: 0:04:44  lr: 0.000649  loss: 2.0876 (2.4109)  time: 12.4529  data: 0.0008  max mem: 9536\n",
      "Epoch: [15] Train  [170/183]  eta: 0:02:40  lr: 0.000648  loss: 2.4720 (2.4155)  time: 12.3462  data: 0.0007  max mem: 9536\n",
      "Epoch: [15] Train  [180/183]  eta: 0:00:37  lr: 0.000646  loss: 2.2886 (2.4115)  time: 12.2652  data: 0.0006  max mem: 9536\n",
      "Epoch: [15] Train Total time: 0:37:38\n",
      "Epoch: [15] Test  [  0/242]  eta: 0:05:52    time: 1.4563  data: 0.3914  max mem: 9536\n",
      "Epoch: [15] Test  [ 10/242]  eta: 0:03:50    time: 0.9948  data: 0.0358  max mem: 9536\n",
      "Epoch: [15] Test  [ 20/242]  eta: 0:03:33    time: 0.9381  data: 0.0004  max mem: 9536\n",
      "Epoch: [15] Test  [ 30/242]  eta: 0:03:30    time: 0.9889  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Test  [ 40/242]  eta: 0:03:23    time: 1.0499  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Test  [ 50/242]  eta: 0:03:14    time: 1.0435  data: 0.0004  max mem: 9536\n",
      "Epoch: [15] Test  [ 60/242]  eta: 0:03:07    time: 1.0775  data: 0.0003  max mem: 9536\n",
      "Epoch: [15] Test  [ 70/242]  eta: 0:02:57    time: 1.0877  data: 0.0002  max mem: 9536\n",
      "Epoch: [15] Test  [ 80/242]  eta: 0:02:46    time: 1.0304  data: 0.0003  max mem: 9536\n",
      "Epoch: [15] Test  [ 90/242]  eta: 0:02:35    time: 0.9806  data: 0.0003  max mem: 9536\n",
      "Epoch: [15] Test  [100/242]  eta: 0:02:25    time: 1.0132  data: 0.0002  max mem: 9536\n",
      "Epoch: [15] Test  [110/242]  eta: 0:02:15    time: 1.0321  data: 0.0003  max mem: 9536\n",
      "Epoch: [15] Test  [120/242]  eta: 0:02:05    time: 1.0447  data: 0.0004  max mem: 9536\n",
      "Epoch: [15] Test  [130/242]  eta: 0:01:54    time: 1.0316  data: 0.0006  max mem: 9536\n",
      "Epoch: [15] Test  [140/242]  eta: 0:01:44    time: 0.9814  data: 0.0006  max mem: 9536\n",
      "Epoch: [15] Test  [150/242]  eta: 0:01:33    time: 0.9900  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Test  [160/242]  eta: 0:01:23    time: 1.0044  data: 0.0003  max mem: 9536\n",
      "Epoch: [15] Test  [170/242]  eta: 0:01:13    time: 1.0547  data: 0.0004  max mem: 9536\n",
      "Epoch: [15] Test  [180/242]  eta: 0:01:03    time: 1.1132  data: 0.0004  max mem: 9536\n",
      "Epoch: [15] Test  [190/242]  eta: 0:00:53    time: 1.1136  data: 0.0005  max mem: 9536\n",
      "Epoch: [15] Test  [200/242]  eta: 0:00:43    time: 1.0599  data: 0.0004  max mem: 9536\n",
      "Epoch: [15] Test  [210/242]  eta: 0:00:33    time: 1.0334  data: 0.0003  max mem: 9536\n",
      "Epoch: [15] Test  [220/242]  eta: 0:00:22    time: 1.0433  data: 0.0004  max mem: 9536\n",
      "Epoch: [15] Test  [230/242]  eta: 0:00:12    time: 1.0502  data: 0.0003  max mem: 9536\n",
      "Epoch: [15] Test  [240/242]  eta: 0:00:02    time: 1.0125  data: 0.0003  max mem: 9536\n",
      "Epoch: [15] Test Total time: 0:04:09\n",
      "global correct: 95.5\n",
      "average row correct: ['97.7', '96.5', '77.9', '95.4', '88.0', '87.8', '98.6', '90.7', '96.2', '58.7', '93.7', '64.2', '82.4', '95.3', '95.4', '94.4', '74.2', '96.4', '73.6', '94.5', '88.9']\n",
      "IoU: ['95.1', '90.6', '64.5', '85.1', '72.1', '77.4', '95.7', '88.1', '83.0', '45.0', '89.7', '61.0', '77.4', '89.5', '89.0', '90.3', '66.3', '87.7', '56.4', '89.8', '74.6']\n",
      "mean IoU: 79.4\n",
      "Epoch: [16] Train  [  0/183]  eta: 0:39:40  lr: 0.000646  loss: 2.1689 (2.1689)  time: 13.0072  data: 0.4392  max mem: 9536\n",
      "Epoch: [16] Train  [ 10/183]  eta: 0:35:51  lr: 0.000645  loss: 2.8858 (2.3089)  time: 12.4352  data: 0.0405  max mem: 9536\n",
      "Epoch: [16] Train  [ 20/183]  eta: 0:33:55  lr: 0.000643  loss: 2.0611 (2.3100)  time: 12.4607  data: 0.0007  max mem: 9536\n",
      "Epoch: [16] Train  [ 30/183]  eta: 0:31:45  lr: 0.000642  loss: 2.2975 (2.2883)  time: 12.4620  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Train  [ 40/183]  eta: 0:29:39  lr: 0.000641  loss: 2.9330 (2.3043)  time: 12.4034  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [ 50/183]  eta: 0:27:33  lr: 0.000639  loss: 2.2807 (2.3358)  time: 12.3990  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [ 60/183]  eta: 0:25:26  lr: 0.000638  loss: 2.5518 (2.3369)  time: 12.3390  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [ 70/183]  eta: 0:23:21  lr: 0.000637  loss: 2.3083 (2.3422)  time: 12.3207  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [ 80/183]  eta: 0:21:18  lr: 0.000635  loss: 2.2159 (2.3408)  time: 12.3997  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [ 90/183]  eta: 0:19:13  lr: 0.000634  loss: 2.2430 (2.3452)  time: 12.4020  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [100/183]  eta: 0:17:08  lr: 0.000633  loss: 2.3126 (2.3457)  time: 12.3301  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Train  [110/183]  eta: 0:15:04  lr: 0.000631  loss: 2.2095 (2.3449)  time: 12.3550  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [120/183]  eta: 0:13:00  lr: 0.000630  loss: 2.4703 (2.3559)  time: 12.3849  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [130/183]  eta: 0:10:57  lr: 0.000629  loss: 2.3787 (2.3577)  time: 12.4319  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [140/183]  eta: 0:08:53  lr: 0.000627  loss: 2.2717 (2.3539)  time: 12.4537  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Train  [150/183]  eta: 0:06:49  lr: 0.000626  loss: 3.1747 (2.3532)  time: 12.3749  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Train  [160/183]  eta: 0:04:45  lr: 0.000625  loss: 2.5625 (2.3472)  time: 12.3434  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Train  [170/183]  eta: 0:02:40  lr: 0.000623  loss: 2.4433 (2.3502)  time: 12.2951  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Train  [180/183]  eta: 0:00:37  lr: 0.000622  loss: 2.3640 (2.3525)  time: 12.2531  data: 0.0007  max mem: 9536\n",
      "Epoch: [16] Train Total time: 0:37:45\n",
      "Epoch: [16] Test  [  0/242]  eta: 0:05:59    time: 1.4848  data: 0.4024  max mem: 9536\n",
      "Epoch: [16] Test  [ 10/242]  eta: 0:03:51    time: 0.9977  data: 0.0369  max mem: 9536\n",
      "Epoch: [16] Test  [ 20/242]  eta: 0:03:34    time: 0.9397  data: 0.0004  max mem: 9536\n",
      "Epoch: [16] Test  [ 30/242]  eta: 0:03:30    time: 0.9897  data: 0.0004  max mem: 9536\n",
      "Epoch: [16] Test  [ 40/242]  eta: 0:03:23    time: 1.0494  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [ 50/242]  eta: 0:03:14    time: 1.0448  data: 0.0004  max mem: 9536\n",
      "Epoch: [16] Test  [ 60/242]  eta: 0:03:07    time: 1.0767  data: 0.0004  max mem: 9536\n",
      "Epoch: [16] Test  [ 70/242]  eta: 0:02:57    time: 1.0887  data: 0.0004  max mem: 9536\n",
      "Epoch: [16] Test  [ 80/242]  eta: 0:02:46    time: 1.0327  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Test  [ 90/242]  eta: 0:02:35    time: 0.9798  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Test  [100/242]  eta: 0:02:25    time: 1.0120  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [110/242]  eta: 0:02:15    time: 1.0310  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [120/242]  eta: 0:02:05    time: 1.0460  data: 0.0004  max mem: 9536\n",
      "Epoch: [16] Test  [130/242]  eta: 0:01:54    time: 1.0329  data: 0.0004  max mem: 9536\n",
      "Epoch: [16] Test  [140/242]  eta: 0:01:44    time: 0.9828  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [150/242]  eta: 0:01:33    time: 0.9915  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [160/242]  eta: 0:01:23    time: 1.0048  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [170/242]  eta: 0:01:13    time: 1.0541  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Test  [180/242]  eta: 0:01:03    time: 1.1122  data: 0.0006  max mem: 9536\n",
      "Epoch: [16] Test  [190/242]  eta: 0:00:53    time: 1.1143  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [200/242]  eta: 0:00:43    time: 1.0616  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Test  [210/242]  eta: 0:00:33    time: 1.0341  data: 0.0005  max mem: 9536\n",
      "Epoch: [16] Test  [220/242]  eta: 0:00:22    time: 1.0425  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [230/242]  eta: 0:00:12    time: 1.0495  data: 0.0003  max mem: 9536\n",
      "Epoch: [16] Test  [240/242]  eta: 0:00:02    time: 1.0102  data: 0.0004  max mem: 9536\n",
      "Epoch: [16] Test Total time: 0:04:09\n",
      "global correct: 95.3\n",
      "average row correct: ['97.6', '93.4', '84.0', '90.0', '87.6', '89.3', '98.9', '92.0', '97.3', '63.7', '93.4', '72.0', '84.0', '96.6', '95.5', '93.2', '65.4', '95.4', '71.2', '89.2', '85.5']\n",
      "IoU: ['95.0', '90.4', '64.7', '82.5', '75.8', '73.4', '93.9', '88.1', '86.2', '42.7', '89.4', '63.1', '79.1', '87.2', '88.2', '90.1', '58.6', '86.0', '54.2', '86.3', '80.4']\n",
      "mean IoU: 78.8\n",
      "Epoch: [17] Train  [  0/183]  eta: 0:38:01  lr: 0.000622  loss: 2.5955 (2.5955)  time: 12.4693  data: 0.4129  max mem: 9536\n",
      "Epoch: [17] Train  [ 10/183]  eta: 0:35:49  lr: 0.000620  loss: 2.3770 (2.2975)  time: 12.4263  data: 0.0378  max mem: 9536\n",
      "Epoch: [17] Train  [ 20/183]  eta: 0:33:40  lr: 0.000619  loss: 2.4723 (2.3102)  time: 12.3911  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Train  [ 30/183]  eta: 0:31:32  lr: 0.000618  loss: 2.5956 (2.3111)  time: 12.3335  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Train  [ 40/183]  eta: 0:29:26  lr: 0.000616  loss: 2.1968 (2.2892)  time: 12.3087  data: 0.0006  max mem: 9536\n",
      "Epoch: [17] Train  [ 50/183]  eta: 0:27:22  lr: 0.000615  loss: 2.4118 (2.2832)  time: 12.3179  data: 0.0007  max mem: 9536\n",
      "Epoch: [17] Train  [ 60/183]  eta: 0:25:19  lr: 0.000614  loss: 2.2207 (2.2884)  time: 12.3458  data: 0.0006  max mem: 9536\n",
      "Epoch: [17] Train  [ 70/183]  eta: 0:23:15  lr: 0.000612  loss: 1.9290 (2.2772)  time: 12.3508  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Train  [ 80/183]  eta: 0:21:11  lr: 0.000611  loss: 2.5256 (2.2998)  time: 12.3122  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Train  [ 90/183]  eta: 0:19:08  lr: 0.000610  loss: 2.1412 (2.2941)  time: 12.3322  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Train  [100/183]  eta: 0:17:03  lr: 0.000608  loss: 2.1325 (2.2936)  time: 12.3198  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Train  [110/183]  eta: 0:14:59  lr: 0.000607  loss: 2.0791 (2.2938)  time: 12.2548  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Train  [120/183]  eta: 0:12:57  lr: 0.000606  loss: 2.0481 (2.2912)  time: 12.3651  data: 0.0006  max mem: 9536\n",
      "Epoch: [17] Train  [130/183]  eta: 0:10:54  lr: 0.000604  loss: 2.1389 (2.2947)  time: 12.4317  data: 0.0007  max mem: 9536\n",
      "Epoch: [17] Train  [140/183]  eta: 0:08:51  lr: 0.000603  loss: 2.3813 (2.2974)  time: 12.3951  data: 0.0006  max mem: 9536\n",
      "Epoch: [17] Train  [150/183]  eta: 0:06:47  lr: 0.000602  loss: 2.6346 (2.3075)  time: 12.4098  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Train  [160/183]  eta: 0:04:44  lr: 0.000600  loss: 2.2289 (2.3085)  time: 12.3933  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Train  [170/183]  eta: 0:02:40  lr: 0.000599  loss: 2.2180 (2.3078)  time: 12.3732  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Train  [180/183]  eta: 0:00:37  lr: 0.000598  loss: 2.1751 (2.3070)  time: 12.3383  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Train Total time: 0:37:39\n",
      "Epoch: [17] Test  [  0/242]  eta: 0:05:57    time: 1.4758  data: 0.4175  max mem: 9536\n",
      "Epoch: [17] Test  [ 10/242]  eta: 0:03:51    time: 0.9998  data: 0.0383  max mem: 9536\n",
      "Epoch: [17] Test  [ 20/242]  eta: 0:03:34    time: 0.9417  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [ 30/242]  eta: 0:03:30    time: 0.9911  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [ 40/242]  eta: 0:03:23    time: 1.0528  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [ 50/242]  eta: 0:03:14    time: 1.0470  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Test  [ 60/242]  eta: 0:03:07    time: 1.0805  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Test  [ 70/242]  eta: 0:02:58    time: 1.0931  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Test  [ 80/242]  eta: 0:02:47    time: 1.0342  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [ 90/242]  eta: 0:02:35    time: 0.9834  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [100/242]  eta: 0:02:26    time: 1.0176  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [110/242]  eta: 0:02:15    time: 1.0342  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Test  [120/242]  eta: 0:02:05    time: 1.0467  data: 0.0006  max mem: 9536\n",
      "Epoch: [17] Test  [130/242]  eta: 0:01:55    time: 1.0341  data: 0.0005  max mem: 9536\n",
      "Epoch: [17] Test  [140/242]  eta: 0:01:44    time: 0.9824  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [150/242]  eta: 0:01:34    time: 0.9904  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [160/242]  eta: 0:01:23    time: 1.0048  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [170/242]  eta: 0:01:13    time: 1.0542  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [180/242]  eta: 0:01:04    time: 1.1150  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [190/242]  eta: 0:00:53    time: 1.1187  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [200/242]  eta: 0:00:43    time: 1.0648  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Test  [210/242]  eta: 0:00:33    time: 1.0383  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Test  [220/242]  eta: 0:00:22    time: 1.0437  data: 0.0004  max mem: 9536\n",
      "Epoch: [17] Test  [230/242]  eta: 0:00:12    time: 1.0475  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test  [240/242]  eta: 0:00:02    time: 1.0106  data: 0.0003  max mem: 9536\n",
      "Epoch: [17] Test Total time: 0:04:10\n",
      "global correct: 95.2\n",
      "average row correct: ['97.3', '95.5', '86.2', '90.5', '88.0', '86.6', '97.3', '94.2', '96.8', '65.8', '95.3', '71.7', '84.9', '94.5', '81.2', '94.7', '66.9', '95.4', '76.8', '90.0', '89.7']\n",
      "IoU: ['94.9', '91.8', '57.5', '83.3', '71.0', '75.1', '94.4', '86.3', '86.6', '42.9', '91.7', '63.8', '80.7', '89.2', '78.1', '90.7', '58.8', '91.2', '53.6', '87.0', '71.4']\n",
      "mean IoU: 78.1\n",
      "Epoch: [18] Train  [  0/183]  eta: 0:39:33  lr: 0.000597  loss: 2.0251 (2.0251)  time: 12.9707  data: 0.4127  max mem: 9536\n",
      "Epoch: [18] Train  [ 10/183]  eta: 0:35:18  lr: 0.000596  loss: 2.2215 (2.2428)  time: 12.2441  data: 0.0380  max mem: 9536\n",
      "Epoch: [18] Train  [ 20/183]  eta: 0:33:23  lr: 0.000595  loss: 2.0078 (2.2704)  time: 12.2586  data: 0.0005  max mem: 9536\n",
      "Epoch: [18] Train  [ 30/183]  eta: 0:31:31  lr: 0.000593  loss: 2.2417 (2.2271)  time: 12.4233  data: 0.0005  max mem: 9536\n",
      "Epoch: [18] Train  [ 40/183]  eta: 0:29:26  lr: 0.000592  loss: 2.3596 (2.2426)  time: 12.4173  data: 0.0005  max mem: 9536\n",
      "Epoch: [18] Train  [ 50/183]  eta: 0:27:25  lr: 0.000591  loss: 2.0545 (2.2357)  time: 12.4006  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [ 60/183]  eta: 0:25:23  lr: 0.000589  loss: 2.3010 (2.2558)  time: 12.4597  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [ 70/183]  eta: 0:23:20  lr: 0.000588  loss: 2.4673 (2.2864)  time: 12.4265  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [ 80/183]  eta: 0:21:15  lr: 0.000587  loss: 2.3341 (2.2874)  time: 12.3506  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [ 90/183]  eta: 0:19:11  lr: 0.000585  loss: 2.2560 (2.2848)  time: 12.3522  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [100/183]  eta: 0:17:06  lr: 0.000584  loss: 2.4976 (2.2792)  time: 12.3218  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [110/183]  eta: 0:15:02  lr: 0.000582  loss: 2.4642 (2.2800)  time: 12.2802  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [120/183]  eta: 0:12:58  lr: 0.000581  loss: 2.2211 (2.2799)  time: 12.3298  data: 0.0005  max mem: 9536\n",
      "Epoch: [18] Train  [130/183]  eta: 0:10:54  lr: 0.000580  loss: 2.8945 (2.2837)  time: 12.2203  data: 0.0005  max mem: 9536\n",
      "Epoch: [18] Train  [140/183]  eta: 0:08:50  lr: 0.000578  loss: 2.2202 (2.2834)  time: 12.1815  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [150/183]  eta: 0:06:47  lr: 0.000577  loss: 2.2057 (2.2819)  time: 12.3344  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [160/183]  eta: 0:04:43  lr: 0.000576  loss: 2.1468 (2.2867)  time: 12.3576  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Train  [170/183]  eta: 0:02:40  lr: 0.000574  loss: 2.3329 (2.2829)  time: 12.3733  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Train  [180/183]  eta: 0:00:37  lr: 0.000573  loss: 2.2023 (2.2786)  time: 12.3785  data: 0.0005  max mem: 9536\n",
      "Epoch: [18] Train Total time: 0:37:38\n",
      "Epoch: [18] Test  [  0/242]  eta: 0:06:11    time: 1.5343  data: 0.4654  max mem: 9536\n",
      "Epoch: [18] Test  [ 10/242]  eta: 0:03:53    time: 1.0047  data: 0.0426  max mem: 9536\n",
      "Epoch: [18] Test  [ 20/242]  eta: 0:03:35    time: 0.9406  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [ 30/242]  eta: 0:03:31    time: 0.9903  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [ 40/242]  eta: 0:03:23    time: 1.0510  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [ 50/242]  eta: 0:03:14    time: 1.0461  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [ 60/242]  eta: 0:03:07    time: 1.0814  data: 0.0005  max mem: 9536\n",
      "Epoch: [18] Test  [ 70/242]  eta: 0:02:58    time: 1.0924  data: 0.0005  max mem: 9536\n",
      "Epoch: [18] Test  [ 80/242]  eta: 0:02:47    time: 1.0327  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [ 90/242]  eta: 0:02:35    time: 0.9821  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Test  [100/242]  eta: 0:02:26    time: 1.0162  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [110/242]  eta: 0:02:15    time: 1.0339  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [120/242]  eta: 0:02:05    time: 1.0469  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Test  [130/242]  eta: 0:01:55    time: 1.0338  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [140/242]  eta: 0:01:44    time: 0.9833  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [150/242]  eta: 0:01:34    time: 0.9920  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [160/242]  eta: 0:01:23    time: 1.0064  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [170/242]  eta: 0:01:13    time: 1.0559  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [180/242]  eta: 0:01:04    time: 1.1163  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Test  [190/242]  eta: 0:00:53    time: 1.1183  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Test  [200/242]  eta: 0:00:43    time: 1.0637  data: 0.0004  max mem: 9536\n",
      "Epoch: [18] Test  [210/242]  eta: 0:00:33    time: 1.0378  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [220/242]  eta: 0:00:22    time: 1.0447  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [230/242]  eta: 0:00:12    time: 1.0519  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test  [240/242]  eta: 0:00:02    time: 1.0151  data: 0.0003  max mem: 9536\n",
      "Epoch: [18] Test Total time: 0:04:10\n",
      "global correct: 95.4\n",
      "average row correct: ['97.9', '95.9', '88.1', '90.4', '90.5', '90.3', '96.3', '91.0', '96.1', '71.7', '94.8', '68.1', '79.0', '95.9', '93.4', '93.9', '64.2', '96.1', '57.4', '95.0', '87.6']\n",
      "IoU: ['95.3', '91.0', '58.2', '85.3', '74.3', '76.1', '94.0', '89.0', '81.6', '46.9', '90.6', '63.3', '73.8', '87.6', '85.7', '90.1', '59.6', '84.5', '52.0', '86.3', '80.2']\n",
      "mean IoU: 78.4\n",
      "Epoch: [19] Train  [  0/183]  eta: 0:39:30  lr: 0.000573  loss: 2.1499 (2.1499)  time: 12.9517  data: 0.3523  max mem: 9536\n",
      "Epoch: [19] Train  [ 10/183]  eta: 0:35:44  lr: 0.000571  loss: 2.3546 (2.2838)  time: 12.3979  data: 0.0328  max mem: 9536\n",
      "Epoch: [19] Train  [ 20/183]  eta: 0:33:51  lr: 0.000570  loss: 2.3141 (2.2212)  time: 12.4415  data: 0.0006  max mem: 9536\n",
      "Epoch: [19] Train  [ 30/183]  eta: 0:31:36  lr: 0.000569  loss: 2.3168 (2.2357)  time: 12.3966  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [ 40/183]  eta: 0:29:27  lr: 0.000567  loss: 2.2786 (2.2548)  time: 12.2495  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [ 50/183]  eta: 0:27:24  lr: 0.000566  loss: 2.0185 (2.2554)  time: 12.3157  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [ 60/183]  eta: 0:25:22  lr: 0.000565  loss: 2.2810 (2.2465)  time: 12.4062  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [ 70/183]  eta: 0:23:17  lr: 0.000563  loss: 2.0488 (2.2449)  time: 12.3587  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [ 80/183]  eta: 0:21:15  lr: 0.000562  loss: 2.2218 (2.2415)  time: 12.3999  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [ 90/183]  eta: 0:19:12  lr: 0.000561  loss: 2.1890 (2.2393)  time: 12.4748  data: 0.0005  max mem: 9536\n",
      "Epoch: [19] Train  [100/183]  eta: 0:17:07  lr: 0.000559  loss: 2.1554 (2.2427)  time: 12.3674  data: 0.0005  max mem: 9536\n",
      "Epoch: [19] Train  [110/183]  eta: 0:15:04  lr: 0.000558  loss: 2.0534 (2.2270)  time: 12.4229  data: 0.0005  max mem: 9536\n",
      "Epoch: [19] Train  [120/183]  eta: 0:13:00  lr: 0.000557  loss: 2.1893 (2.2235)  time: 12.4234  data: 0.0005  max mem: 9536\n",
      "Epoch: [19] Train  [130/183]  eta: 0:10:56  lr: 0.000555  loss: 2.0046 (2.2210)  time: 12.3064  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [140/183]  eta: 0:08:52  lr: 0.000554  loss: 2.3295 (2.2292)  time: 12.3153  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [150/183]  eta: 0:06:48  lr: 0.000553  loss: 2.2492 (2.2266)  time: 12.2910  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Train  [160/183]  eta: 0:04:44  lr: 0.000551  loss: 2.5968 (2.2271)  time: 12.3355  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Train  [170/183]  eta: 0:02:40  lr: 0.000550  loss: 2.3633 (2.2279)  time: 12.3094  data: 0.0005  max mem: 9536\n",
      "Epoch: [19] Train  [180/183]  eta: 0:00:37  lr: 0.000549  loss: 2.2783 (2.2281)  time: 12.2975  data: 0.0005  max mem: 9536\n",
      "Epoch: [19] Train Total time: 0:37:42\n",
      "Epoch: [19] Test  [  0/242]  eta: 0:05:53    time: 1.4596  data: 0.3887  max mem: 9536\n",
      "Epoch: [19] Test  [ 10/242]  eta: 0:03:52    time: 1.0007  data: 0.0357  max mem: 9536\n",
      "Epoch: [19] Test  [ 20/242]  eta: 0:03:34    time: 0.9430  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [ 30/242]  eta: 0:03:30    time: 0.9921  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [ 40/242]  eta: 0:03:23    time: 1.0510  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [ 50/242]  eta: 0:03:14    time: 1.0463  data: 0.0002  max mem: 9536\n",
      "Epoch: [19] Test  [ 60/242]  eta: 0:03:07    time: 1.0803  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [ 70/242]  eta: 0:02:58    time: 1.0901  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [ 80/242]  eta: 0:02:47    time: 1.0339  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [ 90/242]  eta: 0:02:35    time: 0.9829  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Test  [100/242]  eta: 0:02:26    time: 1.0163  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [110/242]  eta: 0:02:15    time: 1.0351  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Test  [120/242]  eta: 0:02:05    time: 1.0508  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Test  [130/242]  eta: 0:01:55    time: 1.0381  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [140/242]  eta: 0:01:44    time: 0.9849  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [150/242]  eta: 0:01:34    time: 0.9918  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [160/242]  eta: 0:01:23    time: 1.0051  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [170/242]  eta: 0:01:13    time: 1.0548  data: 0.0005  max mem: 9536\n",
      "Epoch: [19] Test  [180/242]  eta: 0:01:04    time: 1.1168  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Test  [190/242]  eta: 0:00:53    time: 1.1197  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [200/242]  eta: 0:00:43    time: 1.0648  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [210/242]  eta: 0:00:33    time: 1.0387  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test  [220/242]  eta: 0:00:22    time: 1.0445  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Test  [230/242]  eta: 0:00:12    time: 1.0515  data: 0.0004  max mem: 9536\n",
      "Epoch: [19] Test  [240/242]  eta: 0:00:02    time: 1.0140  data: 0.0003  max mem: 9536\n",
      "Epoch: [19] Test Total time: 0:04:10\n",
      "global correct: 95.4\n",
      "average row correct: ['97.5', '97.0', '82.6', '92.6', '91.7', '91.2', '99.0', '92.8', '97.6', '62.8', '97.6', '78.5', '79.4', '95.8', '90.3', '94.6', '79.2', '96.3', '65.3', '91.0', '89.9']\n",
      "IoU: ['95.2', '88.5', '67.0', '84.7', '59.2', '80.1', '95.2', '88.2', '84.6', '49.2', '89.8', '67.7', '74.8', '89.3', '84.8', '90.0', '70.1', '82.9', '54.8', '86.1', '78.4']\n",
      "mean IoU: 79.1\n",
      "Epoch: [20] Train  [  0/183]  eta: 0:38:22  lr: 0.000548  loss: 2.2880 (2.2880)  time: 12.5806  data: 0.4299  max mem: 9536\n",
      "Epoch: [20] Train  [ 10/183]  eta: 0:35:39  lr: 0.000547  loss: 2.4970 (2.2270)  time: 12.3649  data: 0.0397  max mem: 9536\n",
      "Epoch: [20] Train  [ 20/183]  eta: 0:33:44  lr: 0.000545  loss: 2.3391 (2.2502)  time: 12.4142  data: 0.0007  max mem: 9536\n",
      "Epoch: [20] Train  [ 30/183]  eta: 0:31:30  lr: 0.000544  loss: 2.1753 (2.2548)  time: 12.3484  data: 0.0006  max mem: 9536\n",
      "Epoch: [20] Train  [ 40/183]  eta: 0:29:24  lr: 0.000543  loss: 2.0536 (2.2269)  time: 12.2493  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Train  [ 50/183]  eta: 0:27:18  lr: 0.000541  loss: 2.2269 (2.2222)  time: 12.2619  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Train  [ 60/183]  eta: 0:25:14  lr: 0.000540  loss: 2.2400 (2.2109)  time: 12.2712  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Train  [ 70/183]  eta: 0:23:14  lr: 0.000539  loss: 1.8480 (2.2066)  time: 12.3843  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Train  [ 80/183]  eta: 0:21:10  lr: 0.000537  loss: 2.6180 (2.2210)  time: 12.3992  data: 0.0005  max mem: 9536\n",
      "Epoch: [20] Train  [ 90/183]  eta: 0:19:07  lr: 0.000536  loss: 2.3849 (2.2204)  time: 12.3617  data: 0.0007  max mem: 9536\n",
      "Epoch: [20] Train  [100/183]  eta: 0:17:04  lr: 0.000535  loss: 2.3850 (2.2146)  time: 12.3688  data: 0.0005  max mem: 9536\n",
      "Epoch: [20] Train  [110/183]  eta: 0:15:02  lr: 0.000533  loss: 2.7947 (2.2187)  time: 12.4287  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Train  [120/183]  eta: 0:12:58  lr: 0.000532  loss: 1.9746 (2.2113)  time: 12.4298  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Train  [130/183]  eta: 0:10:54  lr: 0.000531  loss: 2.2276 (2.2124)  time: 12.3111  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Train  [140/183]  eta: 0:08:50  lr: 0.000529  loss: 2.2119 (2.2209)  time: 12.2882  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Train  [150/183]  eta: 0:06:47  lr: 0.000528  loss: 2.1454 (2.2244)  time: 12.2961  data: 0.0006  max mem: 9536\n",
      "Epoch: [20] Train  [160/183]  eta: 0:04:43  lr: 0.000526  loss: 2.2722 (2.2265)  time: 12.3341  data: 0.0006  max mem: 9536\n",
      "Epoch: [20] Train  [170/183]  eta: 0:02:40  lr: 0.000525  loss: 2.0834 (2.2247)  time: 12.3948  data: 0.0005  max mem: 9536\n",
      "Epoch: [20] Train  [180/183]  eta: 0:00:37  lr: 0.000524  loss: 2.0161 (2.2254)  time: 12.4280  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Train Total time: 0:37:40\n",
      "Epoch: [20] Test  [  0/242]  eta: 0:06:07    time: 1.5187  data: 0.4456  max mem: 9536\n",
      "Epoch: [20] Test  [ 10/242]  eta: 0:03:53    time: 1.0045  data: 0.0408  max mem: 9536\n",
      "Epoch: [20] Test  [ 20/242]  eta: 0:03:35    time: 0.9432  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [ 30/242]  eta: 0:03:31    time: 0.9932  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [ 40/242]  eta: 0:03:24    time: 1.0543  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [ 50/242]  eta: 0:03:15    time: 1.0502  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Test  [ 60/242]  eta: 0:03:08    time: 1.0822  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [ 70/242]  eta: 0:02:58    time: 1.0921  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [ 80/242]  eta: 0:02:47    time: 1.0339  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [ 90/242]  eta: 0:02:36    time: 0.9832  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [100/242]  eta: 0:02:26    time: 1.0172  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [110/242]  eta: 0:02:15    time: 1.0346  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [120/242]  eta: 0:02:06    time: 1.0483  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [130/242]  eta: 0:01:55    time: 1.0352  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [140/242]  eta: 0:01:44    time: 0.9831  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [150/242]  eta: 0:01:34    time: 0.9919  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Test  [160/242]  eta: 0:01:23    time: 1.0073  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [170/242]  eta: 0:01:14    time: 1.0561  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [180/242]  eta: 0:01:04    time: 1.1161  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [190/242]  eta: 0:00:53    time: 1.1211  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [200/242]  eta: 0:00:43    time: 1.0645  data: 0.0004  max mem: 9536\n",
      "Epoch: [20] Test  [210/242]  eta: 0:00:33    time: 1.0352  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [220/242]  eta: 0:00:22    time: 1.0453  data: 0.0003  max mem: 9536\n",
      "Epoch: [20] Test  [230/242]  eta: 0:00:12    time: 1.0530  data: 0.0005  max mem: 9536\n",
      "Epoch: [20] Test  [240/242]  eta: 0:00:02    time: 1.0143  data: 0.0005  max mem: 9536\n",
      "Epoch: [20] Test Total time: 0:04:10\n",
      "global correct: 95.5\n",
      "average row correct: ['97.5', '95.7', '85.3', '93.1', '83.1', '90.2', '97.8', '94.2', '96.1', '63.2', '96.1', '71.3', '86.0', '93.8', '94.1', '94.3', '68.9', '96.1', '74.7', '91.5', '90.5']\n",
      "IoU: ['95.3', '90.7', '63.4', '85.3', '74.8', '79.4', '93.4', '86.2', '84.9', '43.3', '90.4', '65.6', '79.3', '89.3', '86.1', '90.4', '63.0', '81.8', '56.7', '86.0', '77.7']\n",
      "mean IoU: 79.2\n",
      "Epoch: [21] Train  [  0/183]  eta: 0:40:42  lr: 0.000523  loss: 2.0616 (2.0616)  time: 13.3458  data: 0.4704  max mem: 9536\n",
      "Epoch: [21] Train  [ 10/183]  eta: 0:35:31  lr: 0.000522  loss: 2.1161 (2.2001)  time: 12.3207  data: 0.0433  max mem: 9536\n",
      "Epoch: [21] Train  [ 20/183]  eta: 0:33:32  lr: 0.000521  loss: 2.3435 (2.1892)  time: 12.2957  data: 0.0007  max mem: 9536\n",
      "Epoch: [21] Train  [ 30/183]  eta: 0:31:32  lr: 0.000519  loss: 2.1991 (2.1900)  time: 12.3916  data: 0.0006  max mem: 9536\n",
      "Epoch: [21] Train  [ 40/183]  eta: 0:29:31  lr: 0.000518  loss: 2.1867 (2.2023)  time: 12.4256  data: 0.0006  max mem: 9536\n",
      "Epoch: [21] Train  [ 50/183]  eta: 0:27:25  lr: 0.000517  loss: 2.4015 (2.2028)  time: 12.3781  data: 0.0005  max mem: 9536\n",
      "Epoch: [21] Train  [ 60/183]  eta: 0:25:19  lr: 0.000515  loss: 2.4471 (2.2019)  time: 12.2932  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Train  [ 70/183]  eta: 0:23:15  lr: 0.000514  loss: 2.1058 (2.1977)  time: 12.3095  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Train  [ 80/183]  eta: 0:21:11  lr: 0.000513  loss: 1.9880 (2.1943)  time: 12.3297  data: 0.0006  max mem: 9536\n",
      "Epoch: [21] Train  [ 90/183]  eta: 0:19:08  lr: 0.000511  loss: 1.9851 (2.1945)  time: 12.3128  data: 0.0006  max mem: 9536\n",
      "Epoch: [21] Train  [100/183]  eta: 0:17:03  lr: 0.000510  loss: 2.4278 (2.2017)  time: 12.2751  data: 0.0005  max mem: 9536\n",
      "Epoch: [21] Train  [110/183]  eta: 0:15:00  lr: 0.000508  loss: 2.0484 (2.1960)  time: 12.2731  data: 0.0005  max mem: 9536\n",
      "Epoch: [21] Train  [120/183]  eta: 0:12:56  lr: 0.000507  loss: 2.2843 (2.2051)  time: 12.3280  data: 0.0006  max mem: 9536\n",
      "Epoch: [21] Train  [130/183]  eta: 0:10:53  lr: 0.000506  loss: 2.2789 (2.1975)  time: 12.3148  data: 0.0006  max mem: 9536\n",
      "Epoch: [21] Train  [140/183]  eta: 0:08:50  lr: 0.000504  loss: 2.1840 (2.2028)  time: 12.3062  data: 0.0005  max mem: 9536\n",
      "Epoch: [21] Train  [150/183]  eta: 0:06:46  lr: 0.000503  loss: 2.1991 (2.2030)  time: 12.3468  data: 0.0005  max mem: 9536\n",
      "Epoch: [21] Train  [160/183]  eta: 0:04:43  lr: 0.000502  loss: 2.1271 (2.2013)  time: 12.4207  data: 0.0005  max mem: 9536\n",
      "Epoch: [21] Train  [170/183]  eta: 0:02:40  lr: 0.000500  loss: 2.0202 (2.1988)  time: 12.3801  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Train  [180/183]  eta: 0:00:37  lr: 0.000499  loss: 2.2293 (2.1970)  time: 12.2874  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Train Total time: 0:37:37\n",
      "Epoch: [21] Test  [  0/242]  eta: 0:06:02    time: 1.4960  data: 0.4168  max mem: 9536\n",
      "Epoch: [21] Test  [ 10/242]  eta: 0:03:52    time: 1.0035  data: 0.0383  max mem: 9536\n",
      "Epoch: [21] Test  [ 20/242]  eta: 0:03:35    time: 0.9435  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Test  [ 30/242]  eta: 0:03:31    time: 0.9956  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Test  [ 40/242]  eta: 0:03:24    time: 1.0562  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Test  [ 50/242]  eta: 0:03:15    time: 1.0488  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [ 60/242]  eta: 0:03:08    time: 1.0810  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [ 70/242]  eta: 0:02:58    time: 1.0901  data: 0.0005  max mem: 9536\n",
      "Epoch: [21] Test  [ 80/242]  eta: 0:02:47    time: 1.0336  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Test  [ 90/242]  eta: 0:02:36    time: 0.9845  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Test  [100/242]  eta: 0:02:26    time: 1.0173  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Test  [110/242]  eta: 0:02:15    time: 1.0349  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [120/242]  eta: 0:02:06    time: 1.0495  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [130/242]  eta: 0:01:55    time: 1.0374  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [140/242]  eta: 0:01:44    time: 0.9861  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Test  [150/242]  eta: 0:01:34    time: 0.9930  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [160/242]  eta: 0:01:24    time: 1.0074  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [170/242]  eta: 0:01:14    time: 1.0573  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [180/242]  eta: 0:01:04    time: 1.1152  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [190/242]  eta: 0:00:53    time: 1.1177  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [200/242]  eta: 0:00:43    time: 1.0633  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [210/242]  eta: 0:00:33    time: 1.0368  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [220/242]  eta: 0:00:22    time: 1.0439  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [230/242]  eta: 0:00:12    time: 1.0504  data: 0.0003  max mem: 9536\n",
      "Epoch: [21] Test  [240/242]  eta: 0:00:02    time: 1.0134  data: 0.0004  max mem: 9536\n",
      "Epoch: [21] Test Total time: 0:04:10\n",
      "global correct: 95.3\n",
      "average row correct: ['97.7', '96.1', '86.3', '91.8', '89.0', '91.2', '98.7', '87.0', '96.7', '68.0', '93.7', '71.9', '86.4', '95.0', '92.7', '94.4', '64.1', '96.1', '50.8', '91.3', '88.5']\n",
      "IoU: ['95.1', '89.9', '64.1', '84.9', '58.5', '73.9', '96.2', '85.2', '86.7', '40.3', '89.2', '65.8', '81.7', '85.9', '86.4', '90.7', '58.6', '86.5', '46.7', '87.8', '82.6']\n",
      "mean IoU: 77.9\n",
      "Epoch: [22] Train  [  0/183]  eta: 0:39:00  lr: 0.000499  loss: 2.0098 (2.0098)  time: 12.7917  data: 0.3688  max mem: 9536\n",
      "Epoch: [22] Train  [ 10/183]  eta: 0:35:36  lr: 0.000497  loss: 2.3080 (2.1814)  time: 12.3473  data: 0.0339  max mem: 9536\n",
      "Epoch: [22] Train  [ 20/183]  eta: 0:33:35  lr: 0.000496  loss: 2.2702 (2.2037)  time: 12.3440  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Train  [ 30/183]  eta: 0:31:35  lr: 0.000494  loss: 2.0373 (2.1908)  time: 12.4083  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Train  [ 40/183]  eta: 0:29:27  lr: 0.000493  loss: 2.4241 (2.1834)  time: 12.3579  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Train  [ 50/183]  eta: 0:27:25  lr: 0.000492  loss: 1.9827 (2.1662)  time: 12.3556  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Train  [ 60/183]  eta: 0:25:23  lr: 0.000490  loss: 1.9817 (2.1795)  time: 12.4416  data: 0.0007  max mem: 9536\n",
      "Epoch: [22] Train  [ 70/183]  eta: 0:23:19  lr: 0.000489  loss: 2.3618 (2.1836)  time: 12.4110  data: 0.0008  max mem: 9536\n",
      "Epoch: [22] Train  [ 80/183]  eta: 0:21:15  lr: 0.000488  loss: 2.1163 (2.1861)  time: 12.3620  data: 0.0006  max mem: 9536\n",
      "Epoch: [22] Train  [ 90/183]  eta: 0:19:10  lr: 0.000486  loss: 2.0090 (2.1815)  time: 12.3449  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Train  [100/183]  eta: 0:17:07  lr: 0.000485  loss: 2.0570 (2.1709)  time: 12.4010  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Train  [110/183]  eta: 0:15:04  lr: 0.000483  loss: 2.0204 (2.1697)  time: 12.4924  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Train  [120/183]  eta: 0:13:01  lr: 0.000482  loss: 2.2192 (2.1654)  time: 12.4799  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Train  [130/183]  eta: 0:10:56  lr: 0.000481  loss: 2.2441 (2.1641)  time: 12.3699  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Train  [140/183]  eta: 0:08:52  lr: 0.000479  loss: 1.9478 (2.1592)  time: 12.3175  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Train  [150/183]  eta: 0:06:48  lr: 0.000478  loss: 2.0162 (2.1508)  time: 12.2412  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Train  [160/183]  eta: 0:04:44  lr: 0.000477  loss: 2.0706 (2.1573)  time: 12.2938  data: 0.0006  max mem: 9536\n",
      "Epoch: [22] Train  [170/183]  eta: 0:02:40  lr: 0.000475  loss: 2.0651 (2.1571)  time: 12.3913  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Train  [180/183]  eta: 0:00:37  lr: 0.000474  loss: 2.3900 (2.1635)  time: 12.3524  data: 0.0006  max mem: 9536\n",
      "Epoch: [22] Train Total time: 0:37:43\n",
      "Epoch: [22] Test  [  0/242]  eta: 0:05:53    time: 1.4603  data: 0.3878  max mem: 9536\n",
      "Epoch: [22] Test  [ 10/242]  eta: 0:03:51    time: 0.9984  data: 0.0356  max mem: 9536\n",
      "Epoch: [22] Test  [ 20/242]  eta: 0:03:34    time: 0.9423  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [ 30/242]  eta: 0:03:31    time: 0.9955  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Test  [ 40/242]  eta: 0:03:24    time: 1.0563  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Test  [ 50/242]  eta: 0:03:15    time: 1.0487  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [ 60/242]  eta: 0:03:08    time: 1.0833  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test  [ 70/242]  eta: 0:02:58    time: 1.0940  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test  [ 80/242]  eta: 0:02:47    time: 1.0367  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test  [ 90/242]  eta: 0:02:36    time: 0.9851  data: 0.0006  max mem: 9536\n",
      "Epoch: [22] Test  [100/242]  eta: 0:02:26    time: 1.0167  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Test  [110/242]  eta: 0:02:15    time: 1.0344  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test  [120/242]  eta: 0:02:06    time: 1.0472  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [130/242]  eta: 0:01:55    time: 1.0363  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [140/242]  eta: 0:01:44    time: 0.9868  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test  [150/242]  eta: 0:01:34    time: 0.9942  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test  [160/242]  eta: 0:01:24    time: 1.0066  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [170/242]  eta: 0:01:14    time: 1.0563  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [180/242]  eta: 0:01:04    time: 1.1181  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test  [190/242]  eta: 0:00:53    time: 1.1207  data: 0.0005  max mem: 9536\n",
      "Epoch: [22] Test  [200/242]  eta: 0:00:43    time: 1.0678  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test  [210/242]  eta: 0:00:33    time: 1.0387  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [220/242]  eta: 0:00:22    time: 1.0432  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [230/242]  eta: 0:00:12    time: 1.0517  data: 0.0003  max mem: 9536\n",
      "Epoch: [22] Test  [240/242]  eta: 0:00:02    time: 1.0146  data: 0.0004  max mem: 9536\n",
      "Epoch: [22] Test Total time: 0:04:10\n",
      "global correct: 95.3\n",
      "average row correct: ['97.6', '93.0', '88.5', '89.5', '87.5', '91.0', '98.5', '91.6', '96.3', '58.5', '92.7', '73.7', '86.4', '90.3', '82.8', '94.2', '59.7', '96.1', '73.9', '90.2', '89.2']\n",
      "IoU: ['95.1', '91.4', '60.1', '83.1', '74.6', '78.5', '95.9', '86.5', '84.3', '44.4', '86.6', '66.4', '77.2', '86.1', '79.3', '90.2', '56.2', '88.5', '53.4', '86.8', '80.2']\n",
      "mean IoU: 78.3\n",
      "Epoch: [23] Train  [  0/183]  eta: 0:39:14  lr: 0.000474  loss: 2.0437 (2.0437)  time: 12.8643  data: 0.4329  max mem: 9536\n",
      "Epoch: [23] Train  [ 10/183]  eta: 0:35:51  lr: 0.000472  loss: 2.1291 (2.1737)  time: 12.4349  data: 0.0396  max mem: 9536\n",
      "Epoch: [23] Train  [ 20/183]  eta: 0:33:36  lr: 0.000471  loss: 1.9421 (2.1436)  time: 12.3468  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Train  [ 30/183]  eta: 0:31:25  lr: 0.000469  loss: 2.0015 (2.1466)  time: 12.2630  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [ 40/183]  eta: 0:29:23  lr: 0.000468  loss: 2.1701 (2.1333)  time: 12.2981  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [ 50/183]  eta: 0:27:21  lr: 0.000467  loss: 2.0884 (2.1446)  time: 12.3743  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [ 60/183]  eta: 0:25:18  lr: 0.000465  loss: 2.1405 (2.1392)  time: 12.3577  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [ 70/183]  eta: 0:23:16  lr: 0.000464  loss: 2.0500 (2.1378)  time: 12.3886  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [ 80/183]  eta: 0:21:11  lr: 0.000463  loss: 2.2249 (2.1423)  time: 12.3465  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [ 90/183]  eta: 0:19:07  lr: 0.000461  loss: 2.2449 (2.1488)  time: 12.2826  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [100/183]  eta: 0:17:03  lr: 0.000460  loss: 1.9956 (2.1453)  time: 12.2757  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Train  [110/183]  eta: 0:15:00  lr: 0.000458  loss: 2.0175 (2.1342)  time: 12.3386  data: 0.0006  max mem: 9536\n",
      "Epoch: [23] Train  [120/183]  eta: 0:12:57  lr: 0.000457  loss: 2.1370 (2.1331)  time: 12.3937  data: 0.0006  max mem: 9536\n",
      "Epoch: [23] Train  [130/183]  eta: 0:10:53  lr: 0.000456  loss: 1.9095 (2.1285)  time: 12.2495  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Train  [140/183]  eta: 0:08:50  lr: 0.000454  loss: 2.0646 (2.1285)  time: 12.3002  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Train  [150/183]  eta: 0:06:47  lr: 0.000453  loss: 2.2642 (2.1310)  time: 12.4724  data: 0.0006  max mem: 9536\n",
      "Epoch: [23] Train  [160/183]  eta: 0:04:43  lr: 0.000452  loss: 1.9020 (2.1282)  time: 12.3490  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [170/183]  eta: 0:02:40  lr: 0.000450  loss: 1.9890 (2.1266)  time: 12.2470  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train  [180/183]  eta: 0:00:37  lr: 0.000449  loss: 1.9317 (2.1317)  time: 12.3330  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Train Total time: 0:37:36\n",
      "Epoch: [23] Test  [  0/242]  eta: 0:05:51    time: 1.4521  data: 0.3799  max mem: 9536\n",
      "Epoch: [23] Test  [ 10/242]  eta: 0:03:51    time: 0.9978  data: 0.0348  max mem: 9536\n",
      "Epoch: [23] Test  [ 20/242]  eta: 0:03:34    time: 0.9414  data: 0.0002  max mem: 9536\n",
      "Epoch: [23] Test  [ 30/242]  eta: 0:03:30    time: 0.9927  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [ 40/242]  eta: 0:03:23    time: 1.0538  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [ 50/242]  eta: 0:03:14    time: 1.0477  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [ 60/242]  eta: 0:03:07    time: 1.0816  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [ 70/242]  eta: 0:02:58    time: 1.0923  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [ 80/242]  eta: 0:02:47    time: 1.0347  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [ 90/242]  eta: 0:02:35    time: 0.9842  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Test  [100/242]  eta: 0:02:26    time: 1.0187  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [110/242]  eta: 0:02:15    time: 1.0373  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Test  [120/242]  eta: 0:02:06    time: 1.0498  data: 0.0005  max mem: 9536\n",
      "Epoch: [23] Test  [130/242]  eta: 0:01:55    time: 1.0370  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [140/242]  eta: 0:01:44    time: 0.9857  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Test  [150/242]  eta: 0:01:34    time: 0.9936  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [160/242]  eta: 0:01:24    time: 1.0088  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [170/242]  eta: 0:01:14    time: 1.0576  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [180/242]  eta: 0:01:04    time: 1.1164  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [190/242]  eta: 0:00:53    time: 1.1194  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Test  [200/242]  eta: 0:00:43    time: 1.0636  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Test  [210/242]  eta: 0:00:33    time: 1.0363  data: 0.0003  max mem: 9536\n",
      "Epoch: [23] Test  [220/242]  eta: 0:00:22    time: 1.0444  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Test  [230/242]  eta: 0:00:12    time: 1.0520  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Test  [240/242]  eta: 0:00:02    time: 1.0150  data: 0.0004  max mem: 9536\n",
      "Epoch: [23] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['97.5', '93.2', '86.7', '93.1', '87.6', '93.6', '98.2', '93.5', '96.3', '64.2', '96.9', '74.1', '88.0', '94.1', '96.6', '94.3', '71.9', '95.2', '68.1', '94.6', '89.4']\n",
      "IoU: ['95.3', '91.3', '60.2', '85.2', '74.8', '78.1', '94.5', '87.7', '85.4', '44.0', '89.6', '68.4', '81.5', '88.3', '88.8', '90.5', '61.6', '90.1', '58.0', '85.6', '78.4']\n",
      "mean IoU: 79.9\n",
      "Epoch: [24] Train  [  0/183]  eta: 0:38:44  lr: 0.000448  loss: 1.9352 (1.9352)  time: 12.7010  data: 0.4303  max mem: 9536\n",
      "Epoch: [24] Train  [ 10/183]  eta: 0:35:55  lr: 0.000447  loss: 1.7858 (2.0201)  time: 12.4606  data: 0.0397  max mem: 9536\n",
      "Epoch: [24] Train  [ 20/183]  eta: 0:33:22  lr: 0.000446  loss: 1.9231 (2.0365)  time: 12.2614  data: 0.0006  max mem: 9536\n",
      "Epoch: [24] Train  [ 30/183]  eta: 0:31:21  lr: 0.000444  loss: 1.8637 (2.0480)  time: 12.2029  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train  [ 40/183]  eta: 0:29:15  lr: 0.000443  loss: 2.0763 (2.0481)  time: 12.2751  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Train  [ 50/183]  eta: 0:27:12  lr: 0.000441  loss: 2.3465 (2.0502)  time: 12.2349  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train  [ 60/183]  eta: 0:25:14  lr: 0.000440  loss: 2.0019 (2.0666)  time: 12.3709  data: 0.0005  max mem: 9536\n",
      "Epoch: [24] Train  [ 70/183]  eta: 0:23:11  lr: 0.000439  loss: 2.1942 (2.0728)  time: 12.4258  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train  [ 80/183]  eta: 0:21:06  lr: 0.000437  loss: 2.0211 (2.0749)  time: 12.2621  data: 0.0005  max mem: 9536\n",
      "Epoch: [24] Train  [ 90/183]  eta: 0:19:04  lr: 0.000436  loss: 2.0123 (2.0656)  time: 12.2770  data: 0.0005  max mem: 9536\n",
      "Epoch: [24] Train  [100/183]  eta: 0:17:02  lr: 0.000435  loss: 2.2134 (2.0753)  time: 12.4031  data: 0.0005  max mem: 9536\n",
      "Epoch: [24] Train  [110/183]  eta: 0:14:59  lr: 0.000433  loss: 2.0397 (2.0755)  time: 12.3793  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train  [120/183]  eta: 0:12:56  lr: 0.000432  loss: 1.9501 (2.0725)  time: 12.3746  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train  [130/183]  eta: 0:10:53  lr: 0.000430  loss: 2.3623 (2.0692)  time: 12.4347  data: 0.0005  max mem: 9536\n",
      "Epoch: [24] Train  [140/183]  eta: 0:08:50  lr: 0.000429  loss: 1.9130 (2.0705)  time: 12.4607  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train  [150/183]  eta: 0:06:47  lr: 0.000428  loss: 1.9369 (2.0756)  time: 12.4144  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Train  [160/183]  eta: 0:04:43  lr: 0.000426  loss: 2.2126 (2.0823)  time: 12.3420  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train  [170/183]  eta: 0:02:40  lr: 0.000425  loss: 2.2154 (2.0779)  time: 12.3351  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train  [180/183]  eta: 0:00:37  lr: 0.000423  loss: 1.8212 (2.0791)  time: 12.3833  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Train Total time: 0:37:39\n",
      "Epoch: [24] Test  [  0/242]  eta: 0:05:59    time: 1.4846  data: 0.4188  max mem: 9536\n",
      "Epoch: [24] Test  [ 10/242]  eta: 0:03:52    time: 1.0013  data: 0.0383  max mem: 9536\n",
      "Epoch: [24] Test  [ 20/242]  eta: 0:03:35    time: 0.9441  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [ 30/242]  eta: 0:03:31    time: 0.9942  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [ 40/242]  eta: 0:03:24    time: 1.0536  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [ 50/242]  eta: 0:03:15    time: 1.0494  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [ 60/242]  eta: 0:03:08    time: 1.0814  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [ 70/242]  eta: 0:02:58    time: 1.0915  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Test  [ 80/242]  eta: 0:02:47    time: 1.0349  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Test  [ 90/242]  eta: 0:02:36    time: 0.9848  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Test  [100/242]  eta: 0:02:26    time: 1.0166  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [110/242]  eta: 0:02:15    time: 1.0319  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [120/242]  eta: 0:02:06    time: 1.0456  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [130/242]  eta: 0:01:55    time: 1.0359  data: 0.0004  max mem: 9536\n",
      "Epoch: [24] Test  [140/242]  eta: 0:01:44    time: 0.9858  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [150/242]  eta: 0:01:34    time: 0.9923  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [160/242]  eta: 0:01:23    time: 1.0081  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [170/242]  eta: 0:01:13    time: 1.0564  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [180/242]  eta: 0:01:04    time: 1.1141  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [190/242]  eta: 0:00:53    time: 1.1163  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [200/242]  eta: 0:00:43    time: 1.0632  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [210/242]  eta: 0:00:33    time: 1.0363  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [220/242]  eta: 0:00:22    time: 1.0430  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test  [230/242]  eta: 0:00:12    time: 1.0512  data: 0.0002  max mem: 9536\n",
      "Epoch: [24] Test  [240/242]  eta: 0:00:02    time: 1.0130  data: 0.0003  max mem: 9536\n",
      "Epoch: [24] Test Total time: 0:04:10\n",
      "global correct: 95.5\n",
      "average row correct: ['97.6', '94.3', '90.4', '95.3', '88.6', '86.9', '97.9', '94.1', '96.5', '67.1', '91.4', '74.9', '88.7', '96.0', '96.3', '93.6', '70.4', '96.4', '64.2', '93.9', '89.6']\n",
      "IoU: ['95.5', '91.0', '56.9', '85.8', '75.4', '78.1', '94.4', '89.0', '85.8', '43.1', '87.7', '68.6', '79.9', '88.0', '88.4', '90.1', '62.7', '89.8', '53.5', '85.8', '78.3']\n",
      "mean IoU: 79.4\n",
      "Epoch: [25] Train  [  0/183]  eta: 0:40:19  lr: 0.000423  loss: 1.9421 (1.9421)  time: 13.2225  data: 0.4167  max mem: 9536\n",
      "Epoch: [25] Train  [ 10/183]  eta: 0:36:14  lr: 0.000422  loss: 2.1002 (2.0359)  time: 12.5666  data: 0.0381  max mem: 9536\n",
      "Epoch: [25] Train  [ 20/183]  eta: 0:33:59  lr: 0.000420  loss: 1.8754 (2.0913)  time: 12.4786  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Train  [ 30/183]  eta: 0:31:51  lr: 0.000419  loss: 1.8091 (2.0576)  time: 12.4556  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Train  [ 40/183]  eta: 0:29:46  lr: 0.000417  loss: 2.1289 (2.0667)  time: 12.4653  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Train  [ 50/183]  eta: 0:27:38  lr: 0.000416  loss: 2.2187 (2.0731)  time: 12.4351  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Train  [ 60/183]  eta: 0:25:33  lr: 0.000415  loss: 1.9429 (2.0599)  time: 12.4152  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Train  [ 70/183]  eta: 0:23:26  lr: 0.000413  loss: 2.0713 (2.0574)  time: 12.3842  data: 0.0005  max mem: 9536\n",
      "Epoch: [25] Train  [ 80/183]  eta: 0:21:19  lr: 0.000412  loss: 2.0501 (2.0485)  time: 12.2716  data: 0.0005  max mem: 9536\n",
      "Epoch: [25] Train  [ 90/183]  eta: 0:19:14  lr: 0.000411  loss: 2.1463 (2.0637)  time: 12.2798  data: 0.0006  max mem: 9536\n",
      "Epoch: [25] Train  [100/183]  eta: 0:17:09  lr: 0.000409  loss: 1.9302 (2.0604)  time: 12.3307  data: 0.0006  max mem: 9536\n",
      "Epoch: [25] Train  [110/183]  eta: 0:15:05  lr: 0.000408  loss: 2.0045 (2.0585)  time: 12.3953  data: 0.0005  max mem: 9536\n",
      "Epoch: [25] Train  [120/183]  eta: 0:13:01  lr: 0.000406  loss: 1.8916 (2.0554)  time: 12.4304  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Train  [130/183]  eta: 0:10:57  lr: 0.000405  loss: 1.8618 (2.0579)  time: 12.3904  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Train  [140/183]  eta: 0:08:53  lr: 0.000404  loss: 2.1462 (2.0572)  time: 12.3736  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Train  [150/183]  eta: 0:06:48  lr: 0.000402  loss: 2.1298 (2.0539)  time: 12.2868  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Train  [160/183]  eta: 0:04:44  lr: 0.000401  loss: 1.8551 (2.0524)  time: 12.1823  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Train  [170/183]  eta: 0:02:40  lr: 0.000399  loss: 2.1137 (2.0478)  time: 12.3211  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Train  [180/183]  eta: 0:00:37  lr: 0.000398  loss: 1.8713 (2.0463)  time: 12.4081  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Train Total time: 0:37:45\n",
      "Epoch: [25] Test  [  0/242]  eta: 0:06:10    time: 1.5292  data: 0.4542  max mem: 9536\n",
      "Epoch: [25] Test  [ 10/242]  eta: 0:03:52    time: 1.0033  data: 0.0417  max mem: 9536\n",
      "Epoch: [25] Test  [ 20/242]  eta: 0:03:35    time: 0.9412  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Test  [ 30/242]  eta: 0:03:31    time: 0.9934  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [ 40/242]  eta: 0:03:24    time: 1.0547  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [ 50/242]  eta: 0:03:15    time: 1.0486  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [ 60/242]  eta: 0:03:08    time: 1.0806  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [ 70/242]  eta: 0:02:58    time: 1.0901  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [ 80/242]  eta: 0:02:47    time: 1.0346  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Test  [ 90/242]  eta: 0:02:35    time: 0.9840  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Test  [100/242]  eta: 0:02:26    time: 1.0157  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Test  [110/242]  eta: 0:02:15    time: 1.0340  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [120/242]  eta: 0:02:06    time: 1.0478  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [130/242]  eta: 0:01:55    time: 1.0361  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [140/242]  eta: 0:01:44    time: 0.9855  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [150/242]  eta: 0:01:34    time: 0.9935  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [160/242]  eta: 0:01:23    time: 1.0072  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [170/242]  eta: 0:01:14    time: 1.0566  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [180/242]  eta: 0:01:04    time: 1.1171  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [190/242]  eta: 0:00:53    time: 1.1227  data: 0.0005  max mem: 9536\n",
      "Epoch: [25] Test  [200/242]  eta: 0:00:43    time: 1.0674  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Test  [210/242]  eta: 0:00:33    time: 1.0381  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Test  [220/242]  eta: 0:00:22    time: 1.0469  data: 0.0004  max mem: 9536\n",
      "Epoch: [25] Test  [230/242]  eta: 0:00:12    time: 1.0532  data: 0.0003  max mem: 9536\n",
      "Epoch: [25] Test  [240/242]  eta: 0:00:02    time: 1.0165  data: 0.0002  max mem: 9536\n",
      "Epoch: [25] Test Total time: 0:04:10\n",
      "global correct: 95.5\n",
      "average row correct: ['97.7', '96.4', '88.2', '93.2', '89.0', '87.7', '98.8', '93.8', '96.7', '68.6', '96.2', '80.3', '82.2', '93.9', '90.2', '94.1', '62.1', '96.5', '60.4', '91.2', '89.9']\n",
      "IoU: ['95.6', '88.9', '59.1', '84.9', '71.6', '78.6', '92.0', '89.4', '83.5', '43.5', '89.0', '69.8', '76.7', '89.5', '83.6', '90.6', '57.8', '86.8', '52.6', '87.5', '77.3']\n",
      "mean IoU: 78.5\n",
      "Epoch: [26] Train  [  0/183]  eta: 0:39:29  lr: 0.000398  loss: 2.0379 (2.0379)  time: 12.9479  data: 0.4375  max mem: 9536\n",
      "Epoch: [26] Train  [ 10/183]  eta: 0:35:51  lr: 0.000396  loss: 2.1065 (2.0183)  time: 12.4377  data: 0.0401  max mem: 9536\n",
      "Epoch: [26] Train  [ 20/183]  eta: 0:33:37  lr: 0.000395  loss: 1.8998 (2.0508)  time: 12.3483  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Train  [ 30/183]  eta: 0:31:38  lr: 0.000393  loss: 2.0826 (2.0402)  time: 12.3942  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Train  [ 40/183]  eta: 0:29:31  lr: 0.000392  loss: 2.1066 (2.0291)  time: 12.3958  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Train  [ 50/183]  eta: 0:27:24  lr: 0.000391  loss: 1.9976 (2.0391)  time: 12.2871  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Train  [ 60/183]  eta: 0:25:17  lr: 0.000389  loss: 1.9678 (2.0369)  time: 12.2486  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Train  [ 70/183]  eta: 0:23:17  lr: 0.000388  loss: 1.7977 (2.0209)  time: 12.3723  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Train  [ 80/183]  eta: 0:21:14  lr: 0.000386  loss: 1.9741 (2.0431)  time: 12.4887  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Train  [ 90/183]  eta: 0:19:10  lr: 0.000385  loss: 1.8288 (2.0335)  time: 12.4054  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Train  [100/183]  eta: 0:17:06  lr: 0.000384  loss: 1.7906 (2.0244)  time: 12.3102  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Train  [110/183]  eta: 0:15:02  lr: 0.000382  loss: 1.8971 (2.0315)  time: 12.3226  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Train  [120/183]  eta: 0:12:58  lr: 0.000381  loss: 1.7250 (2.0336)  time: 12.2790  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Train  [130/183]  eta: 0:10:53  lr: 0.000379  loss: 2.0579 (2.0310)  time: 12.1635  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Train  [140/183]  eta: 0:08:49  lr: 0.000378  loss: 2.0658 (2.0268)  time: 12.1326  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Train  [150/183]  eta: 0:06:46  lr: 0.000377  loss: 1.8408 (2.0227)  time: 12.2244  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Train  [160/183]  eta: 0:04:43  lr: 0.000375  loss: 2.0513 (2.0224)  time: 12.4083  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Train  [170/183]  eta: 0:02:40  lr: 0.000374  loss: 1.8851 (2.0239)  time: 12.3247  data: 0.0005  max mem: 9536\n",
      "Epoch: [26] Train  [180/183]  eta: 0:00:36  lr: 0.000372  loss: 3.0067 (2.0284)  time: 12.2588  data: 0.0006  max mem: 9536\n",
      "Epoch: [26] Train Total time: 0:37:36\n",
      "Epoch: [26] Test  [  0/242]  eta: 0:06:00    time: 1.4896  data: 0.4170  max mem: 9536\n",
      "Epoch: [26] Test  [ 10/242]  eta: 0:03:52    time: 1.0016  data: 0.0383  max mem: 9536\n",
      "Epoch: [26] Test  [ 20/242]  eta: 0:03:34    time: 0.9418  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Test  [ 30/242]  eta: 0:03:31    time: 0.9930  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [ 40/242]  eta: 0:03:24    time: 1.0543  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [ 50/242]  eta: 0:03:15    time: 1.0487  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [ 60/242]  eta: 0:03:08    time: 1.0807  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Test  [ 70/242]  eta: 0:02:58    time: 1.0887  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Test  [ 80/242]  eta: 0:02:47    time: 1.0324  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [ 90/242]  eta: 0:02:35    time: 0.9842  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [100/242]  eta: 0:02:26    time: 1.0197  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [110/242]  eta: 0:02:15    time: 1.0366  data: 0.0004  max mem: 9536\n",
      "Epoch: [26] Test  [120/242]  eta: 0:02:06    time: 1.0460  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [130/242]  eta: 0:01:55    time: 1.0337  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [140/242]  eta: 0:01:44    time: 0.9848  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [150/242]  eta: 0:01:34    time: 0.9942  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [160/242]  eta: 0:01:23    time: 1.0065  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [170/242]  eta: 0:01:13    time: 1.0557  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [180/242]  eta: 0:01:04    time: 1.1151  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [190/242]  eta: 0:00:53    time: 1.1174  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [200/242]  eta: 0:00:43    time: 1.0643  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [210/242]  eta: 0:00:33    time: 1.0359  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [220/242]  eta: 0:00:22    time: 1.0436  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [230/242]  eta: 0:00:12    time: 1.0508  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test  [240/242]  eta: 0:00:02    time: 1.0132  data: 0.0003  max mem: 9536\n",
      "Epoch: [26] Test Total time: 0:04:10\n",
      "global correct: 95.7\n",
      "average row correct: ['98.0', '95.2', '82.4', '94.7', '88.6', '88.7', '98.4', '93.4', '95.9', '59.5', '94.8', '73.1', '86.3', '95.0', '95.2', '93.7', '61.6', '95.8', '62.0', '93.3', '90.8']\n",
      "IoU: ['95.6', '92.9', '64.3', '86.7', '76.3', '78.9', '92.4', '89.2', '86.7', '40.4', '89.1', '68.7', '80.3', '89.3', '85.7', '90.8', '56.9', '92.2', '53.6', '85.7', '77.0']\n",
      "mean IoU: 79.6\n",
      "Epoch: [27] Train  [  0/183]  eta: 0:39:17  lr: 0.000372  loss: 1.8064 (1.8064)  time: 12.8843  data: 0.4729  max mem: 9536\n",
      "Epoch: [27] Train  [ 10/183]  eta: 0:35:37  lr: 0.000370  loss: 1.9483 (2.0571)  time: 12.3583  data: 0.0433  max mem: 9536\n",
      "Epoch: [27] Train  [ 20/183]  eta: 0:33:32  lr: 0.000369  loss: 2.1821 (2.0426)  time: 12.3168  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [ 30/183]  eta: 0:31:21  lr: 0.000368  loss: 2.2129 (2.0401)  time: 12.2623  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [ 40/183]  eta: 0:29:14  lr: 0.000366  loss: 1.6934 (1.9969)  time: 12.1882  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [ 50/183]  eta: 0:27:12  lr: 0.000365  loss: 1.9029 (2.0163)  time: 12.2401  data: 0.0002  max mem: 9536\n",
      "Epoch: [27] Train  [ 60/183]  eta: 0:25:07  lr: 0.000363  loss: 1.9018 (2.0259)  time: 12.2233  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [ 70/183]  eta: 0:23:08  lr: 0.000362  loss: 1.8777 (2.0224)  time: 12.3170  data: 0.0004  max mem: 9536\n",
      "Epoch: [27] Train  [ 80/183]  eta: 0:21:05  lr: 0.000361  loss: 2.0969 (2.0160)  time: 12.3827  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [ 90/183]  eta: 0:19:04  lr: 0.000359  loss: 1.9093 (2.0181)  time: 12.4003  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [100/183]  eta: 0:17:02  lr: 0.000358  loss: 2.1550 (2.0154)  time: 12.4304  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [110/183]  eta: 0:14:58  lr: 0.000356  loss: 1.7861 (2.0104)  time: 12.2750  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [120/183]  eta: 0:12:54  lr: 0.000355  loss: 2.1689 (2.0054)  time: 12.1856  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [130/183]  eta: 0:10:52  lr: 0.000354  loss: 2.3780 (2.0127)  time: 12.2900  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [140/183]  eta: 0:08:49  lr: 0.000352  loss: 2.0147 (2.0139)  time: 12.3864  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [150/183]  eta: 0:06:46  lr: 0.000351  loss: 1.9082 (2.0115)  time: 12.3183  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Train  [160/183]  eta: 0:04:42  lr: 0.000349  loss: 1.7276 (2.0153)  time: 12.2869  data: 0.0005  max mem: 9536\n",
      "Epoch: [27] Train  [170/183]  eta: 0:02:39  lr: 0.000348  loss: 1.9342 (2.0151)  time: 12.3185  data: 0.0005  max mem: 9536\n",
      "Epoch: [27] Train  [180/183]  eta: 0:00:36  lr: 0.000346  loss: 1.9623 (2.0160)  time: 12.3548  data: 0.0004  max mem: 9536\n",
      "Epoch: [27] Train Total time: 0:37:33\n",
      "Epoch: [27] Test  [  0/242]  eta: 0:06:06    time: 1.5127  data: 0.4375  max mem: 9536\n",
      "Epoch: [27] Test  [ 10/242]  eta: 0:03:53    time: 1.0052  data: 0.0400  max mem: 9536\n",
      "Epoch: [27] Test  [ 20/242]  eta: 0:03:35    time: 0.9420  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [ 30/242]  eta: 0:03:31    time: 0.9918  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [ 40/242]  eta: 0:03:23    time: 1.0519  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [ 50/242]  eta: 0:03:15    time: 1.0454  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [ 60/242]  eta: 0:03:07    time: 1.0791  data: 0.0002  max mem: 9536\n",
      "Epoch: [27] Test  [ 70/242]  eta: 0:02:58    time: 1.0905  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [ 80/242]  eta: 0:02:47    time: 1.0327  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [ 90/242]  eta: 0:02:35    time: 0.9820  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [100/242]  eta: 0:02:26    time: 1.0165  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [110/242]  eta: 0:02:15    time: 1.0345  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [120/242]  eta: 0:02:05    time: 1.0475  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [130/242]  eta: 0:01:55    time: 1.0344  data: 0.0002  max mem: 9536\n",
      "Epoch: [27] Test  [140/242]  eta: 0:01:44    time: 0.9865  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [150/242]  eta: 0:01:34    time: 0.9947  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [160/242]  eta: 0:01:23    time: 1.0078  data: 0.0002  max mem: 9536\n",
      "Epoch: [27] Test  [170/242]  eta: 0:01:13    time: 1.0572  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [180/242]  eta: 0:01:04    time: 1.1148  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [190/242]  eta: 0:00:53    time: 1.1197  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [200/242]  eta: 0:00:43    time: 1.0643  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [210/242]  eta: 0:00:33    time: 1.0369  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [220/242]  eta: 0:00:22    time: 1.0462  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [230/242]  eta: 0:00:12    time: 1.0518  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test  [240/242]  eta: 0:00:02    time: 1.0143  data: 0.0003  max mem: 9536\n",
      "Epoch: [27] Test Total time: 0:04:10\n",
      "global correct: 95.5\n",
      "average row correct: ['97.6', '95.8', '83.6', '94.1', '83.9', '90.1', '98.8', '91.6', '96.6', '70.4', '91.9', '77.5', '88.8', '95.7', '92.9', '94.0', '72.6', '96.9', '56.7', '93.4', '91.5']\n",
      "IoU: ['95.4', '92.6', '64.1', '87.8', '77.3', '76.0', '95.0', '88.5', '83.9', '43.4', '88.1', '66.7', '79.4', '88.8', '86.7', '90.5', '63.9', '89.5', '51.8', '86.7', '72.0']\n",
      "mean IoU: 79.4\n",
      "Epoch: [28] Train  [  0/183]  eta: 0:41:19  lr: 0.000346  loss: 2.0026 (2.0026)  time: 13.5517  data: 0.4616  max mem: 9536\n",
      "Epoch: [28] Train  [ 10/183]  eta: 0:36:05  lr: 0.000345  loss: 2.0133 (1.9757)  time: 12.5168  data: 0.0422  max mem: 9536\n",
      "Epoch: [28] Train  [ 20/183]  eta: 0:33:42  lr: 0.000343  loss: 1.9012 (1.9569)  time: 12.3538  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Train  [ 30/183]  eta: 0:31:23  lr: 0.000342  loss: 2.1935 (2.0193)  time: 12.2001  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Train  [ 40/183]  eta: 0:29:16  lr: 0.000340  loss: 1.9082 (2.0002)  time: 12.1492  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Train  [ 50/183]  eta: 0:27:16  lr: 0.000339  loss: 1.9074 (2.0031)  time: 12.2937  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Train  [ 60/183]  eta: 0:25:14  lr: 0.000338  loss: 2.2742 (2.0172)  time: 12.3766  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Train  [ 70/183]  eta: 0:23:11  lr: 0.000336  loss: 1.9545 (2.0021)  time: 12.3329  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Train  [ 80/183]  eta: 0:21:09  lr: 0.000335  loss: 1.8398 (2.0046)  time: 12.3452  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Train  [ 90/183]  eta: 0:19:06  lr: 0.000333  loss: 1.9789 (2.0126)  time: 12.3775  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Train  [100/183]  eta: 0:17:02  lr: 0.000332  loss: 1.8005 (2.0102)  time: 12.3402  data: 0.0004  max mem: 9536\n",
      "Epoch: [28] Train  [110/183]  eta: 0:14:59  lr: 0.000330  loss: 2.2724 (2.0122)  time: 12.3076  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Train  [120/183]  eta: 0:12:56  lr: 0.000329  loss: 2.1123 (2.0109)  time: 12.3336  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Train  [130/183]  eta: 0:10:53  lr: 0.000328  loss: 2.3806 (2.0170)  time: 12.3413  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Train  [140/183]  eta: 0:08:50  lr: 0.000326  loss: 1.7255 (2.0084)  time: 12.3435  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Train  [150/183]  eta: 0:06:46  lr: 0.000325  loss: 1.8544 (2.0027)  time: 12.2666  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Train  [160/183]  eta: 0:04:43  lr: 0.000323  loss: 1.9438 (2.0059)  time: 12.1861  data: 0.0005  max mem: 9536\n",
      "Epoch: [28] Train  [170/183]  eta: 0:02:39  lr: 0.000322  loss: 2.0032 (2.0034)  time: 12.2057  data: 0.0005  max mem: 9536\n",
      "Epoch: [28] Train  [180/183]  eta: 0:00:36  lr: 0.000320  loss: 1.7754 (1.9986)  time: 12.2376  data: 0.0005  max mem: 9536\n",
      "Epoch: [28] Train Total time: 0:37:31\n",
      "Epoch: [28] Test  [  0/242]  eta: 0:06:17    time: 1.5609  data: 0.4860  max mem: 9536\n",
      "Epoch: [28] Test  [ 10/242]  eta: 0:03:53    time: 1.0081  data: 0.0444  max mem: 9536\n",
      "Epoch: [28] Test  [ 20/242]  eta: 0:03:35    time: 0.9412  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Test  [ 30/242]  eta: 0:03:31    time: 0.9918  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [ 40/242]  eta: 0:03:24    time: 1.0514  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [ 50/242]  eta: 0:03:15    time: 1.0452  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [ 60/242]  eta: 0:03:08    time: 1.0813  data: 0.0002  max mem: 9536\n",
      "Epoch: [28] Test  [ 70/242]  eta: 0:02:58    time: 1.0915  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [ 80/242]  eta: 0:02:47    time: 1.0316  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [ 90/242]  eta: 0:02:35    time: 0.9816  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [100/242]  eta: 0:02:26    time: 1.0164  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [110/242]  eta: 0:02:15    time: 1.0336  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [120/242]  eta: 0:02:05    time: 1.0458  data: 0.0006  max mem: 9536\n",
      "Epoch: [28] Test  [130/242]  eta: 0:01:55    time: 1.0319  data: 0.0005  max mem: 9536\n",
      "Epoch: [28] Test  [140/242]  eta: 0:01:44    time: 0.9822  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [150/242]  eta: 0:01:34    time: 0.9909  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [160/242]  eta: 0:01:23    time: 1.0054  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [170/242]  eta: 0:01:13    time: 1.0555  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [180/242]  eta: 0:01:04    time: 1.1140  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [190/242]  eta: 0:00:53    time: 1.1170  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [200/242]  eta: 0:00:43    time: 1.0611  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [210/242]  eta: 0:00:33    time: 1.0338  data: 0.0004  max mem: 9536\n",
      "Epoch: [28] Test  [220/242]  eta: 0:00:22    time: 1.0423  data: 0.0003  max mem: 9536\n",
      "Epoch: [28] Test  [230/242]  eta: 0:00:12    time: 1.0486  data: 0.0004  max mem: 9536\n",
      "Epoch: [28] Test  [240/242]  eta: 0:00:02    time: 1.0112  data: 0.0005  max mem: 9536\n",
      "Epoch: [28] Test Total time: 0:04:09\n",
      "global correct: 95.6\n",
      "average row correct: ['97.9', '96.6', '86.9', '93.0', '90.3', '87.1', '98.8', '92.4', '96.9', '65.9', '95.5', '75.1', '82.8', '94.5', '90.1', '93.3', '65.0', '96.3', '62.5', '93.4', '91.2']\n",
      "IoU: ['95.6', '92.2', '60.4', '88.5', '68.9', '78.5', '93.3', '89.1', '82.7', '42.5', '89.7', '68.9', '77.6', '89.8', '84.9', '90.5', '59.7', '88.1', '53.3', '89.2', '78.1']\n",
      "mean IoU: 79.1\n",
      "Epoch: [29] Train  [  0/183]  eta: 0:39:12  lr: 0.000320  loss: 2.2461 (2.2461)  time: 12.8548  data: 0.4794  max mem: 9536\n",
      "Epoch: [29] Train  [ 10/183]  eta: 0:35:37  lr: 0.000319  loss: 1.9461 (2.0133)  time: 12.3549  data: 0.0439  max mem: 9536\n",
      "Epoch: [29] Train  [ 20/183]  eta: 0:33:42  lr: 0.000317  loss: 1.9384 (1.9673)  time: 12.3866  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Train  [ 30/183]  eta: 0:31:25  lr: 0.000316  loss: 2.0920 (1.9690)  time: 12.3055  data: 0.0004  max mem: 9536\n",
      "Epoch: [29] Train  [ 40/183]  eta: 0:29:27  lr: 0.000314  loss: 1.8556 (1.9506)  time: 12.3024  data: 0.0004  max mem: 9536\n",
      "Epoch: [29] Train  [ 50/183]  eta: 0:27:23  lr: 0.000313  loss: 2.2085 (1.9541)  time: 12.4057  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Train  [ 60/183]  eta: 0:25:18  lr: 0.000311  loss: 1.9747 (1.9761)  time: 12.3196  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Train  [ 70/183]  eta: 0:23:12  lr: 0.000310  loss: 1.9252 (1.9615)  time: 12.2559  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Train  [ 80/183]  eta: 0:21:09  lr: 0.000308  loss: 1.9391 (1.9599)  time: 12.2750  data: 0.0004  max mem: 9536\n",
      "Epoch: [29] Train  [ 90/183]  eta: 0:19:06  lr: 0.000307  loss: 2.1434 (1.9557)  time: 12.3422  data: 0.0004  max mem: 9536\n",
      "Epoch: [29] Train  [100/183]  eta: 0:17:03  lr: 0.000306  loss: 1.9674 (1.9568)  time: 12.3729  data: 0.0004  max mem: 9536\n",
      "Epoch: [29] Train  [110/183]  eta: 0:14:59  lr: 0.000304  loss: 2.0435 (1.9677)  time: 12.2951  data: 0.0004  max mem: 9536\n",
      "Epoch: [29] Train  [120/183]  eta: 0:12:56  lr: 0.000303  loss: 2.3264 (1.9712)  time: 12.2909  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Train  [130/183]  eta: 0:10:53  lr: 0.000301  loss: 1.8040 (1.9677)  time: 12.3964  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Train  [140/183]  eta: 0:08:50  lr: 0.000300  loss: 1.9148 (1.9649)  time: 12.3707  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Train  [150/183]  eta: 0:06:46  lr: 0.000298  loss: 1.7678 (1.9681)  time: 12.3189  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Train  [160/183]  eta: 0:04:43  lr: 0.000297  loss: 1.9402 (1.9683)  time: 12.2993  data: 0.0005  max mem: 9536\n",
      "Epoch: [29] Train  [170/183]  eta: 0:02:40  lr: 0.000296  loss: 2.2292 (1.9647)  time: 12.4041  data: 0.0006  max mem: 9536\n",
      "Epoch: [29] Train  [180/183]  eta: 0:00:37  lr: 0.000294  loss: 2.1608 (1.9657)  time: 12.3866  data: 0.0005  max mem: 9536\n",
      "Epoch: [29] Train Total time: 0:37:38\n",
      "Epoch: [29] Test  [  0/242]  eta: 0:05:58    time: 1.4823  data: 0.4028  max mem: 9536\n",
      "Epoch: [29] Test  [ 10/242]  eta: 0:03:51    time: 0.9998  data: 0.0369  max mem: 9536\n",
      "Epoch: [29] Test  [ 20/242]  eta: 0:03:34    time: 0.9404  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [ 30/242]  eta: 0:03:30    time: 0.9907  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [ 40/242]  eta: 0:03:23    time: 1.0515  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [ 50/242]  eta: 0:03:14    time: 1.0452  data: 0.0002  max mem: 9536\n",
      "Epoch: [29] Test  [ 60/242]  eta: 0:03:07    time: 1.0791  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [ 70/242]  eta: 0:02:58    time: 1.0899  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [ 80/242]  eta: 0:02:47    time: 1.0325  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [ 90/242]  eta: 0:02:35    time: 0.9817  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [100/242]  eta: 0:02:26    time: 1.0154  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [110/242]  eta: 0:02:15    time: 1.0344  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [120/242]  eta: 0:02:05    time: 1.0471  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [130/242]  eta: 0:01:55    time: 1.0349  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [140/242]  eta: 0:01:44    time: 0.9839  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [150/242]  eta: 0:01:34    time: 0.9908  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [160/242]  eta: 0:01:23    time: 1.0062  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [170/242]  eta: 0:01:13    time: 1.0571  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [180/242]  eta: 0:01:04    time: 1.1157  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [190/242]  eta: 0:00:53    time: 1.1186  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [200/242]  eta: 0:00:43    time: 1.0648  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [210/242]  eta: 0:00:33    time: 1.0363  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [220/242]  eta: 0:00:22    time: 1.0441  data: 0.0003  max mem: 9536\n",
      "Epoch: [29] Test  [230/242]  eta: 0:00:12    time: 1.0517  data: 0.0004  max mem: 9536\n",
      "Epoch: [29] Test  [240/242]  eta: 0:00:02    time: 1.0148  data: 0.0004  max mem: 9536\n",
      "Epoch: [29] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['98.1', '96.1', '84.7', '93.9', '87.8', '89.0', '97.2', '91.7', '97.8', '63.7', '93.0', '67.9', '84.4', '95.2', '92.0', '93.9', '69.9', '95.9', '57.3', '93.8', '90.0']\n",
      "IoU: ['95.5', '93.1', '61.6', '88.6', '76.8', '77.6', '94.5', '89.0', '83.4', '43.9', '89.2', '63.1', '78.4', '89.1', '85.9', '90.3', '61.7', '91.5', '52.4', '87.4', '77.3']\n",
      "mean IoU: 79.5\n",
      "Epoch: [30] Train  [  0/183]  eta: 0:39:29  lr: 0.000294  loss: 1.9363 (1.9363)  time: 12.9505  data: 0.3845  max mem: 9536\n",
      "Epoch: [30] Train  [ 10/183]  eta: 0:35:46  lr: 0.000292  loss: 1.7547 (1.9241)  time: 12.4097  data: 0.0355  max mem: 9536\n",
      "Epoch: [30] Train  [ 20/183]  eta: 0:33:32  lr: 0.000291  loss: 1.8311 (1.9203)  time: 12.3170  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Train  [ 30/183]  eta: 0:31:31  lr: 0.000289  loss: 1.8751 (1.9188)  time: 12.3374  data: 0.0002  max mem: 9536\n",
      "Epoch: [30] Train  [ 40/183]  eta: 0:29:27  lr: 0.000288  loss: 1.9213 (1.9271)  time: 12.3766  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Train  [ 50/183]  eta: 0:27:22  lr: 0.000286  loss: 2.1576 (1.9232)  time: 12.3278  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Train  [ 60/183]  eta: 0:25:17  lr: 0.000285  loss: 1.9779 (1.9157)  time: 12.2920  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Train  [ 70/183]  eta: 0:23:14  lr: 0.000284  loss: 1.6565 (1.8992)  time: 12.3200  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Train  [ 80/183]  eta: 0:21:10  lr: 0.000282  loss: 1.9402 (1.8980)  time: 12.3051  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Train  [ 90/183]  eta: 0:19:06  lr: 0.000281  loss: 2.2609 (1.8954)  time: 12.2739  data: 0.0002  max mem: 9536\n",
      "Epoch: [30] Train  [100/183]  eta: 0:17:03  lr: 0.000279  loss: 1.7857 (1.8930)  time: 12.3382  data: 0.0002  max mem: 9536\n",
      "Epoch: [30] Train  [110/183]  eta: 0:15:01  lr: 0.000278  loss: 1.8228 (1.8922)  time: 12.4441  data: 0.0002  max mem: 9536\n",
      "Epoch: [30] Train  [120/183]  eta: 0:12:57  lr: 0.000276  loss: 1.9398 (1.8933)  time: 12.4083  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Train  [130/183]  eta: 0:10:53  lr: 0.000275  loss: 1.9610 (1.8938)  time: 12.2814  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Train  [140/183]  eta: 0:08:50  lr: 0.000273  loss: 2.2066 (1.8949)  time: 12.2829  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Train  [150/183]  eta: 0:06:47  lr: 0.000272  loss: 2.0287 (1.8940)  time: 12.3918  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Train  [160/183]  eta: 0:04:43  lr: 0.000270  loss: 1.7983 (1.8903)  time: 12.3924  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Train  [170/183]  eta: 0:02:40  lr: 0.000269  loss: 1.9046 (1.8883)  time: 12.3812  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Train  [180/183]  eta: 0:00:37  lr: 0.000268  loss: 1.9902 (1.8878)  time: 12.4063  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Train Total time: 0:37:40\n",
      "Epoch: [30] Test  [  0/242]  eta: 0:05:51    time: 1.4514  data: 0.3838  max mem: 9536\n",
      "Epoch: [30] Test  [ 10/242]  eta: 0:03:51    time: 0.9994  data: 0.0351  max mem: 9536\n",
      "Epoch: [30] Test  [ 20/242]  eta: 0:03:34    time: 0.9415  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [ 30/242]  eta: 0:03:30    time: 0.9910  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [ 40/242]  eta: 0:03:23    time: 1.0524  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [ 50/242]  eta: 0:03:14    time: 1.0460  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [ 60/242]  eta: 0:03:07    time: 1.0782  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [ 70/242]  eta: 0:02:58    time: 1.0886  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [ 80/242]  eta: 0:02:47    time: 1.0311  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Test  [ 90/242]  eta: 0:02:35    time: 0.9788  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Test  [100/242]  eta: 0:02:25    time: 1.0138  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Test  [110/242]  eta: 0:02:15    time: 1.0335  data: 0.0004  max mem: 9536\n",
      "Epoch: [30] Test  [120/242]  eta: 0:02:05    time: 1.0463  data: 0.0006  max mem: 9536\n",
      "Epoch: [30] Test  [130/242]  eta: 0:01:54    time: 1.0338  data: 0.0005  max mem: 9536\n",
      "Epoch: [30] Test  [140/242]  eta: 0:01:44    time: 0.9832  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [150/242]  eta: 0:01:33    time: 0.9927  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [160/242]  eta: 0:01:23    time: 1.0074  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [170/242]  eta: 0:01:13    time: 1.0546  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [180/242]  eta: 0:01:03    time: 1.1136  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [190/242]  eta: 0:00:53    time: 1.1174  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [200/242]  eta: 0:00:43    time: 1.0625  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [210/242]  eta: 0:00:33    time: 1.0366  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [220/242]  eta: 0:00:22    time: 1.0468  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [230/242]  eta: 0:00:12    time: 1.0531  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test  [240/242]  eta: 0:00:02    time: 1.0147  data: 0.0003  max mem: 9536\n",
      "Epoch: [30] Test Total time: 0:04:09\n",
      "global correct: 95.5\n",
      "average row correct: ['97.4', '96.9', '86.4', '95.2', '90.8', '87.2', '98.6', '93.2', '97.2', '66.2', '95.5', '69.6', '89.6', '88.8', '95.1', '93.8', '76.6', '96.1', '62.1', '96.2', '91.4']\n",
      "IoU: ['95.3', '90.5', '61.0', '88.4', '68.1', '78.1', '93.2', '89.8', '88.3', '41.8', '87.5', '64.8', '83.3', '85.1', '87.2', '90.5', '64.9', '91.2', '51.4', '89.5', '69.9']\n",
      "mean IoU: 79.0\n",
      "Epoch: [31] Train  [  0/183]  eta: 0:39:20  lr: 0.000267  loss: 2.0315 (2.0315)  time: 12.8987  data: 0.5392  max mem: 9536\n",
      "Epoch: [31] Train  [ 10/183]  eta: 0:35:50  lr: 0.000266  loss: 1.7431 (1.9729)  time: 12.4299  data: 0.0493  max mem: 9536\n",
      "Epoch: [31] Train  [ 20/183]  eta: 0:33:20  lr: 0.000264  loss: 1.8103 (1.9620)  time: 12.2425  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [ 30/183]  eta: 0:31:16  lr: 0.000263  loss: 1.8019 (1.9497)  time: 12.1738  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [ 40/183]  eta: 0:29:15  lr: 0.000261  loss: 2.0961 (1.9386)  time: 12.2774  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [ 50/183]  eta: 0:27:14  lr: 0.000260  loss: 1.8327 (1.9280)  time: 12.3271  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [ 60/183]  eta: 0:25:12  lr: 0.000258  loss: 1.5252 (1.9089)  time: 12.3288  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [ 70/183]  eta: 0:23:11  lr: 0.000257  loss: 1.8712 (1.9057)  time: 12.3875  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [ 80/183]  eta: 0:21:07  lr: 0.000255  loss: 1.8409 (1.9102)  time: 12.3288  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [ 90/183]  eta: 0:19:04  lr: 0.000254  loss: 2.0789 (1.9026)  time: 12.2829  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Train  [100/183]  eta: 0:17:01  lr: 0.000252  loss: 2.0084 (1.8999)  time: 12.3416  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Train  [110/183]  eta: 0:14:57  lr: 0.000251  loss: 1.7373 (1.8898)  time: 12.2291  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [120/183]  eta: 0:12:54  lr: 0.000249  loss: 1.8211 (1.8834)  time: 12.2216  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Train  [130/183]  eta: 0:10:51  lr: 0.000248  loss: 1.9965 (1.8794)  time: 12.3146  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Train  [140/183]  eta: 0:08:49  lr: 0.000247  loss: 1.9218 (1.8785)  time: 12.3574  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [150/183]  eta: 0:06:45  lr: 0.000245  loss: 1.9421 (1.8801)  time: 12.2001  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [160/183]  eta: 0:04:42  lr: 0.000244  loss: 1.8670 (1.8839)  time: 12.0792  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Train  [170/183]  eta: 0:02:39  lr: 0.000242  loss: 1.9492 (1.8836)  time: 12.1923  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Train  [180/183]  eta: 0:00:36  lr: 0.000241  loss: 2.0490 (1.8906)  time: 12.3108  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Train Total time: 0:37:27\n",
      "Epoch: [31] Test  [  0/242]  eta: 0:05:53    time: 1.4608  data: 0.3857  max mem: 9536\n",
      "Epoch: [31] Test  [ 10/242]  eta: 0:03:51    time: 0.9986  data: 0.0356  max mem: 9536\n",
      "Epoch: [31] Test  [ 20/242]  eta: 0:03:34    time: 0.9414  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Test  [ 30/242]  eta: 0:03:31    time: 0.9943  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [ 40/242]  eta: 0:03:23    time: 1.0554  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [ 50/242]  eta: 0:03:15    time: 1.0485  data: 0.0002  max mem: 9536\n",
      "Epoch: [31] Test  [ 60/242]  eta: 0:03:08    time: 1.0821  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [ 70/242]  eta: 0:02:58    time: 1.0931  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [ 80/242]  eta: 0:02:47    time: 1.0353  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [ 90/242]  eta: 0:02:35    time: 0.9829  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [100/242]  eta: 0:02:26    time: 1.0177  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Test  [110/242]  eta: 0:02:15    time: 1.0367  data: 0.0004  max mem: 9536\n",
      "Epoch: [31] Test  [120/242]  eta: 0:02:06    time: 1.0501  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [130/242]  eta: 0:01:55    time: 1.0360  data: 0.0002  max mem: 9536\n",
      "Epoch: [31] Test  [140/242]  eta: 0:01:44    time: 0.9835  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [150/242]  eta: 0:01:34    time: 0.9914  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [160/242]  eta: 0:01:23    time: 1.0063  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [170/242]  eta: 0:01:14    time: 1.0563  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [180/242]  eta: 0:01:04    time: 1.1180  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [190/242]  eta: 0:00:53    time: 1.1201  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [200/242]  eta: 0:00:43    time: 1.0632  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [210/242]  eta: 0:00:33    time: 1.0377  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [220/242]  eta: 0:00:22    time: 1.0463  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [230/242]  eta: 0:00:12    time: 1.0533  data: 0.0003  max mem: 9536\n",
      "Epoch: [31] Test  [240/242]  eta: 0:00:02    time: 1.0154  data: 0.0002  max mem: 9536\n",
      "Epoch: [31] Test Total time: 0:04:10\n",
      "global correct: 95.3\n",
      "average row correct: ['97.2', '97.0', '87.5', '96.0', '91.3', '89.9', '98.3', '92.7', '97.3', '71.3', '90.1', '75.3', '86.9', '97.3', '95.1', '93.3', '72.0', '96.2', '60.0', '96.4', '90.8']\n",
      "IoU: ['95.2', '91.4', '61.9', '87.6', '69.3', '77.2', '94.4', '89.6', '84.1', '39.8', '87.2', '68.3', '77.4', '89.4', '87.2', '90.4', '64.5', '90.8', '49.8', '89.5', '71.0']\n",
      "mean IoU: 78.9\n",
      "Epoch: [32] Train  [  0/183]  eta: 0:38:32  lr: 0.000240  loss: 1.8903 (1.8903)  time: 12.6345  data: 0.3948  max mem: 9536\n",
      "Epoch: [32] Train  [ 10/183]  eta: 0:35:22  lr: 0.000239  loss: 1.9772 (2.0733)  time: 12.2668  data: 0.0362  max mem: 9536\n",
      "Epoch: [32] Train  [ 20/183]  eta: 0:33:23  lr: 0.000237  loss: 1.8941 (1.9514)  time: 12.2764  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [ 30/183]  eta: 0:31:17  lr: 0.000236  loss: 1.8179 (1.9355)  time: 12.2716  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [ 40/183]  eta: 0:29:17  lr: 0.000234  loss: 1.7792 (1.9257)  time: 12.2927  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [ 50/183]  eta: 0:27:13  lr: 0.000233  loss: 1.8733 (1.9072)  time: 12.3046  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [ 60/183]  eta: 0:25:08  lr: 0.000231  loss: 2.0971 (1.9100)  time: 12.1942  data: 0.0005  max mem: 9536\n",
      "Epoch: [32] Train  [ 70/183]  eta: 0:23:04  lr: 0.000230  loss: 1.8896 (1.9008)  time: 12.1726  data: 0.0006  max mem: 9536\n",
      "Epoch: [32] Train  [ 80/183]  eta: 0:21:03  lr: 0.000228  loss: 1.8268 (1.8943)  time: 12.2822  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Train  [ 90/183]  eta: 0:19:00  lr: 0.000227  loss: 1.7902 (1.8796)  time: 12.3071  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [100/183]  eta: 0:16:59  lr: 0.000225  loss: 1.7782 (1.8820)  time: 12.3461  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [110/183]  eta: 0:14:56  lr: 0.000224  loss: 2.1428 (1.8755)  time: 12.3795  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Train  [120/183]  eta: 0:12:54  lr: 0.000222  loss: 1.8840 (1.8717)  time: 12.3229  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [130/183]  eta: 0:10:50  lr: 0.000221  loss: 1.7286 (1.8758)  time: 12.2678  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [140/183]  eta: 0:08:47  lr: 0.000219  loss: 2.1848 (1.8790)  time: 12.2121  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Train  [150/183]  eta: 0:06:45  lr: 0.000218  loss: 1.6912 (1.8779)  time: 12.2335  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Train  [160/183]  eta: 0:04:42  lr: 0.000216  loss: 2.0165 (1.8725)  time: 12.1883  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Train  [170/183]  eta: 0:02:39  lr: 0.000215  loss: 1.6317 (1.8660)  time: 12.1946  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Train  [180/183]  eta: 0:00:36  lr: 0.000213  loss: 1.7908 (1.8647)  time: 12.2413  data: 0.0005  max mem: 9536\n",
      "Epoch: [32] Train Total time: 0:37:23\n",
      "Epoch: [32] Test  [  0/242]  eta: 0:05:57    time: 1.4767  data: 0.4124  max mem: 9536\n",
      "Epoch: [32] Test  [ 10/242]  eta: 0:03:51    time: 0.9979  data: 0.0377  max mem: 9536\n",
      "Epoch: [32] Test  [ 20/242]  eta: 0:03:34    time: 0.9414  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Test  [ 30/242]  eta: 0:03:31    time: 0.9942  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Test  [ 40/242]  eta: 0:03:23    time: 1.0540  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [ 50/242]  eta: 0:03:15    time: 1.0474  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Test  [ 60/242]  eta: 0:03:07    time: 1.0807  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Test  [ 70/242]  eta: 0:02:58    time: 1.0908  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [ 80/242]  eta: 0:02:47    time: 1.0352  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [ 90/242]  eta: 0:02:35    time: 0.9848  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [100/242]  eta: 0:02:26    time: 1.0157  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [110/242]  eta: 0:02:15    time: 1.0327  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [120/242]  eta: 0:02:05    time: 1.0458  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [130/242]  eta: 0:01:55    time: 1.0336  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [140/242]  eta: 0:01:44    time: 0.9830  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Test  [150/242]  eta: 0:01:34    time: 0.9909  data: 0.0004  max mem: 9536\n",
      "Epoch: [32] Test  [160/242]  eta: 0:01:23    time: 1.0063  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [170/242]  eta: 0:01:13    time: 1.0549  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [180/242]  eta: 0:01:04    time: 1.1134  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [190/242]  eta: 0:00:53    time: 1.1192  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [200/242]  eta: 0:00:43    time: 1.0653  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [210/242]  eta: 0:00:33    time: 1.0370  data: 0.0002  max mem: 9536\n",
      "Epoch: [32] Test  [220/242]  eta: 0:00:22    time: 1.0445  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [230/242]  eta: 0:00:12    time: 1.0510  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test  [240/242]  eta: 0:00:02    time: 1.0132  data: 0.0003  max mem: 9536\n",
      "Epoch: [32] Test Total time: 0:04:10\n",
      "global correct: 95.4\n",
      "average row correct: ['97.5', '95.5', '85.8', '93.9', '90.8', '89.1', '98.4', '93.3', '97.2', '69.8', '92.7', '72.0', '86.6', '97.2', '93.9', '94.4', '63.9', '96.3', '60.1', '96.0', '91.3']\n",
      "IoU: ['95.3', '92.8', '61.8', '88.8', '75.8', '77.6', '95.8', '90.0', '84.4', '37.9', '89.2', '66.9', '80.3', '89.1', '86.1', '90.6', '59.3', '91.2', '48.8', '89.8', '76.3']\n",
      "mean IoU: 79.4\n",
      "Epoch: [33] Train  [  0/183]  eta: 0:38:28  lr: 0.000213  loss: 1.6824 (1.6824)  time: 12.6169  data: 0.4516  max mem: 9536\n",
      "Epoch: [33] Train  [ 10/183]  eta: 0:35:33  lr: 0.000211  loss: 1.6765 (1.8278)  time: 12.3344  data: 0.0413  max mem: 9536\n",
      "Epoch: [33] Train  [ 20/183]  eta: 0:33:32  lr: 0.000210  loss: 2.0081 (1.8758)  time: 12.3362  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Train  [ 30/183]  eta: 0:31:11  lr: 0.000208  loss: 1.7168 (1.8651)  time: 12.1733  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Train  [ 40/183]  eta: 0:29:12  lr: 0.000207  loss: 1.8421 (1.8629)  time: 12.1516  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Train  [ 50/183]  eta: 0:27:10  lr: 0.000205  loss: 1.9591 (1.8714)  time: 12.3072  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Train  [ 60/183]  eta: 0:25:09  lr: 0.000204  loss: 1.8258 (1.8660)  time: 12.3207  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Train  [ 70/183]  eta: 0:23:05  lr: 0.000202  loss: 1.8482 (1.8628)  time: 12.2759  data: 0.0006  max mem: 9536\n",
      "Epoch: [33] Train  [ 80/183]  eta: 0:21:03  lr: 0.000201  loss: 1.7590 (1.8607)  time: 12.2390  data: 0.0005  max mem: 9536\n",
      "Epoch: [33] Train  [ 90/183]  eta: 0:19:00  lr: 0.000199  loss: 1.6663 (1.8490)  time: 12.2650  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Train  [100/183]  eta: 0:16:59  lr: 0.000198  loss: 1.8081 (1.8465)  time: 12.3242  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Train  [110/183]  eta: 0:14:55  lr: 0.000196  loss: 1.8384 (1.8447)  time: 12.2889  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Train  [120/183]  eta: 0:12:52  lr: 0.000195  loss: 1.8443 (1.8517)  time: 12.1672  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Train  [130/183]  eta: 0:10:49  lr: 0.000193  loss: 1.9977 (1.8469)  time: 12.1359  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Train  [140/183]  eta: 0:08:46  lr: 0.000192  loss: 1.5589 (1.8355)  time: 12.0731  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Train  [150/183]  eta: 0:06:43  lr: 0.000190  loss: 1.8288 (1.8380)  time: 12.1727  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Train  [160/183]  eta: 0:04:41  lr: 0.000189  loss: 1.6545 (1.8327)  time: 12.3043  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Train  [170/183]  eta: 0:02:39  lr: 0.000187  loss: 1.7763 (1.8332)  time: 12.2789  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Train  [180/183]  eta: 0:00:36  lr: 0.000186  loss: 1.7089 (1.8383)  time: 12.1796  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Train Total time: 0:37:18\n",
      "Epoch: [33] Test  [  0/242]  eta: 0:06:00    time: 1.4887  data: 0.4191  max mem: 9536\n",
      "Epoch: [33] Test  [ 10/242]  eta: 0:03:52    time: 1.0016  data: 0.0384  max mem: 9536\n",
      "Epoch: [33] Test  [ 20/242]  eta: 0:03:34    time: 0.9424  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [ 30/242]  eta: 0:03:31    time: 0.9944  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [ 40/242]  eta: 0:03:24    time: 1.0550  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [ 50/242]  eta: 0:03:15    time: 1.0474  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [ 60/242]  eta: 0:03:08    time: 1.0796  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [ 70/242]  eta: 0:02:58    time: 1.0913  data: 0.0002  max mem: 9536\n",
      "Epoch: [33] Test  [ 80/242]  eta: 0:02:47    time: 1.0342  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [ 90/242]  eta: 0:02:35    time: 0.9813  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [100/242]  eta: 0:02:26    time: 1.0145  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [110/242]  eta: 0:02:15    time: 1.0340  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [120/242]  eta: 0:02:05    time: 1.0479  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [130/242]  eta: 0:01:55    time: 1.0342  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [140/242]  eta: 0:01:44    time: 0.9843  data: 0.0006  max mem: 9536\n",
      "Epoch: [33] Test  [150/242]  eta: 0:01:34    time: 0.9931  data: 0.0006  max mem: 9536\n",
      "Epoch: [33] Test  [160/242]  eta: 0:01:23    time: 1.0066  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [170/242]  eta: 0:01:13    time: 1.0563  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Test  [180/242]  eta: 0:01:04    time: 1.1150  data: 0.0004  max mem: 9536\n",
      "Epoch: [33] Test  [190/242]  eta: 0:00:53    time: 1.1171  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [200/242]  eta: 0:00:43    time: 1.0615  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [210/242]  eta: 0:00:33    time: 1.0341  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [220/242]  eta: 0:00:22    time: 1.0448  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [230/242]  eta: 0:00:12    time: 1.0522  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test  [240/242]  eta: 0:00:02    time: 1.0127  data: 0.0003  max mem: 9536\n",
      "Epoch: [33] Test Total time: 0:04:10\n",
      "global correct: 95.7\n",
      "average row correct: ['98.3', '94.2', '82.1', '92.3', '90.8', '87.5', '98.3', '93.6', '97.9', '62.2', '94.7', '72.3', '83.2', '95.0', '94.3', '93.2', '62.9', '96.5', '59.0', '93.6', '89.7']\n",
      "IoU: ['95.7', '92.3', '65.7', '88.9', '76.7', '78.0', '95.6', '90.0', '84.0', '41.0', '90.1', '67.1', '79.3', '90.3', '87.7', '90.5', '59.0', '90.0', '52.3', '87.4', '81.3']\n",
      "mean IoU: 80.1\n",
      "Epoch: [34] Train  [  0/183]  eta: 0:39:06  lr: 0.000185  loss: 2.0251 (2.0251)  time: 12.8223  data: 0.4361  max mem: 9536\n",
      "Epoch: [34] Train  [ 10/183]  eta: 0:35:15  lr: 0.000184  loss: 1.8161 (1.8090)  time: 12.2277  data: 0.0398  max mem: 9536\n",
      "Epoch: [34] Train  [ 20/183]  eta: 0:33:06  lr: 0.000182  loss: 1.6834 (1.8065)  time: 12.1537  data: 0.0002  max mem: 9536\n",
      "Epoch: [34] Train  [ 30/183]  eta: 0:31:02  lr: 0.000181  loss: 2.0281 (1.8183)  time: 12.1475  data: 0.0004  max mem: 9536\n",
      "Epoch: [34] Train  [ 40/183]  eta: 0:29:04  lr: 0.000179  loss: 1.8407 (1.8071)  time: 12.2178  data: 0.0004  max mem: 9536\n",
      "Epoch: [34] Train  [ 50/183]  eta: 0:26:57  lr: 0.000178  loss: 1.6147 (1.7995)  time: 12.1446  data: 0.0002  max mem: 9536\n",
      "Epoch: [34] Train  [ 60/183]  eta: 0:24:58  lr: 0.000176  loss: 1.7032 (1.7872)  time: 12.1462  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Train  [ 70/183]  eta: 0:22:58  lr: 0.000175  loss: 1.6306 (1.7867)  time: 12.2814  data: 0.0004  max mem: 9536\n",
      "Epoch: [34] Train  [ 80/183]  eta: 0:20:57  lr: 0.000173  loss: 1.8007 (1.7981)  time: 12.2774  data: 0.0005  max mem: 9536\n",
      "Epoch: [34] Train  [ 90/183]  eta: 0:18:55  lr: 0.000172  loss: 1.6252 (1.7995)  time: 12.2746  data: 0.0005  max mem: 9536\n",
      "Epoch: [34] Train  [100/183]  eta: 0:16:53  lr: 0.000170  loss: 2.1758 (1.8012)  time: 12.2457  data: 0.0005  max mem: 9536\n",
      "Epoch: [34] Train  [110/183]  eta: 0:14:52  lr: 0.000169  loss: 1.5675 (1.7936)  time: 12.3082  data: 0.0006  max mem: 9536\n",
      "Epoch: [34] Train  [120/183]  eta: 0:12:49  lr: 0.000167  loss: 1.7830 (1.7943)  time: 12.1876  data: 0.0005  max mem: 9536\n",
      "Epoch: [34] Train  [130/183]  eta: 0:10:47  lr: 0.000165  loss: 1.9348 (1.7950)  time: 12.1128  data: 0.0004  max mem: 9536\n",
      "Epoch: [34] Train  [140/183]  eta: 0:08:45  lr: 0.000164  loss: 1.9009 (1.7977)  time: 12.2735  data: 0.0004  max mem: 9536\n",
      "Epoch: [34] Train  [150/183]  eta: 0:06:43  lr: 0.000162  loss: 1.8332 (1.7963)  time: 12.2925  data: 0.0005  max mem: 9536\n",
      "Epoch: [34] Train  [160/183]  eta: 0:04:40  lr: 0.000161  loss: 1.8994 (1.7970)  time: 12.0735  data: 0.0005  max mem: 9536\n",
      "Epoch: [34] Train  [170/183]  eta: 0:02:38  lr: 0.000159  loss: 1.7032 (1.7968)  time: 12.0496  data: 0.0005  max mem: 9536\n",
      "Epoch: [34] Train  [180/183]  eta: 0:00:36  lr: 0.000158  loss: 1.8249 (1.7981)  time: 12.1507  data: 0.0004  max mem: 9536\n",
      "Epoch: [34] Train Total time: 0:37:11\n",
      "Epoch: [34] Test  [  0/242]  eta: 0:06:02    time: 1.4983  data: 0.4186  max mem: 9536\n",
      "Epoch: [34] Test  [ 10/242]  eta: 0:03:52    time: 1.0019  data: 0.0384  max mem: 9536\n",
      "Epoch: [34] Test  [ 20/242]  eta: 0:03:34    time: 0.9417  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [ 30/242]  eta: 0:03:31    time: 0.9928  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [ 40/242]  eta: 0:03:24    time: 1.0550  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [ 50/242]  eta: 0:03:15    time: 1.0505  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [ 60/242]  eta: 0:03:08    time: 1.0832  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [ 70/242]  eta: 0:02:58    time: 1.0918  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [ 80/242]  eta: 0:02:47    time: 1.0324  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [ 90/242]  eta: 0:02:35    time: 0.9806  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [100/242]  eta: 0:02:26    time: 1.0137  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [110/242]  eta: 0:02:15    time: 1.0333  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [120/242]  eta: 0:02:06    time: 1.0487  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [130/242]  eta: 0:01:55    time: 1.0356  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [140/242]  eta: 0:01:44    time: 0.9841  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [150/242]  eta: 0:01:34    time: 0.9933  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [160/242]  eta: 0:01:23    time: 1.0076  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [170/242]  eta: 0:01:13    time: 1.0559  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [180/242]  eta: 0:01:04    time: 1.1136  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [190/242]  eta: 0:00:53    time: 1.1162  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [200/242]  eta: 0:00:43    time: 1.0629  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [210/242]  eta: 0:00:33    time: 1.0348  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [220/242]  eta: 0:00:22    time: 1.0423  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [230/242]  eta: 0:00:12    time: 1.0500  data: 0.0003  max mem: 9536\n",
      "Epoch: [34] Test  [240/242]  eta: 0:00:02    time: 1.0126  data: 0.0004  max mem: 9536\n",
      "Epoch: [34] Test Total time: 0:04:10\n",
      "global correct: 95.6\n",
      "average row correct: ['98.1', '95.5', '83.7', '94.2', '89.5', '84.4', '98.6', '92.8', '97.4', '62.8', '95.8', '70.1', '85.4', '89.0', '93.2', '94.0', '66.1', '96.6', '60.4', '92.5', '87.7']\n",
      "IoU: ['95.6', '92.9', '63.8', '89.2', '78.3', '77.8', '95.5', '89.4', '84.5', '39.9', '86.9', '64.9', '79.4', '85.4', '87.7', '90.4', '60.7', '89.1', '51.8', '89.0', '80.0']\n",
      "mean IoU: 79.6\n",
      "Epoch: [35] Train  [  0/183]  eta: 0:40:12  lr: 0.000157  loss: 1.8557 (1.8557)  time: 13.1830  data: 0.4398  max mem: 9536\n",
      "Epoch: [35] Train  [ 10/183]  eta: 0:35:45  lr: 0.000156  loss: 1.6673 (1.8071)  time: 12.4013  data: 0.0403  max mem: 9536\n",
      "Epoch: [35] Train  [ 20/183]  eta: 0:33:08  lr: 0.000154  loss: 1.7644 (1.8032)  time: 12.1523  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [ 30/183]  eta: 0:31:10  lr: 0.000153  loss: 1.8947 (1.8005)  time: 12.1283  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [ 40/183]  eta: 0:29:15  lr: 0.000151  loss: 1.6083 (1.7978)  time: 12.3503  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [ 50/183]  eta: 0:27:10  lr: 0.000150  loss: 1.5658 (1.7964)  time: 12.3086  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [ 60/183]  eta: 0:25:07  lr: 0.000148  loss: 1.6031 (1.7918)  time: 12.2073  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [ 70/183]  eta: 0:23:02  lr: 0.000146  loss: 1.7514 (1.7908)  time: 12.1853  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [ 80/183]  eta: 0:21:00  lr: 0.000145  loss: 1.7177 (1.8026)  time: 12.1803  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [ 90/183]  eta: 0:18:58  lr: 0.000143  loss: 2.0382 (1.8008)  time: 12.2739  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [100/183]  eta: 0:16:56  lr: 0.000142  loss: 1.6748 (1.8072)  time: 12.3018  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Train  [110/183]  eta: 0:14:55  lr: 0.000140  loss: 1.7140 (1.8059)  time: 12.3279  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Train  [120/183]  eta: 0:12:52  lr: 0.000139  loss: 1.8919 (1.8067)  time: 12.3713  data: 0.0005  max mem: 9536\n",
      "Epoch: [35] Train  [130/183]  eta: 0:10:48  lr: 0.000137  loss: 1.5391 (1.8049)  time: 12.1556  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [140/183]  eta: 0:08:46  lr: 0.000135  loss: 2.8526 (1.8166)  time: 12.0313  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [150/183]  eta: 0:06:43  lr: 0.000134  loss: 1.7846 (1.8184)  time: 12.1788  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [160/183]  eta: 0:04:41  lr: 0.000132  loss: 2.0875 (1.8166)  time: 12.3065  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Train  [170/183]  eta: 0:02:39  lr: 0.000131  loss: 1.6317 (1.8107)  time: 12.2320  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Train  [180/183]  eta: 0:00:36  lr: 0.000129  loss: 2.1304 (1.8118)  time: 12.1244  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Train Total time: 0:37:18\n",
      "Epoch: [35] Test  [  0/242]  eta: 0:06:02    time: 1.4985  data: 0.4317  max mem: 9536\n",
      "Epoch: [35] Test  [ 10/242]  eta: 0:03:52    time: 1.0031  data: 0.0395  max mem: 9536\n",
      "Epoch: [35] Test  [ 20/242]  eta: 0:03:35    time: 0.9420  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Test  [ 30/242]  eta: 0:03:31    time: 0.9934  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Test  [ 40/242]  eta: 0:03:23    time: 1.0531  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Test  [ 50/242]  eta: 0:03:15    time: 1.0454  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Test  [ 60/242]  eta: 0:03:07    time: 1.0799  data: 0.0005  max mem: 9536\n",
      "Epoch: [35] Test  [ 70/242]  eta: 0:02:58    time: 1.0901  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [ 80/242]  eta: 0:02:47    time: 1.0310  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [ 90/242]  eta: 0:02:35    time: 0.9815  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [100/242]  eta: 0:02:26    time: 1.0170  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [110/242]  eta: 0:02:15    time: 1.0341  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [120/242]  eta: 0:02:05    time: 1.0454  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [130/242]  eta: 0:01:55    time: 1.0326  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [140/242]  eta: 0:01:44    time: 0.9847  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [150/242]  eta: 0:01:34    time: 0.9943  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [160/242]  eta: 0:01:23    time: 1.0079  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [170/242]  eta: 0:01:13    time: 1.0583  data: 0.0005  max mem: 9536\n",
      "Epoch: [35] Test  [180/242]  eta: 0:01:04    time: 1.1189  data: 0.0005  max mem: 9536\n",
      "Epoch: [35] Test  [190/242]  eta: 0:00:53    time: 1.1209  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [200/242]  eta: 0:00:43    time: 1.0635  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [210/242]  eta: 0:00:33    time: 1.0358  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [220/242]  eta: 0:00:22    time: 1.0439  data: 0.0003  max mem: 9536\n",
      "Epoch: [35] Test  [230/242]  eta: 0:00:12    time: 1.0506  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test  [240/242]  eta: 0:00:02    time: 1.0131  data: 0.0004  max mem: 9536\n",
      "Epoch: [35] Test Total time: 0:04:10\n",
      "global correct: 95.5\n",
      "average row correct: ['97.7', '96.4', '85.8', '93.9', '85.9', '85.9', '98.6', '93.6', '97.8', '64.5', '93.1', '70.7', '85.3', '95.4', '92.9', '94.0', '67.1', '95.5', '64.6', '95.9', '91.5']\n",
      "IoU: ['95.4', '92.8', '64.6', '88.4', '77.6', '76.9', '94.8', '89.7', '84.2', '39.9', '89.3', '65.1', '79.6', '88.6', '86.6', '90.3', '60.7', '91.9', '52.0', '89.5', '76.5']\n",
      "mean IoU: 79.7\n",
      "Epoch: [36] Train  [  0/183]  eta: 0:39:00  lr: 0.000129  loss: 1.6970 (1.6970)  time: 12.7894  data: 0.4302  max mem: 9536\n",
      "Epoch: [36] Train  [ 10/183]  eta: 0:35:33  lr: 0.000127  loss: 2.1613 (1.8208)  time: 12.3296  data: 0.0394  max mem: 9536\n",
      "Epoch: [36] Train  [ 20/183]  eta: 0:33:21  lr: 0.000125  loss: 1.6583 (1.8159)  time: 12.2564  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Train  [ 30/183]  eta: 0:31:14  lr: 0.000124  loss: 1.7160 (1.8286)  time: 12.2128  data: 0.0010  max mem: 9536\n",
      "Epoch: [36] Train  [ 40/183]  eta: 0:29:08  lr: 0.000122  loss: 2.0063 (1.8265)  time: 12.1705  data: 0.0010  max mem: 9536\n",
      "Epoch: [36] Train  [ 50/183]  eta: 0:27:10  lr: 0.000121  loss: 1.8544 (1.8217)  time: 12.2694  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Train  [ 60/183]  eta: 0:25:11  lr: 0.000119  loss: 1.9121 (1.8193)  time: 12.4028  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Train  [ 70/183]  eta: 0:23:07  lr: 0.000117  loss: 1.7396 (1.8164)  time: 12.3189  data: 0.0002  max mem: 9536\n",
      "Epoch: [36] Train  [ 80/183]  eta: 0:21:02  lr: 0.000116  loss: 1.6439 (1.8052)  time: 12.1650  data: 0.0002  max mem: 9536\n",
      "Epoch: [36] Train  [ 90/183]  eta: 0:18:59  lr: 0.000114  loss: 1.6115 (1.7946)  time: 12.1898  data: 0.0002  max mem: 9536\n",
      "Epoch: [36] Train  [100/183]  eta: 0:16:56  lr: 0.000113  loss: 1.8242 (1.7951)  time: 12.1837  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Train  [110/183]  eta: 0:14:54  lr: 0.000111  loss: 1.8217 (1.7945)  time: 12.2364  data: 0.0005  max mem: 9536\n",
      "Epoch: [36] Train  [120/183]  eta: 0:12:52  lr: 0.000109  loss: 1.7433 (1.7938)  time: 12.3474  data: 0.0005  max mem: 9536\n",
      "Epoch: [36] Train  [130/183]  eta: 0:10:49  lr: 0.000108  loss: 1.6211 (1.7998)  time: 12.2137  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Train  [140/183]  eta: 0:08:46  lr: 0.000106  loss: 1.9342 (1.8013)  time: 12.1286  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Train  [150/183]  eta: 0:06:43  lr: 0.000105  loss: 1.6311 (1.7978)  time: 12.1288  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Train  [160/183]  eta: 0:04:41  lr: 0.000103  loss: 1.8329 (1.7937)  time: 12.1025  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Train  [170/183]  eta: 0:02:38  lr: 0.000101  loss: 1.7268 (1.7922)  time: 12.1841  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Train  [180/183]  eta: 0:00:36  lr: 0.000100  loss: 1.6811 (1.7925)  time: 12.2484  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Train Total time: 0:37:17\n",
      "Epoch: [36] Test  [  0/242]  eta: 0:06:01    time: 1.4942  data: 0.4292  max mem: 9536\n",
      "Epoch: [36] Test  [ 10/242]  eta: 0:03:52    time: 1.0008  data: 0.0392  max mem: 9536\n",
      "Epoch: [36] Test  [ 20/242]  eta: 0:03:34    time: 0.9404  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [ 30/242]  eta: 0:03:30    time: 0.9918  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [ 40/242]  eta: 0:03:23    time: 1.0544  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [ 50/242]  eta: 0:03:14    time: 1.0476  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [ 60/242]  eta: 0:03:07    time: 1.0793  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [ 70/242]  eta: 0:02:58    time: 1.0895  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [ 80/242]  eta: 0:02:47    time: 1.0315  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [ 90/242]  eta: 0:02:35    time: 0.9796  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [100/242]  eta: 0:02:26    time: 1.0148  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [110/242]  eta: 0:02:15    time: 1.0348  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [120/242]  eta: 0:02:05    time: 1.0465  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [130/242]  eta: 0:01:55    time: 1.0333  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [140/242]  eta: 0:01:44    time: 0.9830  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [150/242]  eta: 0:01:34    time: 0.9932  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [160/242]  eta: 0:01:23    time: 1.0085  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [170/242]  eta: 0:01:13    time: 1.0563  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [180/242]  eta: 0:01:04    time: 1.1141  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [190/242]  eta: 0:00:53    time: 1.1167  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [200/242]  eta: 0:00:43    time: 1.0605  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [210/242]  eta: 0:00:33    time: 1.0328  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [220/242]  eta: 0:00:22    time: 1.0423  data: 0.0004  max mem: 9536\n",
      "Epoch: [36] Test  [230/242]  eta: 0:00:12    time: 1.0488  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test  [240/242]  eta: 0:00:02    time: 1.0128  data: 0.0003  max mem: 9536\n",
      "Epoch: [36] Test Total time: 0:04:09\n",
      "global correct: 95.6\n",
      "average row correct: ['97.9', '96.0', '83.5', '94.2', '89.6', '86.1', '98.6', '91.8', '96.3', '62.6', '90.8', '69.9', '89.2', '96.1', '93.9', '93.9', '71.0', '95.8', '59.4', '96.3', '88.2']\n",
      "IoU: ['95.5', '93.0', '65.8', '88.6', '78.7', '76.5', '95.5', '89.3', '85.5', '40.4', '87.3', '64.1', '79.3', '88.3', '87.8', '90.1', '63.4', '91.9', '51.2', '87.4', '77.8']\n",
      "mean IoU: 79.9\n",
      "Epoch: [37] Train  [  0/183]  eta: 0:38:25  lr: 0.000099  loss: 1.6558 (1.6558)  time: 12.5974  data: 0.4297  max mem: 9536\n",
      "Epoch: [37] Train  [ 10/183]  eta: 0:35:05  lr: 0.000098  loss: 1.5828 (1.7487)  time: 12.1685  data: 0.0395  max mem: 9536\n",
      "Epoch: [37] Train  [ 20/183]  eta: 0:33:02  lr: 0.000096  loss: 1.7484 (1.7454)  time: 12.1395  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Train  [ 30/183]  eta: 0:31:05  lr: 0.000094  loss: 1.6974 (1.7418)  time: 12.2025  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Train  [ 40/183]  eta: 0:29:08  lr: 0.000093  loss: 1.8885 (1.7317)  time: 12.2978  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Train  [ 50/183]  eta: 0:27:06  lr: 0.000091  loss: 1.7795 (1.7381)  time: 12.2891  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Train  [ 60/183]  eta: 0:25:00  lr: 0.000089  loss: 1.7451 (1.7307)  time: 12.1420  data: 0.0005  max mem: 9536\n",
      "Epoch: [37] Train  [ 70/183]  eta: 0:23:00  lr: 0.000088  loss: 2.1254 (1.7371)  time: 12.1719  data: 0.0006  max mem: 9536\n",
      "Epoch: [37] Train  [ 80/183]  eta: 0:20:59  lr: 0.000086  loss: 1.5555 (1.7391)  time: 12.3158  data: 0.0006  max mem: 9536\n",
      "Epoch: [37] Train  [ 90/183]  eta: 0:18:59  lr: 0.000084  loss: 1.5811 (1.7488)  time: 12.4069  data: 0.0005  max mem: 9536\n",
      "Epoch: [37] Train  [100/183]  eta: 0:16:56  lr: 0.000083  loss: 2.0851 (1.7528)  time: 12.2927  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Train  [110/183]  eta: 0:14:53  lr: 0.000081  loss: 1.9442 (1.7634)  time: 12.1504  data: 0.0005  max mem: 9536\n",
      "Epoch: [37] Train  [120/183]  eta: 0:12:50  lr: 0.000079  loss: 1.8313 (1.7645)  time: 12.1690  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Train  [130/183]  eta: 0:10:47  lr: 0.000078  loss: 1.9640 (1.7707)  time: 12.1359  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Train  [140/183]  eta: 0:08:45  lr: 0.000076  loss: 1.6483 (1.7701)  time: 12.1346  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Train  [150/183]  eta: 0:06:43  lr: 0.000074  loss: 1.5377 (1.7671)  time: 12.1578  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Train  [160/183]  eta: 0:04:40  lr: 0.000073  loss: 1.6101 (1.7682)  time: 12.2279  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Train  [170/183]  eta: 0:02:38  lr: 0.000071  loss: 1.7425 (1.7678)  time: 12.2138  data: 0.0005  max mem: 9536\n",
      "Epoch: [37] Train  [180/183]  eta: 0:00:36  lr: 0.000069  loss: 1.8912 (1.7679)  time: 12.1406  data: 0.0005  max mem: 9536\n",
      "Epoch: [37] Train Total time: 0:37:14\n",
      "Epoch: [37] Test  [  0/242]  eta: 0:06:02    time: 1.4970  data: 0.4292  max mem: 9536\n",
      "Epoch: [37] Test  [ 10/242]  eta: 0:03:52    time: 1.0033  data: 0.0393  max mem: 9536\n",
      "Epoch: [37] Test  [ 20/242]  eta: 0:03:35    time: 0.9430  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [ 30/242]  eta: 0:03:31    time: 0.9922  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [ 40/242]  eta: 0:03:24    time: 1.0530  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [ 50/242]  eta: 0:03:15    time: 1.0489  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [ 60/242]  eta: 0:03:08    time: 1.0814  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [ 70/242]  eta: 0:02:58    time: 1.0907  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [ 80/242]  eta: 0:02:47    time: 1.0321  data: 0.0002  max mem: 9536\n",
      "Epoch: [37] Test  [ 90/242]  eta: 0:02:35    time: 0.9792  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Test  [100/242]  eta: 0:02:26    time: 1.0127  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Test  [110/242]  eta: 0:02:15    time: 1.0347  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [120/242]  eta: 0:02:05    time: 1.0481  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [130/242]  eta: 0:01:55    time: 1.0323  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [140/242]  eta: 0:01:44    time: 0.9815  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [150/242]  eta: 0:01:34    time: 0.9914  data: 0.0005  max mem: 9536\n",
      "Epoch: [37] Test  [160/242]  eta: 0:01:23    time: 1.0073  data: 0.0005  max mem: 9536\n",
      "Epoch: [37] Test  [170/242]  eta: 0:01:13    time: 1.0564  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [180/242]  eta: 0:01:04    time: 1.1137  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [190/242]  eta: 0:00:53    time: 1.1156  data: 0.0003  max mem: 9536\n",
      "Epoch: [37] Test  [200/242]  eta: 0:00:43    time: 1.0615  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Test  [210/242]  eta: 0:00:33    time: 1.0354  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Test  [220/242]  eta: 0:00:22    time: 1.0432  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Test  [230/242]  eta: 0:00:12    time: 1.0480  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Test  [240/242]  eta: 0:00:02    time: 1.0098  data: 0.0004  max mem: 9536\n",
      "Epoch: [37] Test Total time: 0:04:09\n",
      "global correct: 95.6\n",
      "average row correct: ['98.1', '96.3', '86.8', '94.6', '88.2', '89.6', '96.8', '93.3', '96.8', '58.2', '89.2', '65.8', '87.6', '95.4', '91.3', '94.2', '65.1', '96.2', '57.7', '95.9', '86.8']\n",
      "IoU: ['95.5', '93.2', '63.4', '89.2', '77.7', '77.1', '93.7', '89.8', '85.4', '39.8', '85.9', '62.2', '78.3', '89.0', '86.2', '90.4', '59.5', '91.2', '51.1', '90.1', '80.6']\n",
      "mean IoU: 79.5\n",
      "Epoch: [38] Train  [  0/183]  eta: 0:39:17  lr: 0.000069  loss: 1.5785 (1.5785)  time: 12.8813  data: 0.4543  max mem: 9536\n",
      "Epoch: [38] Train  [ 10/183]  eta: 0:35:06  lr: 0.000067  loss: 1.5919 (1.7335)  time: 12.1735  data: 0.0417  max mem: 9536\n",
      "Epoch: [38] Train  [ 20/183]  eta: 0:33:04  lr: 0.000065  loss: 1.6403 (1.7457)  time: 12.1383  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Train  [ 30/183]  eta: 0:31:04  lr: 0.000064  loss: 1.9774 (1.7634)  time: 12.1950  data: 0.0005  max mem: 9536\n",
      "Epoch: [38] Train  [ 40/183]  eta: 0:29:04  lr: 0.000062  loss: 1.7400 (1.7461)  time: 12.2208  data: 0.0005  max mem: 9536\n",
      "Epoch: [38] Train  [ 50/183]  eta: 0:27:00  lr: 0.000060  loss: 1.6443 (1.7459)  time: 12.1769  data: 0.0005  max mem: 9536\n",
      "Epoch: [38] Train  [ 60/183]  eta: 0:24:56  lr: 0.000059  loss: 1.5726 (1.7441)  time: 12.1069  data: 0.0005  max mem: 9536\n",
      "Epoch: [38] Train  [ 70/183]  eta: 0:22:57  lr: 0.000057  loss: 1.5935 (1.7418)  time: 12.2067  data: 0.0007  max mem: 9536\n",
      "Epoch: [38] Train  [ 80/183]  eta: 0:20:54  lr: 0.000055  loss: 1.9072 (1.7390)  time: 12.2284  data: 0.0006  max mem: 9536\n",
      "Epoch: [38] Train  [ 90/183]  eta: 0:18:53  lr: 0.000053  loss: 1.6000 (1.7366)  time: 12.1647  data: 0.0005  max mem: 9536\n",
      "Epoch: [38] Train  [100/183]  eta: 0:16:51  lr: 0.000052  loss: 1.7555 (1.7347)  time: 12.2088  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Train  [110/183]  eta: 0:14:50  lr: 0.000050  loss: 2.0682 (1.7413)  time: 12.2372  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Train  [120/183]  eta: 0:12:49  lr: 0.000048  loss: 1.4574 (1.7360)  time: 12.3144  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Train  [130/183]  eta: 0:10:47  lr: 0.000046  loss: 1.8128 (1.7377)  time: 12.3723  data: 0.0005  max mem: 9536\n",
      "Epoch: [38] Train  [140/183]  eta: 0:08:46  lr: 0.000045  loss: 1.6653 (1.7337)  time: 12.4078  data: 0.0005  max mem: 9536\n",
      "Epoch: [38] Train  [150/183]  eta: 0:06:43  lr: 0.000043  loss: 1.6668 (1.7294)  time: 12.3346  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Train  [160/183]  eta: 0:04:41  lr: 0.000041  loss: 1.8273 (1.7329)  time: 12.2587  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Train  [170/183]  eta: 0:02:39  lr: 0.000039  loss: 1.9857 (1.7338)  time: 12.2386  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Train  [180/183]  eta: 0:00:36  lr: 0.000037  loss: 1.6939 (1.7311)  time: 12.3397  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Train Total time: 0:37:22\n",
      "Epoch: [38] Test  [  0/242]  eta: 0:05:58    time: 1.4809  data: 0.4108  max mem: 9536\n",
      "Epoch: [38] Test  [ 10/242]  eta: 0:03:52    time: 1.0017  data: 0.0376  max mem: 9536\n",
      "Epoch: [38] Test  [ 20/242]  eta: 0:03:34    time: 0.9426  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Test  [ 30/242]  eta: 0:03:30    time: 0.9916  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Test  [ 40/242]  eta: 0:03:23    time: 1.0525  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [ 50/242]  eta: 0:03:15    time: 1.0475  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [ 60/242]  eta: 0:03:07    time: 1.0800  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [ 70/242]  eta: 0:02:58    time: 1.0921  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [ 80/242]  eta: 0:02:47    time: 1.0334  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [ 90/242]  eta: 0:02:35    time: 0.9806  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Test  [100/242]  eta: 0:02:26    time: 1.0170  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Test  [110/242]  eta: 0:02:15    time: 1.0355  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [120/242]  eta: 0:02:05    time: 1.0472  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [130/242]  eta: 0:01:55    time: 1.0347  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [140/242]  eta: 0:01:44    time: 0.9835  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [150/242]  eta: 0:01:34    time: 0.9900  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [160/242]  eta: 0:01:23    time: 1.0043  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [170/242]  eta: 0:01:13    time: 1.0553  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [180/242]  eta: 0:01:04    time: 1.1159  data: 0.0005  max mem: 9536\n",
      "Epoch: [38] Test  [190/242]  eta: 0:00:53    time: 1.1179  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Test  [200/242]  eta: 0:00:43    time: 1.0609  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [210/242]  eta: 0:00:33    time: 1.0354  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test  [220/242]  eta: 0:00:22    time: 1.0431  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Test  [230/242]  eta: 0:00:12    time: 1.0473  data: 0.0004  max mem: 9536\n",
      "Epoch: [38] Test  [240/242]  eta: 0:00:02    time: 1.0123  data: 0.0003  max mem: 9536\n",
      "Epoch: [38] Test Total time: 0:04:09\n",
      "global correct: 95.6\n",
      "average row correct: ['98.4', '94.5', '83.5', '93.5', '86.2', '87.2', '96.8', '92.4', '96.8', '63.1', '90.6', '60.8', '86.0', '94.3', '93.8', '94.0', '70.1', '95.8', '51.5', '95.1', '89.6']\n",
      "IoU: ['95.4', '93.1', '65.3', '88.2', '78.7', '78.1', '93.9', '89.5', '84.4', '42.7', '87.0', '58.1', '78.6', '88.9', '88.2', '90.4', '62.7', '91.8', '48.3', '89.5', '79.4']\n",
      "mean IoU: 79.6\n",
      "Epoch: [39] Train  [  0/183]  eta: 0:38:54  lr: 0.000037  loss: 1.7451 (1.7451)  time: 12.7559  data: 0.3976  max mem: 9536\n",
      "Epoch: [39] Train  [ 10/183]  eta: 0:36:15  lr: 0.000035  loss: 1.6151 (1.7960)  time: 12.5736  data: 0.0364  max mem: 9536\n",
      "Epoch: [39] Train  [ 20/183]  eta: 0:33:50  lr: 0.000033  loss: 1.4746 (1.7940)  time: 12.4423  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Train  [ 30/183]  eta: 0:31:35  lr: 0.000031  loss: 1.7189 (1.7680)  time: 12.2885  data: 0.0004  max mem: 9536\n",
      "Epoch: [39] Train  [ 40/183]  eta: 0:29:26  lr: 0.000029  loss: 1.7763 (1.7432)  time: 12.2497  data: 0.0004  max mem: 9536\n",
      "Epoch: [39] Train  [ 50/183]  eta: 0:27:16  lr: 0.000028  loss: 1.7657 (1.7480)  time: 12.1773  data: 0.0004  max mem: 9536\n",
      "Epoch: [39] Train  [ 60/183]  eta: 0:25:11  lr: 0.000026  loss: 1.7187 (1.7434)  time: 12.1545  data: 0.0004  max mem: 9536\n",
      "Epoch: [39] Train  [ 70/183]  eta: 0:23:07  lr: 0.000024  loss: 1.8662 (1.7374)  time: 12.2157  data: 0.0002  max mem: 9536\n",
      "Epoch: [39] Train  [ 80/183]  eta: 0:21:04  lr: 0.000022  loss: 1.5675 (1.7336)  time: 12.2270  data: 0.0002  max mem: 9536\n",
      "Epoch: [39] Train  [ 90/183]  eta: 0:18:58  lr: 0.000020  loss: 1.7694 (1.7255)  time: 12.1134  data: 0.0002  max mem: 9536\n",
      "Epoch: [39] Train  [100/183]  eta: 0:16:56  lr: 0.000018  loss: 1.6768 (1.7147)  time: 12.1516  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Train  [110/183]  eta: 0:14:51  lr: 0.000016  loss: 1.7483 (1.7159)  time: 12.0838  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Train  [120/183]  eta: 0:12:49  lr: 0.000014  loss: 1.7095 (1.7236)  time: 12.0224  data: 0.0002  max mem: 9536\n",
      "Epoch: [39] Train  [130/183]  eta: 0:10:47  lr: 0.000012  loss: 1.9576 (1.7206)  time: 12.1792  data: 0.0002  max mem: 9536\n",
      "Epoch: [39] Train  [140/183]  eta: 0:08:45  lr: 0.000010  loss: 1.7358 (1.7193)  time: 12.2929  data: 0.0002  max mem: 9536\n",
      "Epoch: [39] Train  [150/183]  eta: 0:06:43  lr: 0.000008  loss: 1.6828 (1.7212)  time: 12.2531  data: 0.0002  max mem: 9536\n",
      "Epoch: [39] Train  [160/183]  eta: 0:04:40  lr: 0.000005  loss: 1.6536 (1.7207)  time: 12.0773  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Train  [170/183]  eta: 0:02:38  lr: 0.000003  loss: 1.5529 (1.7219)  time: 12.1710  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Train  [180/183]  eta: 0:00:36  lr: 0.000001  loss: 1.6173 (1.7209)  time: 12.2976  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Train Total time: 0:37:15\n",
      "Epoch: [39] Test  [  0/242]  eta: 0:06:00    time: 1.4899  data: 0.4260  max mem: 9536\n",
      "Epoch: [39] Test  [ 10/242]  eta: 0:03:52    time: 1.0024  data: 0.0390  max mem: 9536\n",
      "Epoch: [39] Test  [ 20/242]  eta: 0:03:34    time: 0.9421  data: 0.0004  max mem: 9536\n",
      "Epoch: [39] Test  [ 30/242]  eta: 0:03:31    time: 0.9922  data: 0.0004  max mem: 9536\n",
      "Epoch: [39] Test  [ 40/242]  eta: 0:03:23    time: 1.0535  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [ 50/242]  eta: 0:03:15    time: 1.0474  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [ 60/242]  eta: 0:03:08    time: 1.0806  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [ 70/242]  eta: 0:02:58    time: 1.0910  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [ 80/242]  eta: 0:02:47    time: 1.0327  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [ 90/242]  eta: 0:02:35    time: 0.9800  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [100/242]  eta: 0:02:26    time: 1.0160  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [110/242]  eta: 0:02:15    time: 1.0363  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [120/242]  eta: 0:02:05    time: 1.0464  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [130/242]  eta: 0:01:55    time: 1.0331  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [140/242]  eta: 0:01:44    time: 0.9831  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [150/242]  eta: 0:01:34    time: 0.9910  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [160/242]  eta: 0:01:23    time: 1.0058  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [170/242]  eta: 0:01:13    time: 1.0554  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [180/242]  eta: 0:01:04    time: 1.1142  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [190/242]  eta: 0:00:53    time: 1.1164  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [200/242]  eta: 0:00:43    time: 1.0617  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [210/242]  eta: 0:00:33    time: 1.0342  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [220/242]  eta: 0:00:22    time: 1.0412  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [230/242]  eta: 0:00:12    time: 1.0470  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test  [240/242]  eta: 0:00:02    time: 1.0094  data: 0.0003  max mem: 9536\n",
      "Epoch: [39] Test Total time: 0:04:09\n",
      "global correct: 95.5\n",
      "average row correct: ['97.9', '95.0', '86.9', '94.8', '89.4', '87.3', '91.4', '92.6', '96.6', '64.3', '89.5', '69.1', '87.7', '96.8', '92.9', '93.9', '73.7', '96.8', '58.0', '96.7', '91.0']\n",
      "IoU: ['95.5', '93.2', '61.5', '89.0', '77.3', '77.8', '89.4', '89.2', '85.0', '41.8', '86.5', '63.6', '77.6', '88.0', '87.4', '90.4', '64.7', '90.5', '50.9', '86.2', '73.7']\n",
      "mean IoU: 79.0\n",
      "Training time 1 day, 3:51:21\n"
     ]
    }
   ],
   "source": [
    "# simsiam 4\n",
    "!experiment_name=\"temp\";cd ../ ;\\\n",
    "    name_date=\"${experiment_name}/$(date +%Y-%m%d-%H%M%S)\";\\\n",
    "    dir=\"./results/${name_date}\";mkdir -p ${dir};dir_log=\"${dir}/output.log\";\\\n",
    "CUDA_VISIBLE_DEVICES=3 torchrun --nproc_per_node=1 --master_port=1237 train_multi_GPU.py \\\n",
    "    --wandb False --wandb_model dryrun --sync_bn False --amp True --aux False \\\n",
    "    --model_name aspp_contrast_resnet101 --pre_trained deeplabv3_resnet101_coco.pth \\\n",
    "    --weight_only_backbone False --lr 0.001\\\n",
    "    --data_path pascal-voc-2012 --num_classes 21 --data_train_type train.txt \\\n",
    "    --epochs 40 --batch_size 8 --batch_size_val 6 --memory_size 32768 \\\n",
    "    --contrast 0 --L1_loss 0.1 --L2_loss 0.1 --L3_loss 0.1\\\n",
    "    --loss_name aspp_loss --sample adapt_excite_4 \\\n",
    "    --name_date $name_date \\\n",
    "    2>&1 | tee $dir_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
